---
title: Использование параллелизации запросов и масштабирования в Azure Stream Analytics
description: В этой статье объясняется, как масштабировать задания Stream Analytics с помощью настройки входных разделов, настройки определения запроса и определения единиц потоковой передачи.
services: stream-analytics
author: JSeb225
ms.author: jeanb
manager: kfile
ms.reviewer: jasonh
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 05/07/2018
ms.openlocfilehash: 985746989af39aa55d5d8af735edf62f4c4b77b7
ms.sourcegitcommit: a10074461cf112a00fec7e14ba700435173cd3ef
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/12/2019
ms.locfileid: "73932288"
---
# <a name="leverage-query-parallelization-in-azure-stream-analytics"></a>Использование параллелизации запросов в Azure Stream Analytics
В этой статье показано, как воспользоваться преимуществами параллелизма в Azure Stream Analytics. Узнайте, как масштабировать задания Stream Analytics с помощью настройки входных разделов, настройки аналитики определения запроса.
Предварительно может потребоваться ознакомиться с концепцией потоковой единицы, которая описана в статье [Оптимизация задания для эффективного использования единиц потоковой передачи](stream-analytics-streaming-unit-consumption.md).

## <a name="what-are-the-parts-of-a-stream-analytics-job"></a>Из каких частей состоит задание службы Stream Analytics?
Определение задания Stream Analytics включает запрос, а также входные и выходные данные. Входные данные — это точки, откуда задания считывают данные из потока. Запрос используется для преобразования потока входных данных, а выходные данные являются точками, куда направляются результаты задания.

Задание требует по крайней мере один источник входных данных для потока данных. Входной источник потока данных может храниться в концентраторе событий Azure или в хранилище BLOB-объектов Azure. Дополнительные сведения см. в статьях [Что такое Stream Analytics?](stream-analytics-introduction.md) и [Приступая к работе с Azure Stream Analytics: выявление мошенничества в режиме реального времени](stream-analytics-real-time-fraud-detection.md).

## <a name="partitions-in-sources-and-sinks"></a>Секции в источниках и приемниках
Масштабирование задания Stream Analytics реализует преимущества использования секций во входных или выходных данных. Секционирование позволяет разделить данные на подмножества на основе ключа секции. Процесс, который использует данные (например, задание Streaming Analytics), может получать и записывать различные секции параллельно, тем самым повышая пропускную способность. 

### <a name="inputs"></a>Входные данные
Все входные данные в Azure Stream Analytics могут использовать преимущества секционирования:
-   Концентратор событий (требуется явно задать ключ раздела с помощью ключевого слова PARTITION BY).
-   Концентратор событий (требуется явно задать ключ раздела с помощью ключевого слова PARTITION BY).
-   Хранилище BLOB-объектов

### <a name="outputs"></a>Выходные данные

При работе со Stream Analytics можно воспользоваться преимуществами секционирования в концентраторах событий и выходных данных:
-   Azure Data Lake Storage
-   Функции Azure
-   таблицу Azure;
-   Хранилище BLOB-объектов (требуется явно задать ключ раздела).
-   Cosmos DB (требуется явно задать ключ раздела).
-   Центры событий (требуется явно задать ключ раздела).
-   Центр Интернета вещей (требуется явно задать ключ раздела).
-   Служебная шина
- SQL и хранилище данных SQL с необязательным секционированием. Дополнительные сведения см. на странице [Вывод в базу данных SQL Azure](https://docs.microsoft.com/azure/stream-analytics/stream-analytics-sql-output-perf).

Power BI не поддерживает секционирование. Однако можно по-прежнему секционировать входные данные как описано в [этом разделе](#multi-step-query-with-different-partition-by-values). 

Дополнительные сведения об этих секциях см. в следующих статьях:

* [Обзор функций Центров событий](../event-hubs/event-hubs-features.md#partitions)
* [Секционирование данных](https://docs.microsoft.com/azure/architecture/best-practices/data-partitioning)


## <a name="embarrassingly-parallel-jobs"></a>Задания с усложненным параллелизмом
Задание с *усложненным параллелизмом* — это самый масштабируемый сценарий в Azure Stream Analytics. Он соединяет один раздел входных данных с одним экземпляром запроса и одним разделом выходных данных. Такой параллелизм имеет следующие требования:

1. Если в логике запроса применяется ключ, который обрабатывается тем же экземпляром запроса, необходимо только проследить за тем, чтобы события попадали в ту же секцию входных данных. При использовании Центров событий или Центра Интернета вещей это означает, что для данных событий должно быть задано значение **PartitionKey**. Кроме того, можно использовать секционированные отправители. Для хранилища BLOB-объектов это означает, что события отправляются в папку той же секции. Если логика запроса не требует обработки ключа тем же экземпляром запроса, это требование можно проигнорировать. В качестве примера такой логики можно привести простой запрос select, project или filter.  

2. После того как данные будут распределены в источнике данных, необходимо убедиться в том, что запрос разбит на секции. Для этого на каждом этапе используется параметр **PARTITION BY**. Этапов может быть несколько, но на каждом из них должен использоваться один и тот же ключ. При уровне совместимости 1,0 и 1,1 ключ секционирования должен быть установлен в значение **PartitionId** , чтобы задание было полностью параллельным. Для заданий с компатилити уровня 1,2 и выше пользовательский столбец можно указать в качестве ключа секции во входных параметрах, и задание будет паралеллизед автоматически даже без предложения PARTITION BY. Для вывода концентратора событий свойству "ключевой столбец секции" необходимо присвоить значение "PartitionId".

3. Большая часть выходных данных может воспользоваться преимуществами секционирования, однако при использовании типа выходных данных, не поддерживающих секционирование, задание не будет полностью параллельным. Дополнительные сведения см. в [этом разделе](#outputs).

4. Число секций входных данных должно совпадать с числом секций выходных данных. Выходные данные хранилища BLOB-объектов могут поддерживать секции и наследуют схему секционирования вышестоящего запроса. Если для хранилища BLOB-объектов указан ключ секции, то данные секционируются по входным секциям, поэтому результат по-прежнему вычисляется параллельно. Примеры значений секций, позволяющие выполнять задания с полной параллельной обработкой:

   * 8 секций входных данных концентраторов событий и 8 секций выходных данных концентраторов событий;
   * 8 секций входных данных концентраторов событий и выходные данные хранилища BLOB-объектов;
   * 8 входных секций концентраторов событий и выходные данные хранилища BLOB-объектов, секционированные по пользовательскому полю с произвольной кратностью;
   * 8 секций входных данных хранилища BLOB-объектов и выходные данные хранилища BLOB-объектов;
   * 8 секций входных данных хранилища BLOB-объектов и 8 секций выходных данных концентраторов событий.

Далее рассмотрим примеры сценариев с усложненным параллелизмом.

### <a name="simple-query"></a>Простой запрос

* Входные данные — концентратор событий с 8 секциями.
* Выходные данные: концентратор событий с 8 секциями ("ключевой столбец секции" должен быть установлен для использования "PartitionId")

Запрос:

```SQL
    SELECT TollBoothId
    FROM Input1 Partition By PartitionId
    WHERE TollBoothId > 100
```

Этот запрос является простым фильтром. Поэтому нам не нужно беспокоиться о секционировании входных данных, которые передаются в концентратор событий. Обратите внимание, что задания с уровнем совместимости, предшествующим 1,2, должны включать предложение **Partition by PartitionId** , поэтому оно соответствует требованиям #2 более ранней версии. Выходные данные концентраторов событий необходимо настроить, указав значение **PartitionId** в качестве ключа секции. Последняя проверка: число секций входных данных должно быть равно числу секций выходных данных.

### <a name="query-with-a-grouping-key"></a>Запрос с ключом группирования

* Входные данные — концентратор событий с 8 секциями.
* Выходные данные — хранилище BLOB-объектов.

Запрос:

```SQL
    SELECT COUNT(*) AS Count, TollBoothId
    FROM Input1 Partition By PartitionId
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
```

Этот запрос содержит ключ группирования. Поэтому события, сгруппированные вместе, должны быть отправлены в одну секцию концентратора событий. Так как в этом примере выполняется группирование по TollBoothID, необходимо убедиться, что TollBoothID используется в качестве ключа секции при отправке событий в концентратор событий. Затем в ASA, можно использовать **PARTITION BY PartitionId** для наследования этой схемы разделов и обеспечения полной паралеллизации. Так как выходными данными является хранилище BLOB-объектов, не нужно беспокоиться о настройке значения ключа секции, как описано в требовании 4.

## <a name="example-of-scenarios-that-are-not-embarrassingly-parallel"></a>Примеры сценариев *без* усложненного параллелизма

В предыдущем разделе мы рассмотрели сценарии с усложненным параллелизмом. В этом разделе обсуждаются сценарии, которые не соответствуют всем показателям усложненного параллелизма. 

### <a name="mismatched-partition-count"></a>Несоответствие в числе секций
* Входные данные — концентратор событий с 8 секциями.
* Выходные данные — концентратор событий с 32 секциями.

В этом случае тип запроса не имеет значения. Если число секций входных данных не совпадает с числом секций выходных данных, топология не является топологией с усложненным параллелизмом. Однако все равно можно получить некоторый уровень или паралеллизацию.

### <a name="query-using-non-partitioned-output"></a>Запрос с использованием несекционированных выходных данных
* Входные данные — концентратор событий с 8 секциями.
* Выходные данные: Power BI

В настоящее время выходные данные Power BI не поддерживают секционирование. Таким образом этот сценарий не считается сценарием с усложненным параллелизмом.

### <a name="multi-step-query-with-different-partition-by-values"></a>Многоэтапный запрос с разными значениями параметра PARTITION BY
* Входные данные — концентратор событий с 8 секциями.
* Выходные данные — концентратор событий с 8 секциями.

Запрос:

```SQL
    WITH Step1 AS (
    SELECT COUNT(*) AS Count, TollBoothId, PartitionId
    FROM Input1 Partition By PartitionId
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
    )

    SELECT SUM(Count) AS Count, TollBoothId
    FROM Step1 Partition By TollBoothId
    GROUP BY TumblingWindow(minute, 3), TollBoothId
```

Как видите, на втором этапе в качестве ключа секционирования используется **TollBoothId** . Он не совпадает с ключом в первом шаге, а значит, потребует перетасовки. 

Мы рассмотрели несколько примеров заданий Stream Analytics, соответствующих и не соответствующих критериям топологии с усложненным параллелизмом. При соответствии, задания будут иметь максимально возможное для них масштабирование. Для заданий, не соответствующих ни одному из этих профилей, в дальнейшем будут выпущены обновления в отношении масштабирования. А пока придерживайтесь описанных ниже рекомендаций.

### <a name="compatibility-level-12---multi-step-query-with-different-partition-by-values"></a>Уровень совместимости 1,2 — многоэтапный запрос с разной СЕКЦИей по значениям 
* Входные данные — концентратор событий с 8 секциями.
* Выходные данные: концентратор событий с 8 секциями ("ключевой столбец секции" должен быть установлен для использования "TollBoothId")

Запрос:

```SQL
    WITH Step1 AS (
    SELECT COUNT(*) AS Count, TollBoothId
    FROM Input1
    GROUP BY TumblingWindow(minute, 3), TollBoothId
    )

    SELECT SUM(Count) AS Count, TollBoothId
    FROM Step1
    GROUP BY TumblingWindow(minute, 3), TollBoothId
```

Уровень совместимости 1,2 разрешает выполнение параллельных запросов по умолчанию. Например, запрос из предыдущего раздела будет парттионед при условии, что столбец "TollBoothId" установлен в качестве входного ключа секции. Предложение PARTITION BY Парттионид не требуется.

## <a name="calculate-the-maximum-streaming-units-of-a-job"></a>Расчет максимального количества единиц потоковой передачи для задания
Общее число единиц потоковой передачи, которое можно использовать заданием Stream Analytics, зависит от числа шагов в запросе, определенных для задания, и количества разделов для каждого шага.

### <a name="steps-in-a-query"></a>Шаги в запросе
Запрос может иметь один или несколько шагов. Каждый шаг — это вложенный запрос, определенный с помощью ключевого слова **WITH**. Запрос за рамками ключевого слова **WITH** (только один запрос) также учитывается в качестве шага (например, инструкция **SELECT** в следующем запросе).

Запрос:

```SQL
    WITH Step1 AS (
        SELECT COUNT(*) AS Count, TollBoothId
        FROM Input1 Partition By PartitionId
        GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
    )
    SELECT SUM(Count) AS Count, TollBoothId
    FROM Step1
    GROUP BY TumblingWindow(minute,3), TollBoothId
```

Этот запрос включает 2 шага.

> [!NOTE]
> Этот запрос будет описан далее в этой статье.
>  

### <a name="partition-a-step"></a>Разделы шага
Разделение шага требует наличия следующих условий.

* Источник входных данных должен быть секционирован. 
* Инструкция **SELECT** запроса должна читаться из разделенного источника входных данных.
* Запрос внутри шага должен включать ключевое слово **PARTITION BY**.

Если запрос разделен, входные данные событий будут обработаны и объединены в отдельные группы секции, а выходные данные событий будут сгенерированы для каждой из групп. Если желательно иметь объединенный запрос, необходимо создать второй неразделенный шаг для объединения.

### <a name="calculate-the-max-streaming-units-for-a-job"></a>Рассчитайте максимальное количество единиц потоковой передачи для задания
Все несекционированные шаги можно масштабировать до шести единиц потоковой передачи для задания Stream Analytics. Помимо этого можно добавить 6 единиц потоковой передачи для каждой секции на шаге секционирования.
Дополнительные **примеры** можно просмотреть в таблице ниже.

| Запрос                                               | Максимальное количество единиц потоковой передачи для задания |
| --------------------------------------------------- | ------------------- |
| <ul><li>Запрос содержит один шаг.</li><li>Шаг не секционирован.</li></ul> | 6 |
| <ul><li>Поток входных данных секционирован по 16.</li><li>Запрос содержит один шаг.</li><li>Шаг является секционированным.</li></ul> | 96 (6 * 16 секций) |
| <ul><li>Запрос состоит из двух шагов.</li><li>Ни один из шагов не секционирован.</li></ul> | 6 |
| <ul><li>Поток входных данных секционирован по 3.</li><li>Запрос состоит из двух шагов. Входной шаг секционирован, а второй шаг — нет.</li><li>Инструкция <strong>SELECT</strong> считывает из секционированных входных данных.</li></ul> | 24 (18 и 6 секционированных и несекционированных шагов соответственно) |

### <a name="examples-of-scaling"></a>Примеры масштабирования

Следующий запрос вычисляет количество машин, проходящих через пропускной пункт с тремя пунктами для оплаты и пропускной способности три минуты для каждого пункта. Этот запрос можно масштабировать до шести единиц потоковой передачи.

```SQL
    SELECT COUNT(*) AS Count, TollBoothId
    FROM Input1
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
```

Чтобы использовать дополнительные единицы потоковой передачи для запроса, входной поток данных и запрос должны быть секционированы. При наличии секции потока данных, равной 3, следующий измененный запрос можно масштабировать до 18 единиц потоковой передачи.

```SQL
    SELECT COUNT(*) AS Count, TollBoothId
    FROM Input1 Partition By PartitionId
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
```

Если запрос секционирован, входные данные событий будут обработаны и объединены в отдельные группы секций. Кроме того, для каждой из групп будут сформированы выходные данные событий. Секционирование может вызвать некоторые непредвиденные результаты, если поле **GROUP BY** не является ключом секции во входном потоке данных. Например, поле **TollBoothId** в предыдущем запросе не является ключом секции **Input1**. В результате данные из пункта 1 можно распределить между несколькими секциями.

Каждая из секций **Input1** будет обрабатываться отдельно с помощью Stream Analytics. В результате будет создаваться несколько записей для автомобиля, проходящего через один и тот же пункт. Если нельзя изменить ключ секции ввода, эту проблему можно устранить, добавив несекционированные действия для вычисления значений по секциям, например:

```SQL
    WITH Step1 AS (
        SELECT COUNT(*) AS Count, TollBoothId
        FROM Input1 Partition By PartitionId
        GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
    )

    SELECT SUM(Count) AS Count, TollBoothId
    FROM Step1
    GROUP BY TumblingWindow(minute, 3), TollBoothId
```

Этот запрос можно увеличить до 24 единиц потоковой передачи.

> [!NOTE]
> При объединении двух потоков убедитесь, что потоки разделены с помощью ключа секции столбца, используемого для объединения. Также убедитесь, что количество секций в обоих потоках одинаковое.
> 
> 

## <a name="achieving-higher-throughputs-at-scale"></a>Достижение более высоких пропускной способности в масштабе

Задание с [усложненным параллелизмом](#embarrassingly-parallel-jobs) является обязательным, но недостаточно для обеспечения высокой пропускной способности в масштабе. Каждая система хранения и соответствующая Stream Analytics выходные данные имеют различные возможности для достижения наилучшей пропускной способности записи. Как и в любом сценарии с масштабным масштабированием, существуют некоторые проблемы, которые можно решить с помощью правильных конфигураций. В этом разделе обсуждаются конфигурации для нескольких распространенных выходов и приведены примеры для поддержания скорости приема событий 1000, 5 КБ и 10000 в секунду.

Следующие наблюдения используют Stream Analytics задание с запросом без отслеживания состояния, базовую определяемую пользователем функцию JavaScript, которая выполняет запись в концентратор событий, базу данных SQL Azure или Cosmos DB.

#### <a name="event-hub"></a>Концентратор событий

|Скорость приема (событий в секунду) | Единицы потоковой передачи | Выходные ресурсы  |
|--------|---------|---------|
| 1000     |    1    |  2 TU   |
| 5 КБ     |    6    |  6 TU   |
| 10 000    |    12   |  10 TU  |

Решение [концентратора событий](https://github.com/Azure-Samples/streaming-at-scale/tree/master/eventhubs-streamanalytics-eventhubs) масштабируется линейно в плане единиц потоковой передачи (SU) и пропускной способности, что делает ее наиболее эффективным и удобным способом для анализа и потоковой передачи данных из Stream Analytics. Задания можно масштабировать до 192 SU, что примерно означает обработку до 200 МБ/с или 19 000 000 000 000 событий в день.

#### <a name="azure-sql"></a>Azure SQL
|Скорость приема (событий в секунду) | Единицы потоковой передачи | Выходные ресурсы  |
|---------|------|-------|
|    1000   |   3  |  S3   |
|    5 КБ   |   18 |  P4   |
|    10 000  |   36 |  P6   |

[SQL Azure](https://github.com/Azure-Samples/streaming-at-scale/tree/master/eventhubs-streamanalytics-azuresql) поддерживает параллельную запись, называемую наследованием секционирования, но по умолчанию она отключена. Однако включение наследования секционирования вместе с полностью параллельным запросом может быть недостаточно для достижения более высоких пропускной способности. Пропускная способность записи SQL значительно зависит от конфигурации базы данных SQL Azure и схемы таблицы. В статье о [производительности выходных данных SQL](./stream-analytics-sql-output-perf.md) содержатся более подробные сведения о параметрах, позволяющих максимально увеличить пропускную способность записи. Как указано в статье [вывод Azure Stream Analytics в базу данных SQL Azure](./stream-analytics-sql-output-perf.md#azure-stream-analytics) , это решение не масштабируется линейно в виде полностью параллельного конвейера, превышающего 8 секций, и может потребоваться повторное секционирование перед выходом SQL [(см. раздел)](https://docs.microsoft.com/stream-analytics-query/into-azure-stream-analytics#into-shard-count). Номера SKU уровня "Премиум" необходимы для обеспечения высокой скорости ввода-вывода и издержек от резервных копий журналов, происходящих каждые несколько минут.

#### <a name="cosmos-db"></a>База данных Cosmos
|Скорость приема (событий в секунду) | Единицы потоковой передачи | Выходные ресурсы  |
|-------|-------|---------|
|  1000   |  3    | 20 000 RU  |
|  5 КБ   |  24   | 60K RU  |
|  10 000  |  48   | 120 ТЫС. RU |

[Cosmos DB](https://github.com/Azure-Samples/streaming-at-scale/tree/master/eventhubs-streamanalytics-cosmosdb) выходные данные из Stream Analytics были обновлены для использования собственной интеграции на [уровне совместимости 1,2](./stream-analytics-documentdb-output.md#improved-throughput-with-compatibility-level-12). Уровень совместимости 1,2 обеспечивает значительно более высокую пропускную способность и сокращает потребление единиц запросов по сравнению с 1,1, что является уровнем совместимости по умолчанию для новых заданий. Решение использует контейнеры CosmosDB, секционированные по/Девицеид, а остальная часть решения настроена одинаково.

Вся [потоковая передача в примерах масштабирования Azure](https://github.com/Azure-Samples/streaming-at-scale) использует поправку концентратора событий в качестве входных данных для моделирования тестовых клиентов. Каждое событие ввода — это 1 КБ документ JSON, который преобразует настроенные скорости приема в скорости пропускной способности (1 МБ/с, 5 МБ/с и 10 МБ/с). События имитируют устройство IoT, отправляющее следующие данные JSON (в сокращенной форме) для 1000 устройств:

```
{
    "eventId": "b81d241f-5187-40b0-ab2a-940faf9757c0",
    "complexData": {
        "moreData0": 51.3068118685458,
        "moreData22": 45.34076957651598
    },
    "value": 49.02278128887753,
    "deviceId": "contoso://device-id-1554",
    "type": "CO2",
    "createdAt": "2019-05-16T17:16:40.000003Z"
}
```

> [!NOTE]
> Конфигурация может быть изменена из-за различных компонентов, используемых в решении. Чтобы получить более точную оценку, настройте примеры в соответствии с вашим сценарием.

### <a name="identifying-bottlenecks"></a>Определение узких мест

Используйте панель метрики в задании Azure Stream Analytics для выявления узких мест в конвейере. Просмотрите **события ввода-вывода** для пропускной способности и ["задержка водяного знака"](https://azure.microsoft.com/blog/new-metric-in-azure-stream-analytics-tracks-latency-of-your-streaming-pipeline/) , а также **событий с невыполненной записью** , чтобы определить, имеет ли задание скорость ввода. Для метрик концентратора событий ищите **регулируемые запросы** и соответственно скорректируйте пороговые единицы. Для метрик Cosmos DB ознакомьтесь с **максимальным потреблением единиц запросов в секунду на диапазон ключей секций** в разделе пропускная способность, чтобы обеспечить единообразное использование диапазонов ключей разделов. Для базы данных SQL Azure Отслеживайте **операции ввода-вывода журнала** и **ЦП**.

## <a name="get-help"></a>Справка

За дополнительной помощью обращайтесь на наш [форум Azure Stream Analytics](https://social.msdn.microsoft.com/Forums/azure/home?forum=AzureStreamAnalytics).

## <a name="next-steps"></a>Дополнительная информация
* [Введение в Azure Stream Analytics](stream-analytics-introduction.md)
* [Приступая к работе с Azure Stream Analytics](stream-analytics-real-time-fraud-detection.md)
* [Справочник по языку запросов Azure Stream Analytics](https://docs.microsoft.com/stream-analytics-query/stream-analytics-query-language-reference)
* [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)

<!--Image references-->

[img.stream.analytics.monitor.job]: ./media/stream-analytics-scale-jobs/StreamAnalytics.job.monitor-NewPortal.png
[img.stream.analytics.configure.scale]: ./media/stream-analytics-scale-jobs/StreamAnalytics.configure.scale.png
[img.stream.analytics.perfgraph]: ./media/stream-analytics-scale-jobs/perf.png
[img.stream.analytics.streaming.units.scale]: ./media/stream-analytics-scale-jobs/StreamAnalyticsStreamingUnitsExample.jpg
[img.stream.analytics.preview.portal.settings.scale]: ./media/stream-analytics-scale-jobs/StreamAnalyticsPreviewPortalJobSettings-NewPortal.png   

<!--Link references-->

[microsoft.support]: https://support.microsoft.com
[azure.event.hubs.developer.guide]: https://msdn.microsoft.com/library/azure/dn789972.aspx

[stream.analytics.introduction]: stream-analytics-introduction.md
[stream.analytics.get.started]: stream-analytics-real-time-fraud-detection.md
[stream.analytics.query.language.reference]: https://go.microsoft.com/fwlink/?LinkID=513299
[stream.analytics.rest.api.reference]: https://go.microsoft.com/fwlink/?LinkId=517301

