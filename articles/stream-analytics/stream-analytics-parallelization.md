---
title: Использование параллелизации запросов и масштабирования в Azure Stream Analytics
description: В этой статье объясняется, как масштабировать задания Stream Analytics с помощью настройки входных разделов, настройки определения запроса и определения единиц потоковой передачи.
services: stream-analytics
author: JSeb225
ms.author: jeanb
manager: kfile
ms.reviewer: jasonh
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 05/07/2018
ms.openlocfilehash: 4fd862c2442d2637d799a1f690d5f0a091c80562
ms.sourcegitcommit: f56b267b11f23ac8f6284bb662b38c7a8336e99b
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/28/2019
ms.locfileid: "67449195"
---
# <a name="leverage-query-parallelization-in-azure-stream-analytics"></a>Использование параллелизации запросов в Azure Stream Analytics
В этой статье показано, как воспользоваться преимуществами параллелизма в Azure Stream Analytics. Узнайте, как масштабировать задания Stream Analytics с помощью настройки входных разделов, настройки аналитики определения запроса.
Предварительно может потребоваться ознакомиться с концепцией потоковой единицы, которая описана в статье [Оптимизация задания для эффективного использования единиц потоковой передачи](stream-analytics-streaming-unit-consumption.md).

## <a name="what-are-the-parts-of-a-stream-analytics-job"></a>Из каких частей состоит задание службы Stream Analytics?
Определение задания Stream Analytics включает запрос, а также входные и выходные данные. Входные данные — это точки, откуда задания считывают данные из потока. Запрос используется для преобразования потока входных данных, а выходные данные являются точками, куда направляются результаты задания.

Задание требует по крайней мере один источник входных данных для потока данных. Входной источник потока данных может храниться в концентраторе событий Azure или в хранилище BLOB-объектов Azure. Дополнительные сведения см. в статьях [Что такое Stream Analytics?](stream-analytics-introduction.md) и [Приступая к работе с Azure Stream Analytics: выявление мошенничества в режиме реального времени](stream-analytics-real-time-fraud-detection.md).

## <a name="partitions-in-sources-and-sinks"></a>Секции в источниках и приемниках
Масштабирование задания Stream Analytics реализует преимущества использования секций во входных или выходных данных. Секционирование позволяет разделить данные на подмножества на основе ключа секции. Процесс, который использует данные (например, задание Streaming Analytics), может получать и записывать различные секции параллельно, тем самым повышая пропускную способность. 

### <a name="inputs"></a>Входные данные
Все входные данные в Azure Stream Analytics могут использовать преимущества секционирования:
-   Концентратор событий (требуется явно задать ключ раздела с помощью ключевого слова PARTITION BY).
-   Концентратор событий (требуется явно задать ключ раздела с помощью ключевого слова PARTITION BY).
-   Хранилище BLOB-объектов

### <a name="outputs"></a>outputs

При работе со Stream Analytics можно воспользоваться преимуществами секционирования в концентраторах событий и выходных данных:
-   Azure Data Lake Storage
-   Функции Azure
-   Таблица Azure
-   Хранилище BLOB-объектов (требуется явно задать ключ раздела).
-   Cosmos DB (требуется явно задать ключ раздела).
-   Центры событий (требуется явно задать ключ раздела).
-   Центр Интернета вещей (требуется явно задать ключ раздела).
-   Служебная шина Azure
- SQL и хранилище данных SQL с необязательным секционированием. Дополнительные сведения см. на странице [Вывод в базу данных SQL Azure](https://docs.microsoft.com/azure/stream-analytics/stream-analytics-sql-output-perf).

Power BI не поддерживает секционирование. Однако можно по-прежнему секционировать входные данные как описано в [этом разделе](#multi-step-query-with-different-partition-by-values). 

Дополнительные сведения об этих секциях см. в следующих статьях:

* [Обзор функций Центров событий](../event-hubs/event-hubs-features.md#partitions)
* [Секционирование данных](https://docs.microsoft.com/azure/architecture/best-practices/data-partitioning)


## <a name="embarrassingly-parallel-jobs"></a>Задания с усложненным параллелизмом
Задание с *усложненным параллелизмом* — это самый масштабируемый сценарий в Azure Stream Analytics. Он соединяет один раздел входных данных с одним экземпляром запроса и одним разделом выходных данных. Такой параллелизм имеет следующие требования:

1. Если в логике запроса применяется ключ, который обрабатывается тем же экземпляром запроса, необходимо только проследить за тем, чтобы события попадали в ту же секцию входных данных. При использовании Центров событий или Центра Интернета вещей это означает, что для данных событий должно быть задано значение **PartitionKey**. Кроме того, можно использовать секционированные отправители. Для хранилища BLOB-объектов это означает, что события отправляются в папку той же секции. Если логика запроса не требует обработки ключа тем же экземпляром запроса, это требование можно проигнорировать. В качестве примера такой логики можно привести простой запрос select, project или filter.  

2. После того как данные будут распределены в источнике данных, необходимо убедиться в том, что запрос разбит на секции. Для этого на каждом этапе используется параметр **PARTITION BY**. Этапов может быть несколько, но на каждом из них должен использоваться один и тот же ключ. При уровне совместимости 1.0 и 1.1, ключ секционирования должно быть присвоено **PartitionId** в порядке для задания, которое будет полностью параллельным. Для заданий с уровнем совместимость 1.2 и более поздних версий настраиваемый столбец можно указать в качестве ключа секции в входных параметров и задание будет automoatically paralellized даже без предложение PARTITION BY.

3. Большая часть выходных данных может воспользоваться преимуществами секционирования, однако при использовании типа выходных данных, не поддерживающих секционирование, задание не будет полностью параллельным. Дополнительные сведения см. в [этом разделе](#outputs).

4. Число секций входных данных должно совпадать с числом секций выходных данных. Выходные данные хранилища BLOB-объектов могут поддерживать секции и наследуют схему секционирования вышестоящего запроса. Если для хранилища BLOB-объектов указан ключ секции, то данные секционируются по входным секциям, поэтому результат по-прежнему вычисляется параллельно. Примеры значений секций, позволяющие выполнять задания с полной параллельной обработкой:

   * 8 секций входных данных концентраторов событий и 8 секций выходных данных концентраторов событий;
   * 8 секций входных данных концентраторов событий и выходные данные хранилища BLOB-объектов;
   * 8 входных секций концентраторов событий и выходные данные хранилища BLOB-объектов, секционированные по пользовательскому полю с произвольной кратностью;
   * 8 секций входных данных хранилища BLOB-объектов и выходные данные хранилища BLOB-объектов;
   * 8 секций входных данных хранилища BLOB-объектов и 8 секций выходных данных концентраторов событий.

Далее рассмотрим примеры сценариев с усложненным параллелизмом.

### <a name="simple-query"></a>Простой запрос

* Входные данные: концентратор событий с 8 секциями.
* Выходные данные: концентратор событий с 8 секциями.

Запрос:

```SQL
    SELECT TollBoothId
    FROM Input1 Partition By PartitionId
    WHERE TollBoothId > 100
```

Этот запрос является простым фильтром. Поэтому нам не нужно беспокоиться о секционировании входных данных, которые передаются в концентратор событий. Обратите внимание, что задания с уровнем совместимости, прежде чем 1.2 должен включать **PARTITION BY PartitionId** предложение, поэтому он удовлетворяет требованию #2 выше. Выходные данные концентраторов событий необходимо настроить, указав значение **PartitionId** в качестве ключа секции. Последняя проверка: число секций входных данных должно быть равно числу секций выходных данных.

### <a name="query-with-a-grouping-key"></a>Запрос с ключом группирования

* Входные данные: концентратор событий с 8 секциями.
* Выходные данные: Хранилище BLOB-объектов

Запрос:

```SQL
    SELECT COUNT(*) AS Count, TollBoothId
    FROM Input1 Partition By PartitionId
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
```

Этот запрос содержит ключ группирования. Поэтому события, сгруппированные вместе, должны быть отправлены в одну секцию концентратора событий. Так как в этом примере выполняется группирование по TollBoothID, необходимо убедиться, что TollBoothID используется в качестве ключа секции при отправке событий в концентратор событий. Затем в ASA, можно использовать **PARTITION BY PartitionId** для наследования этой схемы разделов и обеспечения полной паралеллизации. Так как выходными данными является хранилище BLOB-объектов, не нужно беспокоиться о настройке значения ключа секции, как описано в требовании 4.

## <a name="example-of-scenarios-that-are-not-embarrassingly-parallel"></a>Примеры сценариев *без* усложненного параллелизма

В предыдущем разделе мы рассмотрели сценарии с усложненным параллелизмом. В этом разделе обсуждаются сценарии, которые не соответствуют всем показателям усложненного параллелизма. 

### <a name="mismatched-partition-count"></a>Несоответствие в числе секций
* Входные данные: концентратор событий с 8 секциями.
* Выходные данные: концентратор событий с 32 секциями.

В этом случае тип запроса не имеет значения. Если число секций входных данных не совпадает с числом секций выходных данных, топология не является топологией с усложненным параллелизмом. Однако все равно можно получить некоторый уровень или паралеллизацию.

### <a name="query-using-non-partitioned-output"></a>Запрос с использованием несекционированных выходных данных
* Входные данные: концентратор событий с 8 секциями.
* Выходные данные: Power BI

В настоящее время выходные данные Power BI не поддерживают секционирование. Таким образом этот сценарий не считается сценарием с усложненным параллелизмом.

### <a name="multi-step-query-with-different-partition-by-values"></a>Многоэтапный запрос с разными значениями параметра PARTITION BY
* Входные данные: концентратор событий с 8 секциями.
* Выходные данные: концентратор событий с 8 секциями.

Запрос:

```SQL
    WITH Step1 AS (
    SELECT COUNT(*) AS Count, TollBoothId, PartitionId
    FROM Input1 Partition By PartitionId
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
    )

    SELECT SUM(Count) AS Count, TollBoothId
    FROM Step1 Partition By TollBoothId
    GROUP BY TumblingWindow(minute, 3), TollBoothId
```

Как видите, на втором этапе в качестве ключа секционирования используется **TollBoothId** . Он не совпадает с ключом в первом шаге, а значит, потребует перетасовки. 

Мы рассмотрели несколько примеров заданий Stream Analytics, соответствующих и не соответствующих критериям топологии с усложненным параллелизмом. При соответствии, задания будут иметь максимально возможное для них масштабирование. Для заданий, не соответствующих ни одному из этих профилей, в дальнейшем будут выпущены обновления в отношении масштабирования. А пока придерживайтесь описанных ниже рекомендаций.

### <a name="compatibility-level-12---multi-step-query-with-different-partition-by-values"></a>Уровень совместимости 1.2 - многоэтапный запрос с разными значениями параметра PARTITION BY 
* Входные данные: концентратор событий с 8 секциями.
* Выходные данные: концентратор событий с 8 секциями.

Запрос:

```SQL
    WITH Step1 AS (
    SELECT COUNT(*) AS Count, TollBoothId
    FROM Input1
    GROUP BY TumblingWindow(minute, 3), TollBoothId
    )

    SELECT SUM(Count) AS Count, TollBoothId
    FROM Step1
    GROUP BY TumblingWindow(minute, 3), TollBoothId
```

Уровень совместимости 1.2 включает параллельного выполнения запросов по умолчанию. Например запрос из предыдущего раздела будет parttioned до тех пор, пока столбцу «TollBoothId» задано как входной ключ секции. СЕКЦИИ, ParttionId предложение не является обязательным.

## <a name="calculate-the-maximum-streaming-units-of-a-job"></a>Расчет максимального количества единиц потоковой передачи для задания
Общее число единиц потоковой передачи, которое можно использовать заданием Stream Analytics, зависит от числа шагов в запросе, определенных для задания, и количества разделов для каждого шага.

### <a name="steps-in-a-query"></a>Шаги в запросе
Запрос может иметь один или несколько шагов. Каждый шаг — это вложенный запрос, определенный с помощью ключевого слова **WITH**. Запрос за рамками ключевого слова **WITH** (только один запрос) также учитывается в качестве шага (например, инструкция **SELECT** в следующем запросе).

Запрос:

```SQL
    WITH Step1 AS (
        SELECT COUNT(*) AS Count, TollBoothId
        FROM Input1 Partition By PartitionId
        GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
    )
    SELECT SUM(Count) AS Count, TollBoothId
    FROM Step1
    GROUP BY TumblingWindow(minute,3), TollBoothId
```

Этот запрос включает 2 шага.

> [!NOTE]
> Этот запрос будет описан далее в этой статье.
>  

### <a name="partition-a-step"></a>Разделы шага
Разделение шага требует наличия следующих условий.

* Источник входных данных должен быть секционирован. 
* Инструкция **SELECT** запроса должна читаться из разделенного источника входных данных.
* Запрос внутри шага должен включать ключевое слово **PARTITION BY**.

Если запрос разделен, входные данные событий будут обработаны и объединены в отдельные группы секции, а выходные данные событий будут сгенерированы для каждой из групп. Если желательно иметь объединенный запрос, необходимо создать второй неразделенный шаг для объединения.

### <a name="calculate-the-max-streaming-units-for-a-job"></a>Рассчитайте максимальное количество единиц потоковой передачи для задания
Все несекционированные шаги можно масштабировать до шести единиц потоковой передачи для задания Stream Analytics. Помимо этого можно добавить 6 единиц потоковой передачи для каждой секции на шаге секционирования.
Дополнительные **примеры** можно просмотреть в таблице ниже.

| Запрос                                               | Максимальное количество единиц потоковой передачи для задания |
| --------------------------------------------------- | ------------------- |
| <ul><li>Запрос содержит один шаг.</li><li>Шаг не секционирован.</li></ul> | 6 |
| <ul><li>Поток входных данных секционирован по 16.</li><li>Запрос содержит один шаг.</li><li>Шаг является секционированным.</li></ul> | 96 (6 * 16 секций) |
| <ul><li>Запрос состоит из двух шагов.</li><li>Ни один из шагов не секционирован.</li></ul> | 6 |
| <ul><li>Поток входных данных секционирован по 3.</li><li>Запрос состоит из двух шагов. Входной шаг секционирован, а второй шаг — нет.</li><li>Инструкция <strong>SELECT</strong> считывает из секционированных входных данных.</li></ul> | 24 (18 и 6 секционированных и несекционированных шагов соответственно) |

### <a name="examples-of-scaling"></a>Примеры масштабирования

Следующий запрос вычисляет количество машин, проходящих через пропускной пункт с тремя пунктами для оплаты и пропускной способности три минуты для каждого пункта. Этот запрос можно масштабировать до шести единиц потоковой передачи.

```SQL
    SELECT COUNT(*) AS Count, TollBoothId
    FROM Input1
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
```

Чтобы использовать дополнительные единицы потоковой передачи для запроса, входной поток данных и запрос должны быть секционированы. При наличии секции потока данных, равной 3, следующий измененный запрос можно масштабировать до 18 единиц потоковой передачи.

```SQL
    SELECT COUNT(*) AS Count, TollBoothId
    FROM Input1 Partition By PartitionId
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
```

Если запрос секционирован, входные данные событий будут обработаны и объединены в отдельные группы секций. Кроме того, для каждой из групп будут сформированы выходные данные событий. Секционирование может вызвать некоторые непредвиденные результаты, если поле **GROUP BY** не является ключом секции во входном потоке данных. Например, поле **TollBoothId** в предыдущем запросе не является ключом секции **Input1**. В результате данные из пункта 1 можно распределить между несколькими секциями.

Каждая из секций **Input1** будет обрабатываться отдельно с помощью Stream Analytics. В результате будет создаваться несколько записей для автомобиля, проходящего через один и тот же пункт. Если нельзя изменить ключ секции ввода, эту проблему можно устранить, добавив несекционированные действия для вычисления значений по секциям, например:

```SQL
    WITH Step1 AS (
        SELECT COUNT(*) AS Count, TollBoothId
        FROM Input1 Partition By PartitionId
        GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
    )

    SELECT SUM(Count) AS Count, TollBoothId
    FROM Step1
    GROUP BY TumblingWindow(minute, 3), TollBoothId
```

Этот запрос можно увеличить до 24 единиц потоковой передачи.

> [!NOTE]
> При объединении двух потоков убедитесь, что потоки разделены с помощью ключа секции столбца, используемого для объединения. Также убедитесь, что количество секций в обоих потоках одинаковое.
> 
> 

## <a name="achieving-higher-throughputs-at-scale"></a>Достижение также увеличение пропускной способности в нужном масштабе

[Усложненным](#embarrassingly-parallel-jobs) задания, необходимые, но недостаточно для обеспечения более высокой пропускной способности в нужном масштабе. Все хранилища системы и его соответствующие выходные данные Stream Analytics имеет вариантов о том, как достичь пропускной способности лучше всего возможных записи. Как с помощью любого сценария в масштабе, существуют некоторые проблемы, которые могут быть разрешены с помощью правой конфигураций. В этом разделе обсуждаются конфигурации для нескольких распространенных выходные данные, а также содержит примеры для поддержания скорости приема 1 КБ, 5K и 10 тысяч событий в секунду.

Следующие наблюдения использовать задание Stream Analytics с помощью запроса без отслеживания состояния (сквозной), базовой определяемой пользователем функции JavaScript, который записывает в концентратор событий, база данных SQL Azure или Cosmos DB.

#### <a name="event-hub"></a>Концентратор событий

|Скорость приема (событий в секунду) | Единицы потоковой передачи | Выходные данные ресурсов  |
|--------|---------|---------|
| 1 КБ     |    1    |  2 ЕДИНИЦ ПРОПУСКНОЙ СПОСОБНОСТИ   |
| 5 КБ     |    6    |  6 ЕДИНИЦ ПРОПУСКНОЙ СПОСОБНОСТИ   |
| 10 000    |    12   |  10 ЕДИНИЦ ПРОПУСКНОЙ СПОСОБНОСТИ  |

[Концентратора событий](https://github.com/Azure-Samples/streaming-at-scale/tree/master/eventhubs-streamanalytics-eventhubs) решение масштабируется линейно с точки зрения потоковой передачи единиц (SU) и пропускную способность, делая это наиболее эффективный и эффективный способ для анализа и потоковой передачи данных из Stream Analytics. Задания можно масштабировать до 192 SU, который грубо соответствует обработки до 200 МБ в секунду или 19 триллиона событий в день.

#### <a name="azure-sql"></a>Azure SQL
|Скорость приема (событий в секунду) | Единицы потоковой передачи | Выходные данные ресурсов  |
|---------|------|-------|
|    1 КБ   |   3  |  S3   |
|    5 КБ   |   18 |  P4   |
|    10 000  |   36 |  P6   |

[Azure SQL](https://github.com/Azure-Samples/streaming-at-scale/tree/master/eventhubs-streamanalytics-azuresql) поддерживает запись в параллельном режиме, вызванной наследовать секционирования, но он не включен по умолчанию. Тем не менее включении наследовать секционирования, а также использовании полностью параллельного запроса может быть недостаточно для достижения также увеличение пропускной способности. Пропускной способности записи SQL значительно зависят от схемы конфигурации и таблицы базы данных SQL Azure. [Производительности SQL вывода](./stream-analytics-sql-output-perf.md) статьи содержит больше информации о параметрах, которые можно максимально увеличить пропускную способность записи. Как отмечалось в [выходные данные Azure Stream Analytics к базе данных SQL Azure](./stream-analytics-sql-output-perf.md#azure-stream-analytics) статье, это решение не масштабируется линейно, как полностью параллельных конвейер за 8 секций и может потребоваться повторное секционирование перед выходных данных SQL (см. в разделе [ В](https://docs.microsoft.com/stream-analytics-query/into-azure-stream-analytics#into-shard-count)). Номера SKU уровня "премиум" необходимо выдержать высокая скорость операций ввода-ВЫВОДА, а также издержки из резервных копий журнала, происходит каждые несколько минут.

#### <a name="cosmos-db"></a>База данных Cosmos
|Скорость приема (событий в секунду) | Единицы потоковой передачи | Выходные данные ресурсов  |
|-------|-------|---------|
|  1 КБ   |  3    | 20 ТЫСЯЧ ЕДИНИЦ ЗАПРОСОВ  |
|  5 КБ   |  24   | ЕЗ 60 КБ  |
|  10 000  |  48   | 120 ТЫС ЕЗ |

[Cosmos DB](https://github.com/Azure-Samples/streaming-at-scale/tree/master/eventhubs-streamanalytics-cosmosdb) выходные данные Stream Analytics была обновлена для использования встроенной возможности интеграции в разделе [уровень совместимости 1.2](./stream-analytics-documentdb-output.md#improved-throughput-with-compatibility-level-12). Уровень совместимости 1.2 позволяет значительно более высокую пропускную способность и уменьшает потребление единиц Запросов, по сравнению с 1.1, которая является уровнем совместимости по умолчанию для новых заданий. Решение использует контейнеры CosmosDB секционированы по /deviceId и остальная часть решения настраивается одинаково.

Все [потоковую передачу на примеры масштабирования azure](https://github.com/Azure-Samples/streaming-at-scale) использовать концентратор событий, подача с нагрузки, имитируя тестовых клиентов в качестве входных данных. Каждое событие ввода — это документ JSON размером 1 КБ, преобразующей скорости приема настроенный для пропускная способность (1 МБ/с, 5 МБ/с и 10 МБ/с), легко. События имитация устройства Интернета вещей отправляет следующие данные JSON (в сокращенной формы) до 1 K устройств:

```
{
    "eventId": "b81d241f-5187-40b0-ab2a-940faf9757c0",
    "complexData": {
        "moreData0": 51.3068118685458,
        "moreData22": 45.34076957651598
    },
    "value": 49.02278128887753,
    "deviceId": "contoso://device-id-1554",
    "type": "CO2",
    "createdAt": "2019-05-16T17:16:40.000003Z"
}
```

> [!NOTE]
> Конфигурации могут измениться в любое время из-за различных компонентов, используемых в решении. Для более точного подсчета настраивать эти образцы для своего сценария.

### <a name="identifying-bottlenecks"></a>Выявление узких мест

Использование области метрики в задании Azure Stream Analytics для выявления узких мест в конвейере. Просмотрите **события ввода и вывода** для пропускной способности и [«Задержка водяной знак»](https://azure.microsoft.com/blog/new-metric-in-azure-stream-analytics-tracks-latency-of-your-streaming-pipeline/) или **отложенных событий** для просмотра, если задание справляется со скоростью ввода. Для метрик в концентратор событий, искать **регулирование запросов** и соответствующим образом настроить пороговое значение единицы измерения. Метрики Cosmos DB, просмотрите **максимальное количество потребляемых единиц Запросов в секунду в диапазоне ключей разделов** под пропускной способности, чтобы обеспечить диапазонов ключей секций равномерно потребляются. Для базы данных SQL Azure, отслеживайте **ввода-ВЫВОДА журнала** и **ЦП**.

## <a name="get-help"></a>Получение справки

За дополнительной помощью обращайтесь на наш [форум Azure Stream Analytics](https://social.msdn.microsoft.com/Forums/azure/home?forum=AzureStreamAnalytics).

## <a name="next-steps"></a>Дальнейшие действия
* [Введение в Azure Stream Analytics](stream-analytics-introduction.md)
* [Приступая к работе с Azure Stream Analytics](stream-analytics-real-time-fraud-detection.md)
* [Справочник по языку запросов Azure Stream Analytics](https://msdn.microsoft.com/library/azure/dn834998.aspx)
* [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)

<!--Image references-->

[img.stream.analytics.monitor.job]: ./media/stream-analytics-scale-jobs/StreamAnalytics.job.monitor-NewPortal.png
[img.stream.analytics.configure.scale]: ./media/stream-analytics-scale-jobs/StreamAnalytics.configure.scale.png
[img.stream.analytics.perfgraph]: ./media/stream-analytics-scale-jobs/perf.png
[img.stream.analytics.streaming.units.scale]: ./media/stream-analytics-scale-jobs/StreamAnalyticsStreamingUnitsExample.jpg
[img.stream.analytics.preview.portal.settings.scale]: ./media/stream-analytics-scale-jobs/StreamAnalyticsPreviewPortalJobSettings-NewPortal.png   

<!--Link references-->

[microsoft.support]: https://support.microsoft.com
[azure.event.hubs.developer.guide]: https://msdn.microsoft.com/library/azure/dn789972.aspx

[stream.analytics.introduction]: stream-analytics-introduction.md
[stream.analytics.get.started]: stream-analytics-real-time-fraud-detection.md
[stream.analytics.query.language.reference]: https://go.microsoft.com/fwlink/?LinkID=513299
[stream.analytics.rest.api.reference]: https://go.microsoft.com/fwlink/?LinkId=517301

