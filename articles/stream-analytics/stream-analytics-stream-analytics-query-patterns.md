---
title: Общие шаблоны запросов в Azure Stream Analytics
description: В этой статье описывается несколько общих шаблонов и структур запросов, которые могут использоваться в заданиях Azure Stream Analytics.
services: stream-analytics
author: rodrigoaatmicrosoft
ms.author: rodrigoa
ms.reviewer: mamccrea
ms.service: stream-analytics
ms.topic: how-to
ms.date: 12/18/2019
ms.custom: devx-track-js
ms.openlocfilehash: 84e3ced20b828087cd3f2b9e7534826debf1706a
ms.sourcegitcommit: 829d951d5c90442a38012daaf77e86046018e5b9
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/09/2020
ms.locfileid: "91279983"
---
# <a name="common-query-patterns-in-azure-stream-analytics"></a>Общие шаблоны запросов в Azure Stream Analytics

Запросы в Azure Stream Analytics выражаются на языке запросов на основе SQL. Эти языковые конструкции описаны в [справочнике по языку запросов Stream Analytics](/stream-analytics-query/stream-analytics-query-language-reference). 

Конструктор запросов может выражать простую сквозную логику для перемещения данных событий из входного потока в хранилище выходных данных. Либо же конструктор может выполнять комплексное сопоставление шаблонов и темпоральный анализ для вычисления агрегатов по различным временным окнам, как описано в руководстве [Создание решения IoT с помощью Stream Analytics](stream-analytics-build-an-iot-solution-using-stream-analytics.md). Вы можете объединить данные из нескольких источников, чтобы сгруппировать события потоковой передачи и выполнять поиск по статическим эталонным данным, что позволит повысить информативность значений событий. Вы можете также записать данные на несколько выходов.

В этой статье описаны решения для нескольких стандартных шаблонов запросов на основе реальных сценариев.

## <a name="supported-data-formats"></a>Поддерживаемые форматы данных

Azure Stream Analytics поддерживает обработку событий в форматах CSV, JSON и Avro.

Данные JSON и Avro могут содержать сложные типы, такие как вложенные объекты (записи) или массивы. Дополнительные сведения о том, как работать с этими сложными типами данных, см. в статье [Анализ данных JSON и AVRO](stream-analytics-parsing-json.md).

## <a name="send-data-to-multiple-outputs"></a>Отправка данных на несколько выходов

Для вывода данных в различные приемники выходных данных можно использовать несколько инструкций **SELECT**. Например, одна инструкция **SELECT** может выводить оповещение на основе порогового значения, в то время как другая может выводить события в хранилище BLOB-объектов.

**Входные данные**

| Убедитесь, | Time |
| --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |
| Make1 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:01.0000000Z |
| Make2 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:03.0000000Z |

**Выход ArchiveOutput**

| Убедитесь, | Time |
| --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |
| Make1 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:01.0000000Z |
| Make2 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:03.0000000Z |

**Выход AlertOutput**

| Убедитесь, | Time | Count |
| --- | --- | --- |
| Make2 |2015-01-01T00:00:10.0000000Z |3 |

**Запрос.**

```SQL
SELECT
    *
INTO
    ArchiveOutput
FROM
    Input TIMESTAMP BY Time

SELECT
    Make,
    System.TimeStamp() AS Time,
    COUNT(*) AS [Count]
INTO
    AlertOutput
FROM
    Input TIMESTAMP BY Time
GROUP BY
    Make,
    TumblingWindow(second, 10)
HAVING
    [Count] >= 3
```

Предложение **INTO** сообщает Stream Analytics, в какие выходные данные записывать данные. Первая инструкция **SELECT** определяет запрос к серверу, который получает данные из входных данных и отправляет их в выход с именем **ArchiveOutput**. Второй запрос выполняет простую агрегацию и фильтрацию перед отправкой результатов в выход нижестоящей системы оповещений с именем **AlertOutput**.

Обратите внимание, что для определения нескольких блоков вложенных запросов можно использовать предложение **WITH**. При этом вы получаете преимущество, так как нужно открывать меньше читателей в источнике входных данных.

**Запрос.**

```SQL
WITH ReaderQuery AS (
    SELECT
        *
    FROM
        Input TIMESTAMP BY Time
)

SELECT * INTO ArchiveOutput FROM ReaderQuery

SELECT 
    Make,
    System.TimeStamp() AS Time,
    COUNT(*) AS [Count] 
INTO AlertOutput 
FROM ReaderQuery
GROUP BY
    Make,
    TumblingWindow(second, 10)
HAVING [Count] >= 3
```

Дополнительные сведения см. в описании [предложения **WITH**](/stream-analytics-query/with-azure-stream-analytics).

## <a name="simple-pass-through-query"></a>Простой запрос к серверу

Простой запрос к серверу можно использовать для копирования данных входного потока в выходные данные. Например, если поток данных, содержащий сведения об автомобилях в реальном времени, необходимо сохранить в базе данных SQL для дальнейшего анализа, это можно сделать с помощью простого запроса к серверу.

**Входные данные**

| Убедитесь, | Time | Вес |
| --- | --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |"1000" |
| Make1 |2015-01-01T00:00:02.0000000Z |"2000" |

**Выходные данные**:

| Убедитесь, | Time | Вес |
| --- | --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |"1000" |
| Make1 |2015-01-01T00:00:02.0000000Z |"2000" |

**Запрос.**

```SQL
SELECT
    *
INTO Output
FROM Input
```

Запрос **SELECT** * проецирует все поля входящего события и отправляет их в выходные данные. Таким же образом **SELECT** можно использовать для проецирования только необходимых полей из входных данных. Если в этом примере необходимо сохранить только поля *Make* и *Time*, их можно указать в инструкции **SELECT**.

**Входные данные**

| Убедитесь, | Time | Вес |
| --- | --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |1000 |
| Make1 |2015-01-01T00:00:02.0000000Z |2000 |
| Make2 |2015-01-01T00:00:04.0000000Z |1500 |

**Выходные данные**:

| Убедитесь, | Time |
| --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |
| Make1 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:04.0000000Z |

**Запрос.**

```SQL
SELECT
    Make, Time
INTO Output
FROM Input
```

## <a name="string-matching-with-like-and-not-like"></a>Совпадение строк с помощью инструкций LIKE и NOT LIKE

**Для проверки соответствия поля определенному шаблону можно использовать инструкции** LIKE**NOT LIKE**. Например, можно создать фильтр, возвращающий только те номерные знаки, которые начинаются с буквы "A" и заканчиваются цифрой 9.

**Входные данные**

| Убедитесь, | License_plate | Time |
| --- | --- | --- |
| Make1 |ABC-123 |2015-01-01T00:00:01.0000000Z |
| Make2 |AAA-999 |2015-01-01T00:00:02.0000000Z |
| Make3 |ABC-369 |2015-01-01T00:00:03.0000000Z |

**Выходные данные**:

| Убедитесь, | License_plate | Time |
| --- | --- | --- |
| Make2 |AAA-999 |2015-01-01T00:00:02.0000000Z |
| Make3 |ABC-369 |2015-01-01T00:00:03.0000000Z |

**Запрос.**

```SQL
SELECT
    *
FROM
    Input TIMESTAMP BY Time
WHERE
    License_plate LIKE 'A%9'
```

Используйте инструкцию **LIKE** для проверки значения поля **License_plate**. Оно должно начинаться с "А", затем должна идти любая строка (пустая или из нескольких символов), и заканчиваться цифрой 9.

## <a name="calculation-over-past-events"></a>Вычисление по прошлым событиям

Для просмотра прошлых событий в течение временного окна и сравнения их с текущим событием может использоваться функция **LAG**. Например, можно выводить марку текущего автомобиля, если она отличается от марки последнего автомобиля, который проехал через пункт взимания дорожного сбора.

**Входные данные**

| Убедитесь, | Time |
| --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |
| Make2 |2015-01-01T00:00:02.0000000Z |

**Выходные данные**:

| Убедитесь, | Time |
| --- | --- |
| Make2 |2015-01-01T00:00:02.0000000Z |

**Запрос.**

```SQL
SELECT
    Make,
    Time
FROM
    Input TIMESTAMP BY Time
WHERE
    LAG(Make, 1) OVER (LIMIT DURATION(minute, 1)) <> Make
```

Используйте **LAG**, чтобы вернуться во входном потоке на одно событие назад, получить значение *Make*, сравнить его со значением *Make* текущего события и вывести событие.

Дополнительные сведения см. в описании [функции **LAG**](/stream-analytics-query/lag-azure-stream-analytics).

## <a name="return-the-last-event-in-a-window"></a>Возврат последнего события в окне

Так как события используются системой в режиме реального времени, функция, которая могла бы определить, было ли событие последним в данном временном окне, отсутствует. Чтобы это определить, необходимо соединить один входной поток с другим. Тогда временем события будет максимальное время для всех событий в этом окне.

**Входные данные**

| License_plate | Убедитесь, | Time |
| --- | --- | --- |
| DXE 5291 |Make1 |2015-07-27T00:00:05.0000000Z |
| YZK 5704 |Make3 |2015-07-27T00:02:17.0000000Z |
| RMV 8282 |Make1 |2015-07-27T00:05:01.0000000Z |
| YHN 6970 |Make2 |2015-07-27T00:06:00.0000000Z |
| VFE 1616 |Make2 |2015-07-27T00:09:31.0000000Z |
| QYF 9358 |Make1 |2015-07-27T00:12:02.0000000Z |
| MDR 6128 |Make4 |2015-07-27T00:13:45.0000000Z |

**Выходные данные**:

| License_plate | Убедитесь, | Time |
| --- | --- | --- |
| VFE 1616 |Make2 |2015-07-27T00:09:31.0000000Z |
| MDR 6128 |Make4 |2015-07-27T00:13:45.0000000Z |

**Запрос.**

```SQL
WITH LastInWindow AS
(
    SELECT 
        MAX(Time) AS LastEventTime
    FROM 
        Input TIMESTAMP BY Time
    GROUP BY 
        TumblingWindow(minute, 10)
)

SELECT 
    Input.License_plate,
    Input.Make,
    Input.Time
FROM
    Input TIMESTAMP BY Time 
    INNER JOIN LastInWindow
    ON DATEDIFF(minute, Input, LastInWindow) BETWEEN 0 AND 10
    AND Input.Time = LastInWindow.LastEventTime
```

Первый шаг в запросе — найти максимальную метку времени в 10-минутных окнах, которая и будет меткой времени последнего события в каждом из них. Второй шаг — соединить результаты первого запроса с исходным потоком, чтобы найти событие, соответствующее последней метке времени в каждом окне. 

**DATEDIFF** — это функция для работы с датами, которая сравнивает метки времени и возвращает разницу во времени между двумя полями даты и времени. Дополнительные сведения см. в статье о [функциях для работы с датами](https://docs.microsoft.com/stream-analytics-query/date-and-time-functions-azure-stream-analytics).

Дополнительные сведения о присоединении потоков см. в описании [инструкции**JOIN**](/stream-analytics-query/join-azure-stream-analytics).

## <a name="data-aggregation-over-time"></a>Агрегация данных за определенный период времени

Для вычисления данных в пределах временного окна их можно агрегировать. В этом примере число вычислено за последние 10 секунд для каждого конкретного автомобиля.

**Входные данные**

| Убедитесь, | Time | Вес |
| --- | --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |1000 |
| Make1 |2015-01-01T00:00:02.0000000Z |2000 |
| Make2 |2015-01-01T00:00:04.0000000Z |1500 |

**Выходные данные**:

| Убедитесь, | Count |
| --- | --- |
| Make1 | 2 |
| Make2 | 1 |

**Запрос.**

```SQL
SELECT
    Make,
    COUNT(*) AS Count
FROM
    Input TIMESTAMP BY Time
GROUP BY
    Make,
    TumblingWindow(second, 10)
```

При таком агрегировании автомобили группируются по полю *Make*, а их число подсчитывается каждые 10 секунд. Выходные данные содержат поля *Make* и *Count* для автомобилей, проезжающих через пункт взимания дорожного сбора.

TumblingWindow — это функция управления окнами, используемая для группирования событий. Агрегирование можно применять ко всем сгруппированным событиям. Дополнительные сведения см. в описании [функций управления окнами](stream-analytics-window-functions.md).

Дополнительные сведения об агрегировании см. в описании [агрегатных функций](/stream-analytics-query/aggregate-functions-azure-stream-analytics).

## <a name="periodically-output-values"></a>Периодический вывод значений

В случае необычных или пропущенных событий из более разреженных входных данных можно сформировать обычные выходные данные. Например, создавайте каждые 5 секунд событие, сообщающее последнюю видимую точку данных.

**Входные данные**

| Time | Значение |
| --- | --- |
| "2014-01-01T06:01:00" |1 |
| "2014-01-01T06:01:05" |2 |
| "2014-01-01T06:01:10" |3 |
| "2014-01-01T06:01:15" |4 |
| "2014-01-01T06:01:30" |5 |
| "2014-01-01T06:01:35" |6 |

**Выходные данные (первые 10 строк)** :

| Window_end | Last_event.Time | Last_event.Value |
| --- | --- | --- |
| 2014-01-01T14:01:00.000Z |2014-01-01T14:01:00.000Z |1 |
| 2014-01-01T14:01:05.000Z |2014-01-01T14:01:05.000Z |2 |
| 2014-01-01T14:01:10.000Z |2014-01-01T14:01:10.000Z |3 |
| 2014-01-01T14:01:15.000Z |2014-01-01T14:01:15.000Z |4 |
| 2014-01-01T14:01:20.000Z |2014-01-01T14:01:15.000Z |4 |
| 2014-01-01T14:01:25.000Z |2014-01-01T14:01:15.000Z |4 |
| 2014-01-01T14:01:30.000Z |2014-01-01T14:01:30.000Z |5 |
| 2014-01-01T14:01:35.000Z |2014-01-01T14:01:35.000Z |6 |
| 2014-01-01T14:01:40.000Z |2014-01-01T14:01:35.000Z |6 |
| 2014-01-01T14:01:45.000Z |2014-01-01T14:01:35.000Z |6 |

**Запрос.**

```SQL
SELECT
    System.Timestamp() AS Window_end,
    TopOne() OVER (ORDER BY Time DESC) AS Last_event
FROM
    Input TIMESTAMP BY Time
GROUP BY
    HOPPINGWINDOW(second, 300, 5)
```

Этот запрос создает события каждые 5 секунд и выводит последнее событие, полученное ранее. От длительности **HOPPINGWINDOW** зависит, насколько далеко будет возвращаться запрос при поиске последнего события.

Дополнительные сведения см. в статье о ["прыгающем" окне](/stream-analytics-query/hopping-window-azure-stream-analytics).

## <a name="correlate-events-in-a-stream"></a>Выявление корреляции между событиями в потоке

Выявить корреляцию между событиями в одном потоке можно путем возврата к предыдущим событиям с помощью функции **LAG**. Например, выходные данные могут создаваться каждый раз, когда через пункт взимания дорожного сбора за последние 90 секунд проезжает два автомобиля одной марки (*Make*) подряд.

**Входные данные**

| Убедитесь, | License_plate | Time |
| --- | --- | --- |
| Make1 |ABC-123 |2015-01-01T00:00:01.0000000Z |
| Make1 |AAA-999 |2015-01-01T00:00:02.0000000Z |
| Make2 |DEF-987 |2015-01-01T00:00:03.0000000Z |
| Make1 |GHI-345 |2015-01-01T00:00:04.0000000Z |

**Выходные данные**:

| Убедитесь, | Time | Current_car_license_plate | First_car_license_plate | First_car_time |
| --- | --- | --- | --- | --- |
| Make1 |2015-01-01T00:00:02.0000000Z |AAA-999 |ABC-123 |2015-01-01T00:00:01.0000000Z |

**Запрос.**

```SQL
SELECT
    Make,
    Time,
    License_plate AS Current_car_license_plate,
    LAG(License_plate, 1) OVER (LIMIT DURATION(second, 90)) AS First_car_license_plate,
    LAG(Time, 1) OVER (LIMIT DURATION(second, 90)) AS First_car_time
FROM
    Input TIMESTAMP BY Time
WHERE
    LAG(Make, 1) OVER (LIMIT DURATION(second, 90)) = Make
```

Функция **LAG** может вернуться во входном потоке на одно событие назад и получить значение *Make*, сравнив его со значением *Make* текущего события.  При выполнении условия данные из предыдущего события можно спроектировать с помощью функции **LAG** в инструкцию **SELECT**.

Дополнительные сведения см. в описании функции [LAG](/stream-analytics-query/lag-azure-stream-analytics).

## <a name="detect-the-duration-between-events"></a>Определение промежутка между событиями

Длительность события можно вычислить на основе данных о последнем событии запуска после получения события завершения. Этот запрос может быть полезен для определения времени, затрачиваемого пользователем на страницу или функцию.

**Входные данные**  

| Пользователь | Компонент | Событие | Time |
| --- | --- | --- | --- |
| user@location.com |RightMenu |Запуск |2015-01-01T00:00:01.0000000Z |
| user@location.com |RightMenu |Конец |2015-01-01T00:00:08.0000000Z |

**Выходные данные**:  

| Пользователь | Компонент | Duration |
| --- | --- | --- |
| user@location.com |RightMenu |7 |

**Запрос.**

```SQL
SELECT
    [user],
    feature,
    DATEDIFF(
        second,
        LAST(Time) OVER (PARTITION BY [user], feature LIMIT DURATION(hour, 1) WHEN Event = 'start'),
        Time) as duration
FROM input TIMESTAMP BY Time
WHERE
    Event = 'end'
```

Функцию **LAST** можно использовать для получения последнего события при определенном условии. В этом примере условие — это событие типа Start, которое позволяет секционировать поиск по пользователю и функции с помощью **PARTITION BY**. Таким образом, при поиске события Start каждый пользователь и каждая функция рассматриваются независимо. **LIMIT DURATION** ограничивает время поиска между событиями End и Start в прошлом промежутке в 1 час.

## <a name="count-unique-values"></a>Число уникальных значений

Для подсчета количества уникальных значений поля, которые отображаются в потоке в течение определенного временного окна, можно использовать инструкции **COUNT** и **DISTINCT**. Для подсчета числа уникальных марок автомобилей (*Make*), которые проезжают через пункт взимания дорожного сбора за 2 секунды, можно создать запрос.

**Входные данные**

| Убедитесь, | Time |
| --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |
| Make1 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:01.0000000Z |
| Make2 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:03.0000000Z |

**Выходные данные:**

| Count_make | Time |
| --- | --- |
| 2 |2015-01-01T00:00:02.000Z |
| 1 |2015-01-01T00:00:04.000Z |

**Запрос:**

```SQL
SELECT
     COUNT(DISTINCT Make) AS Count_make,
     System.TIMESTAMP() AS Time
FROM Input TIMESTAMP BY TIME
GROUP BY 
     TumblingWindow(second, 2)
```

**COUNT(DISTINCT Make)** возвращает количество уникальных значений в столбце **Make** в течение определенного временного окна.
Дополнительные сведения см. в описании [агрегатной функции **COUNT**](/stream-analytics-query/count-azure-stream-analytics).

## <a name="retrieve-the-first-event-in-a-window"></a>Получение первого события в окне

Для получения первого события во временном окне можно использовать **IsFirst**. Например, можно выводить сведения о первом автомобиле через каждые 10 минут.

**Входные данные**

| License_plate | Убедитесь, | Time |
| --- | --- | --- |
| DXE 5291 |Make1 |2015-07-27T00:00:05.0000000Z |
| YZK 5704 |Make3 |2015-07-27T00:02:17.0000000Z |
| RMV 8282 |Make1 |2015-07-27T00:05:01.0000000Z |
| YHN 6970 |Make2 |2015-07-27T00:06:00.0000000Z |
| VFE 1616 |Make2 |2015-07-27T00:09:31.0000000Z |
| QYF 9358 |Make1 |2015-07-27T00:12:02.0000000Z |
| MDR 6128 |Make4 |2015-07-27T00:13:45.0000000Z |

**Выходные данные**:

| License_plate | Убедитесь, | Time |
| --- | --- | --- |
| DXE 5291 |Make1 |2015-07-27T00:00:05.0000000Z |
| QYF 9358 |Make1 |2015-07-27T00:12:02.0000000Z |

**Запрос.**

```SQL
SELECT 
    License_plate,
    Make,
    Time
FROM 
    Input TIMESTAMP BY Time
WHERE 
    IsFirst(minute, 10) = 1
```

Функция **IsFirst** также может секционировать данные и вычислять первое событие для каждой конкретной марки автомобиля (*Make*) в течение 10-минутного интервала.

**Выходные данные**:

| License_plate | Убедитесь, | Time |
| --- | --- | --- |
| DXE 5291 |Make1 |2015-07-27T00:00:05.0000000Z |
| YZK 5704 |Make3 |2015-07-27T00:02:17.0000000Z |
| YHN 6970 |Make2 |2015-07-27T00:06:00.0000000Z |
| QYF 9358 |Make1 |2015-07-27T00:12:02.0000000Z |
| MDR 6128 |Make4 |2015-07-27T00:13:45.0000000Z |

**Запрос.**

```SQL
SELECT 
    License_plate,
    Make,
    Time
FROM 
    Input TIMESTAMP BY Time
WHERE 
    IsFirst(minute, 10) OVER (PARTITION BY Make) = 1
```

Дополнительные сведения см. в описании [функции **IsFirst**](/stream-analytics-query/isfirst-azure-stream-analytics).

## <a name="remove-duplicate-events-in-a-window"></a>Удаление повторяющихся событий за период

При выполнении операции, такой как вычисление средних значений событий за заданный период времени, повторяющиеся события должны быть отфильтрованы. В следующем примере второе событие является дубликатом первого.

**Входные данные**  

| deviceId | Time | attribute | Значение |
| --- | --- | --- | --- |
| 1 |2018-07-27T00:00:01.0000000Z |температура; |50 |
| 1 |2018-07-27T00:00:01.0000000Z |температура; |50 |
| 2 |2018-07-27T00:00:01.0000000Z |температура; |40 |
| 1 |2018-07-27T00:00:05.0000000Z |температура; |60 |
| 2 |2018-07-27T00:00:05.0000000Z |температура; |50 |
| 1 |2018-07-27T00:00:10.0000000Z |температура; |100 |

**Выходные данные**:  

| AverageValue | deviceId |
| --- | --- |
| 70 | 1 |
|45 | 2 |

**Запрос.**

```SQL
With Temp AS (
SELECT
    COUNT(DISTINCT Time) AS CountTime,
    Value,
    DeviceId
FROM
    Input TIMESTAMP BY Time
GROUP BY
    Value,
    DeviceId,
    SYSTEM.TIMESTAMP()
)

SELECT
    AVG(Value) AS AverageValue, DeviceId
INTO Output
FROM Temp
GROUP BY DeviceId,TumblingWindow(minute, 5)
```

**COUNT(DISTINCT Time)** возвращает количество уникальных значений в столбце "Время" в течение определенного интервала. Затем выходные данные первого шага можно использовать для вычисления среднего значения для каждого устройства путем удаления дубликатов.

Дополнительные сведения см. в описании [COUNT(DISTINCT Time)](/stream-analytics-query/count-azure-stream-analytics).

## <a name="specify-logic-for-different-casesvalues-case-statements"></a>Указание логики для различных случаев и значений (операторы CASE)

Инструкции **CASE** могут предоставлять различные вычисления для разных полей на основе определенного критерия. Например, назначьте полосу "A" автомобилям *Make1*, а полосу "B" — всем остальным автомобилям.

**Входные данные**

| Убедитесь, | Time |
| --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |
| Make2 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:03.0000000Z |

**Выходные данные**:

| Убедитесь, |Dispatch_to_lane | Time |
| --- | --- | --- |
| Make1 |"A" |2015-01-01T00:00:01.0000000Z |
| Make2 |"B" |2015-01-01T00:00:02.0000000Z |

**Решение**

```SQL
SELECT
    Make
    CASE
        WHEN Make = "Make1" THEN "A"
        ELSE "B"
    END AS Dispatch_to_lane,
    System.TimeStamp() AS Time
FROM
    Input TIMESTAMP BY Time
```

Выражение **CASE** сравнивает выражение с набором простых выражений, чтобы определить их результат. В этом примере автомобили из *Make1* перенаправляются на полосу "A", а всем остальным автомобилям назначается полоса "B".

Дополнительные сведения см. в описании [выражения CASE](/stream-analytics-query/case-azure-stream-analytics).

## <a name="data-conversion"></a>Преобразование данных

Данные можно трансформировать в другие типы в режиме реального времени с помощью метода **CAST**. Например, вес автомобиля можно преобразовать из типа **nvarchar(max)** в тип **bigint** и использовать для числового вычисления.

**Входные данные**

| Убедитесь, | Time | Вес |
| --- | --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |"1000" |
| Make1 |2015-01-01T00:00:02.0000000Z |"2000" |

**Выходные данные**:

| Убедитесь, | Вес |
| --- | --- |
| Make1 |3000 |

**Запрос.**

```SQL
SELECT
    Make,
    SUM(CAST(Weight AS BIGINT)) AS Weight
FROM
    Input TIMESTAMP BY Time
GROUP BY
    Make,
    TumblingWindow(second, 10)
```

Используйте инструкцию **CAST**, чтобы указать тип данных. Ознакомьтесь со списком поддерживаемых [типов данных Azure Stream Analytics](/stream-analytics-query/data-types-azure-stream-analytics).

Дополнительные сведения см. в статье о [функции преобразования типов](/stream-analytics-query/conversion-functions-azure-stream-analytics).

## <a name="detect-the-duration-of-a-condition"></a>Определение продолжительности условия

Для условий, охватывающих несколько событий, продолжительность условия можно задать с помощью функции **LAG**. Предположим, произошла ошибка, которая привела к неправильному отображению массы всех автомобилей (больше 20 000 фунтов). Необходимо вычислить длительность ошибки.

**Входные данные**

| Убедитесь, | Time | Вес |
| --- | --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |2000 |
| Make2 |2015-01-01T00:00:02.0000000Z |25000 |
| Make1 |2015-01-01T00:00:03.0000000Z |26000 |
| Make2 |2015-01-01T00:00:04.0000000Z |25000 |
| Make1 |2015-01-01T00:00:05.0000000Z |26000 |
| Make2 |2015-01-01T00:00:06.0000000Z |25000 |
| Make1 |2015-01-01T00:00:07.0000000Z |26000 |
| Make2 |2015-01-01T00:00:08.0000000Z |2000 |

**Выходные данные**:

| Start_fault | End_fault |
| --- | --- |
| 2015-01-01T00:00:02.000Z |2015-01-01T00:00:07.000Z |

**Запрос.**

```SQL
WITH SelectPreviousEvent AS
(
SELECT
    *,
    LAG([time]) OVER (LIMIT DURATION(hour, 24)) as previous_time,
    LAG([weight]) OVER (LIMIT DURATION(hour, 24)) as previous_weight
FROM input TIMESTAMP BY [time]
)

SELECT 
    LAG(time) OVER (LIMIT DURATION(hour, 24) WHEN previous_weight < 20000 ) [Start_fault],
    previous_time [End_fault]
FROM SelectPreviousEvent
WHERE
    [weight] < 20000
    AND previous_weight > 20000
```
Первая инструкция **SELECT** выявляет корреляцию текущего измерения веса с предыдущим и проектирует его вместе с текущим измерением. Вторая инструкция **SELECT** ищет последнее событие, для которого *previous_weight* меньше 20 000, если текущий вес меньше 20 000, а *previous_weight* текущего события больше 20 000.

End_fault — текущее соответствующее условиям событие, если предыдущее событие не соответствовало условиям, а Start_fault — последнее соответствующее условиям событие перед ним.

## <a name="process-events-with-independent-time-substreams"></a>Обработка событий с независимым временем (подпотоки)

События могут поступать с опозданием или не по порядку из-за рассинхронизации часов поставщиков событий, секций или сетевой задержки.
Например, часы устройства для *TollID* 2 на пять секунд отстают от часов *TollID* 1, а часы *TollID* 3 отстают от *TollID* 1 на десять секунд. Вычисление для каждого пункта взимания дорожного сбора может выполняться независимо. При этом в качестве метки времени используются только данные собственных часов пункта.

**Входные данные**

| LicensePlate | Убедитесь, | Time | ИД пункта сбора |
| --- | --- | --- | --- |
| DXE 5291 |Make1 |2015-07-27T00:00:01.0000000Z | 1 |
| YHN 6970 |Make2 |2015-07-27T00:00:05.0000000Z | 1 |
| QYF 9358 |Make1 |2015-07-27T00:00:01.0000000Z | 2 |
| GXF 9462 |Make3 |2015-07-27T00:00:04.0000000Z | 2 |
| VFE 1616 |Make2 |2015-07-27T00:00:10.0000000Z | 1 |
| RMV 8282 |Make1 |2015-07-27T00:00:03.0000000Z | 3 |
| MDR 6128 |Make3 |2015-07-27T00:00:11.0000000Z | 2 |
| YZK 5704 |Make4 |2015-07-27T00:00:07.0000000Z | 3 |

**Выходные данные**:

| ИД пункта сбора | Count |
| --- | --- |
| 1 | 2 |
| 2 | 2 |
| 1 | 1 |
| 3 | 1 |
| 2 | 1 |
| 3 | 1 |

**Запрос.**

```SQL
SELECT
      TollId,
      COUNT(*) AS Count
FROM input
      TIMESTAMP BY Time OVER TollId
GROUP BY TUMBLINGWINDOW(second, 5), TollId
```

Предложение **TIMESTAMP BY OVER** обеспечивает независимый просмотр временной шкалы каждого устройства отдельно с помощью подпотоков. Исходящие события для каждого *TollID* создаются по мере их вычисления. Это означает, что события отображаются по порядку по отношению к каждому *TollID*, а не переупорядочиваются, как если бы часы всех устройств были синхронизированы.

Дополнительные сведения см. в описании [TIMESTAMP BY OVER](/stream-analytics-query/timestamp-by-azure-stream-analytics#over-clause-interacts-with-event-ordering).

## <a name="session-windows"></a>Сеансовые окна

Сеансовое окно — это окно, которое поддерживает расширение по мере возникновения событий и закрывается для вычислений, если после определенного промежутка времени не получено ни одного события или для окна достигнута максимальная длительность.
Это окно особенно удобно для расчета данных взаимодействия с пользователем. Окно запускается, когда пользователь начинает взаимодействовать с системой, и закрывается, когда события больше не наблюдаются, что означает, что пользователь прекратил взаимодействие.
Например, если пользователь взаимодействует с веб-страницей, для которой в журнал заносится число щелчков, сеансовое окно можно использовать для определения времени, в течение которого пользователь взаимодействует с сайтом.

**Входные данные**

| User_id | Time | URL-адрес |
| --- | --- | --- |
| 0 | 2017-01-26T00:00:00.0000000Z | "www.example.com/a.html" |
| 0 | 2017-01-26T00:00:20.0000000Z | "www.example.com/b.html" |
| 1 | 2017-01-26T00:00:55.0000000Z | "www.example.com/c.html" |
| 0 | 2017-01-26T00:01:10.0000000Z | "www.example.com/d.html" |
| 1 | 2017-01-26T00:01:15.0000000Z | "www.example.com/e.html" |

**Выходные данные**:

| User_id | StartTime | EndTime | Duration_in_seconds |
| --- | --- | --- | --- |
| 0 | 2017-01-26T00:00:00.0000000Z | 2017-01-26T00:01:10.0000000Z | 70 |
| 1 | 2017-01-26T00:00:55.0000000Z | 2017-01-26T00:01:15.0000000Z | 20 |

**Запрос.**

``` SQL
SELECT
    user_id,
    MIN(time) as StartTime,
    MAX(time) as EndTime,
    DATEDIFF(second, MIN(time), MAX(time)) AS duration_in_seconds
FROM input TIMESTAMP BY time
GROUP BY
    user_id,
    SessionWindow(minute, 1, 60) OVER (PARTITION BY user_id)
```

Инструкция **SELECT** проецирует данные, относящиеся к взаимодействию с пользователем, а также длительность взаимодействия. Группирование данных выполняется по пользователям и окнам **SessionWindow**, которые закрываются при отсутствии взаимодействия в течение 1 минуты с максимальным размером окна 60 минут.

Дополнительные сведения о **SessionWindow** см. в статье о [сеансовом окне](/stream-analytics-query/session-window-azure-stream-analytics).

## <a name="language-extensibility-with-user-defined-function-in-javascript-and-c"></a>Возможность расширения языка с помощью определяемой пользователем функции на JavaScript и C#

Язык запросов Azure Stream Analytics можно расширить с помощью пользовательских функций, написанных на языке JavaScript или C#. Определяемые пользователем функции — это пользовательские или сложные вычисления, которые нельзя легко выразить с помощью языка **SQL**. Эти пользовательские функции можно определить один раз, а затем многократно использовать в запросе. Например, определяемая пользователем функция может использоваться для преобразования шестнадцатеричного значения *nvarchar(max)* в значение *bigint*.

**Входные данные**

| Device_id | HexValue |
| --- | --- |
| 1 | "B4" |
| 2 | "11B" |
| 3 | "121" |

**Выходные данные**:

| Device_id | Decimal |
| --- | --- |
| 1 | 180 |
| 2 | 283 |
| 3 | 289 |

```JavaScript
function hex2Int(hexValue){
    return parseInt(hexValue, 16);
}
```

```C#
public static class MyUdfClass {
    public static long Hex2Int(string hexValue){
        return int.Parse(hexValue, System.Globalization.NumberStyles.HexNumber);
    }
}
```

```SQL
SELECT
    Device_id,
    udf.Hex2Int(HexValue) AS Decimal
From
    Input
```

Определяемая пользователем функция будет вычислять значение *bigint* на основе HexValue для каждого потребляемого события.

Дополнительные сведения см. в инструкциях по [JavaScript](/azure/stream-analytics/stream-analytics-javascript-user-defined-functions) и [C#](/azure/stream-analytics/stream-analytics-edge-csharp-udf).

## <a name="advanced-pattern-matching-with-match_recognize"></a>Расширенное сопоставление шаблонов с помощью MATCH_RECOGNIZE

**MATCH_RECOGNIZE** — это расширенный механизм сопоставления шаблонов, который можно использовать для сопоставления последовательности событий с точно определенным шаблоном регулярного выражения.
Например, если для банкомата получено два последовательных предупреждения, требующих уведомления администратора, для него активируется мониторинг в режиме реального времени.

**Входные данные**

| ATM_id | Operation_id | Return_Code | Time |
| --- | --- | --- | --- |
| 1 | "Ввод ПИН-кода" | Success | 2017-01-26T00:10:00.0000000Z |
| 2 | "Открытие щели выдачи купюр" | Success | 2017-01-26T00:10:07.0000000Z |
| 2 | "Закрытие щели выдачи купюр" | Success | 2017-01-26T00:10:11.0000000Z |
| 1 | "Ввод снимаемой суммы" | Success | 2017-01-26T00:10:08.0000000Z |
| 1 | "Открытие щели выдачи купюр" | "Предупреждение" | 2017-01-26T00:10:14.0000000Z |
| 1 | "Печать чека с остатком на счете" | "Предупреждение" | 2017-01-26T00:10:19.0000000Z |

**Выходные данные**:

| ATM_id | First_Warning_Operation_id | Warning_Time |
| --- | --- | --- |
| 1 | "Открытие щели выдачи купюр" | 2017-01-26T00:10:14.0000000Z |

```SQL
SELECT *
FROM input TIMESTAMP BY time OVER ATM_id
MATCH_RECOGNIZE (
    LIMIT DURATION(minute, 1)
    PARTITON BY ATM_id
    MEASURES
        First(Warning.ATM_id) AS ATM_id,
        First(Warning.Operation_Id) AS First_Warning_Operation_id,
        First(Warning.Time) AS Warning_Time
    AFTER MATCH SKIP TO NEXT ROW
    PATTERN (Success* Warning{2,})
    DEFINE
        Success AS Succes.Return_Code = 'Success',
        Failure AS Warning.Return_Code <> 'Success'
) AS patternMatch
```

Этот запрос соответствует по крайней мере двум последовательным событиям сбоя и создает оповещение при выполнении условий.
**PATTERN** определяет регулярное выражение, которое будет использоваться при сопоставлении. В данном случае это любое количество успешных операций, за которыми следует по крайней мере два последовательных сбоя.
Успешное выполнение и сбой определяются с помощью значения Return_Code и после выполнения условия **MEASURES** проецируются со значением *ATM_id*, первой операцией с предупреждением и временем первого предупреждения.

Дополнительные сведения см. в описании [MATCH_RECOGNIZE](/stream-analytics-query/match-recognize-stream-analytics).

## <a name="geofencing-and-geospatial-queries"></a>Геозоны и геопространственные запросы

Azure Stream Analytics предоставляет встроенные геопространственные функции, которые можно использовать для реализации таких сценариев, как управление парком, обеспечение общего доступа к маршрутам, организация работы подключенных автомобилей и отслеживание ресурсов.
Геопространственные данные могут быть приняты в формате GeoJSON или WKT в составе потока событий или ссылочных данных.
Например, компания, которая специализируется на производстве устройств для печати паспортов, может сдавать их в аренду государственным организациям и консульствам. Расположение этих устройств жестко контролируется во избежание незаконного перемещения и потенциального использования для подделки паспортов. Каждое устройство оснащено GPS-трекером, который возвращает информацию в задание Azure Stream Analytics.
Производитель хотел бы отслеживать расположение этих устройств и получать оповещения, если какое-либо из них покинет санкционированную область, чтобы иметь возможность удаленно его отключить, предупредить уполномоченные органы и вернуть себе оборудование.

**Входные данные**

| Equipment_id | Equipment_current_location | Time |
| --- | --- | --- |
| 1 | "POINT(-122.13288797982818 47.64082002051315)" | 2017-01-26T00:10:00.0000000Z |
| 1 | "POINT(-122.13307252987875 47.64081350934929)" | 2017-01-26T00:11:00.0000000Z |
| 1 | "POINT(-122.13308862313283 47.6406508603241)" | 2017-01-26T00:12:00.0000000Z |
| 1 | "POINT(-122.13341048821462 47.64043760861279)" | 2017-01-26T00:13:00.0000000Z |

**Входные ссылочные данные**

| Equipment_id | Equipment_lease_location |
| --- | --- |
| 1 | "POLYGON((-122.13326028450979 47.6409833866794,-122.13261655434621 47.6409833866794,-122.13261655434621 47.64061471602751,-122.13326028450979 47.64061471602751,-122.13326028450979 47.6409833866794))" |

**Выходные данные**:

| Equipment_id | Equipment_alert_location | Time |
| --- | --- | --- |
| 1 | "POINT(-122.13341048821462 47.64043760861279)" | 2017-01-26T00:13:00.0000000Z |

```SQL
SELECT
    input.Equipment_id AS Equipment_id,
    input.Equipment_current_location AS Equipment_current_location,
    input.Time AS Time
FROM input TIMESTAMP BY time
JOIN
    referenceInput 
    ON input.Equipment_id = referenceInput.Equipment_id
    WHERE 
        ST_WITHIN(input.Equipment_currenct_location, referenceInput.Equipment_lease_location) = 1
```

Запрос позволяет производителю автоматически отслеживать расположение устройств и получать оповещения при выходе устройства из разрешенной геозоны. Встроенная геопространственная функция позволяет пользователям использовать данные GPS в запросе без библиотек сторонних производителей.

Дополнительные сведения см. в статье [Сценарии геозоны и геопространственного агрегирования с Azure Stream Analytics](geospatial-scenarios.md).

## <a name="get-help"></a>Получить справку

Для получения дополнительной помощи воспользуйтесь [страницей вопросов и ответов по Azure Stream Analytics на сайте Майкрософт](https://docs.microsoft.com/answers/topics/azure-stream-analytics.html).

## <a name="next-steps"></a>Дальнейшие действия
* [Введение в Azure Stream Analytics](stream-analytics-introduction.md)
* [Приступая к работе с Azure Stream Analytics](stream-analytics-real-time-fraud-detection.md)
* [Масштабирование заданий в службе Azure Stream Analytics](stream-analytics-scale-jobs.md)
* [Справочник по языку запросов Azure Stream Analytics](https://docs.microsoft.com/stream-analytics-query/stream-analytics-query-language-reference)
* [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)
