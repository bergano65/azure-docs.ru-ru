---
title: Выходные данные Azure Stream Analytics в Cosmos DB
description: Из этой статьи вы узнаете, как с помощью Azure Stream Analytics сохранять выходные данные в Azure Cosmos DB в формате JSON, что позволяет архивировать данные и уменьшать задержки запросов в отношении неструктурированных данных JSON.
services: stream-analytics
author: mamccrea
ms.author: mamccrea
ms.reviewer: mamccrea
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 01/11/2019
ms.custom: seodec18
ms.openlocfilehash: 734cf09869e5a2df5f9a505a3cb8ccc7bc2338d5
ms.sourcegitcommit: c174d408a5522b58160e17a87d2b6ef4482a6694
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/18/2019
ms.locfileid: "59495982"
---
# <a name="azure-stream-analytics-output-to-azure-cosmos-db"></a>Выходные данные Azure Stream Analytics в Azure Cosmos DB  
Stream Analytics позволяет направлять данные из [Azure Cosmos DB](https://azure.microsoft.com/services/documentdb/) в формат JSON, позволяя архивировать данные и уменьшать задержки запросов в отношении неструктурированных данных JSON. В этом документе представлены некоторые рекомендации по реализации данной конфигурации.

Тем, кто не знаком с Cosmos DB, мы рекомендуем просмотреть [схему обучения работе с Azure Cosmos DB](https://azure.microsoft.com/documentation/learning-paths/documentdb/). 

> [!Note]
> В настоящее время Azure Stream Analytics поддерживает соединение только с Azure Cosmos DB при помощи **SQL API**.
> Другие API Azure Cosmos DB в данный момент не поддерживаются. Если указать модулю Azure Stream Analytics учетные записи Azure Cosmos DB, созданные при помощи других API, это может привести к неправильному сохранению данных. 

## <a name="basics-of-cosmos-db-as-an-output-target"></a>Основные сведения о Cosmos DB как объекте вывода данных
Использование выходных данных Azure Cosmos DB в Stream Analytics позволяет записывать результаты обработки потока данных в коллекцию Cosmos DB в формате JSON. Stream Analytics не создает коллекции в базе данных. Их требуется создавать заранее. Благодаря этому вы контролируете выставление счетов за использование коллекций Cosmos DB. Кроме того, вы можете регулировать производительность, целостность и емкость своих коллекций напрямую с помощью [API-интерфейсов Cosmos DB](https://msdn.microsoft.com/library/azure/dn781481.aspx).

> [!Note]
> Необходимо добавить 0.0.0.0 в список разрешенных IP-адресов брандмауэра Azure Cosmos DB.

Ниже приведены некоторые параметры коллекций Cosmos DB.

## <a name="tune-consistency-availability-and-latency"></a>Настройка согласованности, доступности и задержки
Для соответствия требованиям вашего приложения, Azure Cosmos DB позволяет точно настроить базу данных и коллекции и отрегулировать уровень согласованности, доступности и задержки. В зависимости от того, какие уровни согласованности чтения потребуются вашему сценарию для чтения и записи задержки, вы можете выбирать уровень согласованности в своей учетной записи базы данных. Кроме того, Azure Cosmos DB по умолчанию активирует синхронное индексирование для каждой операции CRUD в вашей коллекции. Это еще один полезный параметр для контроля производительности операций чтения и записи в Azure Cosmos DB. Дополнительные сведения см. в статье об [изменении уровней согласованности в для базы данных и запросов](../cosmos-db/consistency-levels.md).

## <a name="upserts-from-stream-analytics"></a>Вставка и обновление Upsert в Stream Analytics
Интеграция Stream Analytics с Azure Cosmos DB позволяет вставлять или обновлять записи в коллекции с помощью заданного столбца идентификатора документа. Этот процесс называется также *Upsert*.

Stream Analytics использует оптимистичный подход Upsert, при котором обновления выполняются только тогда, когда операция вставки завершается ошибкой из-за конфликта с идентификатором документа. С помощью 1.0 уровень совместимости это обновление выполняется как исправление, поэтому оно допускает частичное обновление к документу, то есть, добавление новых свойств или замена существующего свойства выполняется постепенно. Тем не менее изменение значений свойств массива в документе JSON приводит к перезаписи всего массива, то есть массивы не объединяются. С версии 1.2 поведение upsert изменяется для вставки или замены документа. Это описано далее в разделе 1.2 уровень совместимости ниже.

Если входящий документ JSON содержит существующее поле идентификатора, это поле автоматически используется в качестве столбца идентификаторов документов в Cosmos DB и все последующие операции записи обрабатываются следующим образом:
- для уникальных идентификаторов выполняется вставка;
- если для повторяющихся идентификаторов и параметра Document ID задано значение "ID", выполняется операция upsert;
- если для повторяющихся идентификаторов и параметра Document ID не задано значение, после первого документа возникает ошибка.

Если вы хотите сохранить <i>все</i> документы, включая документы с повторяющимся идентификатором, переименуйте поле идентификатора в запросе (с ключевым словом AS) и разрешите Cosmos DB автоматически создавать поле идентификатора или заменять идентификатор значением из другого столбца (с помощью ключевого слова AS или с помощью параметра Document ID).

## <a name="data-partitioning-in-cosmos-db"></a>Секционирование данных в Cosmos DB
[Неограниченные](../cosmos-db/partition-data.md) контейнеры для Azure Cosmos DB — это рекомендуемый способ секционирования данных, так как Azure Cosmos DB автоматически масштабирует разделы на основе рабочей нагрузки. При записи в неограниченные контейнеры Stream Analytics используется столько же параллельных модулей записи, сколько и на предыдущем шаге запроса или в схеме разбиения входных данных.
> [!Note]
> В настоящее время Azure Stream Analytics поддерживает только неограниченные коллекции с ключами разделов на верхнем уровне. Например, `/region` поддерживается. Вложенные ключи разделов (например, `/region/name`) не поддерживаются. 

Фиксированные коллекции Azure Cosmos DB Stream Analytics не позволяет увеличить или уменьшить, когда они уже полные. Верхний предел их пропускной способности: 10 ГБ и 10 000 ЕЗ/с.  Чтобы перенести данные из контейнера фиксированного размера в контейнер неограниченного размера (например, с ключом секции и пропускной способностью не менее 1000 ЕЗ/с), вам нужно использовать [средство миграции данных](../cosmos-db/import-data.md) или [библиотеку канала изменений](../cosmos-db/change-feed.md).

Запись в несколько фиксированных контейнеров устарела и не является рекомендуемым подходом для масштабирования вашего задания Stream Analytics. Подробные сведения об этом есть также в статье о [секционировании и масштабировании в Cosmos DB](../cosmos-db/sql-api-partition-data.md).

## <a name="improved-throughput-with-compatibility-level-12"></a>Повышенная пропускная способность с 1.2 уровень совместимости
При уровне совместимости 1.2 естественная интеграция Stream Analytics поддерживает массовое записи в Cosmos DB. Это позволяет эффективно запись Cosmos DB с помощью максимальное увеличение пропускной способности и эффективно запросы на регулирование дескриптор. Улучшенная записи механизм доступен в разделе на новый уровень совместимости, из-за разницы поведения upsert.  Прежде чем 1.2 поведение upsert — Вставка или слияние документа. С версии 1.2 поведение операции Upsert изменяется для вставки или замены документа. 

Прежде чем 1.2 использует пользовательскую хранимую процедуру для массовой вставки-обновления документов на ключ секции в Cosmos DB, куда будут записываться пакет как транзакцию. Даже в том случае, когда единственную запись достигает временная ошибка (регулирования), должна быть повторена весь пакет. Это затрудняло сценариев с помощью даже разумным регулирования относительно медленнее. Выполнив сравнение показано, как будет вести себя такие задания с версии 1.2.

Описанный далее порядок установки показаны две идентичные задания Stream Analytics, чтения из того же входа (концентратора событий). Оба задания Stream Analytics, [полностью секционированный](https://docs.microsoft.com/azure/stream-analytics/stream-analytics-parallelization#embarrassingly-parallel-jobs) с транзитный запрос и запись в коллекции идентичные CosmosDB. Метрики в левой части из задания, настроенного с уровнем совместимости 1.0 и настроены на правом 1.2. Ключ раздела коллекции Cosmos DB — уникальный идентификатор guid, поступающих из входного события.

![Сравнение метрик Stream analytics](media/stream-analytics-documentdb-output/stream-analytics-documentdb-output-3.png)

Интенсивность поступления событий в концентраторе событий имеет два раза выше, чем коллекций Cosmos DB (20 тысяч RUs) настроены для принимать, поэтому регулирования ожидается в Cosmos DB. Тем не менее задание с версии 1.2, постоянно производит запись в более высокую пропускную способность (выходные данные событий в минуту), используя ниже среднего использования единиц потоковой Передачи-%. В вашей среде эта разница будет зависеть от несколько дополнительных факторов, таких как выбор формат событий, размер входного события и сообщения, ключи секции, запроса и т.д.

![Сравнение метрик Cosmos db](media/stream-analytics-documentdb-output/stream-analytics-documentdb-output-2.png)

С версии 1.2 Stream Analytics более разумно использовать 100% доступная пропускная способность в Cosmos DB с очень мало resubmissions из ограничения регулирования частоты. Это обеспечивает удобство работы для других рабочих нагрузок, таких как запросы, выполняемые на коллекцию, в то же время. Если вам нужно опробовать как ASA масштабируется с помощью Cosmos DB как приемник для 1-10 тысяч сообщений/сек, вот [проект azure образцов](https://github.com/Azure-Samples/streaming-at-scale/tree/master/eventhubs-streamanalytics-cosmosdb) позволяет сделать.
Обратите внимание на то, что пропускная способность вывода Cosmos DB идентичен 1.0 и 1.1. Поскольку 1.2 в настоящее время не используется по умолчанию, вы можете [установить уровень совместимости](https://docs.microsoft.com/azure/stream-analytics/stream-analytics-compatibility-level) для задания Stream Analytics с помощью портала или с помощью [создания вызова REST API задания](https://docs.microsoft.com/rest/api/streamanalytics/stream-analytics-job). Он имеет *настоятельно рекомендуется* использование 1.2 уровень совместимости в ASA с помощью Cosmos DB. 



## <a name="cosmos-db-settings-for-json-output"></a>Параметры Cosmos DB для выходных данных JSON

При создании Cosmos DB как средства обработки выходных данных в Stream Analytics создается запрос информации, показанный ниже. В этом разделе объясняются определения свойств.

![экран выходных данных documentdb stream analytics](media/stream-analytics-documentdb-output/stream-analytics-documentdb-output-1.png)

|Поле           | ОПИСАНИЕ|
|-------------   | -------------|
|Псевдоним выходных данных    | Псевдоним для ссылки на эти выходные данные в запросе ASA.|
|Подписка    | Выберите подписку Azure.|
|Идентификатор учетной записи      | Имя или универсальный код ресурса (URI) конечной точки учетной записи Azure Cosmos DB.|
|Ключ учетной записи     | Общедоступный ключ доступа к учетной записи Azure Cosmos DB.|
|База данных        | Имя базы данных Azure Cosmos DB.|
|Шаблон имен коллекций | Имя для используемой коллекции. `MyCollection` — это пример допустимых входных данных; должна существовать одна коллекция с именем `MyCollection`.  |
|Идентификатор документа     | Необязательный элемент. Имя столбца в выходных событиях используется как уникальный ключ, на котором должны основываться операции вставки или обновления. Если оставить это поле пустым, все события будут вставлены, без возможности обновления.|
