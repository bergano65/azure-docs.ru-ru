---
title: Как работает Azure Dev пробелы и является настроен
titleSuffix: Azure Dev Spaces
services: azure-dev-spaces
ms.service: azure-dev-spaces
ms.component: azds-kubernetes
author: zr-msft
ms.author: zarhoads
ms.date: 03/04/2019
ms.topic: conceptual
description: Описывает процессы пробелы разработки Azure, power и как они настроены в файле конфигурации azds.yaml
keywords: azds.yaml, пробелы разработки Azure, разработки пробелы, Docker, Kubernetes, Azure, AKS, служба Azure Kubernetes, контейнеры
ms.openlocfilehash: 0397a52e8cd838aafe44a35508f8a68caba4c94e
ms.sourcegitcommit: 6e32f493eb32f93f71d425497752e84763070fad
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/10/2019
ms.locfileid: "59470905"
---
# <a name="how-azure-dev-spaces-works-and-is-configured"></a>Как работает Azure Dev пробелы и является настроен

Разработка приложения Kubernetes может оказаться сложной задачей. Требуется файл конфигурации Docker и Kubernetes. Необходимо выяснить, как тестировать приложения локально и взаимодействовать с другими зависимые службы. Может потребоваться для обработки разработки и тестирования на нескольких службах за один раз и с командой разработчиков.

Azure пробелы разработки помогает разработку, развертывание и отладка приложений Kubernetes непосредственно в Azure Kubernetes Service (AKS). Azure пробелы разработки позволяет группе совместно используют пространство разработки. Совместное использование пространстве разработки в группе позволяет отдельным сотрудникам группы разрабатывать изолированно, без необходимости реплицировать или макетирования зависимостей и других приложений в кластере.

Azure пробелы разработки создает и использует файл конфигурации для развертывания, запуск и отладка приложений Kubernetes в AKS. Этот файл конфигурации находится код приложения и добавляются в систему управления версиями.

В этой статье описываются процессы пробелы разработки Azure, power и как эти процессы настроены в файле конфигурации пробелы разработки Azure. Чтобы получить быстрый запуск пробелы разработки Azure и увидеть, как это на практике, выполните одно из кратких руководств:

* [Java с помощью интерфейса командной строки и Visual Studio Code](quickstart-java.md)
* [.NET core с помощью CLI и Visual Studio Code](quickstart-netcore.md)
* [.NET core в Visual Studio 2017](quickstart-netcore-visualstudio.md)
* [Node.js с использованием интерфейса командной строки и Visual Studio Code](quickstart-nodejs.md)

## <a name="how-azure-dev-spaces-works"></a>Как работает Azure Dev пробелы

Azure пробелы разработки состоит из двух компонентов, которые взаимодействуют с: контроллер и инструментарий на стороне клиента.

![Компоненты Azure Dev пробелы](media/how-dev-spaces-works/components.svg)

Контроллер выполняет следующие действия:

* Управляет созданием пространство разработки и выбора.
* Устанавливает диаграмму Helm приложения и создает объекты Kubernetes.
* Создает образ контейнера приложения.
* Развертывает приложение AKS.
* Не инкрементные сборки и перезапускает при изменении исходного кода.
* Управляет журналы и трассировки HTTP.
* Перенаправляет stdout и stderr в инструментарий на стороне клиента.
* Позволяет членам команды создавать дочерние пробелы разработки, производным от разработки родительское пространство.
* Настройка маршрутизации для приложений, в пространстве, а также между родительскими и дочерними пробелы.

Контроллер находится за пределами AKS. Они влияют поведение и обмен данными между инструментарий на стороне клиента и кластером AKS. Контроллер включается с помощью Azure CLI, при подготовке кластера, чтобы использовать пробелы разработки Azure. После того как он включен, вы можете взаимодействовать с ним с помощью клиентского средства.

Инструментарий на стороне клиента позволяет пользователю:
* Создать файл Dockerfile, диаграмме Helm и файл конфигурации Azure Dev пробелы для приложения.
* Создание родительской и дочерней разработки пробелы.
* Сообщите контроллеру, чтобы создать и запустить приложение.

Пока выполняется приложение, клиентского средства также:
* Получает и отображает stdout и stderr из вашего приложения, работающего в AKS.
* Использует [прямого порта](https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/) для разрешения веб-доступа в приложение с помощью http:\//localhost.
* Присоединяет отладчик к запущенному приложению в AKS.
* Операции синхронизации в исходном коде свою область разработки при обнаружении изменения для инкрементных построений, обеспечивая быструю итерацию.

Можно использовать средства из командной строки как часть клиентской стороне `azds` команды. Можно также использовать клиентского средства с:

* С помощью Visual Studio Code [пробелы разработки Azure расширение](https://marketplace.visualstudio.com/items?itemName=azuredevspaces.azds).
* Visual Studio 2017 с [Visual Studio Tools for Kubernetes](https://aka.ms/get-vsk8stools).

Ниже приведен базовый поток по настройке и использовании пространств разработки Azure.
1. Подготовка кластера AKS пробелов разработки Azure
1. Подготовка кода для запуска на пробелы разработки Azure
1. Выполнять код в сфере разработки
1. Отладить код в пространстве разработки
1. Совместно используют пространство разработки

Будут рассмотрены подробнее, как работает Azure Dev пробелы в каждом из следующих разделах.

## <a name="prepare-your-aks-cluster"></a>Подготовка кластера AKS

Подготовка кластера AKS включает:
* Проверка вашего AKS кластер находится в регионе [поддерживается пробелами разработки Azure](https://docs.microsoft.com/azure/dev-spaces/#a-rapid,-iterative-kubernetes-development-experience-for-teams).
* Проверка того, работающих под управлением Kubernetes 1.10.3 или более поздней версии.
* Включение кластера с помощью пробелов разработки Azure `az aks use-dev-spaces`

Дополнительные сведения о том, как создать и настроить кластер AKS пробелов разработки Azure см. в одном из руководства по началу работы:
* [Начало работы в Azure Dev Spaces с использованием Java](get-started-java.md)
* [Начало работы в Azure Dev Spaces и .NET Core и Visual Studio](get-started-netcore-visualstudio.md)
* [Начало работы в Azure Dev Spaces с .NET Core](get-started-netcore.md)
* [Начало работы в Azure Dev Spaces с Node.js](get-started-nodejs.md)

Если пробелы разработки Azure включена в кластере AKS, он устанавливает контроллер для кластера. Контроллер — это отдельный ресурс Azure вне кластера и выполняет указанные ниже к ресурсам кластера:

* Создает или определяет пространство имен Kubernetes для использования в качестве пространстве разработки.
* Удаляет любое пространство имен Kubernetes с именем *azds*, если он существует и создает новую.
* Развертывает объект инициализатора Kubernetes.

Он также использует один и тот же субъект службы, использующего кластера AKS для выполнения вызовов службы для других компонентов Azure Dev пробелы.

![Azure Dev пространств Подготовьте кластера](media/how-dev-spaces-works/prepare-cluster.svg)

Для использования пробелов разработки Azure, должна быть по крайней мере один пробел разработки. Azure пробелы разработки использует пространств имен Kubernetes в кластере AKS для разработки пробелы. При установке контроллера появится запрос для создания нового пространства имен Kubernetes или выберите существующее пространство имен для использования в качестве первое пространство разработки. Если пространство имен используется в качестве пространстве разработки, контроллер будет добавлять *azds.io/space=true* метку для этого пространства имен, чтобы он определялся как пространстве разработки. После подготовки кластера по умолчанию выбран пространстве начальной разработки, создать или указать. При выборе пробел, он используется пробелами разработки Azure для создания новых рабочих нагрузок.

По умолчанию контроллер создает область разработки с именем *по умолчанию* путем обновления существующего *по умолчанию* пространств имен Kubernetes. Можно использовать клиентские средства для создания новой разработки пробелы и удалять существующие разработки пробелы. Из-за ограничений в Kubernetes *по умолчанию* пространстве разработки нельзя удалить. Контроллер также удаляет все существующие пространства имен Kubernetes с именем *azds* для предотвращения конфликтов с `azds` команда, используемая с инструментарием стороне клиента.

Объект инициализатора Kubernetes используется для добавления модулей POD с тремя контейнерами во время развертывания для инструментирования: контейнер devspaces прокси, devspaces прокси init контейнер и контейнер devspaces сборки. **Все три эти контейнеры выполняются корневой доступ в кластере AKS.** Они также используют один и тот же субъект службы, использующего кластера AKS для выполнения вызовов службы для других компонентов Azure Dev пробелы.

![Azure Kubernetes пробелы разработки инициализатора](media/how-dev-spaces-works/kubernetes-initializer.svg)

Контейнер devspaces для прокси-сервера является сопроводительным контейнером, который обрабатывает весь трафик TCP в и из нее контейнер приложения и позволяет выполнять маршрутизацию. Контейнер devspaces прокси перенаправляет HTTP-сообщений при использовании определенных пробелы. Например он может помочь маршрутизировать сообщения HTTP между приложениями в родительских и дочерних пространствах. Все отличные от HTTP-трафик проходит через devspaces-прокси-сервер без изменений. Контейнер devspaces для прокси-сервера также регистрирует все входящие и исходящие сообщения HTTP и отправляет их на стороне клиента, средства в виде трассировок. Затем можно просмотреть эти данные трассировки разработчиком для проверки поведения приложения.

Контейнер devspaces прокси init — [контейнера init](https://kubernetes.io/docs/concepts/workloads/pods/init-containers/) , добавляющий Дополнительные правила маршрутизации на основе иерархии пространства для контейнера этого приложения. Он добавляет правила маршрутизации, обновив контейнер приложения */etc/resolv.conf* файл и iptables конфигурации перед его запуском. Обновления для */etc/resolv.conf* разрешить для разрешения DNS служб в родительский пробелы. Обновления конфигурации iptables убедитесь весь трафик TCP в и из приложения контейнера направляются хотя devspaces для прокси-сервера. Все обновления devspaces прокси init происходят в дополнение к правилам добавляет Kubernetes.

Контейнер сборки devspaces контейнер init и содержит исходный код проекта и подключить сокет Docker. Исходный код проекта и доступ к Docker позволяет контейнер приложения, сборка которого будет выполняться непосредственно pod.

> [!NOTE]
> Azure пробелы разработки используется один узел для создания контейнера приложения и запустите его. Таким образом пробелы разработки Azure не обязательно в реестре внешних контейнеров для построения и выполнения приложения.

Инициализатор объекта Kubernetes ожидает передачи данных для любой новой pod, созданный в кластере AKS. Которой развертывается на любое пространство имен с *azds.io/space=true* метки, он внедряет этот pod с дополнительные контейнеры. Контейнер сборки devspaces внедряется только в том случае, если контейнер приложения выполняется с помощью клиентского средства.

После подготовки кластера AKS, можно использовать клиентские средства для подготовки и выполнения кода в области разработки.

## <a name="prepare-your-code"></a>Подготовка кода

Чтобы запустить приложение в области разработки, он должен помещать в контейнеры, и необходимо определить способ его развертывания в Kubernetes. Для контейнеризации приложения, требуется файл Dockerfile. Чтобы определить, как приложение развертывается в Kubernetes, вам потребуется [чарта Helm](https://docs.helm.sh/). Чтобы помочь в создании диаграммы Helm и файл Dockerfile для вашего приложения, укажите клиентских средств `prep` команды:

```cmd
azds prep --public
```

`prep` Команда будет проверять файлы в проекте и попытке создать диаграмму Helm и файл Dockerfile для выполнения приложений в Kubernetes. В настоящее время `prep` команда будет создана диаграмма Helm и файл Dockerfile со следующими языками:

* Java
* Node.js
* .NET Core

Вы *необходимо* запуска `prep` команду из каталога, который содержит исходный код. Под управлением `prep` команда из правильного каталога разрешает клиентские инструментарий для идентификации языка и создать соответствующие Dockerfile, чтобы поместить приложение на базе. Можно также запустить `prep` команду из каталога, который содержит *pom.xml* файл для проектов Java.

При запуске `prep` команду из каталога, содержащего исходный код, инструментарий на стороне клиента не будет создавать файл Dockerfile. Он также будет отображаться ошибка: *Не удалось создать файл Dockerfile из-за неподдерживаемый язык*. Эта ошибка также возникает в том случае, если инструментарий на стороне клиента не распознает тип проекта.

При запуске `prep` команды, у вас есть возможность указать `--public` флаг. Этот флаг сообщает на контроллере, чтобы создать конечную точку доступном через Интернет для этой службы. Если этот флаг не указан, служба доступна только в пределах кластера или с помощью туннеля localhost, созданный инструментарий на стороне клиента. Можно включить или отключить это поведение после выполнения команды `prep` команду, обновив созданный чарта Helm.

`prep` Команды не приведет к замене всех существующих файлов Dockerfile или Helm диаграмм в проекте. Если в существующей диаграммой Dockerfile или Helm используется то же соглашение об именовании файлов, создаваемых `prep` команде `prep` команда пропустит Создание этих файлов. В противном случае `prep` команда будет создавать собственный Dockerfile или Helm диаграммы вдоль стороны существующих файлов.

`prep` Команда также создаст `azds.yaml` файл в корне проекта. Azure пробелы разработки использует этот файл для сборки, установить, настроить и запустить приложение. Этот файл конфигурации отображает расположение диаграммы Helm и файл Dockerfile, а также предоставляет дополнительную настройку на основе этих артефактов.

Ниже приведен пример файла azds.yaml, созданных с помощью [пример приложения .NET Core](https://github.com/Azure/dev-spaces/tree/master/samples/dotnetcore/getting-started/webfrontend):

```yaml
kind: helm-release
apiVersion: 1.1
build:
  context: .
  dockerfile: Dockerfile
install:
  chart: charts/webfrontend
  values:
  - values.dev.yaml?
  - secrets.dev.yaml?
  set:
    replicaCount: 1
    image:
      repository: webfrontend
      tag: $(tag)
      pullPolicy: Never
    ingress:
      annotations:
        kubernetes.io/ingress.class: traefik-azds
      hosts:
        # This expands to [space.s.][rootSpace.]webfrontend.<random suffix>.<region>.azds.io
        # Customize the public URL by changing the 'webfrontend' text between the $(rootSpacePrefix) and $(hostSuffix) tokens
        # For more information see https://aka.ms/devspaces/routing
        - $(spacePrefix)$(rootSpacePrefix)webfrontend$(hostSuffix)
configurations:
  develop:
    build:
      dockerfile: Dockerfile.develop
      useGitIgnore: true
      args:
        BUILD_CONFIGURATION: ${BUILD_CONFIGURATION:-Debug}
    container:
      sync:
      - "**/Pages/**"
      - "**/Views/**"
      - "**/wwwroot/**"
      - "!**/*.{sln,csproj}"
      command: [dotnet, run, --no-restore, --no-build, --no-launch-profile, -c, "${BUILD_CONFIGURATION:-Debug}"]
      iterate:
        processesToKill: [dotnet, vsdbg]
        buildCommands:
        - [dotnet, build, --no-restore, -c, "${BUILD_CONFIGURATION:-Debug}"]
```

`azds.yaml` Файла, созданного `prep` команда должна работать нормально для простой и единый проект сценария разработки. Если данного конкретного проекта выросла сложности, может потребоваться обновить этот файл после выполнения команды `prep` команды. Например проект может необходима определенная Ручная настройка в сборку или запустить процесс основан на разработку или отладка должна. Также возможно несколько приложений в проекте, требующих несколько процессов сборки или содержимое другой сборки.

## <a name="run-your-code"></a>Выполнения кода

Для выполнения кода в пространстве разработки, выдавать `up` команду в том же каталоге, что ваш `azds.yaml` файла:

```cmd
azds up
```

`up` Команда передает исходные файлы приложения и другие артефакты, необходимые для сборки и запуска проекта в области разработки. После этого контроллера в своем пространстве разработки:

1. Создаются объекты Kubernetes для развертывания приложения.
1. Создает контейнер для вашего приложения.
1. Развертывает приложение в области разработки.
1. Создает общедоступный DNS-имя для конечной точки приложения, если настроен.
1. Использует *прямого порта* для предоставления доступа к конечной точке приложения с помощью http://locahost.
1. Перенаправляет stdout и stderr в инструментарий на стороне клиента.


### <a name="starting-a-service"></a>Запуск службы

При запуске службы в области разработки, инструментарий на стороне клиента и контроллера работать совместно для синхронизации исходных файлов, создать контейнер и объекты Kubernetes и запуска приложения.

На более детальном уровне, вот что происходит при запуске `azds up`:

1. Файлы синхронизируются с компьютера пользователя к хранилищу файлов Azure, которое является уникальным для пользователя кластера AKS. Исходный код, диаграмма Helm и файлы конфигурации загружаются. Дополнительные сведения о процессе синхронизации можно найти в следующем разделе.
1. Контроллер создает запрос на запуск нового сеанса. Этот запрос содержит несколько свойств, включая уникальный идентификатор, имя пространства, путь к исходному коду и отладки флаг.
1. Заменяет контроллера *$(tag)* заполнитель в диаграмме Helm с уникальный идентификатор сеанса и устанавливает диаграмму Helm для своей службы. Добавляя ссылку на уникальный идентификатор сеанса в диаграмму Helm позволяет контейнеру развертывается в кластере AKS для данного конкретного сеанса, должны быть привязаны к запрос сеанса и связанные сведения.
1. Во время установки чарта Helm инициализатор объекта Kubernetes добавляет дополнительных контейнеров pod приложения для инструментирования и доступа к исходному коду проекта. Для предоставления трассировки HTTP и маршрутизация пространства добавляются devspaces для прокси-сервера и контейнеров devspaces прокси init. Контейнер сборки devspaces добавляется для предоставления pod с доступом к экземпляру Docker и исходный код проекта для создания контейнера приложения.
1. При запуске приложения pod контейнер сборки devspaces и devspaces прокси init контейнера используются для создания контейнера приложения. Затем запускаются в контейнер приложения и контейнеры devspaces для прокси-сервера.
1. После запуска приложения контейнера клиентские функции используется Kubernetes *прямого порта* функциональные возможности для обеспечения доступа к приложению по протоколу HTTP через http://localhost. Это перенаправление портов компьютера разработки подключается к службе в области разработки.
1. После запуска всех контейнеров в pod, служба будет работать. На этом этапе клиентские функции начинает выполнять потоковую передачу трассировок HTTP, stdout и stderr. Эта информация отображается по клиентские функции для разработчиков.

### <a name="updating-a-running-service"></a>Обновление работающей службы

Во время работы службы Azure Dev пробелы имеет возможность обновления этой службы, при изменении любого из исходных файлов проекта. Пробелы разработки также обрабатывает обновление службы по-разному в зависимости от типа файла, который изменяется. Существует три способа разработки пробелы можно обновить работающую службу:

* Прямое обновление файла
* Перестроение и перезапустить процесс приложения внутри контейнера, работающем приложении
* Перестройки и повторного развертывания приложения-контейнера

![Служба синхронизации файлов Azure Dev пробелы](media/how-dev-spaces-works/file-sync.svg)

Определенные файлы проекта, статические ресурсы, такие как html, css и cshtml-файлы, можно обновить непосредственно в контейнере приложения без перезапуска ничего. Если изменяется статических активов, новый файл синхронизации в области разработки и затем использовать в выполняемом контейнере.

Изменения в файлы, такие как исходный код или файлы конфигурации приложений могут применяться приложения процесс в работающем контейнере. После синхронизации эти файлы внутри контейнера с помощью перезапуска процесса приложения *devhostagent* процесса. При первоначальном создании приложения-контейнера, контроллер заменяет команду запуска приложения другой процесс, называемый *devhostagent*. Фактический процесс приложения затем выполнены как дочерний процесс под *devhostagent*, и его выходные данные перенаправляются с помощью *devhostagent*выходных данных. *Devhostagent* процесс также является частью разработки пробелы и позволяет выполнять команды в выполняемом контейнере от имени разработчиков пробелы. При выполнении перезагрузки, *devhostagent*:

* Останавливает текущий процесс и процессы, связанные с приложением
* Перестраивает приложение
* Перезапускает процесс или процессы, связанные с приложением

Способ *devhostagent* выполняет предыдущие действия настраивается в `azds.yaml` файла конфигурации. Эта конфигурация подробно описана в следующем разделе.

Обновления файлов проекта, например файлы Dockerfile, CSPROJ-файлов или любую часть диаграммы Helm требуют контейнера приложения для повторного создания и повторного развертывания. Если один из этих файлов синхронизирован с пространстве разработки, контроллер работает [обновление helm](https://helm.sh/docs/helm/#helm-upgrade) команды и контейнер приложения повторного создания и развертывания.

### <a name="file-synchronization"></a>Синхронизация файлов

Первый раз при запуске приложения в области разработки, передаются исходные файлы приложения. Во время работы приложения и на более поздних перезапусков, передаются только измененные файлы. Для координации этого процесса используются два файла: файл на стороне клиента и файл стороне контроллера.

Клиентский файл хранится во временном каталоге и по хэшу в каталоге проекта, запущенного в пробелах разработки. Например, в Windows будет иметь файл как *Users\USERNAME\AppData\Local\Temp\1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef.synclog* для вашего проекта. В Linux, клиентский файл хранится в */TMP* каталога. Каталог в macOS можно найти, выполнив `echo $TMPDIR` команды.

Этот файл в формате JSON и содержит:

* Запись для каждого файла проекта, который синхронизируется с пространстве разработки
* Идентификатор синхронизации
* Отметка времени последней операции синхронизации.

Каждая запись файла проекта содержит путь к файлу и его метку времени.

Файл со стороны контроллера хранится в кластере AKS. Он содержит код синхронизации и отметка времени последней синхронизации.

Синхронизация происходит, когда отметки времени синхронизации не совпадают между на стороне клиента и стороне контроллера файлами. Во время синхронизации инструментарий клиентский выполняет итерацию по записи файлов в файле на стороне клиента. Если метка времени файла после метки времени синхронизации, этот файл синхронизируется в области разработки. По завершении синхронизации на стороне клиента и на стороне контроллера файлы обновляются отметки времени синхронизации.

Все файлы проекта будут синхронизированы, если клиентский файл не существует. Это поведение позволяет принудительно полной синхронизации, удалив файл на стороне клиента.

### <a name="how-routing-works"></a>Как работает маршрутизация

Пространстве разработки построена на основе AKS и использует те же [сети понятия](../aks/concepts-network.md). Azure пробелы разработки также есть централизованная *ingressmanager* службы и развертывает собственные входящий контроллер кластера AKS. *Ingressmanager* контролируется AKS кластеров разработки пробелов и дополняет контроллеру входящего трафика пробелы разработки Azure в кластере с объектами входящего трафика для маршрутизации в модулях приложения службой. Добавляет в контейнер devspaces для прокси-сервера в каждой pod `azds-route-as` заголовок HTTP для HTTP-трафик в пространстве разработки на основе URL-адреса. Например, запрос на URL-адрес *http://azureuser.s.default.serviceA.fedcba09...azds.io* получит заголовок HTTP с `azds-route-as: azureuser`. Контейнер devspaces для прокси-сервера не будет добавлять `azds-route-as` заголовка, если он уже имеется.

HTTP-запрос при попытке службы из за пределов кластера, запрос направляется к контроллеру входящего трафика. Входящий контроллер направляет запрос непосредственно на соответствующие pod, в соответствии с входящих объектов и правила. Контейнер devspaces для прокси-сервера в модуль получает запрос, добавляет `azds-route-as` заголовка на основании URL-адрес и затем направляет запрос к контейнеру приложения.

При HTTP-запроса к службе из другой службы в кластере, запрос сначала проходит через контейнер devspaces прокси вызывающей службы. Просматривает контейнер devspaces для прокси-сервера HTTP-запроса и проверяет `azds-route-as` заголовка. На основе заголовка, контейнер devspaces прокси будет искать IP-адрес службы, связанной со значением заголовка. При обнаружении IP-адресом контейнера devspaces прокси перенаправляет запрос на этот IP-адрес. Если IP-адрес не найден, контейнер devspaces для прокси-сервер перенаправляет запрос в родительский контейнер приложения.

Например, приложения *serviceA* и *serviceB* развертываются в родительское пространство разработки вызывается *по умолчанию*. *serviceA* зависит от *serviceB* и выполняет HTTP-вызовы к нему. Пользователь Azure создает дочерний пространстве разработки, на основе *по умолчанию* пространства называемого *azureuser*. Пользователь Azure также развертывает собственную версию *serviceA* в свои дочерние пространства. При запросе к *http://azureuser.s.default.serviceA.fedcba09...azds.io*:

![Azure пробелы разработки маршрутизации](media/how-dev-spaces-works/routing.svg)

1. Входящий контроллер ищет IP-адрес для pod, связанный с URL-адрес, который является *serviceA.azureuser*.
1. Входящий контроллер находит IP-адрес для pod в пространстве разработки пользователя Azure и направляет запрос к *serviceA.azureuser* pod.
1. Контейнер devspaces прокси в *serviceA.azureuser* pod получает запрос и добавляет `azds-route-as: azureuser` в HTTP-заголовке.
1. Контейнер devspaces прокси в *serviceA.azureuser* pod направляет запрос к *serviceA* контейнер приложения в *serviceA.azureuser* pod.
1. *ServiceA* приложение *serviceA.azureuser* pod вызывает *serviceB*. *ServiceA* приложение также содержит код, чтобы сохранить существующее `azds-route-as` заголовок, который в данном случае является `azds-route-as: azureuser`.
1. Контейнер devspaces прокси в *serviceA.azureuser* pod получает запрос и ищет IP-адреса *serviceB* на основе значения из `azds-route-as` заголовка.
1. Контейнер devspaces прокси в *serviceA.azureuser* pod не удается найти IP-адрес для *serviceB.azureuser*.
1. Контейнер devspaces прокси в *serviceA.azureuser* pod ищет IP-адрес для *serviceB* в родительское пространство, которая представляет собой *serviceB.default*.
1. Контейнер devspaces прокси в *serviceA.azureuser* pod находит IP-адрес для *serviceB.default* и направляет запрос к *serviceB.default* pod.
1. Контейнер devspaces прокси в *serviceB.default* pod получает запрос и перенаправляет запрос на *serviceB* контейнер приложения в *serviceB.default*pod.
1. *ServiceB* приложение *serviceB.default* pod возвращает ответ *serviceA.azureuser* pod.
1. Контейнер devspaces прокси в *serviceA.azureuser* pod получает ответ и направляет ответ *serviceA* контейнер приложения в *serviceA.azureuser* pod.
1. *ServiceA* приложение получает ответ, а затем возвращает свой ответ.
1. Контейнер devspaces прокси в *serviceA.azureuser* pod получает ответ от *serviceA* контейнер приложения и передает ответ на исходного участника, за пределами кластера.

Весь остальной трафик TCP, который не является HTTP проходит через контроллер входящего трафика и контейнеры devspaces для прокси-сервер без изменений.

### <a name="how-running-your-code-is-configured"></a>О том, как настроено выполнение кода

Использует Azure пробелы разработки `azds.yaml` файл для установки и настройки службы. Использует контроллер `install` свойство в `azds.yaml` файл, чтобы установить диаграмму Helm и создавать объекты Kubernetes:

```yaml
...
install:
  chart: charts/webfrontend
  values:
  - values.dev.yaml?
  - secrets.dev.yaml?
  set:
    replicaCount: 1
    image:
      repository: webfrontend
      tag: $(tag)
      pullPolicy: Never
    ingress:
      annotations:
        kubernetes.io/ingress.class: traefik-azds
      hosts:
      # This expands to [space.s.][rootSpace.]webfrontend.<random suffix>.<region>.azds.io
      # Customize the public URL by changing the 'webfrontend' text between the $(rootSpacePrefix) and $(hostSuffix) tokens
      # For more information see https://aka.ms/devspaces/routing
      - $(spacePrefix)$(rootSpacePrefix)webfrontend$(hostSuffix)
...
```

По умолчанию `prep` команда создаст диаграмму Helm. Он также задает *install.chart* свойство в каталог чарта Helm. Если вы хотите использовать диаграмму Helm в другом месте, можно обновить это свойство для использования этого расположения.

При установке чарты Helm, пробелы разработки Azure предоставляет способ для переопределения значений в диаграмме Helm. По умолчанию в диаграмме Helm используются значения в `charts/APP_NAME/values.yaml`.

С помощью *install.values* можно перечислить один или несколько файлов, которые определяют значения будут заменены в диаграмме Helm. Например при желании, особенно при запуске приложения в области разработки конфигурации имя узла или базы данных, можно использовать эту функцию для переопределения. Можно также добавить *?* в конце любого из имен файлов, чтобы задать его как необязательные.

*Install.set* свойство можно настроить одно или несколько значений, которые необходимо заменен на диаграмме Helm. Все значения, настроенные в *install.set* переопределяют значения, заданные в файлы, перечисленные в *install.values*. Свойства в разделе *install.set* зависят от значений в диаграмме Helm и может отличаться в зависимости от созданного чарта Helm.

В приведенном выше примере *install.set.replicaCount* свойство сообщает контроллеру, сколько экземпляров приложения для запуска в области разработки. В зависимости от сценария это значение можно увеличить, но он будет влиять на присоединение отладчика к pod вашего приложения. Дополнительные сведения см. в разделе [статьи об устранении неполадок](troubleshooting.md).

В диаграмме Helm созданный образ контейнера имеет значение *{{. VALUES.Image.Repository}} :{{. VALUES.Image.Tag}}*. `azds.yaml` Файл определяет *install.set.image.tag* свойство как *$(tag)* по умолчанию, который используется как значение для *{{. VALUES.Image.Tag}}*. Установив *install.set.image.tag* свойство таким образом, он позволяет образ контейнера для вашего приложения, который должен быть отмечен конкретным образом, при выполнении пробелы разработки Azure. В этом конкретном случае изображение помечается как  *<value from image.repository>: $(tag)*. Необходимо использовать *$(tag)* переменной в качестве значения *install.set.image.tag* в порядке для разработки пространств распознавать и найдите контейнер в кластере AKS.

В приведенном выше примере `azds.yaml` определяет *install.set.ingress.hosts*. *Install.set.ingress.hosts* свойство определяет формат имени узла для общедоступных конечных точек. Это свойство также использует *$(spacePrefix)*, *$(rootSpacePrefix)*, и *$(hostSuffix)*, которые являются значениями, предоставляемых контроллером. 

*$(SpacePrefix)* имя пространство разработки дочернего, которое принимает форму *SPACENAME.s*. *$(RootSpacePrefix)* имя родительского пространства. Например если *azureuser* — это пространство дочернего элемента *по умолчанию*, значение *$(rootSpacePrefix)* — *по умолчанию* и значение *$(spacePrefix)* — *azureuser.s*. Если пространство не является пробелом дочерних *$(spacePrefix)* пуст. Например если *по умолчанию* пространство имеет не родительское пространство, а значение для *$(rootSpacePrefix)* — *по умолчанию* и значение *$(spacePrefix)* пуст. *$(HostSuffix)* является DNS-суффикс, указывающий контроллеру входящего трафика Azure Dev пробелы, работающего в кластере AKS. Этот DNS-суффикс соответствует запись DNS с подстановочными знаками, например  *\*. RANDOM_VALUE.eus.azds.IO*, который был создан при добавлении контроллера пробелы разработки Azure в кластере AKS.

В указанных выше `azds.yaml` файл, вы можете также обновить *install.set.ingress.hosts* для изменения имени узла приложения. Например, если вы хотите упростить имя узла приложения *$(spacePrefix)$(rootSpacePrefix)webfrontend$(hostSuffix)* для *$(spacePrefix)$(rootSpacePrefix)web$(hostSuffix)*.

Чтобы создать контейнер для приложения, контроллер использует ниже разделах `azds.yaml` файла конфигурации:

```yaml
build:
  context: .
  dockerfile: Dockerfile
...
configurations:
  develop:
    build:
      dockerfile: Dockerfile.develop
      useGitIgnore: true
      args:
        BUILD_CONFIGURATION: ${BUILD_CONFIGURATION:-Debug}
...
```

Контроллер использует файл Dockerfile для сборки и запуска приложения.

*Build.context* списки свойств каталога, в которой находятся файлы Dockerfile. *Build.dockerfile* свойство определяет имя файла Dockerfile для создания рабочей версии приложения. *Configurations.develop.build.dockerfile* свойство настраивает имя Dockerfile для разработки версию приложения.

Наличие разных файлов Dockerfile для разработки и эксплуатации позволяет включать определенные операции во время разработки и отключать эти элементы для развертывания в рабочей среде. Например, вы можете включить отладку или более подробное ведение журнала во время разработки и disable в рабочей среде. Эти свойства также можно обновить, если ваши файлы Dockerfile названы по-разному или в другом месте.

Чтобы помочь вам быстро выполняйте итерацию во время разработки, пробелы разработки Azure синхронизация изменений из локального проекта и постепенно обновлять приложение. Под разделом в `azds.yaml` файл конфигурации используется для настройки синхронизации и обновления:

```yaml
...
configurations:
  develop:
    ...
    container:
      sync:
      - "**/Pages/**"
      - "**/Views/**"
      - "**/wwwroot/**"
      - "!**/*.{sln,csproj}"
      command: [dotnet, run, --no-restore, --no-build, --no-launch-profile, -c, "${BUILD_CONFIGURATION:-Debug}"]
      iterate:
        processesToKill: [dotnet, vsdbg]
        buildCommands:
        - [dotnet, build, --no-restore, -c, "${BUILD_CONFIGURATION:-Debug}"]
...
```

Файлы и каталоги, которые синхронизирует изменения, перечислены в *configurations.develop.container.sync* свойство. Эти каталоги, изначально синхронизируются при выполнении `up` команду, а также при обнаружении изменений. При наличии дополнительных или других каталоги, в которых вы хотите синхронизировать область разработки, можно изменить это свойство.

*Configurations.develop.container.iterate.buildCommands* свойство указывает, как создать приложение в сценариях разработки. *Configurations.develop.container.command* свойство предоставляет команды для запуска приложения в сценариях разработки. Можно обновить одним из этих свойств, если имеются дополнительные флаги сборки или времени выполнения или параметры, которые вы хотите использовать во время разработки.

*Configurations.develop.container.iterate.processesToKill* список процессов для прерывания работы, чтобы остановить приложение. Вы можете обновить это свойство, если вы хотите изменить поведение перезапуска приложения во время разработки. Например, если вы обновили *configurations.develop.container.iterate.buildCommands* или *configurations.develop.container.command* свойства для изменения, как создается приложение или к работе, может потребоваться изменить, какие процессы будут остановлены.

При подготовке кода с помощью `azds prep` команды, у вас есть возможность добавить `--public` флаг. Добавление `--public` флаг создает общедоступный URL-адрес для вашего приложения. Если опустить этот флаг, приложение доступно только в пределах кластера или с помощью туннеля localhost. После того, как `azds prep` команды, вы можете изменить этот параметр изменение *ingress.enabled* свойство в `charts/APPNAME/values.yaml`:

```yaml
ingress:
  enabled: true
```

## <a name="debug-your-code"></a>Отладка кода

Для приложений Java, .NET и Node.js можно выполнять отладку приложения, запущенного непосредственно в области разработки с помощью Visual Studio Code или Visual Studio 2017. Предоставляют набор инструментов, чтобы подключиться к пространству разработки, запустить приложение и подключить отладчик, Visual Studio Code и Visual Studio 2017. После выполнения команды `azds prep`, можно открыть проект в Visual Studio Code или Visual Studio 2017. Visual Studio Code или Visual Studio 2017 будет создавать свои собственные файлы конфигурации для подключения, который отделен от выполнения `azds prep`. Из в Visual Studio Code или Visual Studio 2017 можно установить точки останова и запускать приложения область разработки.

![Отладка кода](media/get-started-node/debug-configuration-nodejs2.png)

При запуске приложения с помощью Visual Studio Code или Visual Studio 2017 для отладки, они обрабатывают, запуск и подключение пространству разработки так же, как работает `azds up`. Клиентские средства в Visual Studio Code и Visual Studio 2017 также включают дополнительный параметр, используя сведения для отладки. Параметр содержит имя образа отладчика, расположение отладчика в на рисунке отладчика и целевое расположение в контейнере приложения для подключения отладчика папки. 

На рисунке отладчик автоматически определяется по инструментарий на стороне клиента. Он использует метод, аналогичную той, которая использовалась во время Dockerfile и создать диаграмму Helm, при выполнении `azds prep`. После подключения отладчика в образ приложения он выполняется с использованием `azds exec`.

## <a name="sharing-a-dev-space"></a>Совместное использование пространстве разработки

При работе с командой, вы можете [совместно использовать пространстве разработки в вся группа](how-to/share-dev-spaces.md) и создавать производные разработки пространства. Пространстве разработки можно использовать любой пользователь с правами участника в группу ресурсов в области разработки.

Можно также создать новое пространство разработки, который является производным от другого пространстве разработки. При создании производных разработки пробел, *azds.io/родительского space = РОДИТЕЛЬСКОГО ПРОСТРАНСТВА ИМЕНИ* метка добавляется к пространству имен пространстве производном разработки. Кроме того все приложения из родительского пространства разработки являются общими для пространстве производном разработки. При развертывании обновленной версии приложения пространстве производном разработки, он будет существовать только в пространстве производном разработки и пространстве разработки родительского не будут затрагиваться. У вас есть более трех уровней производных разработки пробелов или *прародителя* пробелы.

Пространстве производном разработки также разумно будет маршрутизацию запросов между свои собственные приложения и приложения, совместно из его родительского элемента. Маршрутизация работает, пытается выполнить запрос маршрута к приложению в пространстве производном разработки и возврата к общего приложения из родительского пространства разработки. Маршрутизация вернется к общего приложения в пространстве прародителя Если приложение не находится в родительское пространство.

Например: 
* Пространстве разработки *по умолчанию* есть приложения *serviceA* и *serviceB* .
* Пространстве разработки *azureuser* является производным от *по умолчанию*.
* Обновленная версия *serviceA* развертывается *azureuser*.

При использовании *azureuser*, все запросы к *serviceA* будут направляться на обновленную версию в *azureuser*. Запрос на *serviceB* вначале предпринимается попытка направляться *azureuser* версии *serviceB*. Так как он не существует, он будет перенаправлен к *по умолчанию* версии *serviceB*. Если *azureuser* версии *serviceA* удаляется, все запросы к *serviceA* будет переключиться на использование *по умолчанию* версии *serviceA*.

## <a name="next-steps"></a>Дальнейшие действия

Чтобы приступить к использованию пробелов разработки Azure, см. в разделе следующих кратких руководств:

* [Java с помощью интерфейса командной строки и Visual Studio Code](quickstart-java.md)
* [.NET core с помощью CLI и Visual Studio Code](quickstart-netcore.md)
* [.NET core в Visual Studio 2017](quickstart-netcore-visualstudio.md)
* [Node.js с использованием интерфейса командной строки и Visual Studio Code](quickstart-nodejs.md)

Чтобы начать работу с командной разработки, см. следующие статьи с инструкциями:

* [Групповая разработка - Java с помощью интерфейса командной строки и Visual Studio Code](team-development-java.md)
* [Групповая разработка — .NET Core с помощью CLI и Visual Studio Code](team-development-netcore.md)
* [Групповая разработка — .NET Core в Visual Studio 2017](team-development-netcore-visualstudio.md)
* [Групповая разработка - Node.js с использованием интерфейса командной строки и Visual Studio Code](team-development-nodejs.md)
