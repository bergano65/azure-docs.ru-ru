---
title: Предотвращение лжевзаимосвязи и несбалансированных данных посредством AutoML
titleSuffix: Azure Machine Learning
description: Выявляйте и устраняйте распространенные недостатки моделей машинного обучения с помощью решений для автоматизированного машинного обучения в составе Машинного обучения Azure.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: conceptual
ms.reviewer: nibaccam
author: nibaccam
ms.author: nibaccam
ms.date: 04/09/2020
ms.openlocfilehash: 77b5b52153c552008406b4b85083bcba5542cebe
ms.sourcegitcommit: 3d79f737ff34708b48dd2ae45100e2516af9ed78
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/23/2020
ms.locfileid: "87012728"
---
# <a name="prevent-overfitting-and-imbalanced-data-with-automated-machine-learning"></a>Предотвращение лжевзаимосвязи и несбалансированных данных посредством автоматизированного машинного обучения

Лжевзаимосвязь и несбалансированные данные — это распространенные недостатки при создании моделей машинного обучения. По умолчанию решения для автоматизированного машинного обучения в составе Машинного обучения Azure предоставляют диаграммы и метрики, помогающие выявлять эти риски, и реализуют рекомендации по их устранению. 

## <a name="identify-over-fitting"></a>Выявление лжевзаимосвязи

Лжевзаимосвязь в машинном обучении возникает, когда модель слишком хорошо соответствует обучающим данным и поэтому не может точно прогнозировать неизвестные тестовые данные. Иными словами, модель просто запомнила определенные закономерности и шум в обучающих данных, но недостаточно гибка для составления прогнозов на основе реальных данных.

Рассмотрим приведенные ниже обученные модели и их точность прогнозирования на основе обучающих и тестовых данных.

| Модель | Точность при обучении | Точность при тестировании |
|-------|----------------|---------------|
| Объект | 99,9 % | 95 % |
| B | 87 % | 87 % |
| C | 99,9 % | 45 % |

В отношении модели **А** следует заметить, что существует распространенное заблуждение о том, что если точность при тестировании на основе неизвестных данных ниже, чем точность при обучении, то в модели есть лжевзаимосвязь. Однако точность при тестировании всегда должна быть ниже, чем точность при обучении. Различие между лжевзаимосвязью и правильной взаимосвязью сводится к *разнице в точности*. 

Если сравнить модели **А** и **B**, модель **А** лучше, так как ее точность при тестировании выше, и хотя она немного ниже 95 %, это не существенная разница, которая может свидетельствовать о наличии лжевзаимосвязи. Выбирать модель **В** только потому, что точность при обучении и тестировании ближе друг к другу, не следует.

Модель **C** представляет собой более явный случай лжевзаимосвязи. Точность при обучении очень высока, но точность при тестировании далека от нее. Это различие является субъективным и истекает из знания проблемы и данных, а также допустимой величины погрешности.

## <a name="prevent-over-fitting"></a>Предотвращение лжевзаимосвязи

В самых крайних случаях модель с лжевзаимосвязью будет предполагать, что сочетания значений признаков, которые наблюдались во время обучения, всегда будут давать аналогичный результат.

Лучший способ предотвратить лжевзаимосвязь заключается в соблюдении рекомендаций по машинному обучению, в том числе следующих:

* используйте больше обучающих данных и устраняйте статистические отклонения;
* предотвращайте утечку конечных значений;
* используйте меньше признаков;
* **регуляризация и оптимизация гиперпараметров**;
* **ограничения сложности модели**;
* **перекрестная проверка**.

В контексте автоматизированного машинного обучения первые три приведенных выше пункта являются **практическими рекомендациями к реализации**. Последние три пункта, выделенные жирным шрифтом, — это **рекомендации, реализуемые автоматизированным машинным обучением** по умолчанию для защиты от лжевзаимосвязи. Если машинное обучение не является автоматизированным, необходимо соблюдать все шесть рекомендаций, чтобы избежать лжевзаимосвязи.

### <a name="best-practices-you-implement"></a>Реализация рекомендаций

Использование **большего объема данных** — это самый простой и эффективный способ предотвратить лжевзаимосвязь, который, помимо прочего, обычно повышает точность. При использовании большего объема данных модели труднее запоминать конкретные закономерности и она вынуждена принимать более гибкие решения, учитывающие больше условий. Также важно выявлять **статистические отклонения**, чтобы в обучающих данных не было изолированных шаблонов, которых не будет в реальных данных. Эта задача может быть сложна, так как между обучающим и тестовым наборами лжевзаимосвязь может отсутствовать, но при сравнении с реальными тестовыми данными она может выявляться.

**Утечка конечных значений** — аналогичная проблема. В этом случае лжевзаимосвязь между обучающим и тестовым наборами может также быть незаметна, но обнаруживаться во время прогнозирования. Утечка конечных значений происходит, когда во время обучения модель "подсматривает" данные, к которым не должна иметь доступа. Например, если задача состоит в том, чтобы предсказать в понедельник, какой будет цена товара в пятницу, но в одном из признаков случайно оказались данные за четверг, эти данные будут недоступны модели во время прогнозирования, так как она не может заглянуть в будущее. Утечку конечных значений легко не заметить, но она часто проявляется в виде необычно высокой точности прогнозов. Если вы пытаетесь спрогнозировать цену акций и обучили модель с точностью до 95 %, скорее всего, в ваших признаках где-то есть утечка конечных значений.

**Удаление признаков** также может помочь устранить лжевзаимосвязь, так как у модели будет не так много полей для запоминания конкретных шаблонов и в результате она будет гибче. Измерить эту характеристику количественно может быть сложно, но если вы смогли удалить признаки, сохранив уровень точности, то вы, вероятно, сделали модель более гибкой и уменьшили риск лжевзаимосвязи.

### <a name="best-practices-automated-ml-implements"></a>Рекомендации, реализуемые автоматизированным машинным обучением

**Регуляризация** — это процесс минимизации функции стоимости для наложения штрафа на сложные модели с лжевзаимосвязью. Существуют различные типы функций регуляризации, но в целом все они налагают штраф на размер коэффициента, дисперсию и сложность модели. Автоматизированное машинное обучение использует функции L1 (Lasso), L2 (Ridge) и ElasticNet (одновременно L1 и L2) в различных сочетаниях с различными гиперпараметрами модели, которые контролируют лжевзаимосвязь. Простыми словами, автоматизированное машинное обучение пробует разные уровни регуляризации модели и выбирает наилучший результат.

Автоматизированное машинное обучение также реализует явные **ограничения сложности модели** для предотвращения лжевзаимосвязи. В большинстве случаев эта реализация предназначена для алгоритмов дерева принятия решений или леса с ограниченной максимальной глубиной дерева и ограниченным общим числом деревьев в лесе или совокупности.

**Перекрестная проверка** — это процесс выделения нескольких подмножеств из полного набора обучающих данных и обучения модели на основе каждого из них. Идея состоит в том, что модели может "повезти" с одним подмножеством, с которым ее точность будет высока, но если подмножеств много, такая высокая точность не может достигаться каждый раз. При перекрестной проверке вы предоставляете набор контрольных данных, указываете подмножества, а затем автоматизированное машинное обучение обучает модель и настраивает гиперпараметры для сведения ошибок к минимуму. Одно из подмножеств может иметь лжевзаимосвязь, но использование нескольких подмножеств уменьшает вероятность лжевзаимосвязи в окончательной модели. Оборотной стороной является то, что перекрестная проверка увеличивает время обучения и, следовательно, стоимость, так как модель приходится обучать не один раз, а несколько — по одному разу для каждого из *n* подмножеств перекрестной проверки. 

> [!NOTE]
> Перекрестная проверка по умолчанию не включена. Ее необходимо настроить в параметрах автоматического машинного обучения. Однако после настройки перекрестной проверки и предоставления набора данных для проверки процесс выполняется автоматически. Дополнительные сведения о [конфигурации перекрестной проверки в автоматическом ML](how-to-configure-cross-validation-data-splits.md)

<a name="imbalance"></a>

## <a name="identify-models-with-imbalanced-data"></a>Выявление моделей с несбалансированными данными

Несбалансированность обычно обнаруживается в данных для сценариев классификации. Под нею понимаются данные, которые содержат непропорциональную долю наблюдений в каждом классе. Дисбаланс может привести к появлению ложного впечатления о повышении точности модели, так как входные данные смещены в сторону одного класса и это смещение отражается на обученной модели. 

Кроме того, запуски автоматизированного машинного обучения автоматически создают приведенные ниже диаграммы, которые помогают оценить правильность классификаций модели и выявить модели, на которые могла повлиять несбалансированность данных.

Диаграмма| Описание
---|---
[Матрица неточностей](how-to-understand-automated-ml.md#confusion-matrix)| Оценивает правильно классифицированные метки относительно фактических меток данных. 
[Соотношение полноты и точности](how-to-understand-automated-ml.md#precision-recall-chart)| Оценивает отношение количества правильных меток к количеству обнаруженных экземпляров меток данных. 
[Кривые ROC](how-to-understand-automated-ml.md#roc)| Оценивает отношение количества правильных меток к количеству ложноположительных меток.

## <a name="handle-imbalanced-data"></a>Обработка несбалансированных данных 

В рамках своей цели упрощения рабочего процесса машинного обучения **автоматизированный ML имеет встроенные возможности** для помощи с несбалансированными данными, такими как, 

- **Весовой столбец**. Автоматический ML поддерживает столбец весовых коэффициентов в качестве входных данных, что приводит к сокращению или уменьшению количества строк, которые можно использовать, чтобы сделать класс более или менее важным.

- Алгоритмы, используемые автоматизированным обнаружением машинного обучения, не сбалансированы, если количество выборок в классе "доля" равно или меньше 20% от количества выборок в классе большинства, где класс миноритария относится к элементу с наименьшим числом выборок и класс большинства относится к одному с большинством выборок. В дальнейшем Аутомл будет выполнять эксперимент с данными с подвыборкой, чтобы проверить, может ли использование весов класса решить эту проблему и повысить производительность. Если он повышает производительность в рамках этого эксперимента, применяется это средство устранения.

- Использование метрики производительности, которая лучше работает с несбалансированными данными. Например, AUC_weighted является основной метрикой, которая вычисляет вклад каждого класса на основе относительного числа выборок, представляющих этот класс, и, следовательно, более надежен в отношении дисбаланса.

Следующие методы являются дополнительными вариантами для управления несбалансированными данными **за пределами автоматизированного ML**. 

- Повторная выборка для выравнивания баланса классов путем дополнительной выборки для более мелких классов или сокращения выборки для более крупных классов. Использование этих методов требует опыта.

- Проверьте метрики производительности для несбалансированных данных. Например, оценка F1 — это среднее гармоническое точность и отзыв. Точность измеряет точное значение классификатора, где более высокая точность указывает на меньше ложных срабатываний, а при отзыве измеряет полноту классификатора, где более высокий отзыв означает меньше ложных отрицательных результатов.

## <a name="next-steps"></a>Дальнейшие действия

Примеры и сведения о создании моделей с помощью автоматического машинного обучения:

+ Выполните [руководство по автоматическому обучению модели регрессии с помощью Машинного обучения Azure](tutorial-auto-train-models.md).

+ Настройте параметры для автоматического обучающего эксперимента.
  + В Студии машинного обучения Azure выполните [эти инструкции](how-to-use-automated-ml-for-ml-models.md).
  + При использовании пакета SDK для Python выполните [эти инструкции](how-to-configure-auto-train.md).


