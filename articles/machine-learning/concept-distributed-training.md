---
title: Что такое распределенное обучение?
titleSuffix: Azure Machine Learning
description: Узнайте о распределенном обучении и о том, как Машинное обучение Azure поддерживает его.
services: machine-learning
ms.service: machine-learning
author: nibaccam
ms.author: nibaccam
ms.subservice: core
ms.topic: conceptual
ms.date: 03/27/2020
ms.openlocfilehash: 62edee6a882191551ce2409646ea8b617576c059
ms.sourcegitcommit: 829d951d5c90442a38012daaf77e86046018e5b9
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/09/2020
ms.locfileid: "89651152"
---
# <a name="distributed-training-with-azure-machine-learning"></a>Распределенное обучение с помощью Машинное обучение Azure

В этой статье вы узнаете о распределенном обучении и о том, как Машинное обучение Azure поддерживает его для моделей глубокого обучения. 

В распределенном обучении Рабочая нагрузка для обучения модели разделяется и совместно используется несколькими мини-процессорами, называемыми рабочими узлами. Эти рабочие узлы работают параллельно, чтобы ускорить обучение модели. Распределенное обучение можно использовать для традиционных моделей МАШИНного обучения, но оно лучше подходит для вычислений и ресурсоемких задач, таких как [глубокое обучение](concept-deep-learning-vs-machine-learning.md) для обучения глубоко нейронных сетей. 

## <a name="deep-learning-and-distributed-training"></a>Глубокое обучение и распределенное обучение 

Существует два основных типа распределенного обучения: [параллелизм данных](#data-parallelism) и [параллелизм моделей](#model-parallelism). Для распределенного обучения по моделям глубокого обучения [пакет SDK для машинное обучение Azure в Python](https://docs.microsoft.com/python/api/overview/azure/ml/intro?view=azure-ml-py&preserve-view=true) поддерживает интеграцию с популярными платформами, PyTorch и TensorFlow. Обе платформы используют параллелизм данных для распределенного обучения и могут использовать [хоровод](https://horovod.readthedocs.io/en/latest/summary_include.html) для оптимизации скорости вычислений. 

* [Распределенное обучение с помощью PyTorch](how-to-train-pytorch.md#distributed-training)

* [Распределенное обучение с помощью TensorFlow](how-to-train-tensorflow.md#distributed-training)

Для моделей ML, для которых не требуется распределенное обучение, см. статью [обучение моделей с помощью машинное обучение Azure](concept-train-machine-learning-model.md#python-sdk) для различных способов обучения моделей с использованием пакета SDK для Python.

## <a name="data-parallelism"></a>Параллелизм данных

Параллелизм данных — это самый простой способ реализации двух подходов к распределенному обучению, который достаточно для большинства вариантов использования.

При таком подходе данные делятся на секции, где количество секций равно общему количеству доступных узлов в кластере вычислений. Модель копируется на каждый из этих рабочих узлов, и каждый рабочий процесс работает с собственным подмножеством данных. Помните, что каждый узел должен иметь емкость для поддержки модели, для которой выполняется обучение, то есть модель должна полностью соответствовать каждому узлу. На следующей схеме показана визуальная демонстрация этого подхода.

![Data-parallelism-концепция-схема](./media/concept-distributed-training/distributed-training.svg)

Каждый узел независимо рассчитывает ошибки между прогнозами для учебных примеров и выходных данных с метками. В свою очередь, каждый узел обновляет свою модель на основе ошибок и должен передать все изменения на другие узлы, чтобы обновить соответствующие модели. Это означает, что рабочие узлы должны синхронизировать параметры модели или градиенты в конце пакетного вычисления, чтобы убедиться в том, что они обучены единообразной моделью. 

## <a name="model-parallelism"></a>Параллелизм модели

В случае параллелизма модели, также известной как параллелизм сети, модель делится на разные части, которые могут выполняться параллельно на разных узлах, и каждый из них будет выполняться на одних и тех же данных. Масштабируемость этого метода зависит от степени параллелизации алгоритма задачей, и ее реализация сложнее, чем параллелизм данных. 

В случае параллелизма модели рабочие узлы должны синхронизировать общие параметры, как правило, один раз для каждого этапа перенаправления вперед или обратного распространения. Кроме того, более крупные модели не являются проблемой, так как каждый узел работает с подразделом модели для тех же обучающих данных.

## <a name="next-steps"></a>Дальнейшие шаги

* Узнайте, как [использовать целевые объекты вычислений для обучения модели](how-to-set-up-training-targets.md) с помощью пакета SDK для Python.
* Технический пример см. в статье [сценарий эталонной архитектуры](https://docs.microsoft.com/azure/architecture/reference-architectures/ai/training-deep-learning).
* [Обучение моделей ml с помощью TensorFlow](how-to-train-tensorflow.md).
* [Обучение моделей ml с помощью PyTorch](how-to-train-pytorch.md). 