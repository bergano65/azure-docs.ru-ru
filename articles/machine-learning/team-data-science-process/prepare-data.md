---
title: Подготовительные данные для машинного обучения ML (классическая модель) — процесс обработки и анализа данных группы
description: Предварительная обработка и очистка данных для подготовки к эффективному использованию в машинном обучении.
services: machine-learning
author: marktab
manager: marktab
editor: marktab
ms.service: machine-learning
ms.subservice: team-data-science-process
ms.topic: article
ms.date: 01/10/2020
ms.author: tdsp
ms.custom: seodec18, previous-author=deguhath, previous-ms.author=deguhath
ms.openlocfilehash: caedcf313ab809e9607907545f26ca1b62bbeca7
ms.sourcegitcommit: f52ce6052c795035763dbba6de0b50ec17d7cd1d
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/24/2020
ms.locfileid: "76720050"
---
# <a name="tasks-to-prepare-data-for-enhanced-machine-learning"></a>Задачи по подготовке данных для расширенного машинного обучения
Предварительная обработка и очистка данных — это важные задачи, которые необходимо выполнить, прежде чем набор данных можно будет использовать для обучения модели. Необработанные данные зачастую искажены и ненадежны, и в них могут быть пропущены значения. Использование таких данных при моделировании может приводить к неверным результатам. Эти задачи являются частью процесса обработки и анализа данных группы и обычно подразумевают первоначальное изучение набора данных, используемого для определения и планирования необходимой предварительной обработки. Более подробные инструкции по процессу TDSP см. в процедуре, описанной в статье [Процесс обработки и анализа данных группы](overview.md).

Задачи предварительной обработки и очистки, например задача просмотра данных, можно выполнять в самых разных средах, таких как SQL или Hive или Машинное обучение Azure Studio (классическая модель), а также с различными инструментами и языками, такими как R или Python, в зависимости от того, где ваши данные хранится и как он форматируется. Так как по своей природе процесс TDSP является итеративным, эти задачи могут выполняться на различных этапах рабочего процесса.

В этой статье описываются различные основные понятия и задачи обработки данных, которые можно выполнить до или после приема данных в Машинное обучение Azure Studio (классическая модель).

Пример изучения данных и предварительной обработки в Машинное обучение Azure Studio (классическая модель) см. в видео о [предварительной обработке данных](https://azure.microsoft.com/documentation/videos/preprocessing-data-in-azure-ml-studio/) .

## <a name="why-pre-process-and-clean-data"></a>Зачем нужна предварительная обработка и очистка данных?
Реальные данные собираются для последующей обработки из разных источников и процессов. Они могут содержать ошибки и повреждения, негативно влияющие на качество набора данных. Вот какими могут быть типичные проблемы с качеством данных:

* **Неполнота**: данные не содержат атрибутов, или в них пропущены значения.
* **Шум**: данные содержат ошибочные записи или выбросы.
* **Несогласованность**: данные содержат конфликтующие между собой записи или расхождения.

Качественные данные — это необходимое условие для создания качественных моделей прогнозирования. Чтобы избежать появления ситуации «мусор на входе, мусор на выходе» и повысить качество данных и, как следствие, эффективность модели, необходимо провести мониторинг работоспособности данных, как можно раньше обнаружить проблемы и решить, какие действия по предварительной обработке и очистке данных необходимы.

## <a name="what-are-some-typical-data-health-screens-that-are-employed"></a>Какие есть стандартные методы мониторинга работоспособности данных
Вот что нужно оценить, чтобы проверить качество данных:

* Количество **записей**.
* количество **атрибутов** (или **компонентов**);
* **Типы данных** атрибута (номинальные, порядковые или непрерывные).
* Количество **пропущенных значений**.
* **Правильно сформированные** данные.
  * Если данные имеют формат TSV или CSV, проверьте правильность разделения столбцов и строк соответствующими разделителями.
  * Если данные имеют формат HTML или XML, убедитесь, что формат данных соответствует надлежащим стандартам.
  * Для извлечения структурированной информации из частично структурированных или неструктурированных данных также может потребоваться синтаксический анализ.
* **Несогласованные записи данных**. Проверьте допустимость диапазона значений. Например, если данные содержат GPA-запись учащегося (среднее значение точки), проверьте, находится ли GPA в указанном диапазоне, скажем 0 ~ 4.

При обнаружении проблем с данными необходимо выполнить **действия по обработке** , что часто включает в себя очистку отсутствующих значений, нормализацию данных, дискретизация, обработку текста для удаления и/или замены внедренных символов, которые могут влиять на выравнивание данных, смешанные типы данных в общих полях и т. д.

**В машинном обучении Azure используются табличные данные правильного формата**.  Если данные уже находятся в табличной форме, предварительная обработка данных может выполняться непосредственно с Машинное обучение Azure Studio (классической) в Машинное обучение.  Если данные находятся не в табличной форме, а, например, в формате XML, для их преобразования в табличную форму может потребоваться синтаксический анализ.  

## <a name="what-are-some-of-the-major-tasks-in-data-pre-processing"></a>Каковы главные задачи предварительной обработки данных
* **Очистка данных**: заполнение отсутствующих значений, обнаружение и удаление шума данных и выбросов.
* **Преобразование данных** — нормализация данных для снижения измерений и искажений.
* **Уплотнение данных** — создание выборки данных или атрибутов для упрощения обработки данных.
* **Дискретизация данных** — преобразование непрерывных атрибутов в категориальные, чтобы проще было использовать некоторые методы машинного обучения.
* **Очистка текста**: удалите внедренные символы, которые могут вызвать неправильное выравнивание данных, например внедренные вкладки в файле данных с разделителями-табуляцией, внедренные новые строки, которые могут нарушить работу записей, например.

В следующем разделе описаны некоторые шаги предварительной обработки данных.

## <a name="how-to-deal-with-missing-values"></a>Как обрабатывать пропущенные значения
При работе с пропущенными значениями лучше сначала определить причину их появления в данных, что поможет решить проблему. Вот какие бывает методы обработки пропущенных значений:

* **Удаление**: удаление записей с пропущенными значениями.
* **Фиктивная подстановка** — замена пропущенных значений фиктивными, например подстановка значения *unknown* (неизвестно) вместо категориальных или значения 0 вместо чисел.
* **Подстановка среднего значения**: пропущенные числовые данные можно заменить средним значением.
* **Подстановка часто используемого элемента**: пропущенные категориальные значения можно заменить наиболее часто используемым элементом.
* **Подстановка по регрессии**: использование регрессионного метода для замены пропущенных значений регрессионными.  

## <a name="how-to-normalize-data"></a>Как нормализовать данные
Нормализация данных позволяет масштабировать числовые значения в указанный диапазон. Ниже представлены распространенные методы нормализации данных.

* **Нормализация по методу минимакса**: линейное преобразование данных в диапазоне, например, от 0 до 1, где минимальное и максимальное масштабируемые значения соответствуют 0 и 1 соответственно.
* **Нормализация по Z-показателю**: масштабирование данных на основе среднего значения и стандартного отклонения: деление разницы между данными и средним значением на стандартное отклонение.
* **Десятичное масштабирование**: масштабирование данных путем удаления десятичного разделителя значения атрибута.  

## <a name="how-to-discretize-data"></a>Как дискретизировать данные
Данные можно дискретизировать, преобразовав непрерывные значения в номинальные атрибуты или интервалы. Это можно сделать несколькими способами.

* **Группирование равной ширины**: разделение диапазона всех возможных значений атрибута в группы (N) одинакового размера с последующим присвоением значений, относящихся к ячейке с соответствующим номером.
* **Группирование равной высоты**: разделение всех возможных значений атрибута в группы (N), содержащие одинаковое количество экземпляров, с последующим присвоением значений, относящихся к ячейке с соответствующим номером.  

## <a name="how-to-reduce-data"></a>Как сократить объем данных
Существуют различные методы, с помощью которых вы можете уменьшить размер данных для упрощения обработки данных. В зависимости от размера данных и домена вы можете применить такие методы:

* **Выборка записей**: создание выборки записей данных и выбор репрезентативного подмножества из общего набора данных.
* **Выборка атрибутов**: выбор в данных набора важнейших атрибутов.  
* **Агрегирование**: разделение данных на группы и хранение числовых значений для каждой группы. Например, для уменьшения размера данных вы можете агрегировать числа, обозначающие ежедневный доход сети ресторанов за последние 20 лет, так, чтобы указывался ежемесячный доход.  

## <a name="how-to-clean-text-data"></a>Как очистить данные
**Текстовые поля в табличных данных** могут содержать символы, влияющие на выравнивание столбцов и (или) границы записи. Например, встроенные вкладки в файле с разделителями-табуляциями приводят к неправильному выравниванию столбца, а внедренные символы новой строки приведут к разрыву строк записи. Неправильная обработка кодировки текста при записи или чтении текста приводит к утере информации, непреднамеренному вводу нечитаемых символов (например, значений NULL) и может также повлиять на синтаксический анализ текста. Чтобы очистить текстовые поля, исправить выравнивание и извлечь структурированные текстовые данные из неструктурированных или полу-структурированных, могут потребоваться тщательные разбор и редактирование текста.

**Функция просмотра данных** позволяет ознакомиться с данными заблаговременно. Это поможет вам выявить те или иные проблемы с данными и применить соответствующие методы для решения этих проблем.  Важно понимать, что породило проблемы, как они могли появиться. Этот процесс также помогает выбрать действия по обработке данных, которые необходимо предпринять для их устранения. Определение окончательных вариантов использования и персонажей можно также использовать для определения приоритетов при обработке данных.

## <a name="references"></a>Ссылки
> *Интеллектуальный анализ данных: концепции и методы.* Издание третье, Morgan Kaufmann Publishers, 2011. Цзявей Хань (Jiawei Han), Мишлин Кэмбер (Micheline Kamber) и Цзянь Пей (Jian Pei)
> 
> 

