---
title: Определение сценариев для машинного обучения Azure — командный процесс обработки и анализа данных
description: Выберите оптимальные сценарии использования процесса обработки и анализа данных группы для расширенной прогнозной аналитики.
services: machine-learning
author: marktab
manager: marktab
editor: marktab
ms.service: machine-learning
ms.subservice: team-data-science-process
ms.topic: article
ms.date: 01/10/2020
ms.author: tdsp
ms.custom: seodec18, previous-author=deguhath, previous-ms.author=deguhath
ms.openlocfilehash: 2d589d6c3394556499daf033c4c1d528a214b0e3
ms.sourcegitcommit: 96918333d87f4029d4d6af7ac44635c833abb3da
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/04/2020
ms.locfileid: "93319305"
---
# <a name="scenarios-for-advanced-analytics-in-azure-machine-learning"></a>Сценарии для расширенной аналитики в Машинном обучении Azure
В этой статье описаны различные источники примеров данных и типовые сценарии, в которых можно использовать [процесс обработки и анализа данных группы (TDSP)](overview.md). Процесс TDSP предоставляет систематический подход для совместной работы групп над созданием интеллектуальных приложений. В представленных сценариях продемонстрированы варианты рабочих процессов обработки данных на основе характеристик данных, исходных расположений и целевых репозиториев в Azure.

**Дерево принятия решений** для выбора образцов сценариев, подходящих для данных и целей, представлено в последнем разделе.

В каждом из следующих разделов представлен один из сценариев. Для каждого сценария перечислены возможные операции обработки и анализа или расширенного анализа данных, а также вспомогательные ресурсы Azure.

> [!NOTE]
> **Для каждого из них вам понадобится:**
> <br/>
> 
> * [создать учетную запись хранения;](../../storage/common/storage-account-create.md)
>   <br/>
> * [Создание рабочей области машинного обучения Azure](../classic/create-workspace.md)
> 
> 

## <a name="scenario-1-small-to-medium-tabular-dataset-in-local-files"></a><a name="smalllocal"></a>Сценарий \# 1. Малый и средний табличный набор данных в локальных файлах
![Локальные файлы небольшого и среднего размера][1]

#### <a name="additional-azure-resources-none"></a>Дополнительные ресурсы Azure: отсутствуют
1. Войдите в [Студию машинного обучения Azure](https://studio.azureml.net/).
1. Отправьте набор данных.
1. Создайте поток операций эксперимента Машинного обучения Azure, начиная с отправленных наборов данных.

## <a name="scenario-2-small-to-medium-dataset-of-local-files-that-require-processing"></a><a name="smalllocalprocess"></a>Сценарий \#№2. Набор данных небольшого и среднего размера в локальных файлах, требующий обработки
![Локальные файлы небольшого и среднего размера, требующие обработки][2]

#### <a name="additional-azure-resources-azure-virtual-machine-ipython-notebook-server"></a>Дополнительные ресурсы Azure: виртуальная машина Azure (сервер IPython Notebook)
1. Создайте виртуальную машину Azure с IPython Notebook.
1. Отправка данных в контейнер службы хранилища Azure.
1. Предварительная обработка и очистка данных в записной книжке IPython Notebook для доступа к данным из контейнера службы хранилища Azure.
1. Преобразование данных в очищенную табличную форму.
1. Сохраните преобразованные данные в большие двоичные объекты Azure.
1. Войдите в [Студию машинного обучения Azure](https://studio.azureml.net/).
1. Считайте данные из больших двоичных объектов Azure с помощью модуля [Импорт данных][import-data].
1. Создайте поток операций эксперимента Машинного обучения Azure, начиная с принятых наборов данных.

## <a name="scenario-3-large-dataset-of-local-files-targeting-azure-blobs"></a><a name="largelocal"></a>Сценарий\# №3. Большой набор данных в локальных файлах, загружаемый в большие двоичные объекты Azure
![Локальные файлы большого размера][3]

#### <a name="additional-azure-resources-azure-virtual-machine-ipython-notebook-server"></a>Дополнительные ресурсы Azure: виртуальная машина Azure (сервер IPython Notebook)
1. Создайте виртуальную машину Azure с IPython Notebook.
1. Отправка данных в контейнер службы хранилища Azure.
1. Предварительно обработайте и очистите данные в IPython Notebook из больших двоичных объектов Azure.
1. При необходимости преобразуйте данные в очищенную табличную форму.
1. Просмотрите данные и при необходимости создайте компоненты.
1. Извлеките пример данных небольшого или среднего размера.
1. Сохраните пример данных в большие двоичные объекты Azure.
1. Войдите в [Студию машинного обучения Azure](https://studio.azureml.net/).
1. Считайте данные из больших двоичных объектов Azure с помощью модуля [Импорт данных][import-data].
1. Создайте поток операций эксперимента Машинного обучения Azure, начиная с принятых наборов данных.

## <a name="scenario-4-small-to-medium-dataset-of-local-files-targeting-sql-server-in-an-azure-virtual-machine"></a><a name="smalllocaltodb"></a>Сценарий \#№4. Набор данных небольшого и среднего размера в локальных файлах, загружаемый на сервер SQL Server в виртуальной машине Azure
![Локальные файлы небольшого и среднего размера для базы данных SQL в Azure][4]

#### <a name="additional-azure-resources-azure-virtual-machine-sql-server--ipython-notebook-server"></a>Дополнительные ресурсы Azure: виртуальная машина Azure (сервер SQL Server и IPython Notebook)
1. Создайте виртуальную машину Azure с SQL Server и IPython Notebook.
1. Отправка данных в контейнер службы хранилища Azure.
1. Предварительная обработка и очистка данных в контейнере службы хранилища Azure с помощью записной книжки IPython Notebook.
1. При необходимости преобразуйте данные в очищенную табличную форму.
1. Сохраните данные в локальных файлах виртуальной машины (IPython Notebook запущен на виртуальной машине, и в качестве локальных дисков используются диски виртуальной машины).
1. Загрузите данные в базу данных SQL Server на виртуальной машине Azure.
   
   Вариант \# №1. Использование SQL Server Management Studio.
   
   * Вход в SQL Server виртуальную машину
   * Запустите среду SQL Server Management Studio.
   * Создайте базу данных и целевые таблицы.
   * Используйте один из методов массового импорта для загрузки локальных файлов виртуальной машины.
   
   Вариант \# №2. Использование IPython Notebook (не рекомендуется использовать этот вариант для средних и больших наборов данных).
   
   <!-- -->    
   * Используйте строку подключения ODBC для доступа к SQL Server на виртуальной машине.
   * Создайте базу данных и целевые таблицы.
   * Используйте один из методов массового импорта для загрузки локальных файлов виртуальной машины.
1. Просмотрите данные и при необходимости создайте компоненты. Эти функции не нужно материализовать в таблицах базы данных. Необходимо указать только запросы, требуемые для их создания.
1. При необходимости выберите размер примера данных.
1. Войдите в [Студию машинного обучения Azure](https://studio.azureml.net/).
1. Считайте данные непосредственно из SQL Server с помощью модуля [Импорт данных][import-data]. Вставьте необходимый запрос, который извлекает поля, создает компоненты и образцы данных, если это необходимо, непосредственно в запросе на [Импорт данных][import-data] .
1. Создайте поток операций эксперимента Машинного обучения Azure, начиная с принятых наборов данных.

## <a name="scenario-5-large-dataset-in-local-files-target-sql-server-in-azure-vm"></a><a name="largelocaltodb"></a>Сценарий \# 5. большой набор данных в локальных файлах, целевой SQL Server на виртуальной машине Azure
![Локальные файлы большого размера для базы данных SQL в Azure][5]

#### <a name="additional-azure-resources-azure-virtual-machine-sql-server--ipython-notebook-server"></a>Дополнительные ресурсы Azure: виртуальная машина Azure (сервер SQL Server и IPython Notebook)
1. Создайте виртуальную машину Azure с SQL Server и IPython Notebook.
1. Отправка данных в контейнер службы хранилища Azure.
1. Предварительно обработайте и очистите данные (необязательно).
   
    a.  Предварительно обработайте и очистите данные в IPython Notebook из больших двоичных объектов Azure.
   
    b.  При необходимости преобразуйте данные в очищенную табличную форму.
   
    c.  Сохраните данные в локальных файлах виртуальной машины (IPython Notebook запущен на виртуальной машине, и в качестве локальных дисков используются диски виртуальной машины).
1. Загрузите данные в базу данных SQL Server на виртуальной машине Azure.
   
    a.  Войдите в SQL Server виртуальную машину.
   
    b.  Если данные еще не сохранены, Скачайте файлы данных из контейнера хранилища Azure в локальную папку виртуальной машины.
   
    c.  Запустите среду SQL Server Management Studio.
   
    d.  Создайте базу данных и целевые таблицы.
   
    д)  Загрузите данные, используя один из методов массового импорта.
   
    е)  Если требуется объединить таблицы, создайте индексы, чтобы ускорить этот процесс.
   
   > [!NOTE]
   > Чтобы ускорить загрузку данных большого размера, мы советуем создать секционированные таблицы и массово импортировать данные в параллельном режиме. Дополнительные сведения см. в статье [Параллельный массовый импорт данных с использованием таблиц секционирования SQL](parallel-load-sql-partitioned-tables.md).
   > 
   > 
1. Просмотрите данные и при необходимости создайте компоненты. Эти функции не нужно материализовать в таблицах базы данных. Необходимо указать только запросы, требуемые для их создания.
1. При необходимости выберите размер примера данных.
1. Войдите в [Студию машинного обучения Azure](https://studio.azureml.net/).
1. Считайте данные непосредственно из SQL Server с помощью модуля [Импорт данных][import-data]. Вставьте необходимый запрос, который извлекает поля, создает компоненты и образцы данных, если это необходимо, непосредственно в запросе на [Импорт данных][import-data] .
1. Создайте простой поток операций эксперимента Машинного обучения Azure, начиная с отправленного набора данных.

## <a name="scenario-6-large-dataset-in-a-sql-server-database-on-premises-targeting-sql-server-in-an-azure-virtual-machine"></a><a name="largedbtodb"></a>Сценарий \# 6. большой набор данных в локальной базе данных SQL Server, нацеленный на SQL Server на виртуальной машине Azure
![Большая локальная база данных SQL для базы данных SQL в Azure][6]

#### <a name="additional-azure-resources-azure-virtual-machine-sql-server--ipython-notebook-server"></a>Дополнительные ресурсы Azure: виртуальная машина Azure (сервер SQL Server и IPython Notebook)
1. Создайте виртуальную машину Azure с SQL Server и IPython Notebook.
1. Экспортируйте данные из SQL Server в файлы дампа, используя один из методов экспорта данных.
   
   > [!NOTE]
   > Если вы решили переместить все данные из локальной базы данных, альтернативный метод (более быстрый) для перемещения полной базы данных на экземпляр SQL Server в Azure. Пропустите шаги для экспорта данных, создайте базу данных, загрузите или импортируйте данные в целевую базу данных и воспользуйтесь альтернативным методом.
   > 
   > 
1. Отправка файлов дампа в контейнер службы хранилища Azure.
1. Загрузите данные в базу данных SQL Server на виртуальной машине Azure.
   
   a.  Войдите на виртуальную машину SQL Server.
   
   b.  Скачайте файлы данных из контейнера службы хранилища Azure в локальную папку виртуальной машины.
   
   c.  Запустите среду SQL Server Management Studio.
   
   d.  Создайте базу данных и целевые таблицы.
   
   д)  Загрузите данные, используя один из методов массового импорта.
   
   е)  Если требуется объединить таблицы, создайте индексы, чтобы ускорить этот процесс.
   
   > [!NOTE]
   > Чтобы быстрее загружать данные большого размера, создайте секционированные таблицы и массово импортируйте данные в параллельном режиме. Дополнительные сведения см. в статье [Параллельный массовый импорт данных с использованием таблиц секционирования SQL](parallel-load-sql-partitioned-tables.md).
   > 
   > 
1. Просмотрите данные и при необходимости создайте компоненты. Эти функции не нужно материализовать в таблицах базы данных. Необходимо указать только запросы, требуемые для их создания.
1. При необходимости выберите размер примера данных.
1. Войдите в [Студию машинного обучения Azure](https://studio.azureml.net/).
1. Считайте данные непосредственно из SQL Server с помощью модуля [Импорт данных][import-data]. Вставьте необходимый запрос, который извлекает поля, создает компоненты и образцы данных, если это необходимо, непосредственно в запросе на [Импорт данных][import-data] .
1. Создайте простой поток операций эксперимента Машинного обучения Azure, начиная с отправленного набора данных.

### <a name="alternate-method-to-copy-a-full-database-from-an-on-premises--sql-server-to-azure-sql-database"></a>Альтернативный метод копирования всей базы данных из локальной системы SQL Server в базу данных SQL Azure
![Отсоединение локальной базы данных и присоединение к базе данных SQL в Azure][7]

#### <a name="additional-azure-resources-azure-virtual-machine-sql-server--ipython-notebook-server"></a>Дополнительные ресурсы Azure: виртуальная машина Azure (сервер SQL Server и IPython Notebook)
Чтобы реплицировать всю базу данных SQL Server в виртуальной машине SQL Server, вам следует скопировать базу данных из одного расположения или сервера в другое (на другой) при условии, что база данных может временно работать в автономном режиме. Вы можете использовать SQL Server Management Studio Обозреватель объектов или эквивалентные команды Transact-SQL.

1. Отсоедините базу данных в исходном расположении. Дополнительные сведения см. [в разделе отсоединение базы данных](https://technet.microsoft.com/library/ms191491\(v=sql.110\).aspx).
1. В окне проводника Windows или командной строки Windows скопируйте файлы отсоединенной базы данных и файлы журнала в целевое расположение на виртуальной машине SQL Server в Azure.
1. Присоедините скопированные файлы к целевому экземпляру SQL Server. Дополнительные сведения см. в статье [Attach a Database](https://technet.microsoft.com/library/ms190209\(v=sql.110\).aspx).

[Перемещение базы данных с помощью отсоединения и присоединения (Transact-SQL)](https://technet.microsoft.com/library/ms187858\(v=sql.110\).aspx)

## <a name="scenario-7-big-data-in-local-files-target-hive-database-in-azure-hdinsight-hadoop-clusters"></a><a name="largedbtohive"></a>Сценарий \# №7. Данные большого размера в локальных файлах, загружаемые в базу данных Hive в кластерах Azure HDInsight Hadoop
![Данные большого размера в локальных файлах для базы данных Hive][9]

#### <a name="additional-azure-resources-azure-hdinsight-hadoop-cluster-and-azure-virtual-machine-ipython-notebook-server"></a>Дополнительные ресурсы Azure: кластер Azure HDInsight Hadoop и виртуальная машина Azure (сервер IPython Notebook)
1. Создайте виртуальную машину Azure с сервером IPython Notebook.
1. Создайте кластер Azure HDInsight Hadoop.
1. Предварительно обработайте и очистите данные (необязательно).
   
   a.  Предварительно обработайте и очистите данные в IPython Notebook из больших двоичных объектов Azure.
   
   b.  При необходимости преобразуйте данные в очищенную табличную форму.
   
   c.  Сохраните данные в локальных файлах виртуальной машины (IPython Notebook запущен на виртуальной машине, и в качестве локальных дисков используются диски виртуальной машины).
1. Отправьте данные в контейнер по умолчанию для кластера Hadoop, выбранный на шаге 2.
1. Загрузите данные в базу данных Hive в кластере Azure HDInsight Hadoop.
   
   a.  Войдите на головной узел кластера Hadoop.
   
   b.  Откройте командную строку Hadoop.
   
   c.  Введите корневой каталог Hive в командной строке Hadoop с помощью команды `cd %hive_home%\bin`.
   
   d.  Выполните запросы Hive, чтобы создать базы данных и таблицы и загрузить данные из хранилища больших двоичных объектов в таблицы Hive.
   
   > [!NOTE]
   > При загрузке больших данных пользователи могут создавать таблицы Hive с разделами. Затем они могут использовать цикл `for` в командной строке Hadoop на головном узле, чтобы загрузить данные в таблицу Hive, секционированную на разделы.
   > 
   > 
1. Просмотрите данные и при необходимости создайте компоненты в командной строке Hadoop. Эти функции не нужно материализовать в таблицах базы данных. Необходимо указать только запросы, требуемые для их создания.
   
   a.  Войдите на головной узел кластера Hadoop.
   
   b.  Откройте командную строку Hadoop.
   
   c.  Введите корневой каталог Hive в командной строке Hadoop с помощью команды `cd %hive_home%\bin`.
   
   d.  Выполните запросы Hive в командной строке Hadoop на головном узле кластера Hadoop, чтобы просмотреть данные и при необходимости создать компоненты.
1. При необходимости создайте пример данных для Студии машинного обучения Azure.
1. Войдите в [Студию машинного обучения Azure](https://studio.azureml.net/).
1. Считайте данные непосредственно из `Hive Queries` с помощью модуля [Импорт данных][import-data]. Вставьте необходимый запрос, который извлекает поля, создает компоненты и образцы данных, если это необходимо, непосредственно в запросе на [Импорт данных][import-data] .
1. Создайте простой поток операций эксперимента Машинного обучения Azure, начиная с отправленного набора данных.

## <a name="decision-tree-for-scenario-selection"></a><a name="decisiontree"></a>Дерево принятия решений для выбора сценариев
---
На следующей схеме показаны сценарии, описанные выше, и варианты, выбранные в каждом сценарии ADAPT. Обработка данных, исследование, проектирование признаков и выборка могут выполняться в одном или нескольких методах или средах — в исходных, промежуточных и (или) целевых средах — и может выполняться итеративно по мере необходимости. Схема иллюстрирует только некоторые из возможных операций и не является исчерпывающей.

![Примеры сценариев с пошаговыми действиями процесса обработки и анализа данных][8]

### <a name="advanced-analytics-in-action-examples"></a>Практические примеры расширенного анализа
Полные пошаговые примеры моделей машинного обучения Azure, в которых демонстрируется применение ADAPT на базе общедоступных наборов данных, см. в перечисленных ниже статьях.

* [Процесс обработки и анализа данных группы на практике: использование SQL Server](sql-walkthrough.md).
* [Процесс обработки и анализа данных группы на практике: использование кластеров HDInsight Hadoop](hive-walkthrough.md).

[1]: ./media/plan-sample-scenarios/dsp-plan-small-in-aml.png
[2]: ./media/plan-sample-scenarios/dsp-plan-local-with-processing.png
[3]: ./media/plan-sample-scenarios/dsp-plan-local-large.png
[4]: ./media/plan-sample-scenarios/dsp-plan-local-to-db.png
[5]: ./media/plan-sample-scenarios/dsp-plan-large-to-db.png
[6]: ./media/plan-sample-scenarios/dsp-plan-db-to-db.png
[7]: ./media/plan-sample-scenarios/dsp-plan-attach-db.png
[8]: ./media/plan-sample-scenarios/dsp-plan-sample-scenarios.png
[9]: ./media/plan-sample-scenarios/dsp-plan-local-to-hive.png


<!-- Module References -->
[import-data]: /azure/machine-learning/studio-module-reference/import-data