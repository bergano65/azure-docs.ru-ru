---
title: Оптимизация обработки данных
titleSuffix: Azure Machine Learning
description: Ознакомьтесь с рекомендациями по оптимизации скорости обработки данных и интеграции, которые Машинное обучение Azure поддерживаются для обработки данных в масштабе.
services: machine-learning
ms.service: machine-learning
ms.author: sgilley
author: sdgilley
ms.subservice: core
ms.reviewer: nibaccam
ms.topic: conceptual
ms.date: 06/26/2020
ms.openlocfilehash: f95c4256f4a0a3fdf410efecf9c22d578d1963a2
ms.sourcegitcommit: f988fc0f13266cea6e86ce618f2b511ce69bbb96
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/31/2020
ms.locfileid: "87461805"
---
# <a name="optimize-data-processing-with-azure-machine-learning"></a>Оптимизация обработки данных с помощью Машинное обучение Azure

В этой статье вы узнаете о рекомендациях, которые помогут оптимизировать скорость обработки данных в локальной и масштабируемой среде.

Машинное обучение Azure интегрированы с пакетами и платформами с открытым исходным кодом для обработки данных. Используя эти интеграции и рекомендации в этой статье, можно улучшить скорость обработки данных как локально, так и в масштабе.

## <a name="parquet-and-csv-file-formats"></a>Форматы файлов Parquet и CSV

Файлы с разделителями-запятыми (CSV) являются обычными форматами для обработки данных. Однако для задач машинного обучения рекомендуется использовать форматы файлов Parquet.

[Файлы Parquet](https://parquet.apache.org/) хранят данные в формате с двоичными столбцами. Этот формат полезен, если требуется разделить данные на несколько файлов. Кроме того, этот формат позволяет ориентироваться на соответствующие поля для экспериментов машинного обучения. Вместо того чтобы читать файл данных размером 20 ГБ, можно уменьшить эту нагрузку, выбрав необходимые столбцы для обучения модели машинного обучения. Файлы Parquet также можно сжать, чтобы снизить вычислительную мощность и занимать меньше пространства.

CSV-файлы обычно используются для импорта и экспорта данных, так как их легко редактировать и читать в Excel. Данные в CSV хранятся в виде строк в формате, основанном на строках, а файлы можно сжимать, чтобы уменьшить нагрузку при обмене данными. Несжатые CSV могут увеличиться на 2-10, а сжатие CSV — еще дальше. Таким образом, размер CSV-файла размером 5 ГБ в памяти расширяется до 8 ГБ ОЗУ на компьютере. Такое сжатие может увеличить задержку передачи данных, что не идеально подходит для обработки больших объемов данных. 

## <a name="pandas-dataframe"></a>Кадр данных Pandas

[Кадры данных Pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/overview.html) обычно используются для обработки и анализа. `Pandas`хорошо работает с размерами данных менее 1 ГБ, но время обработки для `pandas` кадров данные замедляется, когда размер файлов достигает 1 ГБ. Это замедление связано с тем, что размер данных в хранилище не совпадает с размером данных в кадре. Например, данные в CSV-файлах могут расширяться до 10 раз в кадре данных, поэтому CSV-файл размером 1 ГБ может стать 10 ГБ в кадре данных.

`Pandas`является однопотоковым, то есть операции выполняются по одному за раз на одном ЦП. Рабочие нагрузки можно легко распараллелить нескольким виртуальным ЦП в одном Машинное обучение Azure вычислительного экземпляра с такими пакетами, как [Модин](https://modin.readthedocs.io/en/latest/) , которые переносятся `Pandas` с помощью распределенной серверной части.

Для параллелизации задач с помощью `Modin` и [Даск](https://dask.org)просто измените эту строку кода `import pandas as pd` на `import modin.pandas as pd` .

## <a name="dataframe-out-of-memory-error"></a>Кадр данных: ошибка нехватки памяти 

Обычно ошибка *нехватки памяти* возникает, когда кадр данных расширяется выше доступной оперативной памяти на компьютере. Эта концепция также применима к распределенной платформе, такой как `Modin` или `Dask` .  Это значит, что Ваша операция пытается загрузить кадр данных в памяти на каждом узле в кластере, но для этого недостаточно ОЗУ.

Одним из решений является увеличение объема ОЗУ в соответствии с размерами кадров данных в памяти. Рекомендуемый размер вычислительных ресурсов и вычислительная мощность в два раза больше объема ОЗУ. Поэтому, если размер таблицы данных составляет 10 ГБ, используйте целевой объект вычислений с объемом ОЗУ не менее 20 ГБ, чтобы кадр данных можно было разместить в памяти и обработать. 

Для нескольких виртуальных процессоров виртуальных ЦП следует помнить о том, что один раздел можно легко разместить в ОЗУ, каждый виртуальных ЦП на компьютере. То есть при наличии 16 ГБ ОЗУ 4 виртуальных ЦП требуется около 2 ГБ кадров данных на каждый виртуальных ЦП.

### <a name="minimize-cpu-workloads"></a>Сокращение количества рабочих нагрузок ЦП

Если не удается добавить ОЗУ на компьютер, можно применить следующие методы для сокращения нагрузки ЦП и оптимизации времени обработки. Эти рекомендации относятся как к отдельным, так и к распределенным системам.

Метод | Описание
----|----
Сжатие | Используйте другое представление для данных, так как использует меньше памяти и не влияет на результаты вычисления.<br><br>*Пример:* Вместо того чтобы хранить записи в виде строки с приблизительно 10 байтами на запись, сохраните их как логическое значение, true или false, которое можно хранить в 1 байт.
Фрагментирующего | Загрузка данных в память в поднаборах (фрагментах), обработка данных по одному подмножеству во времени или несколько подмножеств в параллельном режиме. Этот метод лучше всего подходит, если необходимо обработать все данные, но не нужно загружать все данные в память одновременно. <br><br>*Пример:* Вместо того чтобы обрабатывать данные за весь год одновременно, загрузите и обработайте данные за один месяц за раз.
Индексация | Примените и используйте индекс — сводку, в которой вы узнаете, где найти нужные данные. Индексирование полезно, когда необходимо использовать только подмножество данных, а не полный набор<br><br>*Пример:* Если у вас есть годовые данные по продажам, отсортированные по месяцам, индекс поможет быстро найти нужный месяц, который необходимо обработать.

## <a name="scale-data-processing"></a>Масштабирование обработки данных

Если предыдущие рекомендации недостаточно, и вы не можете получить виртуальную машину, подходящую для ваших данных, 

* Используйте платформу, например `Spark` или, `Dask` для обработки данных "недостаточно памяти". В этом случае кадр данных загружается в раздел ОЗУ по секциям и обрабатывается с окончательным результатом сбора в конце.  

* Развертывание в кластере с помощью распределенной платформы. В этом случае нагрузка обработки данных разделяется и обрабатывается на нескольких процессорах, работающих параллельно, с окончательным результатом, собранными в конце.


### <a name="recommended-distributed-frameworks"></a>Рекомендуемые распределенные платформы

В следующей таблице приводятся рекомендации по распределенным платформам, интегрированным с Машинное обучение Azure в зависимости от настроек кода или размера данных.

Опыт или размер данных | Рекомендация
------|------
Если вы знакомы с`Pandas`| `Modin`или `Dask` кадр данных
Если вы предпочитаете`Spark` | `PySpark`
Для данных менее 1 ГБ | `Pandas`Локальное **или** удаленное машинное обучение Azure вычислительного экземпляра
Для данных, превышающих 10 ГБ| Перемещение в кластер с помощью `Ray` , `Dask` или`Spark`

`Dask`Кластеры в кластере машинного обучения Azure можно создавать с помощью пакета [Даск-клаудпровидер](https://cloudprovider.dask.org/en/latest/#azure) . Или можно выполнить `Dask` локально на вычислительном экземпляре.

## <a name="next-steps"></a>Дальнейшие действия

* [Параметры приема данных с машинное обучение Azure](concept-data-ingestion.md).
* [Создание и регистрация наборов данных](how-to-create-register-datasets.md).
