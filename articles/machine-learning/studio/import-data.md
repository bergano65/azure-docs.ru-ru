---
title: Импорт обучающих данных из разных источников данных
titleSuffix: Azure Machine Learning Studio
description: Импорт данных в студию машинного обучения Azure из разных источников данных Узнайте, какие типы данных и форматы данных поддерживаются.
services: machine-learning
ms.service: machine-learning
ms.subservice: studio
ms.topic: article
author: ericlicoding
ms.author: amlstudiodocs
ms.custom: previous-author=heatherbshapiro, previous-ms.author=hshapiro
ms.date: 02/01/2019
ms.openlocfilehash: 64a90f0586d5b5010e6b67b59f497317f03f62eb
ms.sourcegitcommit: 75fef8147209a1dcdc7573c4a6a90f0151a12e17
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 02/20/2019
ms.locfileid: "56455098"
---
# <a name="import-your-training-data-into-azure-machine-learning-studio-from-various-data-sources"></a>Импорт обучающих данных в Студию машинного обучения Azure из разных источников данных

При разработке и обучении решения прогнозной аналитики в Студии машинного обучения можно использовать собственные данные из таких источников: 

* **локальный файл**, заранее отправляйте данные из жесткого диска, чтобы создать модуль набора данных в рабочей области;
* **источники данных в Интернете**, с помощью модуля [Импорт данных][import-data] получайте данные из одного или нескольких подключенных источников в ходе эксперимента;
* **эксперимент Студии машинного обучения**, чтобы использовать данные, сохраненные в виде набора данных в Студии машинного обучения;
* [**локальная база данных SQL Server**](use-data-from-an-on-premises-sql-server.md), чтобы использовать данные из локальной базы данных SQL Server без необходимости вручную копировать данные.

> [!NOTE]
> В Студии машинного обучения есть множество примеров наборов данных, которые можно использовать для обучающих данных. Подробнее см. в статье [Использование примеров наборов данных](use-sample-datasets.md).

## <a name="prepare-data"></a>Подготовка данных

Студия машинного обучения Microsoft Azure предназначена для работы с прямоугольными массивами или таблицами данных, такими как текстовые данные с разделителями или структурированные данные из базы данных, хотя в некоторых случаях могут быть использованы данные из непрямоугольных массивов.

Прежде чем импортировать данные в Студию, лучше всего предварительно очистить их. Например, обратите внимание на строки без кавычек.

Тем не менее в Студии доступны модули, позволяющие выполнить некоторую обработку данных в рамках вашего эксперимента после импорта данных. В зависимости от алгоритмов машинного обучения, которые вы будете использовать, необходимо решить, как будут обрабатываться структурные трудности в данных, например отсутствующие значения и разреженные данные, и существуют ли модули, которые могут здесь помочь. В разделе **Преобразование данных** палитры модулей найдите модули, которые выполняют такие функции.

В любой точке вашего эксперимента можно просмотреть или скачать данные, созданные модулем, щелкнув правой кнопкой мыши порт вывода. В зависимости от модуля могут быть доступны разные варианты скачивания или вы сможете просмотреть данные в веб-браузере в Студии.

## <a name="supported-data-formats-and-data-types"></a>Поддерживаемые форматы и типы данных

В свой эксперимент можно импортировать значительное количество типов данных, в зависимости от того, какая система используется для импорта данных и каков источник этих данных:

* Обычный текст (TXT)
* Текст с разделителями-запятыми с заголовком (CSV) или без заголовка (NH.CSV)
* Текст с разделителями-табуляциями с заголовком (TSV) или без заголовка (NH.TSV)
* Файл Excel
* таблицу Azure;
* Таблица Hive
* Таблицы базы данных SQL
* Значения OData
* данные SVMLight (SVMLIGHT) (подробнее о формате см. в [определении SVMLight](http://svmlight.joachims.org/));
* данные в формате ARFF (подробнее о формате см. в [определении ARFF](http://weka.wikispaces.com/ARFF));
* ZIP-файл (ZIP)
* Файл объекта или рабочей области R (RData)

При импорте данных в содержащем метаданные формате (например, ARFF), Студия использует эти метаданные для определения заголовка и типа данных каждого столбца.

При импорте данных в формате, например, TSV или CSV, который не содержит этих метаданных, Студия при выборке данных пытается определить тип данных для каждого столбца. Если данные не содержат заголовки столбцов, Студия использует имена по умолчанию.

Вы можете явно указать или изменить заголовки и типы данных для столбцов с помощью модуля [Изменить метаданные][edit-metadata].

Студия распознает следующие типы данных.

* Строка
* Целое число 
* Double
* Логическое
* DateTime
* TimeSpan

Для передачи данных между модулями Студия использует внутренний тип данных, который называется ***Таблица данных***. Данные можно явно преобразовать в формат таблицы данных с использованием модуля [Convert to Dataset][convert-to-dataset] (Преобразование в набор данных).

Любой модуль, который принимает форматы, отличные от таблицы данных, перед передачей данных в следующий модуль преобразует данные в формат таблицы данных без вмешательства пользователя.

При необходимости можете преобразовать формат таблицы данных обратно в формат CSV, TSV, ARFF или SVMLight, используя другие модули преобразования.
Узнать о модулях, которые выполняют эти функции, можно узнать в разделе **Преобразование форматов данных** палитры модулей.

## <a name="data-capacities"></a>Емкости данных

Модули в Студии машинного обучения поддерживают наборы данных объемом до 10 ГБ плотных числовых данных для распространенных случаев использования. Если модуль принимает несколько видов входных данных, то их общий объем должен составлять 10 ГБ. Вы можете создать выборку больших наборов данных с помощью запросов Hive или Базы данных SQL Azure или предварительной обработки модуля "Обучение на основе счетчиков" перед импортом данных.  

Следующие типы данных можно развернуть в большие наборы данных при нормализации признаков. Максимальный объем этих данных — менее 10 ГБ:

* разреженные;
* категориальные;
* строк
* Двоичные данные

В следующих модулях можно использовать наборы данных объемом менее 10 ГБ:

* модули системы рекомендаций;
* модуль метода увеличения числа примеров миноритарного класса с помощью синтетических объектов (SMOTE);
* модули написания скриптов: R, Python, SQL;
* модули, в которых объем выходных данных может превышать объем входных данных, такие как "Слияние" или "Хэширование признаков";
* "Перекрестная проверка", "Гиперпараметры модели настройки", "Порядковая регрессия" и "Многоклассовая классификация «один — все»", когда число итераций очень велико.

Для наборов данных объемом больше, чем несколько гигабайт, требуется передать данные в службу хранилища Azure или базу данных SQL Azure либо использовать HDInsight, а не отправлять данные прямо из локального файла.

Вы можете найти сведения о данных изображений в ссылке на модуль [Импорт образов](https://docs.microsoft.com/azure/machine-learning/studio-module-reference/import-images#bkmk_Notes).

## <a name="import-from-a-local-file"></a>Импорт из локального файла

Вы можете отправить файл с данными с жесткого диска и использовать его в качестве данных для обучения в Студии. При импорте файла данных, можете создать модуль набора данных, который готов для использования в экспериментах рабочей области.

Чтобы импортировать данные из локального жесткого диска, выполните следующие действия:

1. В Студии щелкните **+Создать** в нижней части окна.
2. Выберите **Набор данных** и **From local file** (Из локального файла).
3. В диалоговом окне **Upload a new dataset**  (Отправить новый набор данных) перейдите к файлу, который необходимо отправить.
4. Введите имя, укажите тип данных и, при необходимости, введите описание. Рекомендуем ввести описание — оно позволяет записать все характеристики данных, которые необходимо помнить при использовании данных в будущем.
5. Флажок **Это новая версия существующего набора данных** позволяет обновить существующий набор данных новыми данными. Чтобы выполнить это, установите флажок, а затем введите имя существующего набора данных.

![Передача нового набора данных](./media/import-data/upload-dataset-from-local-file.png)

Время передачи зависит от объема данных и скорости подключения к службе. Если вы знаете, что передача файла займет много времени, выполните другие задачи в Студии. Тем не менее закрытие браузера до завершения загрузки данных приведет к ошибке передачи данных.

После загрузки данные сохраняются в модуле набора данных и доступны для любого эксперимента в рабочей области.

При редактировании эксперимента вы можете найти ранее отправленные наборы данных в списке **My Datasets** (Мои наборы данных), который входит в список **Saved Datasets** (Сохраненные наборы данных), в палитре модулей. Перетащите набор данных на холст эксперимента, где нужно использовать эти данные для последующего анализа и машинного обучения.

## <a name="import-from-online-data-sources"></a>Импорт из сетевых источников данных

Используя модуль [Импорт данных][import-data], ваш эксперимент может импортировать данные из различных подключенных источников данных во время проведения эксперимента.

> [!NOTE]
> Эта статья содержит общие сведения о модуле [Импорт данных][import-data]. Дополнительные сведения о типах данных, к которым можно получить доступ, форматах, параметрах, а также ответы на часто задаваемые вопросы см. в разделе справки по модулю [Импорт данных][import-data].

Вы можете получить доступ к данным из одного из нескольких подключенных источников данных во время запуска эксперимента с помощью модуля [Импорт данных][import-data].

* URL-адрес с использованием HTTP;
* Hadoop с использованием HiveQL
* Хранилище blob-объектов Azure
* таблицу Azure;
* базу данных SQL Azure или сервер SQL Server на виртуальной машине Azure;
* локальная база данных SQL Server;
* поставщик веб-канала данных (в настоящее время OData).
* Azure Cosmos DB

Так как доступ к этим данным для обучения осуществляется во время эксперимента, они доступны только в рамках этого эксперимента. Для сравнения: данные, хранящиеся в модуле набора данных, доступны для любого эксперимента в рабочей области.

Чтобы получить доступ к онлайн-источникам данных в своем эксперименте в Студии, добавьте модуль [Импорт данных][import-data]. Затем выберите **Запустить мастер импорта данных** в разделе **Свойства**, чтобы получить пошаговые инструкции по выбору и настройке источника данных. Кроме того, вы можете вручную выбрать **Источник данных** в разделе **Свойства** и указать параметры, необходимые для доступа к данным.

Поддерживаемые сетевые источники данных описаны в таблице ниже. Кроме того, в этой таблице перечислены поддерживаемые форматы файлов и параметры, используемые для доступа к данным.

> [!IMPORTANT]
> В настоящее время модули [Импорт данных][import-data] и [Экспорт данных][export-data] могут читать и записывать только данные в службе хранилища Azure, созданной с помощью классической модели развертывания. Другими словами, новый тип учетной записи хранилища BLOB-объектов Azure, предоставляющий "горячий" или "холодный" уровень доступа к хранилищу, не еще поддерживается.
>
> Как правило, это не повлияет на учетные записи хранения Azure, созданные до появления данного уровня служб.
> Если необходимо создать учетную запись, выберите **классическую** модель развертывания или используйте Resource Manager и в качестве **типа учетной записи** выберите **Общее назначение**, а не **Хранилище BLOB-объектов**.
>
> Дополнительные сведения см. в статье [Хранилище BLOB-объектов Azure: горячий, холодный, архивный уровни хранилища и уровень "Премиум" (предварительная версия)](../../storage/blobs/storage-blob-storage-tiers.md).

### <a name="supported-online-data-sources"></a>Поддерживаемые сетевые источники данных
Модуль **Импорт данных** Студии машинного обучения Azure поддерживает следующие источники данных:

| источник данных | ОПИСАНИЕ | Параметры |
| --- | --- | --- |
| URL-адрес с использованием протокола HTTP |Считывает данные в файлах с разделителями-запятыми (CSV), файлах с разделителями-табуляциями (TSV), а также в файлах в формате ARFF и SVM-light из любого URL-адреса, использующего протокол HTTP. |<b>URL-адрес</b>. Задает полное имя файла, включая URL-адрес сайта и имя файла с любым расширением. <br/><br/><b>Формат данных</b>. Задает один из поддерживаемых форматов данных: CSV, TSV, ARFF или SVM-light. Если данные содержат строку заголовков, она используется для назначения имен столбцов. |
| Hadoop/HDFS |Считывает данные из распределенного хранилища в Hadoop. Необходимые вам данные можно указать с помощью HiveQL, языка запросов на основе SQL. С помощью HiveQL вы также можете выполнить статистическую обработку и фильтрацию данных перед их добавлением в Студию. |<b>Запрос к базе данных Hive</b>. Указывает запрос Hive, используемый для создания данных.<br/><br/><b>URI сервера HCatalog</b>. Задает имя кластера в формате *&lt;имя кластера&gt;.azurehdinsight.net.*<br/><br/><b>Имя учетной записи пользователя Hadoop</b>. Задает имя учетной записи пользователя Hadoop для подготовки кластера.<br/><br/><b>Пароль учетной записи пользователя Hadoop</b>. Задает учетные данные, используемые при подготовке кластера. Дополнительные сведения см. в статье [Создание кластеров Hadoop в HDInsight](../../hdinsight/hdinsight-provision-clusters.md).<br/><br/><b>Расположение выходных данных</b>. Указывает, где хранятся данные: в распределенной файловой системе Hadoop (HDFS) или в Azure. <br/><ul>Если выходные данные хранятся в HDFS, укажите универсальный код ресурса (URI) сервера HDFS. (не забудьте указать имя кластера HDInsight без префикса HTTPS://). <br/><br/>Если выходные данные хранятся в Azure, необходимо указать имя учетной записи хранения Azure, ключ доступа к хранилищу и имя контейнера хранилища.</ul> |
| База данных SQL |Считывает данные, хранящиеся в базе данных SQL Azure или в базе данных SQL Server, запущенной на виртуальной машине Azure. |<b>Имя сервера базы данных</b>. Указывает имя сервера, на котором запущена база данных.<br/><ul>Если используется база данных SQL Azure, введите создаваемое имя сервера. Обычно оно указывается в таком формате: *&lt;созданный_идентификатор&gt;.database.windows.net*. <br/><br/>Если используется случае сервер SQL, размещенный на виртуальной машине, то введите *tcp:&lt;DNS-имя_виртуальной_машины&gt;, 1433*.</ul><br/><b>Имя базы данных</b>. Задает имя базы данных на сервере. <br/><br/><b>Имя учетной записи пользователя сервера</b>. Задает имя пользователя учетной записи с разрешением на доступ к базе данных. <br/><br/><b>Пароль учетной записи пользователя сервера</b>. Указывает пароль для учетной записи пользователя.<br/><br/><b>Запрос к базе данных</b>. Введите инструкцию SQL, описывающую данные, которые необходимо получить. |
| Локальная база данных SQL |Считывает данные, хранящиеся в локальной базе данных SQL. |<b>Шлюз данных</b>. Задает имя шлюза управления данными, установленного на компьютере, имеющем доступ к базе данных SQL Server. Сведения о настройке шлюза см. в разделе [Выполнение аналитики с помощью студии машинного обучения Azure на основе данных из локальной базы данных SQL Server](use-data-from-an-on-premises-sql-server.md).<br/><br/><b>Имя сервера базы данных</b>. Указывает имя сервера, на котором запущена база данных.<br/><br/><b>Имя базы данных</b>. Задает имя базы данных на сервере. <br/><br/><b>Имя учетной записи пользователя сервера</b>. Задает имя пользователя учетной записи с разрешением на доступ к базе данных. <br/><br/><b>Имя пользователя и пароль</b>. Чтобы ввести учетные данные базы данных, щелкните <b>Введите значения</b>. Можно использовать встроенную аутентификацию Windows или аутентификацию SQL Server, в зависимости от настроек локального сервера SQL Server.<br/><br/><b>Запрос к базе данных</b>. Введите инструкцию SQL, описывающую данные, которые необходимо получить. |
| таблице Azure |Считывает данные из службы таблиц в хранилище Azure.<br/><br/>Если вам нечасто требуется считывание больших объемов данных, используйте службу таблиц Azure. Это недорогое и гибкое нереляционное (NoSQL) решение хранилища с высокой степенью масштабируемости и доступности. |Изменение параметров в модуле **Импорт данных** зависит от того, обращаетесь ли вы к общедоступной информации или к частной учетной записи хранения, для входа в которую нужны учетные данные. Это определяется параметром <b>Тип проверки подлинности</b>, который может иметь значение PublicOrSAS или Account. Каждое из этих значений имеет собственный набор параметров. <br/><br/><b>URI общедоступного или подписанного URL-адреса (SAS)</b>. Используются следующие параметры:<br/><br/><ul><b>URI таблицы</b>. Задает общедоступный или подписанный URL-адрес (SAS) таблицы.<br/><br/><b>Определяет строки для поиска имен свойств</b>. Значение <i>TopN</i> позволяет проверить указанное число строк, а значение <i>ScanAll</i> — получить все строки в таблице. <br/><br/>Если данные однородные и прогнозируемые, рекомендуется выбрать *TopN* и ввести значение N. Для больших таблиц это может сократить время чтения.<br/><br/>Если данные структурированы и имеют наборы свойств, которые различаются в зависимости от вложенности и положения таблицы, выберите значение *ScanAll*, чтобы проверить все строки. Это гарантирует целостность полученного свойства и преобразования метаданных.<br/><br/></ul><b>Частная учетная запись хранения</b>. Используются следующие параметры: <br/><br/><ul><b>Имя учетной записи</b>. Указывает имя учетной записи, содержащей таблицу, выбранную для чтения.<br/><br/><b>Ключ учетной записи</b>. Указывает ключ к хранилищу данных, связанный с этой учетной записью.<br/><br/><b>Имя таблицы</b>. Указывает имя таблицы, содержащей данные для чтения.<br/><br/><b>Строки для поиска имен свойств</b>. Значение <i>TopN</i> позволяет проверить указанное число строк, а значение <i>ScanAll</i> — получить все строки в таблице.<br/><br/>Если данные однородные и прогнозируемые, то рекомендуется выбрать *TopN* и ввести значение N. Для больших таблиц это может сократить время чтения.<br/><br/>Если данные структурированы и имеют наборы свойств, которые различаются в зависимости от вложенности и положения таблицы, выберите значение *ScanAll*, чтобы проверить все строки. Это гарантирует целостность полученного свойства и преобразования метаданных.<br/><br/> |
| Хранилище больших двоичных объектов Azure |Считывает данные, хранящиеся в службе больших двоичных объектов в хранилище Azure, включая изображения, неструктурированные текстовые данные и двоичные данные.<br/><br/>Службу BLOB-объектов можно использовать для предоставления общего доступа к данным или для закрытого хранения данных приложения. Доступ к данным можно получить из любого места, подключившись через протокол HTTP или HTTPS. |Изменение параметров в модуле **Импорт данных** зависит от того, обращаетесь ли вы к общедоступной информации или к частной учетной записи хранения, для входа в которую нужны учетные данные. Это определяется параметром <b>Тип проверки подлинности</b>, который может иметь значение PublicOrSAS или Account.<br/><br/><b>URI общедоступного или подписанного URL-адреса (SAS)</b>. Используются следующие параметры:<br/><br/><ul><b>Универсальный код ресурса (URI)</b>. Задает общедоступный или подписанный URL-адрес (SAS) большого двоичного объекта службы хранилища.<br/><br/><b>Формат файла</b>. Задает формат данных в службе BLOB-объектов. Поддерживаемые форматы: CSV, TSV и ARFF.<br/><br/></ul><b>Частная учетная запись хранения</b>. Используются следующие параметры: <br/><br/><ul><b>Имя учетной записи</b>. Указывает имя учетной записи, содержащей большой двоичный объект, выбранный для чтения.<br/><br/><b>Ключ учетной записи</b>. Указывает ключ к хранилищу данных, связанный с этой учетной записью.<br/><br/><b>Путь к контейнеру, каталогу или большому двоичному объекту</b>. Указывает имя большого двоичного объекта, содержащего данные для чтения.<br/><br/><b>Формат файла большого двоичного объекта</b>. Задает формат данных в службе BLOB-объектов. Поддерживаемые форматы данных: CSV, TSV, ARFF, CSV с заданной кодировкой и Excel. <br/><br/><ul>Если используется формат CSV или TSV, обязательно укажите, содержит ли файл строку заголовка.<br/><br/>Для чтения данных из книги Excel можно использовать параметр Excel. В параметре <i>Формат данных Excel</i> укажите, где находятся данные: в диапазоне листа Excel или в таблице Excel. В параметре <i>Excel sheet or embedded table</i> (Лист или внедренная таблица Excel) укажите имя листа или таблицы для считывания данных.</ul><br/> |
| Поставщик веб-канала данных |Считывает данные, получаемые от поддерживаемого поставщика веб-канала. В настоящее время поддерживается только формат Open Data Protocol (OData). |<b>Тип содержимого данных</b>. Задает формат OData.<br/><br/><b>Исходный URL-адрес</b>. Указывает полный URL-адрес веб-канала данных. <br/>Например, этот URL-адрес позволяет считывать данные из примера базы данных Northwind: http://services.odata.org/northwind/northwind.svc/. |

## <a name="import-from-another-experiment"></a>Импорт из другого эксперимента

Иногда понадобится получить в эксперименте промежуточный результат, который будет использоваться в другом эксперименте. Для этого сохраните модуль как набор данных, выполнив указанные ниже действия.

1. Щелкните выходные данные модуля, которые требуется сохранить в виде набора данных.
2. Щелкните **Сохранить как набор данных**.
3. При появлении запроса введите имя и описание, которое позволит легко идентифицировать набор данных.
4. Установите флажок **ОК** .

После завершения сохранения набор данных будет доступен для использования в любом эксперименте в рабочей области. Его можно найти в списке **Сохраненные наборы данных** в палитре модулей.

## <a name="next-steps"></a>Дополнительная информация

[Развертывание веб-служб Студии машинного обучения Azure, использующих модули импорта и экспорта данных](web-services-that-use-import-export-modules.md)


<!-- Module References -->
[import-data]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/
[export-data]: https://msdn.microsoft.com/library/azure/7A391181-B6A7-4AD4-B82D-E419C0D6522C/


<!-- Module References -->
[convert-to-dataset]: https://msdn.microsoft.com/library/azure/72bf58e0-fc87-4bb1-9704-f1805003b975/
[edit-metadata]: https://msdn.microsoft.com/library/azure/370b6676-c11c-486f-bf73-35349f842a66/
[import-data]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/
