---
title: 'Скрытое выделение Дирихле метода: ссылка на модуль'
titleSuffix: Azure Machine Learning
description: Сведения об использовании модуля скрытого выделения Дирихле метода для группирования неклассифицированного текста в категории.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: likebupt
ms.author: keli19
ms.date: 06/05/2020
ms.openlocfilehash: f9f239ea69aaf71e591a447feb300c13a45ba1a4
ms.sourcegitcommit: 53acd9895a4a395efa6d7cd41d7f78e392b9cfbe
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/22/2020
ms.locfileid: "90907850"
---
# <a name="latent-dirichlet-allocation-module"></a>Модуль выделения скрытых Дирихле метода

В этой статье описывается использование модуля скрытого выделения памяти Дирихле метода в конструкторе Машинное обучение Azure для группирования неклассифицированного текста в категории. 

Скрытое выделение Дирихле метода (LDA) часто используется в обработке на естественном языке для поиска похожих текстов. Другим распространенным термином является *моделирование разделов*.

Этот модуль принимает столбец текста и создает следующие выходные данные:

+ Исходный текст вместе с показателем для каждой категории

+ Матрица функций, которая содержит извлеченные термины и коэффициенты для каждой категории

+ Преобразование, которое можно сохранить и применить повторно к новому тексту, используемому в качестве входных данных

В этом модуле используется библиотека scikit-учиться. Дополнительные сведения о scikit см. в [репозитории GitHub](https://github.com/scikit-learn/scikit-learn), который содержит учебники и описание алгоритма.

## <a name="more-about-latent-dirichlet-allocation"></a>Дополнительные сведения о скрытом выделении Дирихле метода

LDA обычно не является методом классификации. Но он использует регенеративный подход, поэтому вам не нужно предоставлять известные метки классов, а затем определять закономерности.  Вместо этого алгоритм создает модель вероятностная, которая используется для выделения групп разделов. Модель вероятностная можно использовать для классификации существующих обучающих вариантов или новых вариантов, предоставляемых модели в качестве входных данных.

Вы можете предпочесть регенеративную модель, поскольку она позволяет избежать принятия строгих предположений относительно связи между текстом и категориями. Он использует только распределение слов для математических моделей.

Теория обсуждается в этой статье, которая доступна как загрузка в формате PDF: [скрытые Дирихле метода выделения: блеи, NG и Иордания](https://ai.stanford.edu/~ang/papers/nips01-lda.pdf).

Реализация в этом модуле основана на [библиотеке scikit-учиться](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/decomposition/_lda.py) для Lda.

Дополнительные сведения см. в разделе [Технические примечания](#technical-notes) .

## <a name="how-to-configure-latent-dirichlet-allocation"></a>Настройка выделения скрытых Дирихле метода

Для этого модуля требуется набор данных, содержащий столбец текста, либо необработанный, либо предварительно обработанный.

1. Добавьте в конвейер модуль **выделения скрытых Дирихле метода** .

2. В качестве входных данных для модуля укажите набор данных, содержащий один или несколько текстовых столбцов.

3. Для поля **целевые столбцы**выберите один или несколько столбцов, содержащих текст для анализа.

    Можно выбрать несколько столбцов, но они должны иметь **строковый** тип данных.

    Так как LDA создает табличную матрицу из текста, обычно анализируется один текстовый столбец.

4. Для параметра  **число разделов для модели**введите целое число от 1 до 1000, которое указывает, сколько категорий или разделов нужно наследовать от входного текста.

    По умолчанию создаются 5 разделов.

5. Для **n-грамм**укажите максимальную длину n-грамм, созданную во время хэширования.

    Значение по умолчанию — 2, то есть создаются и биграмм, и униграмм.

6. Выберите параметр **нормализация** для преобразования выходных значений в вероятности. 

    Вместо того чтобы представлять преобразованные значения как целые числа, значения в наборе данных вывода и функции будут преобразованы следующим образом:

    + Значения в наборе данных будут представлены как вероятность, где `P(topic|document)` .

    + Значения в матрице раздела функции будут представлены как вероятность, где `P(word|topic)` .

    > [!NOTE] 
    > В Машинное обучение Azure Designer библиотека scikit-учиться больше не поддерживает ненормализованные *doc_topic_distr* выходные данные из версии 0,19. В этом модуле параметр **нормализации** может применяться только к выходным данным в *матрице разделов компонентов* . *Преобразованный вывод набора данных* всегда нормализован.

7. Выберите параметр **Показывать все параметры**и задайте для него значение **true** , если необходимо задать следующие дополнительные параметры.

    Эти параметры относятся к реализации scikit-учиться LDA. Есть несколько хороших руководств по LDA в scikit-учиться, а также официальный [документ scikit-учиться](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html).

    + **Параметр Ро**. Укажите более раннюю вероятность для распределения разделов. Этот параметр соответствует `topic_word_prior` параметру sklearn. Если предполагается, что распределение слов является плоским, используется значение **1** . то есть все слова считаются екуипробабле. Если вы считаете, что большинство слов имеют разреженные, можно установить более низкое значение.

    + **Альфа-параметр**. Укажите более раннюю вероятность для веса разделов в документе. Этот параметр соответствует `doc_topic_prior` параметру sklearn.

    + **Предполагаемое количество документов**. Введите число, представляющее наиболее подходящую оценку количества документов (строк), которые будут обработаны. Этот параметр позволяет модулю выделить хэш-таблицу достаточного размера. Он соответствует `total_samples` параметру в scikit-учиться.

    + **Размер пакета**. Введите число, которое указывает, сколько строк следует включить в каждый пакет текста, отправляемый в модель LDA. Этот параметр соответствует `batch_size` параметру в scikit — сведения.

    + **Начальное значение итерации, используемое в расписании обновлений для образовательных**заработок. Укажите начальное значение, довнвеигхтс скорость обучения для ранних итераций в интерактивном обучении. Этот параметр соответствует `learning_offset` параметру в scikit — сведения.

    + **Питание, применяемое к итерации во время обновлений**. Указывает уровень мощности, применяемый к количеству итераций, для управления частотой обучения во время обновлений в сети. Этот параметр соответствует `learning_decay` параметру в scikit — сведения.

    + **Количество проходов по данным**. Укажите максимальное число циклов, по которым алгоритм будет циклически проходить по данным. Этот параметр соответствует `max_iter` параметру в scikit — сведения.

8. Выберите параметр **построить словарь n-граммы** или **построить словарь n-граммы до Lda**, если вы хотите создать список n-грамм в начальном проходе перед классификацией текста.

    Если исходный словарь создан заранее, можно использовать словарь при просмотре модели. Возможность сопоставлять результаты с текстом, а не с числовыми индексами, как правило, проще для интерпретации. Однако сохранение словаря займет больше времени и использует дополнительное хранилище.

9. Для параметра **максимальный размер словаря ngram**введите общее число строк, которые могут быть созданы в словаре n-грамм.

    Этот параметр полезен для управления размером словаря. Но если число n-граммы во входных данных превышает этот размер, могут возникать конфликты.

10. Отправьте конвейер. Модуль LDA использует алгоритм Байеса теорема, чтобы определить, какие темы могут быть связаны с отдельными словами. Слова не связаны только с какими либо разделами или группами. Вместо этого каждая n-грамма имеет определенную вероятность, связанную с любым из обнаруженных классов.

## <a name="results"></a>Результаты

Модуль имеет два выхода:

+ **Преобразованный набор данных**. Этот выход содержит входной текст, указанное число обнаруженных категорий и оценки каждого текстового примера для каждой категории.

+ **Матрица раздела компонентов**: крайний левый столбец содержит функцию извлеченного текста. Столбец для каждой категории содержит оценку для этой функции в этой категории.


### <a name="lda-transformation"></a>Преобразование LDA

Этот модуль также выводит *Преобразование Lda* , которое применяет Lda к набору данных.

Это преобразование можно сохранить и использовать повторно для других наборов данных. Этот метод может быть полезен, если вы обучились по большому совокупностиу и хотите повторно использовать коэффициенты или категории.

Чтобы повторно использовать это преобразование, выберите значок **Register DataSet (зарегистрировать набор данных** ) на правой панели модуля скрытого распределения Дирихле метода, чтобы он оставался в категории **наборы данных** в списке модулей. Затем можно подключить этот модуль к модулю [Apply преобразование](apply-transformation.md) , чтобы повторно использовать это преобразование.

### <a name="refining-an-lda-model-or-results"></a>Уточнение модели LDA или результатов

Как правило, нельзя создать отдельную модель LDA, которая будет соответствовать всем потребностям. Даже модель, предназначенная для одной задачи, может потребовать много итераций для повышения точности. Мы рекомендуем использовать все эти методы для улучшения модели:

+ Изменение параметров модели
+ Использование визуализации для понимания результатов
+ Получение отзывов экспертов о предметной области, чтобы определить, полезны ли созданные разделы

Качественные меры также могут быть полезны для оценки результатов. Чтобы оценить результаты моделирования разделов, учитывайте следующее.

+ Достоверность. Похожи ли аналогичные элементы?
+ Разнообразия. Может ли модель отличать похожие элементы, когда это требуется для бизнес-задачи?
+ масштабируемость; Работает ли он с широким диапазоном текстовых категорий или только с узким целевым доменом?

Вы часто можете улучшить точность моделей на основе LDA, используя обработку на естественном языке для очистки, суммирования и упрощения или категоризации текста. Например, следующие методы, поддерживаемые в Машинное обучение Azure, могут улучшить точность классификации:

+ Удаление стоп-слов

+ Нормализация вариантов

+ Лемматизация или извлечение корней

+ Распознавание именованных сущностей

Дополнительные сведения см. в разделе [Предварительная обработка текста](preprocess-text.md).

В конструкторе также можно использовать библиотеки R или Python для обработки текста: [выполнение скрипта r](execute-r-script.md),  [выполнение скрипта Python](execute-python-script.md).



## <a name="technical-notes"></a>Технические примечания

В этом разделе содержатся сведения о реализации, советы и ответы на часто задаваемые вопросы.

### <a name="implementation-details"></a>Сведения о реализации

По умолчанию распределения выходов для преобразованного набора данных и матрицы компонентов-разделов нормализованы как вероятности.

+ Преобразованный набор данных нормализуется как условная вероятность разделов, заданных документом. В этом случае сумма каждой строки равна 1.

+ Матрица функций-разделов нормализована как условная вероятность слов, заданных в разделе. В этом случае сумма каждого столбца равна 1.

> [!TIP]
> Иногда модуль может вернуть пустой раздел. Чаще всего причиной является псевдо-случайная инициализация алгоритма. В этом случае можно попробовать изменить связанные параметры. Например, можно изменить максимальный размер словаря N-грамм или число битов, используемых для хэширования компонентов.

### <a name="lda-and-topic-modeling"></a>Моделирование LDA и разделов

Выделение скрытых Дирихле метода часто используется для *моделирования разделов на основе содержимого*, что по сути означает категории обучения из неклассифицированного текста. В разделе моделирование разделов на основе содержимого раздел представляет собой распределение по словам.

Например, предположим, что вы предоставили совокупности проверок клиентов, включающих множество продуктов. Текст проверок, отправленных клиентами с течением времени, содержит много терминов, некоторые из которых используются в нескольких разделах.

*Раздел* , идентифицированный процессом Lda, может представлять обзоры для отдельного продукта или представлять группу проверок продукта. Для LDA сам раздел является просто распределением вероятности по времени для набора слов.

Термины редко исключаются для одного продукта. Они могут ссылаться на другие продукты или представлять собой общие термины, применимые ко всем («отлично», «ужасные»). Другие термины могут быть неучитываемыми словами. Однако метод LDA не пытается захватить все слова в вселенной или понять, как взаимосвязаны слова, помимо вероятностей совместного вхождения. Он может группировать только те слова, которые используются в конечном домене.

После того как индексы терминов будут вычислены, мера сходства на основе расстояния сравнивает отдельные строки текста, чтобы определить, похожи ли два фрагмента текста. Например, может оказаться, что у продукта есть несколько имен, которые имеют строгую корреляцию. Или вы можете обнаружить, что строго отрицательные термины обычно связаны с определенным продуктом. Для определения связанных терминов и создания рекомендаций можно использовать меру подобия.

###  <a name="module-parameters"></a>Параметры модуля

|Имя|Type|Диапазон|Необязательно|По умолчанию|Описание|  
|----------|----------|-----------|--------------|-------------|-----------------|  
|Целевые столбцы|Выполните действия на странице Выбор столбцов.||Обязательно|StringFeature|Имя или индекс целевого столбца.|  
|Число разделов для модели|Тип Integer|[1; 1000]|Обязательно|5|Моделирование распределения документов по N темам.|  
|N-граммы|Тип Integer|[1; 10]|Обязательно|2|Порядок N-датаграмм, созданных во время хэширования.|  
|Нормализовать|Логическое значение|Значение true или false|Обязательно|Да|Нормализовать выходные данные в вероятности.  Преобразованный набор данных будет иметь вид P (раздел&#124;документ), а матрица с тем или другими компонентами будет иметь вид P (Word&#124;разделе).|  
|Отображение всех параметров|Логическое значение|Значение true или false|Обязательно|False|Предоставляет дополнительные параметры, относящиеся к scikit-учиться Интернету LDA.|  
|Параметр Ро|Float|[намерено; 1,0]|Применяется, если установлен флажок " **Показывать все параметры** "|0,01|Предварительное распространение слова раздела.|  
|Альфа-параметр|Float|[намерено; 1,0]|Применяется, если установлен флажок " **Показывать все параметры** "|0,01|Документ, посвященный предыдущему распространению.|  
|Предполагаемое число документов|Тип Integer|[1;int.MaxValue]|Применяется, если установлен флажок " **Показывать все параметры** "|1000|Предполагаемое количество документов. Соответствует `total_samples` параметру.|  
|Размер пакета|Тип Integer|[1; 1024]|Применяется, если установлен флажок " **Показывать все параметры** "|32|Размер пакета.|  
|Начальное значение итерации, используемое в расписании обновления темпов обучения|Тип Integer|[0; int. MaxValue|Применяется, если установлен флажок " **Показывать все параметры** "|0|Начальное значение, довнвеигхтс обучающий темп для ранних итераций. Соответствует `learning_offset` параметру.|  
|Питание, применяемое к итерации во время обновлений|Float|[0.0; 1.0]|Применяется, если установлен флажок " **Показывать все параметры** "|0,5|Питание, применяемое к количеству итераций для контроля скорости обучения. Соответствует `learning_decay` параметру. |  
|Число итераций обучения|Тип Integer|[1; 1024]|Применяется, если установлен флажок " **Показывать все параметры** "|25|Число итераций для обучения.|  
|Сборка словаря n-граммы|Логическое значение|Значение true или false|Применяется, если флажок " **Показывать все параметры** " *не* установлен.|Да|Создает словарь n-граммы до вычисления LDA. Полезно для проверки и интерпретации модели.|  
|Максимальный размер словаря ngram|Тип Integer|[1;int.MaxValue]|Применяется, когда параметр **Build Dictionary объекта n-граммы** имеет **значение true**|20 000|Максимальный размер словаря n-граммы. Если число токенов во входных данных превышает этот размер, могут возникать конфликты.|  
|Число битов, используемых для хэширования компонентов.|Тип Integer|[1; 31]|Применяется, если флажок " **Показывать все параметры** " *не* установлен и **словарь сборки n-граммы** имеет **значение false**|12|Число битов, используемых для хэширования компонентов.| 
|Сборка словаря n-граммы до LDA|Логическое значение|Значение true или false|Применяется, если установлен флажок " **Показывать все параметры** "|Да|Создает словарь n-граммы до LDA. Полезно для проверки и интерпретации модели.|  
|Максимальное число n-граммы в словаре|Тип Integer|[1;int.MaxValue]|Применяется, если установлен флажок **Показывать все параметры** и параметр **построить словарь N-граммы** имеет **значение true** .|20 000|Максимальный размер словаря. Если число токенов во входных данных превышает этот размер, могут возникать конфликты.|  
|Число хэш-битов|Тип Integer|[1; 31]|Применяется, если установлен флажок **Показывать все параметры** и параметр **построить словарь N-граммы** имеет **значение false** .|12|Число битов, используемых при хэшировании компонентов.|   


## <a name="next-steps"></a>Дальнейшие действия

Ознакомьтесь с [набором доступных модулей](module-reference.md) в службе Машинного обучения Azure. 

Список ошибок, характерных для модулей, см. [в разделе исключения и коды ошибок для конструктора](designer-error-codes.md).
