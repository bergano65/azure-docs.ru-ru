---
title: 'Лес решений с двумя классами: Справочник по модулям'
titleSuffix: Azure Machine Learning
description: Узнайте, как использовать модуль леса решений с двумя классами в Машинное обучение Azure для создания модели машинного обучения на основе алгоритма лесов принятия решений.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: likebupt
ms.author: keli19
ms.date: 04/22/2020
ms.openlocfilehash: c98935781699510d84247f80367d5c57cb388f6b
ms.sourcegitcommit: 1ed0230c48656d0e5c72a502bfb4f53b8a774ef1
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/24/2020
ms.locfileid: "82137643"
---
# <a name="two-class-decision-forest-module"></a>Модуль леса решений с двумя классами

В этой статье описывается модуль в Машинное обучение Azure Designer (Предварительная версия).

Этот модуль используется для создания модели машинного обучения на основе алгоритма лесов принятия решений.  

Леса принятия решений — это быстрые, контролируемые модели ансамблей. Этот модуль хорошо подходит для прогнозирования целевого объекта с максимальным количеством двух результатов. 

## <a name="understanding-decision-forests"></a>Общие сведения о лесах принятия решений

Этот алгоритм леса принятия решений — это метод обучения ансамблей, предназначенный для задач классификации. Методы ансамблей основаны на общем принципе, который не полагается на одну модель, можно получить лучшие результаты и более обобщенную модель, создав несколько связанных моделей и объединив их каким-либо образом. Вообще говоря, модели совокупности обеспечивают большее покрытие и точность, чем одно дерево принятия решений. 

Существует множество способов создания отдельных моделей и их объединения в ансамблей. Эта конкретная реализация леса принятия решений работает путем создания нескольких деревьев решений и последующего **голосования** по наиболее популярным выходным классам. Голосование — один из более известных методов создания результатов в модели ансамблей. 

+ Многие отдельные деревья классификации создаются с использованием всего набора данных, но разными (обычно случайными) начальными точками. Это отличается от подхода случайного леса, в котором отдельные деревья принятия решений могут использовать только произвольную часть данных или функций.
+ Каждое дерево в дереве леса принятия решений выводит гистограмму ненормализованной частоты меток. 
+ Процесс статистической обработки суммирует эти гистограммы и нормализует результат, чтобы получить "вероятностные" для каждой метки. 
+ Деревья с высокой достоверностью прогноза будут иметь больший вес в окончательном принятии решения ансамблей.

Деревья принятия решений в целом имеют много преимуществ для задач классификации:
  
- Они могут захватывать нелинейные границы принятия решений.
- Вы можете обучить и прогнозировать большие объемы данных, так как они эффективны в расчете и использовании памяти.
- Выбор компонентов интегрирован в процессы обучения и классификации.  
- Деревья могут поддерживать шумы данных и многие функции.  
- Это непараметрической модели, то есть они могут выполнять обработку данных с различными распределениями. 

Однако простые деревья принятия решений могут переобучению данные и менее обобщаться, чем дерево это совокупности.

Дополнительные сведения см. в разделе [леса принятия решений](https://go.microsoft.com/fwlink/?LinkId=403677).  

## <a name="how-to-configure"></a>Порядок настройки
  
1.  Добавьте модуль **леса решений из двух классов** в конвейер в машинное обучение Azure и откройте панель **свойств** модуля. 

    Модуль можно найти в разделе **машинное обучение**. Разверните узел **Инициализация**, а затем — **классификация**.  
  
2.  Для **метода повторной выборки**выберите метод, используемый для создания отдельных деревьев.  Вы можете выбрать одну из **баггинг** или **реплицировать**.  
  
    -   **Баггинг**: баггинг также называется статистической обработкой *начальной загрузки*. В этом методе каждое дерево увеличилось на новом образце, созданном случайным образом выборки исходного набора данных с заменой до тех пор, пока набор данных не станет размером оригинала.  
  
         Выходные данные моделей объединяются функцией *голосования*, которая является формой статистической обработки. Каждое дерево в лесу решения классификации выводит гистограмму ненормализованной частоты меток. Статистическая обработка заключается в суммировании этих гистограмм и нормализации для получения "вероятностей" для каждой метки. Таким образом, деревья с высокой достоверностью прогноза будут иметь больший вес в окончательном принятии решения ансамблей.  
  
         Дополнительные сведения см. в записи Википедии для агрегатной загрузки.  
  
    -   **Репликация**. в репликации каждое дерево обучено на идентичных входных данных. Определение того, какой предикат разбиения используется для каждого узла дерева, остается случайным, и деревья будут различными.   
  
3.  Укажите, как должна быть обучена модель, установив параметр " **создать режим инструктора** ".  
  
    -   **Один параметр**. Если вы умеете настраивать модель, вы можете указать конкретный набор значений в качестве аргументов.

    -   **Диапазон параметров**. Если вы не знаете наилучших параметров, оптимальные параметры можно найти с помощью модуля [Настройка модели параметры](tune-model-hyperparameters.md) . Вы предоставляете некоторый диапазон значений, и преподаватель выполняет итерацию по нескольким сочетаниям параметров, чтобы определить сочетание значений, которое дает наилучший результат.
  
4.  Для параметра **число деревьев принятия решений**введите максимальное число деревьев принятия решений, которые могут быть созданы в ансамблей. Создавая больше деревьев принятия решений, вы можете получить более эффективное покрытие, но при этом увеличивается время обучения.  
  
    > [!NOTE]
    >  Это значение также управляет количеством деревьев, отображаемых при визуализации обученной модели. Если требуется просмотреть или распечатать одно дерево, можно задать значение 1. Однако можно создать только одно дерево (дерево с начальным набором параметров) и дальнейшие итерации не выполняются.
  
5.  Для **максимальной глубины деревьев принятия решений**введите число, ограничивающее максимальную глубину дерева принятия решений. Увеличение глубины дерева может повысить точность, однако при этом могут возникать лжевзаимосвязи и увеличиваться время обучения.
  
6.  Для **числа случайных разбиений на узел**введите число разбиений, которое будет использоваться при построении каждого узла дерева. *Разбиение* означает, что функции на каждом уровне дерева (node) случайным образом делятся.
  
7.  Для параметра **минимальное число выборок на конечный узел**укажите минимальное число вариантов, необходимых для создания любого узла терминала (конечного) в дереве.
  
     Увеличив это значение, вы увеличиваете пороговое значение для создания новых правил. Например, при использовании значения по умолчанию 1, даже один случай может привести к созданию нового правила. Если увеличить его до 5, для создания правила обучающие данные должны будут содержать не менее пяти вариантов.  
  
8.  Установите флажок **Разрешить неизвестные значения для функций** категории, чтобы создать группу для неизвестных значений в обучающих или проверочных наборах. Модель может быть менее точной для известных значений, но она может предоставлять лучшие прогнозы для новых (неизвестных) значений. 

     Если отменить выбор этого параметра, то модель может принимать только значения, содержащиеся в обучающих данных.
  
9. Присоединение набора данных с меткой и обучение модели:

    + Если присвоить **параметру** **создать режим инструктора** значение Single, подключить набор данных с тегами и модуль [обучение модели](train-model.md) .  
  
    + Если задать **режим создания инструктора** в **диапазоне параметров**, подключите набор данных с тегами и обучите модель с помощью [параметров настройки модели](tune-model-hyperparameters.md).  
  
    > [!NOTE]
    > 
    > При передаче диапазона параметров для [обучения модели](train-model.md)используется только значение по умолчанию в списке с одним параметром.  
    > 
    > Если передать один набор значений параметров в модуль [Настройка модели настройки](tune-model-hyperparameters.md) , когда он ожидает диапазон параметров для каждого параметра, он пропускает значения и использует значения по умолчанию для учений.  
    > 
    > Если выбрать параметр **диапазон параметров** и ввести одно значение для любого параметра, это единственное заданное значение будет использоваться во время очистки, даже если другие параметры меняются в диапазоне значений.  
    
## <a name="results"></a>Результаты

После завершения обучения:

+ Чтобы сохранить моментальный снимок обученной модели, выберите вкладку **выходные данные** в правой панели модуля **обучение модели** . Щелкните значок **зарегистрировать набор данных** , чтобы сохранить модель как модуль для повторного использования.

+ Чтобы использовать модель для оценки, добавьте модуль **оценки модели** в конвейер.

## <a name="next-steps"></a>Следующие шаги

См. [набор модулей, доступных](module-reference.md) для машинное обучение Azure. 