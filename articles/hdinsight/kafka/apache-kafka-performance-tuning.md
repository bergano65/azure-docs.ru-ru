---
title: Оптимизация производительности для кластеров Apache Kafka HDInsight
description: Содержит общие сведения о методах оптимизации Apache Kafka рабочих нагрузок в Azure HDInsight.
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
ms.service: hdinsight
ms.topic: conceptual
ms.date: 12/19/2019
ms.openlocfilehash: 752068af531c4a0ecc832d266f88105c14452ecb
ms.sourcegitcommit: 849bb1729b89d075eed579aa36395bf4d29f3bd9
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/28/2020
ms.locfileid: "75494923"
---
# <a name="performance-optimization-for-apache-kafka-hdinsight-clusters"></a>Оптимизация производительности для кластеров Apache Kafka HDInsight

В этой статье приводятся некоторые рекомендации по оптимизации производительности Apache Kafka рабочих нагрузок в HDInsight. Основное внимание уделяется настройке параметров производителя и брокера. Существует несколько способов измерения производительности, и применяемые оптимизации будут зависеть от бизнес-потребностей.

## <a name="architecture-overview"></a>Обзор архитектуры

Разделы Kafka используются для организации записей. Записи создаются производителями, а используются потребителями. Производители отправляют записи в брокеры Kafka, которые затем сохраняют данные. Каждый рабочий узел в кластере HDInsight — это брокер Kafka.

Разделы позволяют распределить записи между брокерами. При считывании записей можно использовать один потребитель на секцию, чтобы обеспечить параллельную обработку данных.

Репликация используется для дублирования секций между узлами. Это обеспечивает защиту от простоев узла (брокера). Один раздел из группы реплик назначается руководителем секции. Трафик производителя направляется в ведущую секцию каждого узла в зависимости от состояния, которым управляет ZooKeeper.

## <a name="identify-your-scenario"></a>Определение своего сценария

Apache Kafka производительность имеет два основных аспекта: пропускная способность и задержка. Пропускная способность — это максимальная скорость, с которой данные могут быть обработаны. Обычно лучше использовать более высокую пропускную способность. Задержка — это время, затрачиваемое на сохранение или получение данных. Обычно лучше использовать меньшую задержку. Правильный баланс между пропускной способностью, задержкой и стоимостью инфраструктуры приложения может быть непростой задачей. Требования к производительности, скорее всего, будут соответствовать одной из следующих трех распространенных ситуаций, в зависимости от того, требуется ли высокая пропускная способность, низкая задержка или и то, и другое:

* Высокая пропускная способность, низкая задержка. Для этого сценария требуется высокая пропускная способность и низкая задержка (~ 100 мс). Примером такого типа приложения является наблюдение за доступностью служб.
* Высокая пропускная способность, высокая задержка. Этот сценарий требует высокой пропускной способности (~ 1,5 Гбит/с), но может допускать большую задержку (< 250 мс). Примером такого типа приложения является прием данных телеметрии для процессов практически в реальном времени, таких как безопасность и приложения обнаружения вторжений.
* Низкая пропускная способность, низкая задержка. В этом сценарии требуется низкая задержка (< 10 мс) для обработки в режиме реального времени, но это может допускать более низкую пропускную способность. Примером такого типа приложения являются проверки орфографии и грамматики в сети.

## <a name="producer-configurations"></a>Конфигурации Producer

В следующих разделах будут выводиться некоторые из наиболее важных свойств конфигурации для оптимизации производительности поставщиков Kafka. Подробное описание всех свойств конфигурации см. в разделе [Apache Kafka документация по конфигурациям Producer](https://kafka.apache.org/documentation/#producerconfigs).

### <a name="batch-size"></a>Размер пакета

Apache Kafka производители собираются группы сообщений (называемые пакетами), которые отправляются как единое целое для хранения в одном разделе хранилища. Размер пакета — это число байтов, которые должны присутствовать перед передачей группы. Увеличение `batch.size` параметра может увеличить пропускную способность, поскольку снижает нагрузку на запросы из сети и запросов ввода-вывода. При низкой нагрузке увеличенный размер пакета может увеличить задержку отправки Kafka, так как производитель ожидает, пока пакет будет готов. При интенсивной нагрузке рекомендуется увеличить размер пакета, чтобы повысить пропускную способность и задержку.

### <a name="producer-required-acknowledgments"></a>Обязательные подтверждения производителя

Конфигурация требуемого `acks` производителя определяет число подтверждений, необходимых для заполнения секции, прежде чем запрос на запись будет считаться завершенным. Этот параметр влияет на надежность данных и принимает значения `0`, `1`или. `-1` Значение `-1` означает, что подтверждение должно быть получено от всех реплик до завершения записи. Параметр `acks = -1` обеспечивает более надежную защиту от потери данных, но также приводит к более высокой задержке и снижению пропускной способности. Если требования к приложению требуют более высокой пропускной `acks = 0` способности `acks = 1`, попробуйте установить или. Помните, что не подтверждая все реплики, можно снизить надежность данных.

### <a name="compression"></a>сжатие;

Производитель Kafka можно настроить для сжатия сообщений перед их отправкой брокерам. `compression.type` Параметр задает используемый кодек сжатия. Поддерживаемые кодеки сжатия: gzip, "привязки" и "lz4". Сжатие является полезным и должно учитываться при наличии ограничений на емкость диска.

Среди двух часто используемых кодеков сжатия, `gzip` и `snappy`, `gzip` имеет более высокий коэффициент сжатия, что приводит к меньшему использованию места на диске за счет более высокой нагрузки на ЦП. `snappy` Кодек обеспечивает меньшее сжатие с меньшей нагрузкой ЦП. Вы можете решить, какой кодек следует использовать на основе ограничений на диск или процессор брокера. `gzip`может сжимать данные по скорости в пять раз выше, `snappy`чем.

Использование сжатия данных увеличит количество записей, которые могут храниться на диске. Это также может увеличить нагрузку на ЦП в случаях, когда несоответствие форматов сжатия, используемых производителем и брокером. данные должны быть сжаты перед отправкой, а затем распакованы перед обработкой.

## <a name="broker-settings"></a>Параметры компонента Service Broker

В следующих разделах будут выводиться некоторые из наиболее важных параметров для оптимизации производительности брокеров Kafka. Подробное описание всех параметров компонента Service Broker см. [в разделе Apache Kafka документация по конфигурациям Producer](https://kafka.apache.org/documentation/#producerconfigs).

### <a name="number-of-disks"></a>Количество дисков

Диски хранилища имеют ограниченный объем операций ввода-вывода в секунду (количество операций входа и выхода) и байтов чтения/записи в секунду. При создании новых секций Kafka сохраняет каждый новый раздел на диске с минимальным количеством существующих секций, чтобы сбалансировать их по доступным дискам. Несмотря на стратегию хранения, при обработке сотен реплик секций на каждом диске Kafka может легко загрузить доступную пропускную способность диска. Компромисс между пропускной способностью и ценой. Если для приложения требуется более высокая пропускная способность, создайте кластер с более управляемыми дисками на каждый брокер. В настоящее время HDInsight не поддерживает добавление управляемых дисков в работающий кластер. Дополнительные сведения о настройке количества управляемых дисков см. в статье [Настройка хранилища и масштабируемости для Apache Kafka в HDInsight](apache-kafka-scalability.md). Изучите затраты на увеличение дискового пространства для узлов в кластере.

### <a name="number-of-topics-and-partitions"></a>Число разделов и разделов

Производители Kafka записывают в разделы. Kafka потребители считываются из разделов. Раздел связан с журналом, который представляет собой структуру данных на диске. Kafka добавляет записи от производителей (-ов) к концу журнала разделов. Журнал разделов состоит из множества секций, распределенных по нескольким файлам. Эти файлы, в свою очередь, распределяются между несколькими узлами кластера Kafka. Потребители читают из разделов Kafka по их ритмичности и могут выбрать их позиции (смещение) в журнале разделов.

Каждый раздел Kafka является файлом журнала в системе, а потоки-производители могут записывать в несколько журналов одновременно. Аналогично, поскольку каждый поток-потребитель считывает сообщения из одной секции, использование из нескольких секций также обрабатывается параллельно.

Увеличение плотности секций (число секций на брокер) увеличивает нагрузку, связанную с операциями с метаданными, а также запрос/ответ на секцию между лидером секции и его подписчиков. Даже в отсутствие данных, передаваемых через, реплики секционирования по-прежнему получают данные от лидеров, что приводит к дополнительной обработке запросов send и Receive по сети.

Для Apache Kafka кластеров 1,1 и выше в HDInsight рекомендуется иметь не более 1000 секций на брокер, включая реплики. Увеличение количества секций на брокер снижает пропускную способность и может привести к недоступности раздела. Дополнительные сведения о поддержке секций Kafka Apache Kafka см. в [записи блога о увеличении числа поддерживаемых секций в версии 1.1.0](https://blogs.apache.org/kafka/entry/apache-kafka-supports-more-partitions). Дополнительные сведения об изменении разделов см. в разделе [Apache Kafka: изменение разделов](https://kafka.apache.org/documentation/#basic_ops_modify_topic).

### <a name="number-of-replicas"></a>Количество реплик

Более высокий коэффициент репликации приводит к дополнительным запросам между лидером секции и подписчиков. Следовательно, более высокий коэффициент репликации потребляет больше места на диске и ЦП для обработки дополнительных запросов, увеличивая задержку записи и уменьшая пропускную способность.

Мы рекомендуем использовать по крайней мере 3 раза репликацию для Kafka в Azure HDInsight. В большинстве регионов Azure есть три домена сбоя, но в регионах с двумя доменами сбоя пользователи должны использовать репликацию 4X.

Дополнительные сведения о репликации см. в разделе [Apache Kafka: репликация](https://kafka.apache.org/documentation/#replication) и [Apache Kafka: увеличение коэффициента репликации](https://kafka.apache.org/documentation/#basic_ops_increase_replication_factor).

## <a name="next-steps"></a>Дальнейшие действия

* [Processing trillions of events per day with Apache Kafka on Azure](https://azure.microsoft.com/blog/processing-trillions-of-events-per-day-with-apache-kafka-on-azure/) (Ежедневная обработка триллионов событий с помощью Apache Kafka в Azure)
* [Что такое Apache Kafka в HDInsight?](apache-kafka-introduction.md)
