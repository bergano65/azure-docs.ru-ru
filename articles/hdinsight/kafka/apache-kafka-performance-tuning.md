---
title: Оптимизация производительности для кластеров Apache Kafka HDInsight
description: Обзор методов оптимизации рабочих нагрузок Apache Kafka в Azure HDInsight.
services: hdinsight
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
ms.service: hdinsight
ms.topic: conceptual
ms.date: 02/21/2019
ms.openlocfilehash: 903cd8921801ffb47dd73f48e507f30aa0b6dccc
ms.sourcegitcommit: 49c8204824c4f7b067cd35dbd0d44352f7e1f95e
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/22/2019
ms.locfileid: "58373155"
---
# <a name="performance-optimization-for-apache-kafka-hdinsight-clusters"></a>Оптимизация производительности для кластеров Apache Kafka HDInsight

В этой статье приводятся советы по оптимизации производительности рабочих нагрузок Apache Kafka в HDInsight. Основное внимание уделяется регулировка производителя и настройки компонента service broker. Существуют различные способы измерения производительности и оптимизации, которые можно применить будет зависеть от вашей деятельности.

## <a name="architecture-overview"></a>Общие сведения об архитектуре

Разделы Kafka используются для организации записей. Записи созданных поставщиков и используются потребителями. Производители отправки записей брокеров Kafka, которые затем хранения данных. Каждый рабочий узел в кластере HDInsight — это брокер Kafka.

Разделы позволяют распределить записи между брокерами. При считывании записей можно использовать один потребитель на секцию, чтобы обеспечить параллельную обработку данных.

Репликация используется для дублирования секций между узлами. Это обеспечивает защиту от сбоев узлов (брокеров). Одна секция среди группа реплик используется в качестве лидера секции. Трафик производителя направляется в ведущую секцию каждого узла в зависимости от состояния, которым управляет ZooKeeper.

## <a name="identify-your-scenario"></a>Определение своего сценария

Производительности Apache Kafka имеет два основных аспекта – пропускной способности и задержки. Пропускная способность — в качестве максимальной скорости, с которой данные могут обрабатываться. Более высокая пропускная способность — как правило, лучше. Задержка определяет время, необходимое для данных, сохраняемый или извлекаемый. Низкая задержка обычно лучше. Поиск баланса между пропускную способность, задержки и затраты на инфраструктуру приложения может оказаться сложной задачей. Требований к производительности скорее всего будут соответствовать одному из следующих трех распространенных ситуациях зависимости от необходимости высокую пропускную способность и низкую задержку:

* Высокая пропускная способность, низкую задержку. Данный сценарий требует высокой пропускной способностью и низкой задержкой (около 100 миллисекунд). Примером такого приложения является наблюдение.
* Высокая пропускная способность, высокую задержку. Этот сценарий требует высокой пропускной способности (~1.5 Гбит/с), но также допускающие большее время задержки (< 250 мс). Примером такого приложения является прием данных телеметрии для практически в реальном времени процессов, таких как приложения обнаружения вторжения и нарушений безопасности.
* С низкой пропускной способностью, низкой задержкой. Этот сценарий требует низкой задержкой (< 10 мс) для обработки в реальном времени, но может выдержать меньшей пропускной способности. Примером такого приложения является проверки орфографии и грамматики в сети.

## <a name="producer-configurations"></a>Производитель конфигураций

В следующих разделах будут освещены некоторые из наиболее важных свойств конфигурации для оптимизации производительности вашего производители Kafka. Подробное описание всех свойств конфигурации, см. в разделе [документации Apache Kafka в конфигурациях производитель](https://kafka.apache.org/documentation/#producerconfigs).

### <a name="batch-size"></a>Размер пакета

Производители Apache Kafka Соберите группы сообщений (называемых пакеты), которые отправляются как единое храниться в одной секции. Размер пакета означает число байтов, которые должны быть созданы до передачи этой группы. Увеличение `batch.size` параметр можно увеличить пропускную способность, так как уменьшает обработку дополнительной нагрузки от сети и запросов ввода-ВЫВОДА. Под нагрузкой света размер пакета, увеличение может увеличить задержку отправки Kafka, как производитель ожидает готовности пакета. В условиях большой нагрузки рекомендуется увеличить размер пакета для повышения пропускной способности и задержки.

### <a name="producer-required-acknowledgements"></a>Производитель необходимые подтверждения

Производитель необходимые `acks` конфигурация определяет число подтверждений, требующегося лидера секции запрос на запись считается завершена. Этот параметр влияет на надежность данных, и он получает значения `0`, `1`, или `-1`. Значение `-1` означает, что подтверждение должны быть получены из всех реплик до завершения записи. Параметр `acks = -1` предоставляет более строгие гарантии от потери данных, но он также результаты в большее время задержки и меньшей пропускной способности. Если вашему приложению требуется более высокая пропускная способность, попробуйте установить параметр `acks = 0` или `acks = 1`. Имейте в виду, что не подтверждают всех реплик может снизить надежность данных.

### <a name="compression"></a>Сжатие

Производитель Kafka можно настроить так, чтобы сжимать сообщения перед их отправкой брокеров. `compression.type` Параметр указывает кодек сжатия для использования. Поддерживаемые кодеки — «gzip,» «snappy,» и «lz4.» Сжатие целесообразно использовать и его следует рассматривать при наличии ограничения на емкость диска.

Между двумя часто используемые кодеки `gzip` и `snappy`, `gzip` имеет более высокий коэффициент сжатия, что приводит к низким на диске за счет большую нагрузку на ЦП. `snappy` Кодек обеспечивает меньшее сжатие меньшую нагрузку на ЦП. Можно решить, какие кодек, чтобы использовать зависимости от ограничения ЦП broker диска или производителя. `gzip` можно сжать данные со скоростью, пять раз выше, чем `snappy`.

С помощью сжатия данных увеличивается число записей, которые могут храниться на диске. Его также можно увеличить количество ЦП издержки в случаях, где существует несоответствие между форматами сжатия, используемый производителем и брокер. так как данные должны быть сжимаются перед отправкой и распаковку перед обработкой.

## <a name="broker-settings"></a>Параметры брокера

В следующих разделах будут освещены некоторые наиболее важные параметры для оптимизации производительности вашего брокеров Kafka. Подробное описание всех параметров брокера, см. в разделе [документации Apache Kafka в конфигурациях производитель](https://kafka.apache.org/documentation/#producerconfigs).


### <a name="number-of-disks"></a>Количество дисков

Диски хранилища имеют ограниченную операций ввода-ВЫВОДА (ввода-вывода операций в секунду) и чтение и запись байтов в секунду. При создании новых секций, Kafka хранит каждой новой секции на диске с наименьшим количеством существующих секций для распределения их по доступные диски. Несмотря на стратегии хранения данных, при обработке сотен реплики секций на каждом диске Kafka можно легко насытить пропускная способность доступных дисков. Недостатком здесь является соотношение пропускной способности и затрат. Если приложению требуется более высокую пропускную способность, создайте кластер с несколько управляемых дисков на брокер. HDInsight в настоящее время не поддерживает добавление управляемых дисков в работающем кластере. Дополнительные сведения о том, как настроить количество управляемых дисков см. в разделе [Настройка хранилища и масштабируемости для Apache Kafka в HDInsight](apache-kafka-scalability.md). Понимаете последствия стоимость увеличения памяти для узлов в кластере.

### <a name="number-of-topics-and-partitions"></a>Количество разделов и разделов

Производители Kafka записи на разделы. Потребители Kafka чтения из разделов. Раздел, связанный с журнал, который представляет собой структуру данных на диске. Kafka добавляет записи из producer(s) в конец раздела журнала. Раздел журнала состоит из много секций, которые распределены между несколькими файлами. В свою очередь, эти файлы распределены по нескольким узлам кластера Kafka. Объекты-получатели читают разделов Kafka в их периодичность и и можно выбрать их положении (смещении) в разделе журнала.

Каждый раздел Kafka — это файл журнала в системе, а потоки-производители могут записывать в нескольких журналах одновременно. Аналогичным образом так как каждый поток-потребитель считывает сообщения из одной секции, потребление из нескольких разделов обрабатывается также параллельно.

Увеличение плотности секции (число секций на брокер) добавляет нагрузку связана с операции с метаданными, а также на секции запрос ответ между лидера секции и его подписчиков. Даже в случае отсутствия данных, передаваемых через реплики секции по-прежнему выбирать данные из руководителей, которых приводит к дополнительной обработки для операции отправки и получения запросов по сети.

Для Apache Kafka кластеры 1.1 и выше в HDInsight, мы рекомендуем иметь не более 1000 секций на брокер, включая реплики. Увеличение числа секций на broker уменьшает пропускную способность и также может привести к недоступности раздела. Дополнительные сведения о поддержке разделов Kafka см. в разделе [официальный Apache Kafka записи блога на увеличение количество поддерживаемых секций в версии 1.1.0](https://blogs.apache.org/kafka/entry/apache-kafka-supports-more-partitions). Дополнительные сведения об изменении разделов см. в разделе [Apache Kafka: изменение темы](https://kafka.apache.org/documentation/#basic_ops_modify_topic).

### <a name="number-of-replicas"></a>Количество реплик

Высокий коэффициент репликации приводит дополнительные запросы между лидером секции и подписчиков. Следовательно, выше коэффициент репликации использует несколько дисков и ЦП для обработки дополнительных запросов, увеличение записи задержки и снижает пропускную способность.

Мы рекомендуем использовать по крайней мере 3-кратную репликацию для Kafka в Azure HDInsight. Большинстве регионов Azure имеют три домена сбоя, но в регионах с двумя доменами сбоя, пользователи должны использовать 4 x репликации.

Дополнительные сведения о репликации см. в разделе [Apache Kafka: репликация](https://kafka.apache.org/documentation/#replication) и [Apache Kafka: увеличить коэффициент репликации](https://kafka.apache.org/documentation/#basic_ops_increase_replication_factor).

## <a name="next-steps"></a>Дальнейшие действия

* [Processing trillions of events per day with Apache Kafka on Azure](https://azure.microsoft.com/blog/processing-trillions-of-events-per-day-with-apache-kafka-on-azure/) (Ежедневная обработка триллионов событий с помощью Apache Kafka в Azure)
* [Что такое Apache Kafka в HDInsight?](apache-kafka-introduction.md)
