---
title: Оптимизация Apache Hive с помощью Apache Ambari в Azure HDInsight
description: Используйте веб-интерфейс Apache Ambari для настройки и оптимизации Apache Hive.
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
ms.service: hdinsight
ms.topic: conceptual
ms.date: 05/04/2020
ms.openlocfilehash: ce3916ef1155224a91c0736c3dabe907ae8d2611
ms.sourcegitcommit: e0330ef620103256d39ca1426f09dd5bb39cd075
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/05/2020
ms.locfileid: "82796373"
---
# <a name="optimize-apache-hive-with-apache-ambari-in-azure-hdinsight"></a>Оптимизация Apache Hive с помощью Apache Ambari в Azure HDInsight

Apache Ambari — это веб-интерфейс для управления кластерами HDInsight и их мониторинга. Общие сведения о пользовательском веб-интерфейсе Ambari см. [в статье Управление кластерами HDInsight с помощью веб-интерфейса Apache Ambari](hdinsight-hadoop-manage-ambari.md).

В следующих разделах описаны параметры конфигурации, используемые для оптимизации общей производительности Apache Hive.

1. Чтобы изменить параметры конфигурации Hive, выберите **Hive** на боковой панели "Services" (Службы).
1. Перейдите на вкладку **Configs** (Конфигурации).

## <a name="set-the-hive-execution-engine"></a>Настройка подсистемы выполнения Hive

Hive предоставляет два ядра выполнения: Apache Hadoop MapReduce и Apache TEZ. Tez работает быстрее, чем MapReduce. По умолчанию в кластерах HDInsight Linux используется подсистема выполнения Tez. Вот как можно изменить подсистему выполнения.

1. На вкладке **Configs** (Конфигурации) Hive в поле фильтра введите **execution engine**.

    ![Механизм выполнения поиска Apache Ambari](./media/optimize-hive-ambari/ambari-search-execution.png)

1. Свойство **Optimization** (Оптимизация) по умолчанию имеет значение **Tez**.

    ![Оптимизация — Apache Tez Engine](./media/optimize-hive-ambari/optimization-apache-tez.png)

## <a name="tune-mappers"></a>Настройка модулей сопоставления

Hadoop пытается разделить (*сопоставить*) отдельный файл на несколько файлов и параллельно обрабатывать эти файлы. Число модулей сопоставления зависит от того, на сколько файлов разделяется файл. Следующие два параметра конфигурации влияют на число разбиений для подсистемы выполнения Tez:

* `tez.grouping.min-size`: минимальный размер сгруппированного разбиения; значение по умолчанию составляет 16 МБ (16 777 216 байтов);
* `tez.grouping.max-size`: максимальный размер сгруппированного разбиения; значение по умолчанию составляет 1 ГБ (1 073 741 824 байтов).

В качестве рекомендации по производительности уменьшите оба этих параметра, чтобы повысить задержку и увеличить пропускную способность.

Например, чтобы задать четыре задачи модуля сопоставления для данных размером в 128 МБ, можно для обоих параметров задать значение 32 МБ (33 554 432 байтов).

1. Чтобы изменить параметры ограничения, перейдите на вкладку **Configs** (Конфигурации) службы Tez. Разверните панель **General** (Общие) и найдите параметры `tez.grouping.max-size` и `tez.grouping.min-size`.

1. Задайте для обоих параметров значение **33 554 432** байтов (32 МБ).

    ![Размеры группирования Tez Apache Ambari](./media/optimize-hive-ambari/apache-tez-grouping-size.png)

Эти изменения влияют на все задания Tez на сервере. Чтобы получить оптимальные результаты, выберите соответствующие значения параметров.

## <a name="tune-reducers"></a>Настройка модулей сжатия

Apache ORC и Snappy обеспечивают высокую производительность. Однако в Hive может использоваться слишком мало модулей сжатия по умолчанию, что может приводить к возникновению узких мест.

Предположим, что имеются входные данные размером в 50 ГБ. В формате ORC с использованием сжатия Snappy эти данные имеют размер 1 ГБ. Hive оценивает необходимое количество модулей сжатия по формуле: (число входных байтов для модулей сжатия / `hive.exec.reducers.bytes.per.reducer`).

В качестве параметров по умолчанию в этом примере используется четыре модулей сжатия.

Параметр `hive.exec.reducers.bytes.per.reducer` задает количество байтов, обрабатываемых модулем сжатия. Значение по умолчанию — 64 МБ. Если уменьшить это значение, это увеличит распараллеливание, что может повысить производительность. Слишком маленькое значение может также привести к использованию слишком большого числа модулей сжатия, что может отрицательно повлиять на производительность. Этот параметр зависит от конкретных требований к обработке данных, параметров сжатия и других факторов среды.

1. Чтобы изменить этот параметр, перейдите на вкладку **Configs** (Конфигурации) Hive и найдите параметр **Data per Reducer** (Данные на модуль сжатия) на странице "Settings" (Параметры).

    ![Данные Apache Ambari для каждого из них](./media/optimize-hive-ambari/ambari-data-per-reducer.png)

1. Выберите **Edit** (Изменить), чтобы изменить значение параметра на 128 МБ (134 217 728 байтов), и нажмите клавишу **ВВОД**, чтобы сохранить изменение.

    ![Ambari данные для каждого уменьшения](./media/optimize-hive-ambari/data-per-reducer-edited.png)
  
    При наличии входного размера 1 024 МБ с 128 МБ данных на один из них 8 модулей сжатия (1024/128).

1. Неправильное значение параметра **Data per Reducer** (Данные на модуль сжатия) может привести к появлению большого количества модулей сжатия, что отрицательно повлияет на производительность запросов. Чтобы задать максимальное число модулей сжатия, задайте для параметра `hive.exec.reducers.max` соответствующее значение. Значение по умолчанию — 1009.

## <a name="enable-parallel-execution"></a>Включение параллельного выполнения

Запрос Hive выполняется в один или несколько этапов. Если независимые этапы могут выполняться параллельно, это повышает производительность запросов.

1. Чтобы включить параллельное выполнение запросов, перейдите на вкладку **Configs** (Конфигурации) и найдите свойство `hive.exec.parallel`. Значением по умолчанию является false. Установите значение true и нажмите клавишу **ВВОД**, чтобы сохранить изменения.

1. Чтобы ограничить число заданий, выполняемых параллельно, измените `hive.exec.parallel.thread.number` свойство. Значение по умолчанию: 8.

    ![Параллельное отображение Apache Hive Exec](./media/optimize-hive-ambari/apache-hive-exec-parallel.png)

## <a name="enable-vectorization"></a>Включение векторизации

Hive обрабатывает данные построчно. Векторизация указывает Hive обрабатывать данные блоками по 1024 строки, а не по одной строке за раз. Векторизация применима только к формату файлов ORC.

1. Чтобы включить векторизированное выполнение запросов, перейдите на вкладку **Configs** (Конфигурации) и найдите параметр `hive.vectorized.execution.enabled`. Для Hive 0.13.0 или более поздних версий значение по умолчанию — true.

1. Чтобы включить векторизированное выполнение сжимаемой части запроса, задайте для параметра `hive.vectorized.execution.reduce.enabled` значение true. Значением по умолчанию является false.

    ![Apache Hive векторное выполнение](./media/optimize-hive-ambari/hive-vectorized-execution.png)

## <a name="enable-cost-based-optimization-cbo"></a>Включение оптимизации с учетом затрат

По умолчанию Hive выполняет набор правил, чтобы найти один оптимальный план выполнения запроса. Оптимизация на основе затрат (статистические) оценивает несколько планов для выполнения запроса. И назначает стоимость каждому плану, а затем определяет самый дешевый план для выполнения запроса.

Чтобы включить статистические, перейдите к разделу**Параметры** **конфигурации** >  **Hive** > и найдите параметр **включить Оптимизатор на основе затрат**, а затем установите переключатель в положение **вкл**.

![Оптимизатор на основе затрат HDInsight](./media/optimize-hive-ambari/hdinsight-cbo-config.png)

Приведенные ниже дополнительные параметры позволяют повысить производительность запросов Hive при использовании оптимизации с учетом затрат.

* `hive.compute.query.using.stats`

    Если задано значение true, служба Hive использует статистические данные, хранящиеся в ее метахранилище, для ответа на такие простые запросы, как `count(*)`.

    ![Apache Hive вычисление запроса с помощью статистики](./media/optimize-hive-ambari/hive-compute-query-using-stats.png)

* `hive.stats.fetch.column.stats`

    Статистика по столбцам создается при включении оптимизации с учетом затрат. Hive использует статистику по столбцам, которая хранится в метахранилище, чтобы оптимизировать запросы. Если столбцов много, то получение статистики по столбцам для каждого из них занимает больше времени. Если задано значение false, этот параметр отключает получение статистики по столбцам из метахранилища.

    ![Статистика по столбцам набора Apache Hive статистики](./media/optimize-hive-ambari/hive-stats-fetch-column-stats.png)

* `hive.stats.fetch.partition.stats`

    Базовая статистика по секциям, например число строк, размер данных и размер файла, хранится в метахранилище. Если задано значение true, статистика по секциям извлекается из хранилище метаданных. Если значение равно false, размер файла выбирается из файловой системы. И количество строк извлекается из схемы строки.

    ![Статистика по секциям Hive](./media/optimize-hive-ambari/hive-stats-fetch-partition-stats.png)

## <a name="enable-intermediate-compression"></a>Включение промежуточного сжатия

Задачи сопоставления создают промежуточные файлы, которые используются задачами модуля сжатия. Промежуточное сжатие сокращает размер промежуточных файлов.

Как правило, узким местом заданий Hadoop является ввод-вывод. Сжатие данных может ускорить ввод-вывод и общую передачу данных по сети.

Ниже приведены доступные типы сжатия.

| Формат | Инструмент | Алгоритм | Расширение файла | Возможность разделения |
| --- | --- | --- | --- | --- |
| GZip | GZip | DEFLATE | `.gz` | нет |
| Bzip2 | Bzip2 | Bzip2 |`.bz2` | Да |
| LZO | `Lzop` | LZO | `.lzo` | Да, при индексации. |
| Snappy | Н/Д | Snappy | Snappy | нет |

Как правило, метод сжатия разделяемы важен, в противном случае будет создано несколько средств сопоставления. Если входными данными является текст, то `bzip2` является наилучшим вариантом. Для формата ORC наиболее быстрым методом сжатия является Snappy.

1. Чтобы включить промежуточное сжатие, перейдите на вкладку **Configs** (Конфигурации) Hive, а затем установите для параметра `hive.exec.compress.intermediate` значение true. Значением по умолчанию является false.

    !["Средний уровень сжатия файла Hive"](./media/optimize-hive-ambari/hive-exec-compress-intermediate.png)

    > [!NOTE]  
    > Чтобы сжимать промежуточные файлы, выберите кодек сжатия с наименьшими затратами мощности ЦП, даже если этот кодек не обеспечивает высокую степень сжатия.

1. Чтобы задать кодек промежуточного сжатия, добавьте пользовательское свойство `mapred.map.output.compression.codec` в файл `hive-site.xml` или `mapred-site.xml`.

1. Вот как можно добавить пользовательский параметр.

    а. Последовательно выберите **Hive** > **Конфигурация** > **Hive дополнительно** > **Пользовательский Hive — сайт**.

    b. Щелкните **Добавить свойство...** в нижней части области пользовательский Hive — сайт.

    c. В окне "Add Property" (Добавление свойства) введите ключ `mapred.map.output.compression.codec` и значение `org.apache.hadoop.io.compress.SnappyCodec`.

    d. Нажмите **Добавить**.

    ![' Apache Hive пользовательское свойство Add '](./media/optimize-hive-ambari/hive-custom-property.png)

    Этот параметр позволяет сжать промежуточный файл, используя сжатие с помощью привязки. После добавления свойство отображается в области "Custom hive-site" (Настраиваемый сайт Hive).

    > [!NOTE]  
    > Эта процедура изменяет файл `$HADOOP_HOME/conf/hive-site.xml`.

## <a name="compress-final-output"></a>Сжатие окончательных выходных данных

Окончательные выходные данные Hive также могут быть сжаты.

1. Чтобы включить сжатие окончательных выходных данных Hive, перейдите на вкладку **Configs** (Конфигурации) Hive, а затем установите для параметра `hive.exec.compress.output` значение true. Значением по умолчанию является false.

1. Чтобы выбрать кодек для сжатия выходных данных, добавьте пользовательское свойство `mapred.output.compression.codec` в область "Custom hive-site" (Настраиваемый сайт Hive), как описано на шаге 3 в предыдущем разделе.

    ![Apache Hive пользовательское свойство ADD2](./media/optimize-hive-ambari/hive-custom-property2.png)

## <a name="enable-speculative-execution"></a>Включение спекулятивного выполнения

При выполнении гипотетического выполнения запустится определенное количество повторяющихся задач для обнаружения и запрета передатчика выполняемых задач. Повышение общего выполнения заданий за счет оптимизации результатов отдельных задач.

Спекулятивное выполнение не следует включать для длительных задач MapReduce с большим количеством входных данных.

* Чтобы включить спекулятивное выполнение, перейдите на вкладку **Configs** (Конфигурации) Hive, а затем установите для параметра `hive.mapred.reduce.tasks.speculative.execution` значение true. Значением по умолчанию является false.

    ![' Hive mapred уменьшить задачи, выполняющие упреждающее выполнение "](./media/optimize-hive-ambari/hive-mapred-reduce-tasks-speculative-execution.png)

## <a name="tune-dynamic-partitions"></a>Настройка динамических секций

Hive позволяет создавать динамические разделы при вставке записей в таблицу без предварительного определения каждой секции. Эта возможность является мощным компонентом. Хотя это может привести к созданию большого количества секций. И большое количество файлов для каждой секции.

1. Чтобы в Hive использовались динамические секции, параметр `hive.exec.dynamic.partition` должен иметь значение true (это значение по умолчанию).

1. Измените режим динамических секций на *strict* (Строгий). В строгом режиме хотя бы одна секция должна быть статической. Этот параметр предотвращает запросы без фильтра секций в предложении WHERE, т. е. *ограничение* не позволит запросам проверять все секции. Перейдите на вкладку **Configs** (Конфигурации) Hive, а затем задайте для параметра `hive.exec.dynamic.partition.mode` значение **strict** (Строгий). По умолчанию используется значение **nonstrict** (Нестрогий).

1. Чтобы ограничить число создаваемых динамических секций, измените параметр `hive.exec.max.dynamic.partitions`. По умолчанию используется значение 5000.

1. Чтобы ограничить общее число динамических секций на узел, измените параметр `hive.exec.max.dynamic.partitions.pernode`. По умолчанию используется значение 2000.

## <a name="enable-local-mode"></a>Включение локального режима

Локальный режим позволяет Hive выполнять все задачи задания на одном компьютере. Или иногда в одном процессе. Этот параметр улучшает производительность запросов, если входные данные невелики. А затраты на запуск задач для запросов потребляют значительный процент общего выполнения запроса.

Чтобы включить локальный режим, добавьте параметр `hive.exec.mode.local.auto` в область "Custom hive-site" (Настраиваемый сайт Hive), как описано на шаге 3 в разделе [Включение промежуточного сжатия](#enable-intermediate-compression).

![Локальный автоматический режим Apache Hive Exec](./media/optimize-hive-ambari/hive-exec-mode-local-auto.png)

## <a name="set-single-mapreduce-multigroup-by"></a>Настройка отдельного запроса MapReduce MultiGROUP BY

Если это свойство имеет значение true, то запрос MultiGROUP BY с общими ключами group-by создает отдельное задание MapReduce.  

Чтобы включить этот режим, добавьте параметр `hive.multigroupby.singlereducer` в область "Custom hive-site" (Настраиваемый сайт Hive), как описано на шаге 3 в разделе [Включение промежуточного сжатия](#enable-intermediate-compression).

![Настройка отдельного запроса MapReduce MultiGROUP BY в Hive](./media/optimize-hive-ambari/hive-multigroupby-singlereducer.png)

## <a name="additional-hive-optimizations"></a>Дополнительные оптимизации Hive

В следующих разделах описаны дополнительные оптимизации Hive, которые можно применить.

### <a name="join-optimizations"></a>Оптимизация соединений

По умолчанию в Hive используется *соединение в случайном порядке*. В Hive специальные модули сопоставления считывают входные данные и создают пару "ключ-значение" соединения в промежуточном файле. Hadoop сортирует и объединяет эти пары на этапе обработки в случайном порядке. Этот этап обработки в случайном порядке является высокозатратным. Выбор правильного соединения в соответствии с вашими данными может значительно повысить производительность.

| Тип соединения | Если | Как | Параметры Hive | Комментарии |
| --- | --- | --- | --- | --- |
| Соединение в случайном порядке. | <ul><li>Выбор по умолчанию.</li><li>Всегда работает.</li></ul> | <ul><li>Считывает данные из части одной из таблиц.</li><li>Объединяет и сортирует данные по ключу соединения.</li><li>Отправляет один контейнер в каждый модуль сжатия.</li><li>Соединение выполняется на стороне модуля сжатия.</li></ul> | Не требуется значительная настройка Hive. | Работает каждый раз. |
| Соединение с сопоставлением | <ul><li>В памяти может поместиться одна таблица.</li></ul> | <ul><li>Небольшая таблица считывается в хэш-таблицу памяти.</li><li>Осуществляется потоковая передача посредством части большого файла.</li><li>Выполняется соединение каждой записи из хэш-таблицы.</li><li>Соединение выполняет исключительно модуль сопоставления.</li></ul> | `hive.auto.confvert.join=true` | Быстрый, но ограниченный |
| Сортировка, слияние, объединение | Если обе таблицы: <ul><li>отсортированы одинаково;</li><li>одинаково разделены на контейнеры (объединены);</li><li>соединяются по отсортированному или объединенному столбцу.</li></ul> | Каждый процесс: <ul><li>считывает контейнер из каждой таблицы;</li><li>обрабатывает строку с наименьшим значением.</li></ul> | `hive.auto.convert.sortmerge.join=true` | Эффективно |

### <a name="execution-engine-optimizations"></a>Оптимизации подсистемы выполнения

Дополнительные рекомендации по оптимизации подсистемы выполнения Hive.

| Параметр | Рекомендуемая | Значение по умолчанию HDInsight |
| --- | --- | --- |
| `hive.mapjoin.hybridgrace.hashtable` | True — более безопасное и медленное выполнение, false — более быстрое выполнение. | false |
| `tez.am.resource.memory.mb` | Верхняя граница размером 4 ГБ для большинства | Автоматическая настройка. |
| `tez.session.am.dag.submit.timeout.secs` | Более 300 | 300 |
| `tez.am.container.idle.release-timeout-min.millis` | Более 20 000 | 10000 |
| `tez.am.container.idle.release-timeout-max.millis` | Более 40 000 | 20 000 |

## <a name="next-steps"></a>Дальнейшие действия

* [Управление кластерами HDInsight с помощью веб-интерфейса Ambari](hdinsight-hadoop-manage-ambari.md)
* [Управление кластерами HDInsight с помощью REST API Ambari](hdinsight-hadoop-manage-ambari-rest-api.md)
* [Оптимизация запросов Apache в Hive в Azure HDInsight](./hdinsight-hadoop-optimize-hive-query.md)
* [Оптимизация кластеров](./optimize-hive-ambari.md)
* [Оптимизация Apache HBase](./optimize-hbase-ambari.md)
* [Optimize Apache Pig](./optimize-pig-ambari.md)