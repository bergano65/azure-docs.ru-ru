---
title: Сравнение вариантов хранения для использования с кластерами Azure HDInsight
description: Предоставляет обзор типов хранилища и того, как они работают с Azure HDInsight.
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
ms.service: hdinsight
ms.topic: conceptual
ms.date: 04/08/2019
ms.openlocfilehash: 320b8f948d08e46c43085e174dfbe838f44bac79
ms.sourcegitcommit: cababb51721f6ab6b61dda6d18345514f074fb2e
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/04/2019
ms.locfileid: "66479165"
---
# <a name="compare-storage-options-for-use-with-azure-hdinsight-clusters"></a>Сравнение вариантов хранения для использования с кластерами Azure HDInsight

Можно выбрать несколько различных Azure служб хранилища при создании кластеров HDInsight:

* Хранилище Azure
* Azure Data Lake Storage 2-го поколения
* Azure Data Lake Storage 1-го поколения

В этой статье предоставлен обзор типов хранилища и их уникальных функций.

В следующей таблице перечислены службы хранилища Azure, которые поддерживаются в разных версиях HDInsight:

| Служба хранилища | Тип учетной записи | Тип пространства имен | Поддерживаемые службы | Поддерживаемые уровни производительности | Поддерживаемые уровни доступа | Версия HDInsight | Тип кластера |
|---|---|---|---|---|---|---|---|
|Azure Data Lake Storage 2-го поколения| Общего назначения версии 2 | Иерархическое (файловая система) | BLOB-объект | Стандартная | "Горячий", "холодный", архивировать | 3.6+ | Все |
|Хранилище Azure| Общего назначения версии 2 | Object | BLOB-объект | Стандартная | "Горячий", "холодный", архивировать | 3.6+ | Все |
|Хранилище Azure| Общего назначения версии 1 | Object | BLOB-объект | Стандартная | Н/Д | Все | Все |
|Хранилище Azure| Хранилище BLOB-объектов ** | Object | Блочный BLOB-объект | Стандартная | "Горячий", "холодный", архивировать | Все | Все |
|Azure Data Lake Storage 1-го поколения| Н/Д | Иерархическое (файловая система) | Н/Д | Н/Д | Н/Д | Только 3.6 | Все, кроме HBase |

** Для кластеров HDInsight только учетные записи дополнительное хранилище может иметь тип BlobStorage.

Дополнительные сведения о типах учетных записей хранения Azure, см. в разделе [Обзор учетной записи хранения Azure](../storage/common/storage-account-overview.md)

Дополнительные сведения о уровни доступа к службе хранилища Azure, см. в разделе [хранилище BLOB-объектов Azure: "Премиум" (Предварительная версия), "Горячий", "холодный" и архивный уровни хранилища](../storage/blobs/storage-blob-storage-tiers.md)

Можно создать кластер с помощью различных сочетаний служб для основной и дополнительный дополнительного хранилища. В следующей таблице перечислены хранилища конфигурации кластера, которые в настоящее время поддерживаются в HDInsight:

| Версия HDInsight | Основное хранилище | Дополнительное хранилище | Поддерживаются |
|---|---|---|---|
| 3.6 & 4.0 | Общего назначения версии 1, общего назначения версии 2 | Общего назначения версии 1, общего назначения версии 2, BlobStorage (блочные BLOB-объекты) | Да |
| 3.6 & 4.0 | Общего назначения версии 1, общего назначения версии 2 | Data Lake Storage 2-го поколения | Нет |
| 3.6 & 4.0 | Общего назначения версии 1, общего назначения версии 2 | Data Lake Storage 1-го поколения | Да |
| 3.6 & 4.0 | 2-го поколения хранилища Озера данных * | Data Lake Storage 2-го поколения | Да |
| 3.6 & 4.0 | 2-го поколения хранилища Озера данных * | Общего назначения версии 1, общего назначения версии 2, BlobStorage (блочные BLOB-объекты) | Да |
| 3.6 & 4.0 | Data Lake Storage 2-го поколения | Data Lake Storage 1-го поколения | Нет |
| 3.6 | Data Lake Storage 1-го поколения | Data Lake Storage 1-го поколения | Да |
| 3.6 | Data Lake Storage 1-го поколения | Общего назначения версии 1, общего назначения версии 2, BlobStorage (блочные BLOB-объекты) | Да |
| 3.6 | Data Lake Storage 1-го поколения | Data Lake Storage 2-го поколения | Нет |
| 4,0 | Data Lake Storage 1-го поколения | Любой | Нет |

* = Одну или несколько Gen2 хранилища Озера данных учетных записей, возможно, пока они находятся все программу установки, чтобы использовать одно удостоверение управляемый для доступа к кластеру.

## <a name="use-azure-data-lake-storage-gen2-with-apache-hadoop-in-azure-hdinsight"></a>Использование Azure Data Lake Storage 2-го поколения с Apache Hadoop в Azure HDInsight

Azure Data Lake Storage 2-го поколения принимает основные возможности Azure Data Lake Storage 1-го поколения и интегрирует их в хранилище BLOB-объектов Azure. К этим функциям относится файловая система, которая совместима с Hadoop, Azure Active Directory (Azure AD) и списки управления доступом (ACL) на основе POSIX. Эта комбинация обеспечивает производительность Azure Data Lake Storage 1-го поколения в сочетании с распределением по уровням и возможностью управлять жизненным циклом данных хранилища BLOB-объектов.

Дополнительные сведения об Azure Data Lake Storage 2-го поколения см. в [этой статье](../storage/blobs/data-lake-storage-introduction.md).

### <a name="core-functionality-of-azure-data-lake-storage-gen2"></a>Основные функциональные возможности Azure Data Lake Storage 2-го поколения

* **Доступ, совместимый с Hadoop.** В Azure Data Lake Storage 2-го поколения вы можете получать доступ к данным и управлять ими так же, как и в распределенной файловой системе Hadoop (HDFS). Во всех средах Apache Hadoop, в том числе Azure HDInsight и Azure Databricks, доступен драйвер файловой системы больших двоичных объектов Azure (ABFS). Используйте ABFS для получения доступа к данным, хранящимся в Data Lake Storage 2-го поколения.

* **Супермножество разрешений POSIX.** Модель безопасности Data Lake 2-го поколения поддерживает разрешения ACL и POSIX, а также некоторую дополнительную детализацию, относящуюся к Data Lake Storage 2-го поколения. Параметры можно настроить с помощью средств администрирования или платформ, таких как Apache Hive и Apache Spark.

* **Экономичность.** Data Lake Storage 2-го поколения обеспечивает недорогие транзакции и емкость хранилища. Такие функции, как жизненный цикл хранилища BLOB-объектов Azure, помогают снизить затраты, регулируя тарифные ставки при перемещении данных в течение жизненного цикла.

* **Совместимость со средствами, платформами и приложениями хранилища BLOB-объектов.** Azure Data Lake Storage 2-го поколения поддерживает множество средств, платформ и приложений хранилища BLOB-объектов.

* **Оптимизированный драйвер.** Драйвер ABFS оптимизирован специально для аналитики больших данных. Соответствующие интерфейсы REST API подключены через конечную точку распределенной файловой системы (DFS) — dfs.core.windows.net.

### <a name="whats-new-for-azure-data-lake-storage-gen-2"></a>Новые возможности Azure Data Lake Storage 2-го поколения

#### <a name="managed-identities-for-secure-file-access"></a>Управляемые удостоверения для безопасного доступа к файлам

Azure HDInsight использует управляемые удостоверения, чтобы защитить доступ к кластеру файлов в Azure Data Lake Storage 2-го поколения. Управляемые удостоверения — это функция Azure Active Directory, которая предоставляет службы Azure с набором автоматически управляемых учетных данных. Эти учетные данные можно использовать для аутентификации в любой службе, которая поддерживает аутентификацию Active Directory. Для управляемых удостоверений не требуется хранить учетные данные в коде или файлах конфигурации.

Дополнительные сведения см. в статье [Что такое управляемые удостоверения для ресурсов Azure?](../active-directory/managed-identities-azure-resources/overview.md)

#### <a name="azure-blob-file-system-driver"></a>Драйвер файловой системы больших двоичных объектов Azure

Приложения Apache Hadoop изначально рассчитаны на чтение и запись данных из локального дискового хранилища. Драйвер файловой системы Hadoop, такой как ABFS, позволяет приложениям Hadoop работать с облачным хранилищем за счет эмуляции регулярных операций файловой системы Hadoop. Затем драйвер преобразует полученные из приложения команды в операции, чтобы их поддерживала фактическая платформа облачного хранения.

Ранее драйвер файловой системы Hadoop преобразовывал все операции файловой системы в вызовы REST API службы хранилища Azure на стороне клиента, а затем вызывал REST API. Это преобразование на стороне клиента привело к нескольким вызовам REST API на одну операцию файловой системы, например переименование файла. В ABFS некоторая логика файловой системы Hadoop была перемещена со стороны клиента на сторону сервера. API Azure Data Lake Storage 2-го поколения теперь выполняется параллельно с API больших двоичных объектов. Такая миграция повышает производительность, так как теперь общие операции файловой системы Hadoop выполняются с помощью одного вызова REST API.

Дополнительные сведения см. в [The Azure Blob Filesystem driver (ABFS): A dedicated Azure Storage driver for Hadoop](../storage/blobs/data-lake-storage-abfs-driver.md) (Драйвер файловой системы BLOB-объектов Azure (ABFS) — выделенный драйвер службы хранилища Azure Storage для Hadoop).

#### <a name="uri-scheme-for-azure-data-lake-storage-gen-2"></a>Схема URI для Azure Data Lake Storage 2-го поколения 

Azure Data Lake Storage 2-го поколения использует схему URI для доступа к файлам в службе хранилища Azure из HDInsight:

`abfs[s]://<FILE_SYSTEM_NAME>@<ACCOUNT_NAME>.dfs.core.windows.net/<PATH>`

Эта схема URI предоставляет как доступ с использованием SSL-шифрования с префиксом `abfss://`, так и незашифрованный доступ с префиксом `abfs://`. Используйте `abfss` всегда, когда это возможно, даже при обращении к данным, которые хранятся в том же регионе Azure.

`<FILE_SYSTEM_NAME>` идентифицирует путь к файловой системе Data Lake Storage 2-го поколения.

`<ACCOUNT_NAME>` определяет имя учетной записи службы хранилища Azure. Обязательно использовать полное доменное имя (FQDN).

`<PATH>` — это имя пути к файлу или каталогу HDFS.

Если значения для `<FILE_SYSTEM_NAME>` и `<ACCOUNT_NAME>` не указаны, используется файловая система по умолчанию. Для файлов в файловой системе по умолчанию можно использовать относительный или абсолютный путь. Например, для ссылки на файл `hadoop-mapreduce-examples.jar`, который поставляется с кластерами HDInsight, можно использовать один из приведенных ниже вариантов:

```
abfss://myfilesystempath@myaccount.dfs.core.windows.net/example/jars/hadoop-mapreduce-examples.jar
abfss:///example/jars/hadoop-mapreduce-examples.jar /example/jars/hadoop-mapreduce-examples.jar
```

> [!Note]
> В кластерах HDInsight версий 2.1 и 1.6 файл называется `hadoop-examples.jar`. При работе с файлами вне HDInsight вы увидите, что большинство программ не распознают формат ABFS, но вместо этого ожидают формат базового пути, например `example/jars/hadoop-mapreduce-examples.jar`.

Дополнительные сведения см. в статье [Use the Azure Data Lake Storage Gen2 URI](../storage/blobs/data-lake-storage-introduction-abfs-uri.md) (Использование универсального кода ресурса в Azure Data Lake Storage 2-го поколения).

## <a name="azure-storage"></a>Хранилище Azure

Служба хранилища Azure — это надежное, универсальное решение, которое полностью интегрируется с HDInsight. HDInsight может использовать контейнер больших двоичных объектов в службе хранилища Azure в качестве файловой системы по умолчанию для кластера. С помощью интерфейса HDFS все компоненты HDInsight могут напрямую взаимодействовать со структурированными или неструктурированными данными, хранящимися как большие двоичные объекты.

Мы рекомендуем использовать отдельное хранилище контейнеров для хранилища кластера по умолчанию и бизнес-данных, для выявления журналов HDInsight и временные файлы из бизнес-данных. Кроме того, рекомендуется удалить контейнер больших двоичных объектов по умолчанию, который содержит журналы приложений и системы, после каждого использования, чтобы сократить затраты на хранение. Обязательно извлеките эти журналы перед удалением контейнера.

Если выбран для защиты вашей учетной записи хранения с **брандмауэры и виртуальные сети** ограничения на **выбранные сети**, не забудьте включить исключения **Разрешить надежные Microsoft службы...**  HDInsight можно получить доступ к вашей учетной записи хранения.

### <a name="hdinsight-storage-architecture"></a>Архитектура хранилища HDInsight

Следующая схема является абстрактным представлением архитектуры HDInsight службы хранилища Azure:

![Диаграмма, показывающая, как кластеры Hadoop используют API HDFS для доступа к структурированным и неструктурированным данным и их хранения в хранилище BLOB-объектов](./media/hdinsight-hadoop-compare-storage-options/HDI.WASB.Arch.png "Архитектура хранилища HDInsight")

HDInsight предоставляет доступ к распределенной файловой системе, которая локально присоединена к вычислительным узлам. Доступ к этой файловой системе может осуществляться с использованием полного универсального кода ресурса (URI), например:

    hdfs://<namenodehost>/<path>

HDInsight также обеспечивает доступ к данным в службе хранилища Azure. Синтаксис выглядит так:

    wasb://<containername>@<accountname>.blob.core.windows.net/<path>

Рассмотрите некоторые рекомендации для использования учетной записи хранения Azure с кластерами HDInsight.

* **Контейнеры в учетных записях хранения, подключенных к кластеру.** Так как имя учетной записи и ключ связываются с кластером во время создания, вы получаете полный доступ к большим двоичным объектам в этих контейнерах.

* **Общедоступные контейнеры или общедоступные большие двоичные объекты в учетных записях хранения, *не* подключенных к кластеру.** У вас есть разрешение только для чтения к большим двоичным объектам в контейнерах.
  
  > [!NOTE]  
  > Общедоступные контейнеры позволяют получить список всех доступных в этом контейнере больших двоичных объектов, а также метаданные контейнера. Общедоступные BLOB-объекты позволяют получить доступ к BLOB-объектам только при условии, что вам известен точный URL-адрес. Дополнительные сведения см. в статье [Управление анонимным доступом на чтение к контейнерам и большим двоичным объектам](../storage/blobs/storage-manage-access-to-resources.md).

* **Частные контейнеры в учетных записях хранения, *не* подключенных к кластеру.** Вы не можете получить доступ к большим двоичным объектам в контейнерах, если не определите учетную запись хранения при отправке заданий WebHCat. 

Определенные на этапе создания учетные записи хранения и их ключи хранятся в файле %HADOOP_HOME%/conf/core-site.xml на узлах кластера. По умолчанию HDInsight будет использовать учетные записи хранения, определенные в файле core-site.xml. Этот параметр можно изменить с помощью [Apache Ambari](./hdinsight-hadoop-manage-ambari.md).

Множество заданий WebHCat, включая Apache Hive, MapReduce, потоковую передачу Apache Hadoop и Apache Pig, могут переносить описание учетных записей хранения и метаданные вместе с ними. (В настоящее время это работает для Pig с учетными записями хранения, но не с метаданными.) Дополнительные сведения см. в разделе об [использовании кластера HDInsight с дополнительными учетными записями хранения и метахранилищами](https://social.technet.microsoft.com/wiki/contents/articles/23256.using-an-hdinsight-cluster-with-alternate-storage-accounts-and-metastores.aspx).

Большие двоичные объекты могут использоваться для хранения как структурированных, так и неструктурированных данных. В контейнерах больших двоичных объектов данные хранятся в виде пар "ключ — значение" и отсутствует иерархия каталогов. Тем не менее, в имени ключа может использоваться знак косой черты "/", чтобы оно выглядело так, будто файл хранится в структуре каталогов. Например, ключ большого двоичного объекта может выглядеть следующим образом: `input/log1.txt`. Фактического каталога `input` не существует, но из-за косой черты в имени ключа, ключ выглядит как путь к файлу.

### <a id="benefits"></a>Преимущества службы хранилища Azure
Вычислительные кластеры и ресурсы хранилища, которые не являются совместно размещенными, подразумевают затраты производительности. Эти затраты компенсируются благодаря созданию вычислительных кластеров близко к ресурсам учетной записи хранения в регионе Azure. В этом регионе эти вычислительные узлы могут получать эффективный доступ к данным по высокоскоростной сети в службе хранилища Azure.

При хранении данных в службе хранилища Azure вместо HDFS вы получаете ряд преимуществ:

* **Повторное использование данных и общий доступ.** Данные в файловой системе HDFS расположены в вычислительном кластере. Только приложения, имеющие доступ к вычислительному кластеру, могут использовать данные через API HDFS. Доступ к данным в службе хранилища Azure, напротив, может осуществляться через API HDFS или через REST API хранилища BLOB-объектов. Из за этого для создания и использования данных можно применять больший набор приложений (включая другие кластеры HDInsight) и средств.

* **Архивация данных.** Сохранение данных в службе хранилища Azure позволяет безопасно (без потери пользовательских данных) удалять используемые для расчетов кластеры HDInsight.

* **Затраты на хранение данных.** Хранение данных в файловой системе DFS в долгосрочной перспективе является более затратным, чем хранение данных в службе хранилища Azure, так как стоимость вычислительного кластера превышает стоимость службы хранилища Azure. Кроме того, так как данные не требуется повторно загружать при создании каждого вычислительного кластера, вы экономите также на загрузке данных.

* **Гибкое горизонтальное масштабирование.** Хотя HDFS и представляет собой масштабируемую файловую систему, масштаб определяется количеством узлов, создаваемых для кластера. Изменение масштаба может оказаться более сложным, чем использование гибких возможностей масштабирования службы хранилища Azure, которые вы получаете автоматически.

* **Георепликация.** Доступна функция георепликации для вашей службы хранилища Azure. Хотя это обеспечивает возможность географического восстановления и избыточность данных, переход в расположение геореплицированных данных при отработке отказа заметно влияет на производительность, что может привести к дополнительным затратам. Поэтому мы рекомендуем взвешенно подходить к использованию георепликации, применяя ее, только когда стоимость данных окупает дополнительные затраты.

Определенные задания и пакеты MapReduce могут создавать промежуточные результаты, которые нет нужды хранить в службе хранилища Azure. В таком случае можно выбрать хранение данных в локальной системе HDFS. HDInsight использует DFS для некоторых таких промежуточных результатов в заданиях Hive и других процессах.

> [!NOTE]  
> Большинство команд HDFS (например, `ls`, `copyFromLocal` и `mkdir`) работают правильно в службе хранилища Azure. В службе хранилища Azure будет отличаться поведение только тех команд, которые относятся к стандартной реализации HDFS (под названием DFS), например `fschk` и `dfsadmin`.

## <a name="overview-of-azure-data-lake-storage-gen1"></a>Общие сведения об Azure Data Lake Storage Gen1

Azure Data Lake Storage 1-го поколения — это гипермасштабируемый репозиторий корпоративного уровня для аналитических рабочих нагрузок больших данных. Использование Azure Data Lake позволяет сохранять данные с любым размером, типом и скоростью приема в одном расположении для эксплуатационной и исследовательской аналитики.

Получите доступ к Data Lake Storage 1-го поколения из Hadoop (имеется в кластере HDInsight) с помощью REST API, совместимых с WebHDFS. Хранилище Data Lake Storage 1-го поколения разработано для анализа сохраненных данных и адаптировано к различным сценариям аналитики данных. По умолчанию оно содержит возможности, которые необходимы для реальных задач предприятия, в частности безопасность, управляемость, масштабируемость, надежность и доступность.

Дополнительные сведения об Azure Data Lake Storage 1-го поколения см. в [этой статье](../data-lake-store/data-lake-store-overview.md).

Ниже перечислены основные возможности Data Lake Storage 1-го поколения.

### <a name="compatibility-with-hadoop"></a>Совместимость с Hadoop

Data Lake Storage 1-го поколения имеет файловую систему Apache Hadoop, которая совместима с HDFS и поддерживает экосистему Hadoop.  Существующие приложения и службы HDInsight, использующие API-интерфейс WebHDFS, могут легко интегрироваться с Data Lake Storage 1-го поколения. Data Lake Storage 1-го поколения также предоставляет для приложений интерфейс REST, совместимый с WebHDFS.

Данные, хранящиеся в Data Lake Storage 1-го поколения, можно легко анализировать с помощью аналитических платформ Hadoop, таких как MapReduce или Hive. Для прямого доступа к данным, хранящимся в Data Lake Storage 1-го поколения, можно подготовить и настроить кластеры Azure HDInsight.

### <a name="unlimited-storage-petabyte-files"></a>Неограниченное пространство хранения, файлы петабайтного размера

Data Lake Storage 1-го поколения предоставляет неограниченное пространство и подходит для хранения разнообразных данных для анализа. В нем нет никаких ограничений на размер учетной записи, размер файла или объем данных, которые могут храниться в Data Lake. Отдельные файлы могут иметь размер от килобайт до петабайт, благодаря чему Data Lake Storage 1-го поколения подходит для хранения данных любого типа. Надежность хранения данных обеспечивается созданием нескольких копий. Также нет никаких ограничений на продолжительность хранения данных в Data Lake.

### <a name="performance-tuning-for-big-data-analytics"></a>Настройка производительности для аналитики больших данных

Data Lake Storage 1-го поколения предназначено для работы в крупномасштабных аналитических системах, где требуется высокая пропускная способность для запроса и анализа больших объемов данных. В Data Lake фрагменты файлов распределяются по нескольким отдельным серверам хранилища. При анализе данных подобная настройка улучшает пропускную способность чтения при считывании файла в параллельном режиме.

### <a name="readiness-for-enterprise-highly-available-and-secure"></a>Готовность для предприятий: Высокая доступность и надежность

Data Lake Storage 1-го поколения обладает доступностью и надежностью, соответствующими отраслевым стандартам. Ресурсы данных хранятся продолжительное время — создание избыточных копий защищает от любых непредвиденных сбоев. Предприятия могут использовать Data Lake Storage 1-го поколения в своих решениях как важную часть существующей платформы данных.

Data Lake Storage 1-го поколения также обеспечивает безопасность корпоративного уровня для сохраненных данных. Дополнительные сведения см. в статье о [защите данных в Data Lake Storage 1-го поколения](#DataLakeStoreSecurity).

### <a name="flexible-data-structures"></a>Гибкие структуры данных

Data Lake Storage 1-го поколения может хранить любые данные в собственном формате, как есть, без необходимости предварительного преобразования. В Data Lake Storage 1-го поколения не нужно определять схему до загрузки данных. Конкретная аналитическая платформа интерпретирует данные и определяет схему во время анализа. Из за возможности хранения файлов произвольных форматов и размера Data Lake Storage 1-го поколения может обрабатывать структурированные, полуструктурированные и неструктурированные данные.

В Data Lake Storage 1-го поколения хранятся контейнеры для данных — папки и файлы. Операции с хранимыми данными осуществляются через пакеты SDK, портал Azure и Azure PowerShell. Используя эти интерфейсы и соответствующие контейнеры, вы можете сохранять любые типы данных. Data Lake Storage 1-го поколения обрабатывает сохраняемые данные без учета их типа.

## <a name="DataLakeStoreSecurity"></a>Безопасность данных в Data Lake Storage 1-го поколения
В Data Lake Storage 1-го поколения используются Azure Active Directory для аутентификации и списки контроля доступа (ACL) для управления доступом к данным.

| **Возможность** | **Описание** |
| --- | --- |
| Authentication |Data Lake Storage 1-го поколения интегрируется с Azure Active Directory (Azure AD) для управления удостоверениями и доступом для всех данных, хранящихся в Data Lake Storage 1-го поколения. Благодаря интеграции Data Lake Storage 1-го поколения получает доступ ко всем функциям Azure AD, включая многофакторную проверку подлинности, условный доступ, контроль доступа на основе ролей, отслеживание использования приложений, мониторинг безопасности и предупреждения и т. д. Data Lake Storage 1-го поколения поддерживает протокол OAuth 2.0 для аутентификации в интерфейсе REST. Дополнительные сведения см. в статье [Аутентификация в ADLS 1-го поколения с помощью Azure Active Directory](../data-lake-store/data-lakes-store-authentication-using-azure-active-directory.md).|
| Управление доступом |Data Lake Storage 1-го поколения обеспечивает контроль доступа за счет поддержки разрешений POSIX, предоставляемых протоколом WebHDFS. Списки управления доступом можно включить в корневой папке, вложенных папках, а также в отдельных файлах. Дополнительные сведения о принципе работы списков управления доступом в контексте Data Lake Storage 1-го поколения см. в статье [Контроль доступа в Azure Data Lake Storage 1-го поколения](../data-lake-store/data-lake-store-access-control.md). |
| Шифрование |В Data Lake Storage 1-го поколения можно также включить шифрование данных, хранящихся в учетной записи. Параметры шифрования можно задать во время создания учетной записи Data Lake Storage 1-го поколения. Шифрование данных можно как включить, так и отключить. Дополнительные сведения см. в статье [Шифрование данных в Data Lake Storage 1-го поколения](../data-lake-store/data-lake-store-encryption.md). Инструкции по настройке шифрования см. в статье [Начало работы с Azure Data Lake Storage Gen1 с помощью портала Azure](../data-lake-store/data-lake-store-get-started-portal.md). |

Сведения о защите данных в Azure Data Lake Storage 1-го поколения см. в [этой статье](../data-lake-store/data-lake-store-secure-data.md).

## <a name="applications-that-are-compatible-with-data-lake-storage-gen1"></a>Приложения, совместимые с Data Lake Storage 1-го поколения
Data Lake Storage 1-го поколения совместимо с большинством компонентов с открытым исходным кодом в экосистеме Hadoop. Также оно легко интегрируется с прочими службами Azure.  Перейдите по ссылкам ниже для получения дополнительных сведений об использовании Data Lake Storage 1-го поколения как с компонентами с открытым исходным кодом, так и с другими службами Azure.

* Ознакомьтесь с [приложениями больших данных с открытым исходным кодом, которые работают с Azure Data Lake Storage 1-го поколения](../data-lake-store/data-lake-store-compatible-oss-other-applications.md).
* Сведения об использовании Data Lake Storage 1-го поколения с другими службами Azure для реализации других сценариев см. в статье [Интеграция Azure Data Lake Storage 1-го поколения с другими службами Azure](../data-lake-store/data-lake-store-integrate-with-other-services.md).
* Сведения об использовании Data Lake Storage 1-го поколения в сценариях, таких как прием, обработка, загрузка и визуализация данных, см. в статье [Использование Data Lake Storage 1-го поколения для обеспечения соответствия требованиям больших данных](../data-lake-store/data-lake-store-data-scenarios.md).

## <a name="data-lake-storage-gen1-file-system-adl"></a>Файловая система Data Lake Storage 1-го поколения (adl://)
В средах Hadoop (доступны в кластере HDInsight) вы можете осуществлять доступ к Data Lake Storage 1-го поколения через новую файловую систему AzureDataLakeFilesystem (adl://). Производительность приложений и служб, использующих adl: / /, можно оптимизировать способами, которые в настоящее время недоступны в WebHDFS. В результате при использовании Data Lake Storage 1-го поколения вы получаете возможность либо воспользоваться максимальной производительностью с помощью рекомендуемого adl://, либо сохранить существующий код, продолжая использовать интерфейс API WebHDFS напрямую. Azure HDInsight использует все возможности AzureDataLakeFilesystem для обеспечения максимальной производительности в Data Lake Storage 1-го поколения.

Для доступа к данным в Data Lake Storage 1-го поколения можно использовать:

`adl://<data_lake_storage_gen1_name>.azuredatalakestore.net`

Дополнительные сведения о доступе к данным в Data Lake Storage 1-го поколения см. в разделе [Доступные действия с сохраненными данными](../data-lake-store/data-lake-store-get-started-portal.md#properties).



## <a name="next-steps"></a>Дальнейшие действия

* [Общие сведения о хранилище Azure Data Lake Storage Gen2 (предварительная версия)](../storage/blobs/data-lake-storage-introduction.md)
* [Введение в хранилище Azure](../storage/common/storage-introduction.md)
