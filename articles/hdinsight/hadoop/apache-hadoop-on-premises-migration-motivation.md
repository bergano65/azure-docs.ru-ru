---
title: Миграция локальных кластеров Apache Hadoop в Azure HDInsight — мотивация и преимущества
description: Ознакомьтесь с мотивирующими факторами для миграции локальных кластеров Hadoop в Azure HDInsight и получаемыми в результате преимуществами.
services: hdinsight
author: hrasheed-msft
ms.reviewer: ashishth
ms.service: hdinsight
ms.custom: hdinsightactive
ms.topic: conceptual
ms.date: 10/25/2018
ms.author: hrasheed
ms.openlocfilehash: f899c2fb871ee528219bd48e94de62746626447f
ms.sourcegitcommit: 6135cd9a0dae9755c5ec33b8201ba3e0d5f7b5a1
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/31/2018
ms.locfileid: "50416126"
---
# <a name="migrate-on-premises-apache-hadoop-clusters-to-azure-hdinsight---motivation-and-benefits"></a>Миграция локальных кластеров Apache Hadoop в Azure HDInsight — мотивация и преимущества

Это первая статья в цикле, посвященном рекомендациям по перемещению локальных развертываний экосистемы Apache Hadoop в Azure HDInsight. Этот цикл статей предназначен для людей, которые отвечают за проектирование, развертывание и миграцию решений Apache Hadoop в Azure HDInsight. Она особенно полезна для архитекторов облака, администраторов Hadoop и инженеров DevOps. Разработчикам программного обеспечения, инженерам и специалистам по обработке и анализу данных также пригодятся знания того, как различные типы кластеров работают в облаке.

## <a name="why-to-migrate-to-azure-hdinsight"></a>Миграция в Azure HDInsight

Azure HDInsight является облачным распределением компонентов Hadoop из платформы данных  [Hortonworks Data Platform (HDP)](https://hortonworks.com/products/data-center/hdp/). Azure HDInsight обеспечивает простую, быструю и экономичную обработку больших объемов данных. HDInsight включает в себя наиболее популярные платформы с открытым исходным кодом, такие как:

- Apache Hadoop
- Apache Spark
- Apache Hive с LLAP
- Apache Kafka
- Apache Storm
- Apache HBase
- R

## <a name="advantages-that-azure-hdinsight-offers-over-on-premises-hadoop"></a>Преимущества, которые предоставляет Azure HDInsight по сравнению с локальной средой Hadoop

- **Низкая стоимость**. Затраты можно уменьшить за счет [создания кластеров по требованию](../hdinsight-hadoop-create-linux-clusters-adf.md) и платы только за используемые ресурсы. Несвязанные ресурсы вычисления и хранения обеспечивают гибкость благодаря сохранению объема данных независимо от размера кластера.

- **Автоматическое создание кластера**. Автоматическое создание кластера требует минимальной настройки. Автоматизация может использоваться для кластеров по требованию.

- **Управляемое оборудование и конфигурация**. Используя кластер HDInsight, вы больше не будете беспокоиться о физическом оборудовании или инфраструктуре. Просто укажите конфигурацию кластера, и Azure настроит его.

- **Простое масштабирование**. HDInsight позволяет  [уменьшать и увеличивать](../hdinsight-administer-use-portal-linux.md) масштаб рабочих нагрузок. Azure выполняет перераспределение данных и перебалансировку рабочей нагрузки без прерывания заданий обработки данных.

- **Глобальная доступность**. Служба HDInsight доступна в большем числе [регионов](https://azure.microsoft.com/regions/services/),чем любое другое предложение аналитики больших данных. Служба Azure HDInsight также доступна в Azure для государственных организаций, Китая и Германии, что позволяет обеспечить соответствие требованиям организации в основных независимых регионах.

- **Безопасность и соответствие требованиям**. HDInsight позволяет защитить ресурсы данных в организации с помощью  [виртуальной сети Azure](../hdinsight-extend-hadoop-virtual-network.md),  [шифрования](../hdinsight-hadoop-create-linux-clusters-with-secure-transfer-storage.md), а также интеграции с  [Azure Active Directory](../domain-joined/apache-domain-joined-introduction.md). HDInsight также соответствует наиболее распространенным отраслевым и государственным  [стандартам](https://azure.microsoft.com/overview/trusted-cloud).

- **Упрощенное управление версиями**. Azure HDInsight управляет версией компонентов экосистемы Hadoop и поддерживает их актуальность. Обновления программного обеспечения обычно представляют собой сложный процесс для локальных развертываний.

- **Меньшие кластеры оптимизированы для конкретных рабочих нагрузок и имеют меньшее число зависимостей между компонентами**. В обычной локальной конфигурации Hadoop используется один кластер, который служит многим целям. С помощью Azure HDInsight можно создавать кластеры, зависящие от рабочей нагрузки. Создание кластеров для конкретных рабочих нагрузок устраняет возрастающую сложность обслуживания одного кластера.

- **Производительность**. Вы можете использовать различные инструменты для Hadoop и Spark в предпочитаемой среде разработки.

- **Расширяемость благодаря использованию пользовательских средств или сторонних приложений**. Кластеры HDInsight могут быть расширены за счет установки компонентов, а также могут быть интегрированы с другими решениями для работы с большими данными путем использования [простых](https://azure.microsoft.com/services/hdinsight/partner-ecosystem/) развертываний в Azure Marketplace.

- **Простое управление, администрирование и мониторинг**. Azure HDInsight интегрируется с  [Azure Log Analytics](../hdinsight-hadoop-oms-log-analytics-tutorial.md) и предоставляет единый интерфейс для мониторинга всех кластеров.

- **Интеграция с другими службами Azure**. HDInsight можно легко интегрировать с другими популярными службами Azure, такими как:

    - Фабрика данных Azure (ADF)
    - Хранилище больших двоичных объектов Azure
    - Хранилище Azure Data Lake Gen2
    - Azure Cosmos DB
    - Базы данных SQL Azure
    - Службы Azure Analysis Services

- **Процессы и компоненты самовосстановления**. HDInsight постоянно проверяет инфраструктуру и компоненты с открытым исходным кодом, используя собственную инфраструктуру мониторинга. HDInsight также автоматически восстанавливает критические сбои, такие как недоступность узлов и компонентов с открытым исходным кодом. В случае сбоя любого компонента OSS в Ambari активируются оповещения.

Дополнительные сведения см. в статье [Что такое Azure HDInsight и стек технологий Hadoop](../hadoop/apache-hadoop-introduction.md).

## <a name="migration-planning-process"></a>Процесс планирования миграции

Для планирования переноса локальных кластеров Hadoop в Azure HDInsight нужно:

1. Разобраться с текущим локальным развертыванием и его топологиями.
2. Разобраться с масштабом, сроками текущего проекта и знаниями команды.
3. Разобраться с требованиями Azure.
4. Составить подробный план, следуя рекомендациям.

## <a name="gathering-details-to-prepare-for-a-migration"></a>Сбор сведений для подготовки к миграции

Этот раздел содержит шаблонные вопросники, помогающие собрать такую важную информацию:

- информацию о локальном развертывании;
- сведения о проекте;
- Требования Azure

### <a name="on-premises-deployment-questionnaire"></a>Вопросник по локальному развертыванию

| **Вопрос** | **Пример** | **Ответ** |
|---|---|---|
|**Раздел**: **среда**|||
|Тип распространения кластера|Hortonworks, Cloudera, MapR| |
|Версия распространения кластера|HDP 2.6.5, CDH 5.7|
|Компоненты экосистемы больших данных|HDFS, Yarn, Hive, LLAP, Impala, Kudu, HBase, Spark, MapReduce, Kafka, Zookeeper, Solr, Sqoop, Oozie, Ranger, Atlas, Falcon, Zeppelin, R|
|Типы кластеров|Hadoop, Spark, Confluent Kafka, Storm, Solr|
|Число кластеров|4.|
|Количество главных узлов|2|
|Количество рабочих узлов|100|
|Число граничных узлов| 5|
|Общее используемое дисковое пространство|100 ТБ|
|Конфигурация главного узла|M/Y, ЦП, диск и т. д.|
|Конфигурации узлов данных|M/Y, ЦП, диск и т. д.|
|Конфигурации граничных узлов|M/Y, ЦП, диск и т. д.|
|Используется ли шифрование HDFS?|Yes|
|Высокая доступность|HDFS HA, Metastore HA|
|Аварийное восстановление и резервное копирование|Нужно ли резервное копирование кластера?|  
|Системы, зависящие от кластера|SQL Server, Teradata, Power BI, MongoDB|
|Интеграция сторонних продуктов|Tableau, GridGain, Qubole, Informatica, Splunk|
|**Раздел**: **безопасность**|||
|Безопасность периметра|Брандмауэры|
|Аутентификация и авторизация в кластере|Active Directory, Ambari, Cloudera Manager, без аутентификации|
|Управление доступом к HDFS|  Ручной режим, пользователи SSH|
|Аутентификация и авторизация в Hive|Sentry, LDAP, AD с Kerberos, Ranger|
|Аудит|Ambari, Cloudera Navigator, Ranger|
|Мониторинг|Graphite, collectd, statsd, Telegraf, InfluxDB|
|Оповещение|Kapacitor, Prometheus, Datadog|
|Срок хранения данных| 3 года, 5 лет|
|Администраторы кластера|Единый администратор, несколько администраторов|

### <a name="project-details-questionnaire"></a>Вопросник по проекту

|**Вопрос**|**Пример**|**Ответ**|
|---|---|---|
|**Раздел**: **рабочие нагрузки и частота**|||
|Задания MapReduce|10 заданий — дважды в день||
|Задания Hive|100 заданий — каждый час||
|Пакетные задания Spark|50 заданий — каждые 15 минут||
|Задания потоковой передачи Spark|5 заданий — каждые 3 минуты||
|Задания структурированной потоковой передачи|5 заданий — каждую минуту||
|Задания обучения модели машинного обучения|2 задания — один раз в неделю||
|Языки программирования|Python, Scala, Java||
|Написание сценариев|Shell, Python||
|**Раздел**: **данные**|||
|Источники данных|Неструктурированные файлы, JSON, Kafka, RDBMS||
|Оркестрация данных|Рабочие процессы Oozie, Airflow||
|Поиск в памяти|Apache Ignite, Redis||
|Целевое расположение данных|HDFS, RDBMS, Kafka, MPP ||
|**Раздел**: **метаданные**|||
|Тип базы данных Hive|Mysql, Postgres||
|Нет. хранилищ метаданных Hive|2||
|Нет. таблиц Hive|100||
|Нет. политик Ranger|20||
|Нет. рабочих процессов Oozie|100||
|**Раздел**: **масштабирование**|||
|Объем данных, включая репликацию|100 ТБ||
|Ежедневный объем приема данных|50 ГБ||
|Темп роста объема данных|10 % в год||
|Темп увеличения узлов кластера|5 % в год
|**Раздел**: **использование кластера**|||
|Средняя загрузка ЦП (%)|60 %||
|Среднее использование памяти (%)|75 %||
|Используемое дисковое пространство|75 %||
|Среднее использование сети (%)|25 %
|**Раздел**: **персонал**|||
|Нет. администраторов|2||
|Нет. разработчиков|10||
|Нет. пользователей|100||
|Навыки|Hadoop, Spark||
|Нет. доступных ресурсов для задач по миграции|2||
|**Раздел**: **ограничения**|||
|Текущие ограничения|Высокая задержка||
|Текущие задачи|Проблема параллелизма||

### <a name="azure-requirements-questionnaire"></a>Вопросник по требованиям Azure

|**Раздел**: **инфраструктура** |||
|---|---|---|
|**Вопрос**|**Пример**|**Ответ**|
| Предпочтительный регион|Восточная часть США||
|Есть ли предпочитаемая виртуальная сеть?|Yes||
|Требуется ли аварийное восстановление и высокая доступность?|Yes||
|Нужна ли интеграция с другими облачными службами?|ADF, CosmosDB||
|**Раздел**: **перемещение данных**  |||
|Предпочтения к начальной загрузке|DistCp, Data Box, ADF, WANDisco||
|Передача разностных данных|DistCp, AzCopy||
|Текущая добавочная передача данных|DistCp, Sqoop||
|**Раздел**: **мониторинг и оповещения** |||
|Использование возможностей мониторинга и оповещений Azure или интеграция сторонних решений для мониторинга|Использование возможностей мониторинга и оповещений Azure||
|**Раздел**: **настройки безопасности** |||
|Нужны ли закрытый и защищенный конвейеры данных?|Yes||
|Используется ли присоединенный к домену кластер (ESPP)?|     Yes||
|Нужна ли синхронизация локальной службы AD с облаком?|     Yes||
|Нет. пользователей AD для синхронизации?|          100||
|Допускается ли синхронизация паролей с облаком?|    Yes||
|Разрешены ли пользователи "только в облаке"?|                 Yes||
|Требуется ли MFA?|                       Нет || 
|Есть ли требования к авторизации данных?|  Yes||
|Применяется ли управление доступом на основе ролей?|        Yes||
|Требуется ли аудит?|                  Yes||
|Нужно ли шифрование неактивных данных?|          Yes||
|Нужно ли шифрование данных при передаче?|       Yes||
|**Раздел**: **предпочтения касательно перепроектирования** |||
|Отдельный кластер или определенные типы кластеров|Определенные типы кластеров||
|Требуется ли удаленное или совместно размещенное хранилище?|Удаленное хранилище||
|Размер кластера меньший, так как данные хранятся удаленно?|Меньший размер кластера||
|Требуется ли использование нескольких небольших кластеров вместо одного большого?|Использование нескольких небольших кластеров||
|Требуется ли использование удаленного хранилища метаданных?|Yes||
|Нужно ли совместное использование хранилищ метаданных между разными кластерами?|Yes||
|Нужно ли деконструировать рабочие нагрузки?|Заменить задания Hive заданиями Spark||
|Нужно ли использовать ADF для оркестрации данных?|Нет ||
|Платформа данных в IaaS: HDInsight или Hortonworks|HDInsight||

## <a name="next-steps"></a>Дополнительная информация

Прочитайте следующую статью в этом цикле:

- [Migrate on-premises Apache Hadoop clusters to Azure HDInsight - architecture best practices](apache-hadoop-on-premises-migration-best-practices-architecture.md) (Миграция локальных кластеров Apache Hadoop в Azure HDInsight. Рекомендации по архитектуре)