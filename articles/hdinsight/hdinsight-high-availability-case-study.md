---
title: Пример использования архитектуры высокодоступного решения Azure HDInsight
description: Эта статья представляет собой вымышленное исследование возможной архитектуры высокодоступного решения Azure HDInsight.
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
keywords: Высокая доступность Hadoop
ms.service: hdinsight
ms.topic: conceptual
ms.date: 10/08/2020
ms.openlocfilehash: 4b98b03c2d7eb4a0403b4595c1376656ed42511b
ms.sourcegitcommit: 829d951d5c90442a38012daaf77e86046018e5b9
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/08/2020
ms.locfileid: "91855044"
---
# <a name="azure-hdinsight-highly-available-solution-architecture-case-study"></a>Пример использования архитектуры высокодоступного решения Azure HDInsight

Механизмы репликации Azure HDInsight можно интегрировать в архитектуру решения высокой доступности. В этой статье вымышленный пример использования Contoso Retail используется для объяснения возможных подходов к аварийному восстановлению высокого уровня доступности, расходов и соответствующих им проектов.

Рекомендации по аварийному восстановлению высокого уровня доступности могут иметь много перестановок и комбинаций. Эти решения должны быть получены после того, как заменяются преимущества и недостатки каждого из вариантов. В этой статье рассматривается только одно возможное решение.

## <a name="customer-architecture"></a>Архитектура клиента

На следующем рисунке показана основная архитектура Contoso Retail. Архитектура состоит из потоковой рабочей нагрузки, рабочей нагрузки пакетной службы, уровня обслуживания, уровня потребления, уровня хранилища и системы управления версиями.

:::image type="content" source="./media/hdinsight-high-availability-case-study/contoso-architecture.png" alt-text="Архитектура Contoso Retail":::

### <a name="streaming-workload"></a>Потоковая нагрузка

Устройства и датчики создают данные в HDInsight Kafka, составляющем платформу обмена сообщениями. HDInsight An о клиентах Spark считывает из разделов Kafka. Spark преобразует входящие сообщения и записывает их в кластер HDInsight HBase на уровне обслуживания.

### <a name="batch-workload"></a>Пакетная Рабочая нагрузка

HDInsight An кластер Hadoop, выполняющий Hive и MapReduce, принимает данные из локальных транзакционных систем. Необработанные данные, преобразованные Hive и MapReduce, хранятся в таблицах Hive в логической секции Data Lake, которая поддерживается Azure Data Lake Storage 2-го поколения. Данные, хранящиеся в таблицах Hive, также становятся доступными для Spark SQL, что позволяет пакетно преобразовывать их перед сохранением проверенных данных в HBase для обслуживания.

### <a name="serving-layer"></a>Служебный слой

Кластер HDInsight An HBase с Apache Phoenix используется для обслуживания данных для веб-приложений и панелей мониторинга визуализации. Кластер HDInsight An LLAP используется для выполнения внутренних требований к отчетам.

### <a name="consumption-layer"></a>Уровень потребления

Приложения API Azure и уровень управления API обратно — общедоступная веб-страница. Внутренние требования к отчетам выполняются Power BI.

### <a name="storage-layer"></a>Уровень хранения

Логически секционированные Azure Data Lake Storage 2-го поколения используются в качестве корпоративного Data Lake. Метахранилища HDInsight поддерживаются базой данных SQL Azure.

### <a name="version-control-system"></a>Система управления версиями

Система управления версиями, интегрированная в Azure Pipelines и размещенная за пределами Azure.

## <a name="customer-business-continuity-requirements"></a>Требования к непрерывности бизнес-процессов клиентов

Важно определить минимальные бизнес-функции, которые понадобятся в случае аварии.

### <a name="contoso-retails-business-continuity-requirements"></a>Требования к непрерывной работе бизнес-магазина contoso

* Необходимо защититься от региональных сбоев или региональной работоспособности служб.
* Пользователи никогда не должны видеть ошибку 404. Общедоступное содержимое всегда должно обслуживаться. (RTO = 0)  
* Для большей части года мы можем отобразить общедоступное содержимое, которое устарело на 5 часов. (RPO = 5 часов)
* Во время праздничных праздников наше общедоступное содержимое всегда должно быть актуальным. (RPO = 0)
* Мои внутренние требования к отчетности не считаются критически важными для обеспечения непрерывности бизнес-процессов.
* Оптимизируйте затраты на непрерывность бизнес-процессов.

## <a name="proposed-solution"></a>Предлагаемое решение

На следующем рисунке показана архитектура аварийного восстановления высокого уровня доступности для розничной торговли contoso.

:::image type="content" source="./media/hdinsight-high-availability-case-study/contoso-solution.png" alt-text="Архитектура Contoso Retail" в](hdinsight-business-continuity-architecture.md#apache-spark) нормальных случаях. Процесс репликации Hive выполняется периодически и сопровождается репликацией учетной записи хранения хранилище метаданных Azure SQL и Hive. Учетная запись хранения Spark периодически реплицируется с помощью ADF DistCP. Временная природа этих кластеров помогает оптимизировать затраты. Репликация выполняется каждые 4 часа и поступает на RPO, который хорошо подходит для пяти-часового требования.

Репликация **HBase** использует модель « [лидер-след](hdinsight-business-continuity-architecture.md#apache-hbase) » в обычном режиме, чтобы гарантировать, что данные всегда обслуживаются независимо от региона, а значение RPO равно нулю.

Если в основном регионе есть региональный сбой, веб-страница и содержимое серверной части обслуживаются из дополнительного региона в течение 5 часов с некоторой степенью устаревания. Если панель мониторинга работоспособности служб Azure не указывает на восстановление в течение 5-часового окна, Contoso Retail создаст слой преобразования Hive и Spark в дополнительном регионе, а затем назначит все вышестоящее источники данных в дополнительный регион. Предоставление доступа для записи дополнительного региона приведет к созданию восстановления размещения, включающего в себя репликацию на сервер-источник.

Во время пиковой покупки весь вторичный конвейер всегда активен и работает. Производители Kafka создают оба региона, и репликация HBase будет изменена с Leader-Follower на Leader-Leader, чтобы обеспечить постоянное обновление общедоступного содержимого.

Решение для отработки отказа не должно быть спроектировано для внутренних отчетов, поскольку оно не является критически важным для обеспечения непрерывности бизнес-процессов.

## <a name="next-steps"></a>Дальнейшие действия

Дополнительные сведения об элементах, обсуждаемых в этой статье, см. в следующих статьях:

* [Непрерывность бизнес-процессов Azure HDInsight](./hdinsight-business-continuity.md)
* [Архитектура обеспечения непрерывности бизнес-процессов Azure HDInsight](./hdinsight-business-continuity-architecture.md)
* [Обзор Apache Hive и HiveQL в Azure HDInsight](./hadoop/hdinsight-use-hive.md)