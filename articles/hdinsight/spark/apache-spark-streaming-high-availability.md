---
title: Задания потоковой передачи Spark высокой доступности в YARN — Azure HDInsight
description: Как настроить потоковую передачу Apache Spark для сценария высокой доступности в Azure HDInsight
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
ms.service: hdinsight
ms.topic: conceptual
ms.custom: hdinsightactive
ms.date: 11/29/2019
ms.openlocfilehash: ac51b77e1ffc2b476b0a73dac9b6917552a86ce4
ms.sourcegitcommit: 5aefc96fd34c141275af31874700edbb829436bb
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 12/04/2019
ms.locfileid: "74807159"
---
# <a name="create-high-availability-apache-spark-streaming-jobs-with-yarn"></a>Создание в YARN заданий потоковой передачи Apache Spark с высоким уровнем доступности

Потоковая передача [Apache Spark](https://spark.apache.org/) дает возможность реализовывать масштабируемые отказоустойчивые приложения с высокой пропускной способностью для обработки потоков данных. Вы можете подключать приложения потоковой передачи Spark в кластере HDInsight Spark к различным типам источников данных, таким как концентраторы событий Azure, центр Интернета вещей Azure, [Apache Kafka](https://kafka.apache.org/), [Apache Flume](https://flume.apache.org/), Twitter, [ZeroMQ](http://zeromq.org/), необработанные сокеты TCP, или путем наблюдения за изменениями в файловой системе [Apache Hadoop HDFS](https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html) . Потоковая передача Spark поддерживает отказоустойчивость с гарантией того, что любое указанное событие обрабатывается один раз даже в случае сбоя узла.

Потоковая передача Spark создает долгосрочные задания, в течение которых вы можете применить к данным преобразования, а затем отправить результаты в файловые системы, базы данных, панели мониторинга и консоль. При такой передаче выполняется обработка микропакетов данных — сначала выполняется сбор пакета событий через определенный интервал времени, а затем этот пакет отправляется на обработку и формирование выходных результатов. Интервалы времени для обработки пакета обычно определяются в долях секунды.

![Потоковая передача Spark](./media/apache-spark-streaming-high-availability/apache-spark-streaming.png)

## <a name="dstreams"></a>Потоки DStream

Потоковая передача Spark представляет непрерывный поток данных с использованием *дискретизированного потока* — DStream. Этот поток можно создать из источников входных данных, таких как Центры событий или Kafka, либо путем применения преобразований в другом потоке DStream. При получении события в приложении потоковой передачи Spark оно сохраняется надежным способом, — данные события реплицируются, обеспечивая создание копий на нескольких узлах. Это гарантирует, что сбой одного узла не приведет к утрате события.

Ядро Spark использует *устойчивые распределенные наборы данных* (RDD). Эти наборы данных распределяют данные по нескольким узлам кластера, где каждый узел обычно хранит свои данные в памяти для повышения производительности. Каждый набор данных RDD представляет события, собранные за интервал пакетной обработки. По истечении интервала пакетной обработки потоковая передача Spark формирует новый набор данных RDD со всеми данными, созданными за этот интервал. Этот непрерывный набор RDD собирается в поток DStream. Приложение потоковой передачи Spark обрабатывает данные, хранящиеся в каждом наборе данных RDD в пакете.

![Поток DStream Spark](./media/apache-spark-streaming-high-availability/apache-spark-dstream.png)

## <a name="spark-structured-streaming-jobs"></a>Задания структурированной потоковой передачи Spark

Структурированная потоковая передача Spark была представлена в Spark 2.0 как механизм аналитики для структурированных данных потоковой передачи. В структурированной потоковой передаче Spark используются API механизма пакетной обработки SparkSQL. Как и в случае с потоковой передачей Spark, структурированная потоковая передача Spark выполняет свои вычисления с постоянным поступлением микропакетных пакетов данных. В структурированной потоковой передаче Spark поток данных представлен в качестве входной таблицы с неограниченным количеством строк. То есть входная таблица продолжает расширяться по мере поступления новых данных. Эта таблица непрерывно обрабатывается с помощью долго выполняющегося запроса, а результаты обработки записываются в выходную таблицу.

![Структурированная потоковая передача Spark](./media/apache-spark-streaming-high-availability/structured-streaming.png)

В структурированной потоковой передаче данные передаются в систему и сразу же поступают во входную таблицу. Вы можете написать запросы для выполнения операций в этой входной таблице. Выходные данные запроса поступают в другую таблицу — таблицу результатов. В таблице результатов содержатся результаты запроса, из которых извлекаются данные для отправки во внешнее хранилище данных, например реляционную базу данных. С помощью *интервала триггера* задается расписание для обработки данных во входной таблице. По умолчанию в структурированной потоковой передаче данные обрабатываются по мере их поступления. Однако можно также настроить триггер для выполнения в течение более длительного интервала, что позволит обрабатывать данные потоковой передачи в пакетах на основе времени. Данные в таблице результатов могут обновляться каждый раз при наличии новых данных, чтобы они включали все выходные данные с момента начала потокового запроса (*полный режим*) или могли содержать только те данные, которые были новыми с момента последнего обработки запроса (*режим добавления*).

## <a name="create-fault-tolerant-spark-streaming-jobs"></a>Создание отказоустойчивых заданий потоковой передачи Spark

Чтобы создать высокодоступную среду для заданий потоковой передачи Spark, начните с написания кода отдельных заданий для восстановления в случае сбоя. Задания, для которых доступно самостоятельное восстановление, являются отказоустойчивыми.

RDD имеет несколько свойств, которые помогают обеспечить высокую доступность и отказоустойчивость заданий потоковой передачи Spark:

* Пакеты входных данных, сохраненные в RDD как поток DStream, автоматически реплицируются в памяти для обеспечения отказоустойчивости.
* Данные теряются из-за сбоев рабочих ролей, которые можно повторно вычислить из реплицированных входных данных на разных рабочих узлах, если эти рабочие узлы доступны.
* Быстрое восстановление после сбоя может занять не более секунды, так как при восстановлении после сбоев или других ошибок выполняется вычисление в памяти.

### <a name="exactly-once-semantics-with-spark-streaming"></a>Только один раз семантика с потоковой передачей Spark

Чтобы создать приложение, обрабатывающее каждое событие только один раз, нужно учитывать, как все системные точки отказа перезапускаются после сбоя, а также как избежать потери данных. Только один раз при семантике требуется, чтобы в какой-либо момент никакие данные не терялисься, а обработка сообщений была перезапущена, независимо от того, где происходит сбой. См. раздел [Создание заданий потоковой передачи Spark с точностью после обработки событий](apache-spark-streaming-exactly-once.md).

## <a name="spark-streaming-and-apache-hadoop-yarn"></a>Потоковая передача Spark и Apache Hadoop YARN

В HDInsight работа кластера координируется согласователем *Yet Another Resource Negotiator* (YARN). Проектирование заданий потоковой передачи Spark высокого уровня доступности включает методы для потоковой передачи Spark и компонентов YARN.  Ниже приведен пример конфигурации, в которой используется YARN.

![Архитектура YARN](./media/apache-spark-streaming-high-availability/hdi-yarn-architecture.png)

В следующих разделах описываются рекомендации по проектированию этой конфигурации.

### <a name="plan-for-failures"></a>Планирование на случай сбоев

Чтобы создать конфигурацию YARN для обеспечения высокого уровня доступности, следует учесть возможные сбои исполнителя или драйвера. Некоторые задания потоковой передачи Spark также имеют требования гарантии в отношении данных, для чего требуется дополнительная конфигурация и настройка. Например, приложение потоковой передачи может включать бизнес-требование, которое заключается в гарантии отсутствия потерь данных, независимо от типа ошибки, произошедшей в системе размещения потоковой передачи или кластере HDInsight.

В случае сбоя **исполнителя** задачи и получатели автоматически перезапускаются Spark, поэтому изменение конфигурации не требуется.

Однако если происходит сбой **драйвера**, работа его связанных исполнителей также завершается сбоем, что приводит к потере всех полученных блоков и результатов вычислений. Для восстановления после сбоя драйвера используйте *контрольные точки DStream* , как описано в разделе [Создание заданий потоковой передачи Spark с точностью после обработки событий](apache-spark-streaming-exactly-once.md#use-checkpoints-for-drivers). При этом периодически сохраняется *направленный ациклический граф* (DAG) потоков DStream в отказоустойчивое хранилище, например службу хранилища Azure.  Благодаря этому приложение структурированной потоковой передачи Spark может повторно запускать драйвер, работа которого завершилась ошибкой, на основе сведений о контрольной точке.  Повторный запуск такого драйвера приводит к запуску новых исполнителей, а также повторному запуску получателей.

Выполните действия ниже для восстановления драйверов с помощью контрольных точек DStream.

* Настройте автоматический повторный запуск драйвера в YARN с помощью параметра конфигурации `yarn.resourcemanager.am.max-attempts`.
* Настройте каталог контрольных точек в файловой системе, совместимой с HDFS, с помощью `streamingContext.checkpoint(hdfsDirectory)`.
* Реструктурируйте исходный код для выполнения восстановления на основе контрольных точек, например:

    ```scala
        def creatingFunc() : StreamingContext = {
            val context = new StreamingContext(...)
            val lines = KafkaUtils.createStream(...)
            val words = lines.flatMap(...)
            ...
            context.checkpoint(hdfsDir)
        }

        val context = StreamingContext.getOrCreate(hdfsDir, creatingFunc)
        context.start()
    ```

* Настройте восстановление потерянных данных, включив упреждающее протоколирование (WAL) с помощью `sparkConf.set("spark.streaming.receiver.writeAheadLog.enable","true")`, и отключите репликацию в памяти для входящих потоков DStream с помощью `StorageLevel.MEMORY_AND_DISK_SER`.

Подводя итоги, используя контрольные точки + WAL + надежные приемники, вы сможете доставлять по крайней мере один раз восстановление данных:

* Только один раз, при условии, что полученные данные не теряются, а выходные данные либо идемпотентными, либо транзакционной.
* Только один раз, с новым прямым подходом Kafka, который использует Kafka в качестве реплицируемого журнала вместо использования приемников или Wal.

### <a name="typical-concerns-for-high-availability"></a>Высокий уровень доступности и сложности его обеспечения

* Отслеживать задания потоковой передачи более сложно, чем пакетные задания. Задания потоковой передачи Spark обычно выполняются длительное время, и YARN выполняет статистическую обработку журналов только после завершения задания.  Во время обновления Spark или приложения контрольные точки Spark теряются, поэтому вам нужно очистить каталог контрольных точек во время обновления.

* Настройте такой режим кластера YARN, при котором драйверы запускаются даже в случае сбоя клиента. Чтобы настроить автоматический перезапуск драйверов, выполните команду ниже:

    ```
    spark.yarn.maxAppAttempts = 2
    spark.yarn.am.attemptFailuresValidityInterval=1h
    ```

* У Spark и пользовательского интерфейса потоковой передачи Spark есть настраиваемая система метрик. Кроме того, можно использовать дополнительные библиотеки, например GRAPHITE/Grafana, для загрузки метрик панели мониторинга, например "число обработанных записей", "память/GC-использование в драйвере & исполнители", "Общая задержка", "Использование кластера" и т. д. В структурированной потоковой передаче версии 2.1 или выше для сбора дополнительных метрик можно использовать `StreamingQueryListener`.

* Долго выполняющиеся задания необходимо сегментировать.  Когда приложение потоковой передачи Spark отправляется в кластер, необходимо определить очередь YARN, где будет запущено задание. Чтобы отправить долго выполняющиеся задания в отдельные очереди, можно использовать [Планировщик емкости Yarn](https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html).

* Корректно завершите работу приложения потоковой передачи. Если известны смещения и все состояние приложения хранится извне, вы можете программным способом остановить приложение потоковой передачи в соответствующем месте. Один из способов — использовать перехватчики потока в Spark, устанавливая флажок внешнего хранилища каждые *n* с. Вы можете также использовать *файл маркера*, который создается в HDFS при запуске приложения и удаляется по завершении его работы. Чтобы выбрать этот вариант, используйте отдельный поток в приложении Spark, вызывающий код, подобный коду ниже:

    ```scala
    streamingContext.stop(stopSparkContext = true, stopGracefully = true)
    // to be able to recover on restart, store all offsets in an external database
    ```

## <a name="next-steps"></a>Дальнейшие действия

* [Общие сведения о потоковой передаче Apache Spark](apache-spark-streaming-overview.md)
* [Создание Apache Sparkных заданий потоковой передачи с точностью после обработки событий](apache-spark-streaming-exactly-once.md)
* [Long-running Apache Spark Streaming Jobs on YARN](https://mkuthan.github.io/blog/2016/09/30/spark-streaming-on-yarn/) (Долго выполняющиеся задания потоковой передачи Apache Spark в YARN)
* [Structured Streaming: Fault Tolerant Semantics](https://spark.apache.org/docs/2.1.0/structured-streaming-programming-guide.html#fault-tolerance-semantics) (Структурированная потоковая передача: отказоустойчивая семантика)
* [Discretized Streams: A Fault-Tolerant Model for Scalable Stream Processing](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2012/EECS-2012-259.pdf) (Дискретизированные потоки: отказоустойчивая модель для обработки масштабируемого потока)
