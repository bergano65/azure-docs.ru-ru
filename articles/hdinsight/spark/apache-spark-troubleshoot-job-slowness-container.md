---
title: Apache Spark замедлит работу, когда контейнер службы хранилища Azure содержит много файлов — HDInsight
description: Apache Spark задание выполняется медленно, когда контейнер хранилища Azure содержит много файлов в Azure HDInsight.
ms.service: hdinsight
ms.topic: troubleshooting
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
ms.date: 08/21/2019
ms.openlocfilehash: 40c5d023647d3592e44588fbc24bf2743da34373
ms.sourcegitcommit: c79aa93d87d4db04ecc4e3eb68a75b349448cd17
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/18/2019
ms.locfileid: "71088622"
---
# <a name="apache-spark-job-run-slowly-when-the-azure-storage-container-contains-many-files-in-azure-hdinsight"></a>Apache Spark задание медленно выполняется, если контейнер службы хранилища Azure содержит много файлов в Azure HDInsight

В этой статье описываются действия по устранению неполадок и возможные способы решения проблем при использовании Apache Spark компонентов в кластерах Azure HDInsight.

## <a name="issue"></a>Проблемы

При запуске кластера HDInsight задание Apache Spark, которое выполняет запись в контейнер службы хранилища Azure, замедлит работу при наличии большого количества файлов и вложенных папок. Например, при записи в новый контейнер может потребоваться 20 секунд, а при записи в контейнер с 200 000 деятелей-файлами — 2 минуты.

## <a name="cause"></a>Причина:

Это известная проблема Spark. Медленная работа поступает из `ListBlob` операций и `GetBlobProperties` во время выполнения задания Spark.

Для отслеживания секций Spark должен поддерживать `FileStatusCache` , который содержит сведения о структуре каталогов. С помощью этого кэша Spark может анализировать пути и получать информацию о доступных секциях. Преимущество отслеживания секций заключается в том, что Spark касается только необходимых файлов при чтении данных. Чтобы сохранить эти сведения в актуальном состоянии, при записи новых данных Spark должен вывести список всех файлов в каталоге и обновить этот кэш.

В Spark 2,1 не требуется обновлять кэш после каждой операции записи, Spark проверяет, совпадает ли существующий столбец секционирования с предложенным в текущем запросе записи, поэтому он также приводит к переписи операций в начале каждой операции записи.

В Spark 2,2 при записи данных в режиме добавления эта проблема производительности должна быть исправлена.

## <a name="resolution"></a>Разрешение

При создании секционированного набора данных важно использовать схему секционирования, которая будет ограничивать количество файлов, которые будут перечислены в Spark для обновления `FileStatusCache`.

Для каждого n-го микропакета, где N% 100 = = 0 100 (всего лишь пример), переместите существующие данные в другой каталог, который может быть загружен Spark.

## <a name="next-steps"></a>Следующие шаги

Если вы не видите своего варианта проблемы или вам не удается ее устранить, дополнительные сведения можно получить, посетив один из следующих каналов.

* Получите ответы от экспертов Azure через [службу поддержки сообщества Azure](https://azure.microsoft.com/support/community/).

* Подключайтесь с помощью [@AzureSupport](https://twitter.com/azuresupport) официальной учетной записи Microsoft Azure для улучшения качества работы клиентов, подключив сообщество Azure к нужным ресурсам: ответы, поддержка и эксперты.

* Если вам нужна дополнительная помощь, можно отправить запрос в службу поддержки из [портал Azure](https://portal.azure.com/?#blade/Microsoft_Azure_Support/HelpAndSupportBlade/). Выберите пункт **Поддержка** в строке меню или откройте центр **справки и поддержки** . Дополнительные сведения см. [в](https://docs.microsoft.com/azure/azure-supportability/how-to-create-azure-support-request)этой службе. Доступ к управлению подписками и поддержкой выставления счетов включен в вашу подписку Microsoft Azure, а техническая поддержка предоставляется через один из [планов поддержки Azure](https://azure.microsoft.com/support/plans/).
