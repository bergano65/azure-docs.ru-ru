---
title: Устранение проблем с производительностью Apache HBase в Azure HDInsight
description: Различные рекомендации по настройке производительности Apache HBase и советы по обеспечению оптимальной производительности в Azure HDInsight.
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
ms.service: hdinsight
ms.topic: troubleshooting
ms.date: 09/24/2019
ms.openlocfilehash: 0466b08e551a5fa9da37afe2e5ad175ef28c804e
ms.sourcegitcommit: f29fec8ec945921cc3a89a6e7086127cc1bc1759
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/17/2019
ms.locfileid: "72529567"
---
# <a name="troubleshoot-apache-hbase-performance-issues-on-azure-hdinsight"></a>Устранение проблем с производительностью Apache HBase в Azure HDInsight

В этой статье описываются различные рекомендации по настройке производительности Apache HBase и советы по обеспечению оптимальной производительности в Azure HDInsight. Многие из этих советов зависят от конкретной рабочей нагрузки и шаблона чтения, записи и проверки. Перед применением изменений конфигурации в рабочей среде тщательно протестируйте их.

## <a name="hbase-performance-insights"></a>Аналитика производительности HBase

Основной узким местом в большинстве рабочих нагрузок HBase является журнал упреждающего записи (WAL). Это серьезно влияет на производительность записи. HDInsight HBase имеет разделенную модель вычислений с хранилищем. Данные хранятся в службе хранилища Azure удаленно, даже если на виртуальных машинах размещены серверы регионов. В течение последнего времени WAL был также записан в службу хранилища Azure. В HDInsight такое поведение было усилено. Функция [ускоренного записи](./apache-hbase-accelerated-writes.md) предназначена для решения этой проблемы. Он записывает WAL в диски, управляемые SSD (цен. категория "Премиум") Azure. Это невероятно преимущества для повышения производительности и помогает решать многие проблемы, с которыми сталкиваются некоторые рабочие нагрузки с интенсивными операциями записи.

Чтобы получить значительное улучшение операций чтения, используйте [учетную запись хранения блочного BLOB-объекта](https://azure.microsoft.com/blog/azure-premium-block-blob-storage-is-now-generally-available/) уровня "Премиум" в качестве удаленного хранилища. Этот параметр возможен только в том случае, если включен компонент WAL.

## <a name="compaction"></a>Сжатия

Сжатие — это еще одна потенциальная узкие места, которые в сообществе имеют принципиальное согласие. По умолчанию крупное сжатие отключено в кластерах HDInsight HBase. Сжатие отключено, поскольку, несмотря на то, что это ресурсоемкий процесс, клиенты имеют полную гибкость в планировании в соответствии с их рабочими нагрузками. Например, они могут запланировать его в часы наименьшей нагрузки. Кроме того, локализация данных не является проблемой, так как хранилище является удаленным (поддерживается службой хранилища Azure), а не локальным распределенная файловая система Hadoop (HDFS).

Клиенты должны запланировать значительное сжатие по своему усмотрению. Если это не сделано, сжатие отрицательно повлияет на производительность чтения в долгосрочном запуске.

Для операций сканирования среднее значение задержки, которое значительно выше 100 миллисекунд, должно быть причиной проблемы. Проверьте, правильно ли было запланировано значительное сжатие.

## <a name="apache-phoenix-workload"></a>Рабочая нагрузка Apache Phoenix

Ответы на следующие вопросы помогут лучше понять вашу рабочую нагрузку Apache Phoenix.

* Будут ли все операции чтения преобразованы для просмотра?
    * Если да, каковы характеристики этих проверок?
    * Оптимизирована ли схема таблицы Phoenix для таких проверок, включая соответствующую индексацию?
* Вы использовали инструкцию `EXPLAIN`, чтобы понять планы запросов, создаваемые при чтении?
* Вы пишете "Upsert-Selects"?
    * Если да, то они также будут выполнять проверки. Ожидаемая задержка для проверок среднего значения приблизительно 100 миллисекунд, по сравнению с 10 миллисекундами для Point в HBase.  

## <a name="test-methodology-and-metrics-monitoring"></a>Проверка методологии и мониторинга метрик

Если вы используете тесты производительности, такие как Yahoo! Cloud обслуживает тесты производительности, JMeter или Ферф, чтобы протестировать и настроить производительность, убедитесь, что:

- Клиентские компьютеры не являются узким местом. Для этого проверьте загрузку ЦП на клиентских компьютерах.

- Конфигурации на стороне клиента, например количество потоков, настраиваются соответствующим образом, чтобы повысить пропускную способность клиента.

- Результаты тестов записываются точно и систематически.

Если запросы внезапно начали намного хуже, проверьте наличие потенциальных ошибок в коде приложения. Неожиданно ли создаются большие объемы недопустимых данных? Если это так, это может увеличить задержку чтения.

## <a name="migration-issues"></a>Проблемы с миграцией

Если вы выполняете миграцию в Azure HDInsight, убедитесь, что миграция выполняется систематически и точно, желательно с помощью службы автоматизации. Избегайте ручной миграции. Убедитесь, что выполнены следующие условия:

- Атрибуты таблицы переносятся точно. Атрибуты могут включать как сжатие, фильтры раскрытия и т. д.

- Параметры Salt в таблицах Phoenix соответствуют новому размеру кластера. Например, число сегментов соли должно быть кратно количеству рабочих узлов в кластере. И следует использовать множитель, который является коэффициентом интенсивности оперативного выявления.

## <a name="server-side-configuration-tunings"></a>Настройки конфигурации на стороне сервера

В HDInsight HBase файлах hFile хранятся в удаленном хранилище. При промахе кэша стоимость операций чтения выше, чем в локальных системах, так как данные на локальных системах поддерживаются локальными HDFS. В большинстве сценариев Интеллектуальное использование кэшей HBase (кэш блоков и кэш контейнеров) предназначено для обхода этой проблемы. В тех случаях, когда проблема не обходится, может помочь эта проблема при использовании учетной записи блочного BLOB-объекта уровня "Премиум". Драйвер Windows Azure Storage Blob использует определенные свойства, такие как `fs.azure.read.request.size` для извлечения данных в блоках на основе того, что он определяет как режим чтения (последовательное и случайное), поэтому при чтении могут возникать и другие экземпляры с большим количеством задержек. С помощью экспериментов мы обнаружили, что установка размера блока запроса чтения (`fs.azure.read.request.size`) на 512 КБ и сопоставление размера блока таблиц HBase одинакового размера дает наилучший результат на практике.

Для большинства кластеров узлов с большими размерами HDInsight HBase предоставляет `bucketcache` в виде файла на локальном SSD (цен. категория "Премиум"), подключенном к виртуальной машине, которая работает под управлением `regionservers`. Использование кэша без кучи может обеспечить некоторое улучшение. Это решение имеет ограничение на использование доступной памяти и может быть меньше, чем файловый кэш, поэтому он может не всегда быть лучшим выбором.

Ниже приведены некоторые из других параметров, которые мы настраиваете, и которые были полезны в различной степени:

- Увеличьте размер `memstore` по умолчанию — от 128 МБ до 256 МБ. Как правило, этот параметр рекомендуется использовать для больших сценариев записи.

- Увеличьте число потоков, выделенных для сжатия, от значения по умолчанию от **1** до **4**. Этот параметр важен, если мы наблюдаем частые небольшие сжатия.

- Старайтесь не блокировать `memstore`, так как это ограничение хранилища. Чтобы предоставить этот буфер, увеличьте значение параметра `Hbase.hstore.blockingStoreFiles` равным **100**.

- Для управления сбросами используйте следующие параметры.

    - `Hbase.regionserver.maxlogs`: **140** (предотвращает очистку из-за ограничений WAL)

    - `Hbase.regionserver.global.memstore.lowerLimit`: **0,55**

    - `Hbase.regionserver.global.memstore.upperLimit`: **0,60**

- Конфигурации для настройки пула потоков, зависящие от Phoenix:

    - `Phoenix.query.queuesize`: **10000**

    - `Phoenix.query.threadpoolsize`: **512**

- Другие конфигурации, относящиеся к Phoenix:

    - `Phoenix.rpc.index.handler.count`: **50** (при наличии большого или большого количества поисков в индексе)

    - `Phoenix.stats.updateFrequency`: **1 час**

    - `Phoenix.coprocessor.maxmetadatacachetimetolivems`: **1 час**

    - `Phoenix.coprocessor.maxmetadatacachesize`: **50 МБ**

- Время ожидания RPC: **3 минуты**

   - Таймауты RPC включают время ожидания RPC для HBase, время ожидания клиентского сканера HBase и время ожидания запроса в Phoenix. 
   - Убедитесь, что для параметра `hbase.client.scanner.caching` задано одинаковое значение на стороне сервера и на стороне клиента. Если они не совпадают, этот параметр приводит к ошибкам клиента, связанным с `OutOfOrderScannerException`. Для этого параметра следует задать низкое значение для больших просмотров. Это значение устанавливается равным **100**.

## <a name="other-considerations"></a>Дополнительные рекомендации

Ниже приведены дополнительные параметры, которые следует учесть при настройке.

- `Hbase.rs.cacheblocksonwrite` — по умолчанию в HDI этот параметр имеет значение **true**.

- Параметры, позволяющие отложить незначительное сжатие для последующего использования.

- Экспериментальные параметры, такие как настройка процентных долей очередей, зарезервированных для запросов на чтение и запись.

## <a name="next-steps"></a>Дальнейшие действия

Если проблема не решена, посетите один из следующих каналов для получения дополнительной поддержки.

- Получите ответы от экспертов Azure через [службу поддержки сообщества Azure](https://azure.microsoft.com/support/community/).

- Подключитесь с [@AzureSupport](https://twitter.com/azuresupport). Это официальная учетная запись Microsoft Azure для улучшения качества взаимодействия с клиентами. Он подключает сообщество Azure к нужным ресурсам: ответы, поддержка и эксперты.

- Если вам нужна дополнительная помощь, можно отправить запрос в службу поддержки из [портал Azure](https://portal.azure.com/?#blade/Microsoft_Azure_Support/HelpAndSupportBlade/). Выберите пункт **Поддержка** в строке меню или откройте центр **справки и поддержки** . Для получения более подробных сведений см. статью [о создании запроса на поддержку Azure](https://docs.microsoft.com/azure/azure-supportability/how-to-create-azure-support-request). Ваша Подписка Microsoft Azure включает доступ к управлению подписками и поддержке выставления счетов, а техническая поддержка предоставляется через один из [планов поддержки Azure](https://azure.microsoft.com/support/plans/).
