---
title: Автоматическое масштабирование кластеров Azure HDInsight
description: Используйте функцию автомасштабирования Azure HDInsight для автоматического масштабирования Apache Hadoop кластеров.
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
ms.service: hdinsight
ms.topic: how-to
ms.custom: contperfq1
ms.date: 08/21/2020
ms.openlocfilehash: 7ce4580b366b57e2a1d4904b6ab63bf1834bdb65
ms.sourcegitcommit: 07166a1ff8bd23f5e1c49d4fd12badbca5ebd19c
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/15/2020
ms.locfileid: "90090114"
---
# <a name="autoscale-azure-hdinsight-clusters"></a>Автомасштабирование кластеров Azure HDInsight

Функция автоматического автомасштабирования в Azure HDInsight может автоматически увеличивать или уменьшать число рабочих узлов в кластере на основе ранее заданных критериев. Вы устанавливаете минимальное и максимальное количество узлов во время создания кластера, устанавливаете критерии масштабирования с помощью расписания дневного времени или конкретных метрик производительности, а платформа HDInsight выполняет остальные операции.

## <a name="how-it-works"></a>Принцип работы

Функция автомасштабирования использует два типа условий для запуска событий масштабирования: пороговые значения для различных метрик производительности кластера (называемые *масштабированием на основе загрузки*) и триггеры на основе времени (под названием *масштабирование на основе расписания*). Масштабирование на основе загрузки изменяет количество узлов в кластере в пределах заданного диапазона для обеспечения оптимального использования ЦП и снижения затрат на выполнение. Масштабирование на основе расписания изменяет количество узлов в кластере на основе операций, связанных с конкретными датами и временем.

В следующем видео представлен обзор проблем, решаемых с помощью автоматического масштабирования и способов управления затратами в HDInsight.


> [!VIDEO https://www.youtube.com/embed/UlZcDGGFlZ0?WT.mc_id=dataexposed-c9-niner]

### <a name="choosing-load-based-or-schedule-based-scaling"></a>Выбор масштаба на основе нагрузки или по расписанию

При выборе типа масштабирования учитывайте следующие факторы.

* Дисперсия нагрузки: выполняет ли нагрузка кластера последовательный шаблон в определенное время в определенные дни? Если нет, лучше использовать планирование с учетом нагрузки.
* Требования к соглашению об уровне обслуживания: масштабирование автомасштабирования активно, а не прогнозное. Будет ли существовать достаточная задержка между началом загрузки и увеличением размера кластера на целевой. Если соблюдены требования соглашения об уровне обслуживания, а загрузка является фиксированной известной моделью, лучшим вариантом является "расписание на основе".

### <a name="cluster-metrics"></a>Метрики кластера

Автомасштабирование постоянно выполняет мониторинг кластера и собирает следующие метрики:

|Метрика|Описание|
|---|---|
|Total Pending CPU (Общее число ожидающих ЦП)|Общее число ядер, необходимое для запуска выполнения всех ожидающих контейнеров.|
|Total Pending Memory (Общий объем ожидающей памяти)|Общий объем памяти (в МБ), необходимый для запуска выполнения всех отложенных контейнеров.|
|Total Free CPU (Общее число свободных ЦП)|Сумма всех неиспользуемых ядер на активных рабочих узлах.|
|Total Free Memory (Общий объем свободной памяти)|Сумма неиспользуемой памяти (в МБ) на активных рабочих узлах.|
|Used Memory per Node (Объем используемой памяти на каждом узле)|Нагрузка на рабочем узле. Рабочий узел, на котором используется 10 ГБ памяти, пребывает под большей нагрузкой, чем рабочий узел с 2 ГБ используемой памяти.|
|Число хозяев приложения на узел|Число основных контейнеров приложений, работающих на рабочем узле. Рабочий узел, на котором размещаются два контейнера AM, считается более важным, чем рабочий узел, в котором размещаются нулевые контейнеры.|

Эти метрики проверяются каждые 60 секунд. Вы можете настроить операции масштабирования для кластера, используя любую из этих метрик.

### <a name="load-based-scale-conditions"></a>Условия масштабирования на основе нагрузки

При обнаружении следующих условий компонент автомасштабирования будет выдавать запрос на масштабирование.

|Вертикальное масштабирование|Вертикальное уменьшение масштаба|
|---|---|
|Всего ожидающих ЦП превышает общий свободный ЦП более 3 минут.|Общее число ожидающих ЦП меньше, чем общее число свободных ЦП в течение более чем 10 минут.|
|Общий объем незавершенной памяти превышает общий объем свободной памяти в течение более 3 минут.|Общий объем ожидающей памяти меньше, чем общее количество свободной памяти в течение более чем 10 минут.|

При масштабировании с помощью автомасштабирования возникают запросы на увеличение масштаба для добавления требуемого количества узлов. Масштабирование основано на количестве новых рабочих узлов, необходимых для удовлетворения текущих требований к ЦП и памяти.

Для уменьшения масштаба при автомасштабировании выдается запрос на удаление определенного числа узлов. Горизонтальное масштабирование основано на количестве контейнеров AM на узел. И текущие требования к ЦП и памяти. Служба также определяет, какие узлы являются кандидатами на удаление в зависимости от текущего состояния выполнения задания. При вертикальном уменьшении масштаба сначала узлы выводятся из эксплуатации, а затем они удаляются из кластера.

### <a name="cluster-compatibility"></a>Совместимость кластера

> [!Important]
> Функция автомасштабирования Azure HDInsight появилась в общедоступной версии от 7 ноября 2019 года для кластеров Spark и Hadoop. В эту версию включены усовершенствования, недоступные в предварительной версии этой функции. Если вы создали кластер Spark до 7 ноября 2019 года и хотите использовать функцию автомасштабирования в этом кластере, рекомендуется создать новый кластер и включить автомасштабирование в этом новом кластере.
>
> Автомасштабирование для кластеров Interactive Query (LLAP) и HBase все еще доступно только в предварительной версии. Автомасштабирование доступно только в кластерах Spark, Hadoop, Interactive Query и HBase.

В следующей таблице описаны типы и версии кластеров, совместимые с функцией автомасштабирования.

| Версия | Spark | Hive | LLAP | HBase | Kafka | Storm | ML |
|---|---|---|---|---|---|---|---|
| HDInsight 3,6 без ESP | Да | Да | Да | Да* | нет | нет | нет |
| HDInsight 4,0 без ESP | Да | Да | Да | Да* | нет | нет | нет |
| HDInsight 3,6 с ESP | Да | Да | Да | Да* | нет | нет | нет |
| HDInsight 4,0 с ESP | Да | Да | Да | Да* | нет | нет | нет |

\* Кластеры HBase можно настроить только для масштабирования на основе расписания, но не для загрузки.

## <a name="get-started"></a>Начало работы

### <a name="create-a-cluster-with-load-based-autoscaling"></a>Создание кластера с автомасштабированием на основе нагрузки

Чтобы включить функцию автомасштабирования с масштабированием на основе нагрузки, выполните следующие действия в рамках обычного процесса создания кластера:

1. На вкладке **Настройка и цены** установите флажок **включить Автомасштабирование** .
1. Выберите **на основе нагрузки** **тип автомасштабирования**.
1. Введите предполагаемые значения для следующих свойств:  

    * Начальное **число узлов** для **рабочего узла**.
    * **Минимальное** число рабочих узлов.
    * **Максимальное** число рабочих узлов.

    ![Включить автомасштабирование на основе загрузки рабочих узлов](./media/hdinsight-autoscale-clusters/azure-portal-cluster-configuration-pricing-autoscale.png)

Начальное количество рабочих узлов должно быть в диапазоне между максимальным и минимальным количеством. Это значение определяет начальный размер кластера при его создании. Минимальное число рабочих узлов должно быть равно трем или более. Масштабирование кластера до трех узлов может привести к зависанию в защищенном режиме из-за недостаточной репликации файлов.  Дополнительные сведения см. [в разделе зависнуть в защищенном режиме](./hdinsight-scaling-best-practices.md#getting-stuck-in-safe-mode).

### <a name="create-a-cluster-with-schedule-based-autoscaling"></a>Создание кластера с автомасштабированием на основе расписания

Чтобы включить функцию автомасштабирования с масштабированием на основе расписания, выполните следующие действия в рамках обычного процесса создания кластера:

1. На вкладке **Настройка и цены** установите флажок **включить Автомасштабирование** .
1. Введите **количество узлов** для **рабочего узла**, которое управляет пределом масштабирования кластера.
1. Выберите параметр **Расписание — на основе** **типа автомасштабирования**.
1. Выберите **настроить** , чтобы открыть окно **Конфигурация автомасштабирования** .
1. Выберите часовой пояс и нажмите кнопку **+ Добавить условие** .
1. Выберите дни недели, к которым должно применяться новое условие.
1. Измените время, когда условие должно вступить в силу, и число узлов, до которого будет масштабироваться кластер.
1. При необходимости добавьте дополнительные условия.

    ![Включить создание на основе расписания рабочих узлов](./media/hdinsight-autoscale-clusters/hdinsight-autoscale-clusters-schedule-creation.png)

Число узлов должно быть в диапазоне от 3 до максимального количества рабочих узлов, введенных перед добавлением условий.

### <a name="final-creation-steps"></a>Заключительные шаги создания

Выберите тип виртуальной машины для рабочих узлов, выбрав виртуальную машину из раскрывающегося списка в разделе **размер узла**. После выбора типа виртуальной машины для каждого типа узла можно просмотреть диапазон оценочных затрат для всего кластера. Настройте типы виртуальных машин в соответствии с бюджетом.

![Включить размер узла автомасштабирования на основе расписания рабочего узла](./media/hdinsight-autoscale-clusters/azure-portal-cluster-configuration-pricing-vmsize.png)

Ваша подписка имеет квоту емкости для каждого региона. Общее число ядер головных узлов и максимальное количество рабочих узлов не может превышать квоту емкости. Тем не менее эта квота — нестрогое ограничение. Вы всегда можете создать запрос в службу поддержки, чтобы легко ее повысить.

> [!Note]  
> Если превышено ограничение общей квоты ядра, вы получите сообщение об ошибке: "максимальный узел превышает доступные ядра в этом регионе. Выберите другой регион или обратитесь в службу поддержки, чтобы увеличить квоту."

Дополнительные сведения о создании кластера HDInsight с помощью портала Azure см. в статье [Создание кластеров под управлением Linux в HDInsight с помощью портала Azure](hdinsight-hadoop-create-linux-clusters-portal.md).  

### <a name="create-a-cluster-with-a-resource-manager-template"></a>Создание кластера с помощью шаблона Resource Manager

#### <a name="load-based-autoscaling"></a>Автомасштабирование на основе загрузки

Вы можете создать кластер HDInsight с автомасштабированием на основе нагрузки с помощью шаблона Azure Resource Manager, добавив `autoscale` узел в `computeProfile`  >  `workernode` раздел со свойствами `minInstanceCount` и `maxInstanceCount` как показано в следующем фрагменте кода JSON. Полный шаблон Resource Manager см. в разделе шаблон быстрого запуска [: развертывание кластера Spark с включенным автомасштабированием лоадбасед](https://github.com/Azure/azure-quickstart-templates/tree/master/101-hdinsight-autoscale-loadbased).

```json
{
  "name": "workernode",
  "targetInstanceCount": 4,
  "autoscale": {
      "capacity": {
          "minInstanceCount": 3,
          "maxInstanceCount": 10
      }
  },
  "hardwareProfile": {
      "vmSize": "Standard_D13_V2"
  },
  "osProfile": {
      "linuxOperatingSystemProfile": {
          "username": "[parameters('sshUserName')]",
          "password": "[parameters('sshPassword')]"
      }
  },
  "virtualNetworkProfile": null,
  "scriptActions": []
}
```

#### <a name="schedule-based-autoscaling"></a>Автомасштабирование на основе расписания

Вы можете создать кластер HDInsight с автомасштабированием на основе расписания, используя шаблон Azure Resource Manager, добавив `autoscale` узел в `computeProfile`  >  `workernode` раздел. `autoscale`Узел содержит объект с `recurrence` `timezone` и `schedule` , описывающий, когда будет выполнено изменение. Полный шаблон Resource Manager см. в разделе [развертывание кластера Spark с включенным автомасштабированием на основе расписания](https://github.com/Azure/azure-quickstart-templates/tree/master/101-hdinsight-autoscale-schedulebased).

```json
{
  "autoscale": {
    "recurrence": {
      "timeZone": "Pacific Standard Time",
      "schedule": [
        {
          "days": [
            "Monday",
            "Tuesday",
            "Wednesday",
            "Thursday",
            "Friday"
          ],
          "timeAndCapacity": {
            "time": "11:00",
            "minInstanceCount": 10,
            "maxInstanceCount": 10
          }
        }
      ]
    }
  },
  "name": "workernode",
  "targetInstanceCount": 4
}
```

### <a name="enable-and-disable-autoscale-for-a-running-cluster"></a>Включение и отключение автомасштабирования для работающего кластера

#### <a name="using-the-azure-portal"></a>Использование портала Azure

Чтобы включить Автомасштабирование в работающем кластере, выберите **Размер кластера** в разделе " **Параметры**". Затем выберите **включить Автомасштабирование**. Выберите нужный тип автомасштабирования и введите параметры масштабирования на основе нагрузки или по расписанию. Наконец, щелкните **Сохранить**.

![Включение автомасштабирования на основе расписания рабочих узлов в кластере](./media/hdinsight-autoscale-clusters/azure-portal-settings-autoscale.png)

#### <a name="using-the-rest-api"></a>Использование REST API

Чтобы включить или отключить Автомасштабирование в работающем кластере с помощью REST API, выполните запрос POST к конечной точке автомасштабирования:

```
https://management.azure.com/subscriptions/{subscription Id}/resourceGroups/{resourceGroup Name}/providers/Microsoft.HDInsight/clusters/{CLUSTERNAME}/roles/workernode/autoscale?api-version=2018-06-01-preview
```

Используйте соответствующие параметры в полезных данных запроса. Полезные данные JSON, приведенные ниже, можно использовать для включения автомасштабирования. Используйте полезные данные `{autoscale: null}` для отключения автомасштабирования.

```json
{ "autoscale": { "capacity": { "minInstanceCount": 3, "maxInstanceCount": 5 } } }
```

Полное описание всех параметров полезных данных см. в предыдущем разделе о [включении автомасштабирования на основе загрузки](#load-based-autoscaling) .

## <a name="monitoring-autoscale-activities"></a>Мониторинг действий автомасштабирования

### <a name="cluster-status"></a>Состояние кластера

Состояние кластера, указанное в портал Azure, может помочь в мониторинге действий автомасштабирования.

![Включить состояние кластера автомасштабирования на основе рабочей нагрузки для рабочих узлов](./media/hdinsight-autoscale-clusters/hdinsight-autoscale-clusters-cluster-status.png)

Все сообщения о состоянии кластера, которые вы можете увидеть, описаны в списке ниже.

| Состояние кластера | Описание |
|---|---|
| Запущен | Кластер работает нормально. Все предыдущие действия автомасштабирования успешно завершены. |
| Обновление  | Выполняется обновление конфигурации автомасштабирования кластера.  |
| Конфигурация HDInsight  | Выполняется операция увеличения или уменьшения масштаба кластера.  |
| Ошибка обновления  | При обновлении конфигурации автомасштабирования в HDInsight возникли проблемы. Клиенты могут либо повторить обновление, либо отключить Автомасштабирование.  |
| Ошибка  | В кластере что-то не так, и его использование невозможно. Удалите этот кластер и создайте новый.  |

Чтобы просмотреть текущее число узлов в кластере, перейдите на диаграмму **Размер кластера** на странице **Обзор** кластера. Или выберите **Размер кластера** в разделе " **Параметры**".

### <a name="operation-history"></a>Журнал операций

Вы можете просматривать журнал масштабирования и масштабирования кластера в составе метрик кластера. Можно также перечислить все действия масштабирования за последний день, неделю или другой период времени.

Выберите **метрики** в разделе **мониторинг**. Затем в раскрывающемся списке **Метрика** выберите **Добавить метрику** и **число активных рабочих ролей** . Нажмите кнопку в правом верхнем углу, чтобы изменить диапазон времени.

![Включить метрику автомасштабирования на основе расписания рабочих узлов](./media/hdinsight-autoscale-clusters/hdinsight-autoscale-clusters-chart-metric.png)

## <a name="best-practices"></a>Рекомендации

### <a name="consider-the-latency-of-scale-up-and-scale-down-operations"></a>Учитывайте задержку масштабирования и уменьшения масштаба операций.

Выполнение операции масштабирования может занять от 10 до 20 минут. При настройке настроенного расписания запланируйте эту задержку. Например, если требуется, чтобы размер кластера был 20 в 9:00 AM, задайте для триггера расписания более раннее время, например 8:30 AM, чтобы операция масштабирования была выполнена 9:00.

### <a name="prepare-for-scaling-down"></a>Подготовка к уменьшению масштаба

В процессе масштабирования кластера Автомасштабирование выведет из эксплуатации узлы в соответствии с целевым размером. Если на этих узлах выполняются задачи, автомасштабирование ожидает завершения задач. Так как каждый рабочий узел также обслуживает роль в HDFS, временные данные сдвигаются к оставшимся узлам. Убедитесь, что на оставшихся узлах достаточно места для размещения всех временных данных.

Выполняемые задания будут продолжены. Ожидающие задания ожидают планирования с меньшим числом доступных рабочих узлов.

### <a name="be-aware-of-the-minimum-cluster-size"></a>Учитывайте минимальный размер кластера

Не уменьшайте размер кластера до трех узлов. Масштабирование кластера до трех узлов может привести к зависанию в защищенном режиме из-за недостаточной репликации файлов. Дополнительные сведения см. [в разделе зависнуть в защищенном режиме](hdinsight-scaling-best-practices.md#getting-stuck-in-safe-mode).

### <a name="increase-the-number-of-mappers-and-reducers"></a>Увеличение числа модулей сопоставления и модулей сжатия

Автомасштабирование для кластеров Hadoop также отслеживает использование HDFS. Если HDFS занят, предполагается, что кластеру все еще требуются текущие ресурсы. При наличии в запросе огромных данных можно увеличить число модулей сопоставления и модулей сжатия, чтобы увеличить параллелизм и ускорить операции HDFS. Таким образом, при наличии дополнительных ресурсов будет запущено правильное масштабирование. 

### <a name="set-the-hive-configuration-maximum-total-concurrent-queries-for-the-peak-usage-scenario"></a>Задание максимального количества одновременных запросов для конфигурации Hive для сценария пикового использования

События автомасштабирования не изменяют *Максимальное число одновременных запросов* в конфигурации Hive в Ambari. Это означает, что интерактивная служба Hive Server 2 может обслуживать только заданное количество параллельных запросов в любой момент времени, даже если счетчик управляющих программ LLAP масштабируется вверх и вниз в зависимости от нагрузки и расписания. Общая рекомендация заключается в том, чтобы задать эту конфигурацию для сценария пикового использования, чтобы избежать ручного вмешательства.

Однако может возникнуть сбой перезапуска Hive Server 2, если имеется только небольшое количество рабочих узлов, а значение максимального количества одновременных запросов слишком велико. Как минимум требуется минимальное количество рабочих узлов, которые могут удовлетворять заданному количеству Tez AMS (равной конфигурации максимального количества одновременных запросов). 

## <a name="limitations"></a>Ограничения

### <a name="node-label-file-missing"></a>Отсутствует файл меток узла

Автомасштабирование HDInsight использует файл меток узла, чтобы определить, готов ли узел к выполнению задач. Файл меток узла хранится в HDFS с тремя репликами. Если размер кластера значительно масштабируется и имеется большой объем временных данных, существует небольшая вероятность того, что все три реплики могут быть удалены. В таком случае кластер переходит в состояние ошибки.

### <a name="llap-daemons-count"></a>Число управляющих LLAP

В случае кластеров LLAP с поддержкой аутоскае событие автомасштабирования увеличивается и уменьшает число управляющих программ с числом активных рабочих узлов. Изменение количества управляющих программ не сохраняется в `num_llap_nodes` конфигурации в Ambari. Если службы Hive перезапускаются вручную, число управляющих LLAP сбрасывается в соответствии с конфигурацией в Ambari.

Если служба LLAP перезапущена вручную, необходимо вручную изменить `num_llap_node` конфигурацию (число узлов, необходимое для запуска управляющей программы Hive LLAP) в разделе *Advanced Hive-Interactive-env* в соответствии с текущим числом активных рабочих узлов.

## <a name="next-steps"></a>Дальнейшие шаги

Ознакомьтесь с рекомендациями по масштабированию кластеров вручную в [руководстве по масштабированию](hdinsight-scaling-best-practices.md) .
