---
title: Автоматическое масштабирование кластеров Azure HDInsight (Предварительная версия)
description: Автоматическое масштабирование кластеров с помощью функции автомасштабирования HDInsight
author: hrasheed-msft
ms.reviewer: jasonh
ms.service: hdinsight
ms.custom: hdinsightactive
ms.topic: conceptual
ms.date: 04/11/2019
ms.author: hrasheed
ms.openlocfilehash: 11828b3b056519d0ebe3233f078c6b3f6fc2ea1c
ms.sourcegitcommit: bf509e05e4b1dc5553b4483dfcc2221055fa80f2
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/22/2019
ms.locfileid: "59997501"
---
# <a name="automatically-scale-azure-hdinsight-clusters-preview"></a>Автоматическое масштабирование кластеров Azure HDInsight (Предварительная версия)

>[!Important]
>Функция автомасштабирования HDInsight доступна в предварительной версии. Отправьте сообщение по адресу hdiautoscalepm@microsoft.com для автоматического масштабирования включена для вашей подписки.

Функция автомасштабирования кластера Azure HDInsight на основе загрузки автоматически масштабирует количество рабочих узлов в кластере в рамках предварительно заданного диапазона. Во время создания кластера HDInsight можно задать минимальное и максимальное количество рабочих узлов. Затем автомасштабирование отслеживает требования по загрузке аналитики ресурса и масштабирует количество рабочих узлов соответствующим образом. За использование этой функции не взимается дополнительная плата.

## <a name="getting-started"></a>Приступая к работе

### <a name="create-a-cluster-with-the-azure-portal"></a>Создание кластера с помощью портала Azure

> [!Note]
> Автомасштабирование в настоящее время поддерживается только для кластеров Azure HDInsight Hive, MapReduce и Spark версии 3.6.

Чтобы включить функцию автоматического масштабирования, выполните следующие действия в рамках обычного при создании кластера.

1. Выберите **Настраиваемое (размер, параметры, приложения)** вместо **Быстрое создание**.
2. На шаге 5 **Настраиваемое** (**Размер кластера**) установите флажок **Worker node autoscale** (Автомасштабирование рабочего узла).
3. Введите нужные значения для следующих свойств:  

    * начального **количества рабочих узлов**;  
    * **минимального** количества рабочих узлов;  
    * **максимального** количества рабочих узлов.  

![Включение параметра автоматического масштабирования рабочего узла](./media/hdinsight-autoscale-clusters/usingAutoscale.png)

Начальное количество рабочих узлов должно быть в диапазоне между максимальным и минимальным количеством. Это значение определяет начальный размер кластера при его создании. Минимальное количество рабочих узлов должно быть больше нуля.

После выбора типа виртуальной машины для каждого типа узла вы сможете увидеть предполагаемый диапазон затрат для всего кластера. Затем можно скорректировать эти параметры в соответствии с любым бюджетом.

Ваша подписка имеет квоту емкости для каждого региона. Общее число ядер на головных узлах в сочетании с максимальным числом рабочих узлов не может превышать квоту емкости. Тем не менее эта квота — нестрогое ограничение. Вы всегда можете создать запрос в службу поддержки, чтобы легко ее повысить.

> [!Note]  
> Если вы превысите общую квоту на ядра, вы получите сообщение о том, что максимальное число узлов превышает количество доступных ядер в регионе и нужно выбрать другой регион или обратиться в службу поддержки, чтобы увеличить квоту.

Дополнительные сведения о создании кластера HDInsight с помощью портала Azure см. в статье [Создание кластеров под управлением Linux в HDInsight с помощью портала Azure](hdinsight-hadoop-create-linux-clusters-portal.md).  

### <a name="create-a-cluster-with-a-resource-manager-template"></a>Создание кластера с помощью шаблона Resource Manager

Чтобы создать кластер HDInsight с помощью шаблона Azure Resource Manager, добавьте узел `autoscale` в раздел `computeProfile` > `workernode` со свойствами `minInstanceCount` и `maxInstanceCount`, как показано в указанном ниже фрагменте кода JSON.

```json
{                            
    "name": "workernode",
    "targetInstanceCount": 4,
    "autoscale": {
        "capacity": {
            "minInstanceCount": 2,
            "maxInstanceCount": 10
        }        
    },
    "hardwareProfile": {
        "vmSize": "Standard_D13_V2"
    },
    "osProfile": {
        "linuxOperatingSystemProfile": {
            "username": "[parameters('sshUserName')]",
            "password": "[parameters('sshPassword')]"
        }
    },
    "virtualNetworkProfile": null,
    "scriptActions": []
}
```

Дополнительные сведения о создании кластеров с помощью шаблонов Resource Manager см. в статье [Создание кластеров Apache Hadoop в HDInsight с помощью шаблонов Resource Manager](hdinsight-hadoop-create-linux-clusters-arm-templates.md).  

### <a name="enable-and-disable-autoscale-for-a-running-cluster"></a>Включение и отключение автомасштабирования для работающего кластера

Кроме того, можно только включить или отключить автоматическое масштабирование для новых кластеров HDInsight.

## <a name="monitoring"></a>Мониторинг

Можно просматривать журнал увеличение и уменьшение масштаба кластера как часть метрик кластера. а также вывести список всех действий масштабирования за последний день, неделю или более длительный период времени.

## <a name="how-it-works"></a>Принцип работы

### <a name="metrics-monitoring"></a>Мониторинг метрик

Автомасштабирование постоянно выполняет мониторинг кластера и собирает следующие метрики:

1. **Total Pending CPU** (Общее число ожидающих ЦП). Общее число ядер, необходимое для запуска выполнения всех ожидающих контейнеров.
2. **Total Pending Memory** (Общий объем ожидающей памяти). Общий объем памяти (в МБ), необходимый для запуска выполнения всех отложенных контейнеров.
3. **Total Free CPU** (Общее число свободных ЦП). Сумма всех неиспользуемых ядер на активных рабочих узлах.
4. **Total Free Memory** (Общий объем свободной памяти). Сумма неиспользуемой памяти (в МБ) на активных рабочих узлах.
5. **Used Memory per Node** (Объем используемой памяти на каждом узле). Нагрузка на рабочем узле. Рабочий узел, на котором используется 10 ГБ памяти, пребывает под большей нагрузкой, чем рабочий узел с 2 ГБ используемой памяти.
6. **Number of Application Masters per Node** (Количество основных контейнеров приложений на каждом узле). Число основных контейнеров приложений, работающих на рабочем узле. Рабочего узла, на котором размещается два контейнера AM, считается более важным, чем к рабочему узлу, на котором размещается ноль контейнеры по.

Эти метрики проверяются каждые 60 секунд. Автомасштабирования будет принять увеличение и уменьшение масштаба на основе этих метрик.

### <a name="cluster-scale-up"></a>Масштабирование кластера

При обнаружении следующих условий автомасштабирования будет выдавать запрос вертикального масштабирования:

* Общее число ожидающих ЦП больше, чем общее свободное время ЦП в течение более чем 3 минуты.
* Общее число ожидающих памяти больше, чем общего объема свободной памяти для более 3 минуты.

Мы вычислит, что определенное количество новых рабочих узлах требуется для текущих требований к ЦП и памяти, а затем выполнить запрос вертикального масштабирования, который добавляет соответствующее количество новых рабочих узлах.

### <a name="cluster-scale-down"></a>Уменьшение масштаба кластера

При обнаружении следующих условий автомасштабирования будет выдавать запрос уменьшения масштаба:

* Общее число ожидающих ЦП меньше, чем общее число свободных ЦП в течение более чем 10 минут.
* Общий объем ожидающей памяти меньше, чем общее количество свободной памяти в течение более чем 10 минут.

Исходя из числа контейнеров AM каждого узла и текущая загрузка ЦП и требования к памяти, автомасштабирования будет выдавать запрос на удаление определенное количество узлов, указав, какие узлы являются потенциальными кандидатами для удаления. Увеличение или уменьшение масштаба активирует вывода из эксплуатации рабочих узлов и после узлы находятся полностью выведенных из эксплуатации, они будут удалены.

## <a name="next-steps"></a>Дальнейшие действия

* Прочитайте рекомендации по масштабированию кластеров вручную [здесь](hdinsight-scaling-best-practices.md).
