---
title: 'Настройка производительности: Spark, HDInsight & Azure Data Lake Storage 2-го поколения | Документация Майкрософт'
description: Рекомендации по настройке производительности для Spark в Azure Data Lake Storage 2-го поколения
services: storage
author: normesta
ms.subservice: data-lake-storage-gen2
ms.service: storage
ms.topic: how-to
ms.date: 11/18/2019
ms.author: normesta
ms.reviewer: stewu
ms.openlocfilehash: 06fe2670e5ee0d95df8985c9777d3ad9741336b3
ms.sourcegitcommit: d7008edadc9993df960817ad4c5521efa69ffa9f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/08/2020
ms.locfileid: "86106124"
---
# <a name="tune-performance-spark-hdinsight--azure-data-lake-storage-gen2"></a>Настройка производительности: Spark, HDInsight & Azure Data Lake Storage 2-го поколения

При настройке производительности для Spark необходимо учитывать количество приложений, которые будут выполняться в кластере.  По умолчанию в кластере HDI можно одновременно выполнять 4 приложения (настройку по умолчанию можно изменить).  Вам может понадобиться использовать меньшее количество приложений. В таком случае можно переопределить параметры по умолчанию и использовать больше ресурсов кластера для этих приложений.  

## <a name="prerequisites"></a>Предварительные требования

* **Подписка Azure**. См. страницу [бесплатной пробной версии Azure](https://azure.microsoft.com/pricing/free-trial/).
* **Учетная запись Azure Data Lake Storage 2-го поколения**. Инструкции по ее созданию см. в разделе Краткое руководство. [Создание учетной записи хранения Azure Data Lake Storage 2-го поколения](data-lake-storage-quickstart-create-account.md).
* **Кластер Azure HDInsight** с доступом к учетной записи Data Lake Storage 2-го поколения. См. раздел [Use Azure Data Lake Storage Gen2 with Azure HDInsight clusters](https://docs.microsoft.com/azure/hdinsight/hdinsight-hadoop-use-data-lake-storage-gen2) (Использование хранилища Azure Data Lake поколения 2 с кластерами Azure HDInsight). Убедитесь, что вы включили удаленный рабочий стол для кластера.
* **Работающий кластер Spark в Data Lake Storage 2-го поколения.**  Дополнительные сведения см. в статье [Использование кластера HDInsight Spark для анализа данных в Data Lake Storage 2-го поколения](https://docs.microsoft.com/azure/hdinsight/hdinsight-apache-spark-use-with-data-lake-store).
* **Рекомендации по настройке производительности для Data Lake Storage 2-го поколения**.  Общие вопросы, связанные с производительностью, см. в [рекомендациях по настройке производительности Data Lake Storage 2-го поколения](data-lake-storage-performance-tuning-guidance.md) 

## <a name="parameters"></a>Параметры

Ниже приведены самые важные параметры, которые можно настроить для повышения производительности в Data Lake Storage 2-го поколения при выполнении заданий Spark.

* **num-executors** — количество параллельных задач, которые можно выполнить.

* **executor-memory** — объем памяти, выделенной для каждого исполнителя.

* **executor-cores** — количество ядер, выделенных для каждого исполнителя.                     

**num-executors**.Этот параметр позволяет задать максимальное число задач, которые могут выполняться параллельно.  Фактическое число задач, которые могут выполняться параллельно, ограничено ресурсами памяти и ЦП, доступными в кластере.

**executor-memory** — это объем памяти, выделенной для каждого исполнителя.  Объем памяти, необходимый для каждого исполнителя, зависит от задания.  При выполнении сложных операций требования к памяти возрастают.  Для более простых операций, таких как чтение и запись, требования к памяти ниже.  Объем памяти, необходимый для каждого исполнителя, можно просмотреть в Ambari.  В Ambari перейдите к Spark и откройте вкладку конфигураций.  

**Executor-cores**. Этот параметр задает количество ядер, используемых для каждого исполнителя, что определяет число параллельных потоков, выполняемых на исполнителя.  Например, если задать executor-cores = 2, тогда каждый исполнитель может выполнять 2 параллельные задачи.  Необходимое количество ядер исполнителя зависит от задания.  Задания, включающие большое количество операций ввода-вывода, не требуют большого объема памяти на задачу, так что каждый исполнитель может обрабатывать большее количество параллельных задач.

При выполнении Spark в HDInsight для каждого физического ядра по умолчанию определяются два виртуальных ядра YARN.  Такое количество обеспечивает хороший баланс параллелизма и объема контекста, переключающегося между несколькими потоками.  

## <a name="guidance"></a>Руководство

Во время выполнения аналитических рабочих нагрузок Spark для работы с данными в Data Lake Storage 2-го поколения рекомендуется использовать последнюю версию HDInsight для обеспечения высокой производительности Data Lake Storage 2-го поколения. Если во время вашего задания выполняется большое количество операций ввода-вывода, можно настроить некоторые параметры для повышения производительности.  Data Lake Storage 2-го поколения — это высоко масштабируемая платформа хранилища, способная справиться с высокой пропускной способностью.  Если задание состоит преимущественно из операций чтения или записи, повысить производительность можно, увеличив значение параметра параллелизма для операций ввода-вывода в Data Lake Storage 2-го поколения и из него.

Есть несколько основных способов повышения параллелизма для заданий с большим количеством операций ввода-вывода.

**Шаг 1. Определение количества приложений, выполняющихся в кластере.** Необходимо знать количество выполняющихся в кластере приложений, включая текущее.  Значения по умолчанию для каждого параметра Spark подразумевают, что параллельно выполняются 4 приложения.  Таким образом на каждое приложение доступно всего 25 % ресурсов кластера.  Чтобы получить более высокую производительность, можно переопределить значения по умолчанию, изменив число исполнителей.  

**Шаг 2. Задание памяти исполнителя** — первое, что нужно задать — это исполнительная память.  Требуемый объем памяти зависит от задания, которое необходимо выполнить.  Значение параметра параллелизма можно увеличить, выделив меньший объем памяти на каждый исполнитель.  Если во время выполнения задания возникают исключения памяти, можно повысить значение для этого параметра.  Альтернативой будет обеспечить больший объем памяти, используя кластер с большим объемом памяти или увеличивая размер кластера.  Больший объем памяти позволит использовать дополнительные исполнители, обеспечивая возможность параллельной обработки.

**Шаг 3. Настройка ядер исполнителя.** Для рабочих нагрузок с большим количеством операций ввода-вывода, которые не включают сложные операции, рекомендуется настроить большее количество ядер исполнителя, чтобы увеличить число параллельно выполняемых задач на каждый исполнитель.  Оптимальный вариант — 4 ядра исполнителя.   

Исполнители — ядра = 4

Увеличение количества ядер исполнителя обеспечит больший параллелизм, так что можно поэкспериментировать с разным количеством ядер.  Для заданий, которые включают более сложные операции, количество ядер на исполнитель необходимо уменьшить.  Если количество ядер исполнителя превышает 4, тогда сборка мусора может оказаться неэффективной и производительность снизится.

**Шаг 4. Определение объема памяти YARN в кластере.** Информация об этом доступна в Ambari.  Перейдите по адресу YARN и просмотрите вкладку configs (конфигурации).  В этом окне отображается память YARN.  
Примечание. В этом окне можно увидеть размер контейнера YARN по умолчанию.  Размер контейнера YARN совпадает со значением параметра объема памяти на исполнителя.

Общий объем памяти YARN = узлы * YARN память на узел

**Шаг 5. Вычисление параметра num-executors**

**Вычисление ограничения памяти.** Параметр num-executors ограничен памятью или ЦП.  Ограничение памяти определяется объемом доступной памяти YARN для вашего приложения.  Разделите общий объем памяти YARN на значение executor-memory.  Ограничение необходимо рассчитать для каждого приложения, так что мы разделим полученное значение на количество приложений.

Ограничение памяти = (всего YARN памяти/исполнителя памяти)/число приложений

**Вычисление ограничения ЦП.** Ограничение ЦП можно рассчитать, разделив общее количество виртуальных ядер на количество ядер на исполнителя.  Для каждого физического ядра существует 2 виртуальных ядра.  Как и в случае с ограничением памяти, необходимо делить на количество приложений.

- виртуальные ядра = (узлы в кластере * количество физических ядер в узле * 2)
- Ограничение ЦП = (всего виртуальных ядер/количество ядер на исполнителя)/число приложений

**Настройка параметра num-executors.** Параметр num-executors определяется минимальным значением ограничения памяти и ограничением ЦП. 

число исполнителей = min (всего виртуальных ядер/количество ядер на исполнителя, доступно YARN памяти/исполнителя — память)

Увеличение количества исполнителей не обязательно влияет на повышение производительности.  Следует учитывать, что добавление дополнительных исполнителей ведет к соответствующему увеличению нагрузки для каждого дополнительного исполнителя, что может снизить производительность.  Параметр num-executors ограничен ресурсами кластера.    

## <a name="example-calculation"></a>Пример вычисления

Предположим, у вас есть кластер из 8 узлов D4v2, на котором выполняется 2 приложения, включая приложение, которое вы собираетесь выполнить.  

**Шаг 1. Определите, сколько приложений выполняется в кластере.** Вы знаете, что в кластере выполняется 2 приложения, включая приложение, которое вы собираетесь выполнить.  

**Шаг 2. Задайте параметр executor-memory.** Для данного примера мы определяем, что 6 ГБ памяти на исполнитель будет достаточно для выполнения задания с большим количеством операций ввода-вывода.  

исполнитель — память = 6 ГБ

**Шаг 3. Задайте параметр executor-cores.** Так как это задание с большим количеством операций ввода-вывода, для каждого исполнителя можно задать 4 ядра.  Если задать большее количество ядер на исполнитель, это может вызвать проблемы со сборкой мусора.  

Исполнители — ядра = 4

**Шаг 4. Определите объем памяти YARN в кластере.** Перейдите в Ambari, чтобы узнать, что каждый узел D4v2 имеет 25 ГБ памяти YARN.  Так как в кластере 8 узлов, объем доступной памяти YARN увеличивается в 8 раз.

- Общий объем памяти YARN = узлы * YARN память * на узел
- Общий объем памяти YARN = 8 узлов * 25 ГБ = 200 ГБ

**Шаг 5. Настройте параметр num-executors.** Параметр num-executors определяется общим минимальным значением ограничения памяти и ограничением ЦП, разделенными на количество приложений, выполняемых в Spark.    

**Рассчитайте ограничение памяти.** Ограничение памяти рассчитывается как общий объем памяти YARN, разделенный на объем памяти на исполнитель.

- Ограничение памяти = (всего YARN памяти/исполнителя памяти)/число приложений
- Ограничение памяти = (200 ГБ/6 ГБ)/2
- Ограничение памяти = 16 (округленное)

**Рассчитайте ограничение ЦП.** Ограничение ЦП можно рассчитать, разделив общее количество ядер YARN на количество ядер на исполнителя.

- Ядра YARN = количество узлов в кластере * число ядер на узел * 2
- Ядра YARN = 8 узлов * 8 ядер на D14 * 2 = 128
- Ограничение ЦП = (всего ядер YARN/число ядер на исполнителя)/число приложений
- Ограничение ЦП = (128/4)/2
- Ограничение ЦП = 16

**Настройте параметр num-executors.**

- Num-исполнителя = min (ограничение памяти, ограничение ЦП)
- число исполнителей = min (16, 16)
- число исполнителей = 16

