---
title: Рекомендации по использованию Azure Data Lake Storage 2-го поколения | Документация Майкрософт
description: Ознакомьтесь с рекомендациями по приему и безопасности данных, а также по производительности, связанные с использованием Azure Data Lake Storage 2-го поколения (прежнее название — Azure Data Lake Store).
services: storage
author: normesta
ms.subservice: data-lake-storage-gen2
ms.service: storage
ms.topic: article
ms.date: 12/06/2018
ms.author: normesta
ms.reviewer: sachins
ms.openlocfilehash: 8b39866b990812913924118c564a5e93f898b1cb
ms.sourcegitcommit: c53a800d6c2e5baad800c1247dce94bdbf2ad324
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/30/2019
ms.locfileid: "64939468"
---
# <a name="best-practices-for-using-azure-data-lake-storage-gen2"></a>Рекомендации по использованию Azure Data Lake Storage 2-го поколения

Из этой статьи вы узнаете о лучших методиках и рекомендациях по использованию Azure Data Lake Storage 2-го поколения. В этой статье приводятся сведения о безопасности, производительности, отказоустойчивости и мониторинге для Data Lake Storage 2-го поколения. До появления Data Lake Storage 2-го поколения работа с большими данными в таких службах, как Azure HDInsight, представляла значительные сложности. Нужно было сегментировать данные в нескольких учетных записях хранения больших двоичных объектов, чтобы обеспечить хранение петабайтовых файлов и оптимальную производительность в этом масштабе. С появлением Data Lake Storage 2-го поколения большинство жестких ограничений размера и производительности исчезли. В этой статье рассматриваются некоторые рекомендации по обеспечению высокой производительности при работе с Data Lake Storage 2-го поколения.

## <a name="security-considerations"></a>Вопросы безопасности

Azure Data Lake Storage 2-го поколения предлагает элементы управления доступом POSIX для пользователей, групп и субъектов-служб Azure Active Directory (AAD). Эти элементы управления доступом можно настроить для имеющихся файлов и каталогов. Их также можно использовать для создания разрешений по умолчанию, чтобы применять их к новым файлам или каталогам. См. дополнительные сведения о [списках управления доступом для Data Lake Storage 2-го поколения](storage-data-lake-storage-access-control.md).

### <a name="use-security-groups-versus-individual-users"></a>Сравнение использования групп безопасности и отдельных пользователей

При работе с большими данными в Data Lake Storage 2-го поколения субъект-служба часто используется для предоставления службам, таким как Azure HDInsight, разрешений для работы с данными. Однако встречаются случаи, когда доступ к данным также необходимо предоставить отдельным пользователям. В любом случае старайтесь использовать [группы безопасности](../common/storage-auth-aad.md) Azure Active Directory вместо того, чтобы назначать отдельным пользователям права для каталогов и файлов.

Когда группе безопасности назначены разрешения, для добавления или удаления пользователей в группе не требуются какие-либо изменения в параметрах Data Lake Storage 2-го поколения. Это также поможет не превысить максимальное число записей управления доступом для списка управления доступом (ACL). Сейчас действует ограничение в 32 записи (включая четыре ACL типа POSIX, которые всегда связаны c каждым файлом и каталогом): владелец, группа владельцев, маска и прочие. Каждый каталог может содержать ACL двух типов: ACL для доступа и ACL по умолчанию, что дает вам в общей сложности 64 записи управления доступом. Дополнительные сведения о списках управления доступом в Azure Data Lake Storage 2-го поколения см. в [этой статье](data-lake-storage-access-control.md).

### <a name="security-for-groups"></a>Безопасность для групп

Если вам или вашим пользователям требуется доступ к данным в учетной записи хранения, для которой включено иерархическое пространство имен, лучше всего использовать группы безопасности Azure Active Directory. Некоторые из рекомендуемых группы со может быть **ReadOnlyUsers**, **WriteAccessUsers**, и **FullAccessUsers** для корня файловой системы и даже отдельные шаблоны для ключа подкаталоги. Если есть другие ожидаемые группы пользователей, которые нужно будет добавить позже, но они еще не определены, можно рассмотреть создание пустых групп безопасности с доступом к определенным папкам. Использование группы безопасности позволит позднее обойтись без длительной обработки при назначении новых разрешений тысячам файлов.

### <a name="security-for-service-principals"></a>Безопасность для субъектов-служб

Субъекты-службы Azure Active Directory обычно используются такими службами, как Azure Databricks, для доступа к данным в Data Lake Storage 2-го поколения. Для многих пользователей одного субъекта-службы Azure Active Directory может быть достаточно, и может иметь полные права в корне файловой системы Gen2 хранилища Озера данных. Другим клиентам может потребоваться несколько кластеров с разными субъектами-службами, где у одного кластера будет полный доступ к данным, а у другого — только доступ на чтение. 

### <a name="enable-the-data-lake-storage-gen2-firewall-with-azure-service-access"></a>Включение брандмауэра для Data Lake Storage 2-го поколения с доступом к службе Azure

Data Lake Storage 2-го поколения позволяет включить брандмауэр и ограничить доступ только службами Azure, что очень полезно для сужения вектора внешних атак. Брандмауэр можно включить для учетной записи на портале Azure, выбрав **Брандмауэр** > **Включить брандмауэр** > **Разрешить доступ к службам Azure**.

Чтобы добавить кластеры Azure Databricks в виртуальную сеть, доступ к которой будет разрешен через брандмауэр хранилища, потребуется использовать предварительную версию функции Databricks. Чтобы включить эту функцию, направьте запрос в службу поддержки.

## <a name="resiliency-considerations"></a>Рекомендации по обеспечению устойчивости

При разработке системы с применением Data Lake Storage 2-го поколения или любой облачной службы следует оценить требования к доступности и способы реагирования на возможные перерывы в обслуживании. Проблему можно локализовать на уровне конкретного экземпляра или даже всего региона, поэтому важно учесть все в комплексе. В зависимости от соглашений об уровне обслуживания в отношении целевого времени восстановления и целевой точки восстановления для вашей рабочей нагрузки вы можете выбрать более или менее агрессивную стратегию для обеспечения высокого уровня доступности и аварийного восстановления.

### <a name="high-availability-and-disaster-recovery"></a>Высокий уровень доступности и аварийное восстановление

Высокий уровень доступности (HA) и аварийное восстановление (DR) иногда можно сочетать, хотя связанные стратегии немного отличаются, особенно при работе с данными. Data Lake Storage 2-го поколения уже выполняет трехкратную репликацию в фоновом режиме для защиты от локальных сбоев оборудования. Вы можете добавить и другие механизмы. Например, ZRS повышает уровень доступности, а GRS и RA-GRS — скорость аварийного восстановления. Составляя план для обеспечения высокого уровня доступности, в случае прерывания работы службы нужно как можно быстрее предоставить для рабочей нагрузки доступ к последним данным, выполнив переключение на отдельно реплицированный экземпляр в локальной среде или новом регионе.

Чтобы подготовиться к маловероятному событию катастрофического отказа целого региона, в стратегию аварийного восстановления следует включить репликацию данных в другой регион с помощью GRS или RA-GRS. Также стоит оценить требования для таких пограничных случаев, как повреждение данных. Для них могут потребоваться периодические моментальные снимки, к которым можно будет вернуться в случае сбоя. В зависимости от важности и размера данных рассмотрите возможность развертывания разностных моментальных снимков с интервалом времени 1, 6 и 24 часа в соответствии с допусками риска.

Для обеспечения устойчивости данных в Azure Data Lake Storage 2-го поколения мы рекомендуем выполнять с помощью GRS или RA-GRS георепликацию данных в отдельный регион с частотой, которая соответствует вашим требованиям к высокой доступности и аварийному восстановлению. Обдумайте также, как организовать для приложения, которое использует Data Lake Storage 2-го поколения, автоматическую отработку отказа в дополнительный регион на основе триггеров мониторинга или длительности завершившихся сбоем попыток, или по меньшей мере отправку уведомлений администраторам для устранения неполадок вручную. Имейте в виду, что есть компромисс — выполнить отработку отказа, а не ждать, когда служба снова станет работоспособной.

### <a name="use-distcp-for-data-movement-between-two-locations"></a>Использование программы Distcp для перемещения данных между двумя расположениями

DistCp (сокращение от distributed copy — распределенное копирование) представляет собой программу командной строки Linux, которая входит в состав Hadoop и обеспечивает распределенное перемещение данных между двумя расположениями. Этими расположениями могут быть Data Lake Storage 2-го поколения, HDFS или S3. В программе используются задания MapReduce в кластере Hadoop (например, HDInsight) для масштабирования на всех узлах. Distcp считается самым быстрым способом перемещения больших данных без специальных устройств сетевого сжатия. Это средство также позволяет обновлять разностные данные между двумя расположениями, обрабатывать автоматические повторные попытки, а также применять динамическое масштабирование к вычислениям. Этот подход невероятно эффективен, когда, например, речь идет о реплицировании таблиц Hive и Spark, которые могут содержать много файлов больших размеров в одном каталоге, и вы хотите копировать только измененные данные. Именно поэтому Distcp является наиболее рекомендуемым инструментом для копирования данных между хранилищами больших данных.

Задания копирования могут запустить рабочие процессы Apache Oozie, использующие триггеры частоты или данных, а также задания Cron в Linux. Для интенсивных задач репликации рекомендуется развернуть отдельный кластер HDInsight Hadoop, который можно настроить и масштабировать специально для заданий копирования. Таким образом задания копирования и критические задания не будут влиять на работу друг друга. При выполнении репликации с достаточно широким интервалом кластер может прекращать работу между выполнением каждого задания. При выполнении отработки отказа в дополнительный регион в этом регионе нужно развернуть другой кластер для репликации новых данных обратно в основную учетную запись Data Lake Storage 2-го поколения, когда она возобновит свою работу. Примеры применения DistCp см. в руководстве по [использованию DistCp для копирования данных между BLOB-объектами хранилища Azure и Data Lake Storage 2-го поколения](../blobs/data-lake-storage-use-distcp.md).

### <a name="use-azure-data-factory-to-schedule-copy-jobs"></a>Использование фабрики данных Azure для планирования заданий копирования

Фабрику данных Azure можно также использовать для планирования заданий копирования с помощью действия копирования или даже настроить выполнение с определенной частотой через мастер копирования. Имейте в виду, что для фабрики данных Azure есть ограничение единиц перемещения облачных данных (DMU) и в конечном итоге ограничение пропускной способности или вычислительной мощности рабочих нагрузок с большими данными. Кроме того, Фабрика данных Azure сейчас не предлагает обновление разностных данных между учетными записями Data Lake Storage 2-го поколения, поэтому для таких каталогов, как таблицы Hive, требуется полная репликация. Дополнительные сведения о копировании с помощью Фабрики данных см. в статье [Загрузка данных в Azure Data Lake Storage Gen2 (предварительная версия) с помощью фабрики данных Azure](../../data-factory/load-azure-data-lake-storage-gen2.md).

## <a name="monitoring-considerations"></a>Рекомендации по мониторингу

Data Lake Storage 2-го поколения предоставляет метрики на портале Azure в учетной записи Data Lake Storage 2-го поколения, а также в Azure Monitor. Сведения о доступности Data Lake Storage 2-го поколения отображаются на портале Azure. Чтобы получить самое актуальное состояние доступности для учетной записи Data Lake Storage 2-го поколения, следует выполнить собственные искусственные тесты для проверки доступности. Также доступны и другие метрики, например общий занятый объем хранилища, запросы на чтение и запись, исходящий и входящий трафик. Они позволяют отслеживать приложения и активировать оповещения при превышении пороговых значений (например, среднего времени задержки или количества ошибок в минуту).

## <a name="directory-layout-considerations"></a>Рекомендации в отношении структуры каталога

При размещении данных в Data Lake важно заранее спланировать структуру данных, чтобы можно было эффективно использовать безопасность, секционирование и обработку. Многие из приведенных ниже рекомендаций применимы для всех рабочих нагрузок с большими данными. Каждая рабочая нагрузка включает разные требования к способу использования данных. Ниже приводятся некоторые общие шаблоны, которые следует учесть при работе с пакетными сценариями и Центром Интернета вещей.

### <a name="iot-structure"></a>Структура Центра Интернета вещей

В рабочих нагрузках Центра Интернета вещей большое количество данных может размещаться в хранилище данных, которое охватывает множество продуктов, устройств, организаций и клиентов. Важно заранее спланировать структуру каталога для организации, обеспечения безопасности и эффективной обработки данных для нисходящих потребителей. Ниже приведен общий шаблон, который стоит рассмотреть.

    {Region}/{SubjectMatter(s)}/{yyyy}/{mm}/{dd}/{hh}/

Например, каталог размещения телеметрии для авиационного двигателя в Великобритании может выглядеть так:

    UK/Planes/BA1293/Engine1/2017/08/11/12/

Есть важная причина размещать дату в конце структуры каталога. Если вы хотите заблокировать определенные регионы и типы данных для пользователей или групп, это можно легко сделать с помощью разрешений POSIX. В противном случае, если возникнет необходимость ограничить определенную группу безопасности (например, просмотр данных только по Великобритании или по определенным самолетам), размещение структуры даты в начале потребует создавать отдельное разрешение для каждого из множества вложенных каталогов в каталогах за каждый час. Кроме того, при наличии структуры даты в начале количество каталогов будет экспоненциально увеличиваться с течением времени.

### <a name="batch-jobs-structure"></a>Структура пакетных заданий

На высоком уровне широко используемым подходом в пакетной обработке является размещение данных во вложенном каталоге. Как только данные будут обработаны, поместите новые данные во внешний каталог для использования нисходящими процессами. Эта структура каталогов иногда наблюдается в случае заданий, требующих обработки отдельных файлов и не требующих массовой параллельной обработки больших наборов данных. Как и рекомендованная выше структура Центра Интернета вещей, оптимальная структура каталога использует каталоги родительского уровня для региона и предметной области (например, организации, продукта или производителя). Эта структура помогает обеспечить безопасность данных в организации и оптимизировать управление данными в рабочих нагрузках. Кроме того, рассмотрите дату и время в структуре, чтобы обеспечить лучшую организацию, отфильтрованные поисковые запросы, безопасность и автоматизацию в процессе обработки. Уровень детализации структуры даты определяется интервалом, с которым данные загружаются или обрабатываются, например ежечасно, ежедневно или даже ежемесячно.

Иногда обработка файлов завершается сбоем из-за повреждения данных или непредвиденных форматов. В таких случаях в структуре каталога целесообразно использовать папку **/bad**, чтобы перемещать в нее файлы для дальнейшей проверки. Пакетное задание также может обрабатывать отчет или уведомление об этих *недопустимых* файлах для устранения проблем вручную. Рассмотрите следующую структуру:

    {Region}/{SubjectMatter(s)}/In/{yyyy}/{mm}/{dd}/{hh}/
    {Region}/{SubjectMatter(s)}/Out/{yyyy}/{mm}/{dd}/{hh}/
    {Region}/{SubjectMatter(s)}/Bad/{yyyy}/{mm}/{dd}/{hh}/

Например, маркетинговая фирма ежедневно получает извлечения данных клиентских обновлений от своих клиентов в Северной Америке. Она может выглядеть, как приведенный ниже фрагмент кода, перед обработкой и после нее:

    NA/Extracts/ACMEPaperCo/In/2017/08/14/updates_08142017.csv
    NA/Extracts/ACMEPaperCo/Out/2017/08/14/processed_updates_08142017.csv

В общем случае пакетных данных, обрабатываемых непосредственно в таких базах данных, как Hive или традиционных базах данных SQL, нет необходимости в папке **/in** или **/out**, так как результаты уже выводятся в отдельную папку для таблицы Hive или внешней базы данных. Например, ежедневные извлечения данных от клиентов будут размещаться в их соответствующих папках, а при управлении с помощью фабрики данных Azure, Apache Oozie или Apache Airflow будет ежедневно выполняться задание Hive или Spark для обработки и записи данных в таблицу Hive.
