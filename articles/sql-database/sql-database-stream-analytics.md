---
title: Потоковая передача данных с помощью интеграции Stream Analytics (Предварительная версия)
description: Используйте Azure Stream Analytics для потоковой передачи данных в базу данных SQL Azure.
services: sql-database
ms.service: sql-database
ms.subservice: development
ms.custom: ''
ms.devlang: ''
ms.topic: conceptual
author: ajetasin
ms.author: ajetasi
ms.reviewer: sstein
ms.date: 11/04/2019
ms.openlocfilehash: d233d3c98cc495e4b9e84142781f5eb9faa7eec8
ms.sourcegitcommit: ac56ef07d86328c40fed5b5792a6a02698926c2d
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/08/2019
ms.locfileid: "73820841"
---
# <a name="stream-data-by-using-azure-sql-database-stream-analytics-integration-preview"></a>Потоковая передача данных с помощью интеграции Stream Analytics базы данных SQL Azure (Предварительная версия)

Теперь пользователи могут принимать, обрабатывать, просматривать и анализировать данные потоковой передачи в режиме реального времени в таблицу непосредственно из базы данных SQL в портал Azure с помощью [Azure Stream Analytics](../stream-analytics/stream-analytics-introduction.md). Этот интерфейс обеспечивает широкий спектр сценариев, таких как подключенный автомобиль, удаленный мониторинг, обнаружение мошенничества и многое другое. В портал Azure можно выбрать источник событий (концентратор событий или центр Интернета вещей), просмотреть входящие события в реальном времени и выбрать таблицу для хранения событий. Можно также написать Stream Analytics запросы на языке запросов на портале, чтобы преобразовать входящие события и сохранить их в выбранной таблице. Эта новая точка входа является дополнением к процессам создания и настройки, которые уже существуют в Stream Analytics. Этот интерфейс начинается с контекста базы данных, что позволяет быстро настроить Stream Analytics задание и легко перемещаться между базой данных SQL Azure и Stream Analytics.

![Поток Stream Analytics](media/sql-database-stream-analytics/stream-analytics-flow.png)

## <a name="key-benefits"></a>Основные преимущества

- Минимальное переключение контекста. Вы можете начать с базы данных SQL на портале и начать принимать данные в режиме реального времени в таблицу, не переключаясь на другую службу. 
- Уменьшено количество шагов: контекст базы данных и таблицы используется для предварительной настройки Stream Analytics задания.
- Дополнительная простота в использовании данных для предварительного просмотра: Просмотр входящих данных из источника событий (концентратора событий или центра IoT) в контексте выбранной таблицы. 


## <a name="prerequisites"></a>Предварительные требования

Для выполнения действий, описанных в этой статье, необходимы следующие ресурсы:

- Подписка Azure. Если у вас еще нет подписки Azure, [создайте бесплатную учетную запись](https://azure.microsoft.com/free/). 
- База данных SQL. Дополнительные сведения см. [в статье Создание отдельной базы данных в базе данных SQL Azure](sql-database-single-database-get-started.md).
- Правило брандмауэра, разрешающее компьютеру подключаться к серверу Azure SQL Server. Дополнительные сведения см. [в разделе Создание правила брандмауэра на уровне сервера](sql-database-server-level-firewall-rule.md).


## <a name="configure-stream-analytics-integration"></a>Настройка интеграции с Stream Analytics

1. Войдите на портал Azure. 
2. Перейдите к базе данных SQL, в которой вы хотите получать данные потоковой передачи. Выберите **Stream Analytics (Предварительная версия)** . 

    ![Анализ потока](media/sql-database-stream-analytics/stream-analytics.png)

3. Чтобы начать передачу данных потоковой передачи в эту базу данных SQL, выберите **создать** и укажите имя для задания потоковой передачи, а затем нажмите кнопку **Далее: вход**. 

    ![Создание задания Stream Analytics](media/sql-database-stream-analytics/create-job.png)

4. Введите сведения об источнике событий, а затем нажмите кнопку **Далее: выходные данные**.

   - **Тип входных данных**: концентратор событий или центр Интернета вещей
   - **Входной псевдоним**: введите имя для указания источника событий. 
   - **Подписка**: то же, что и подписка на базу данных SQL 
   - **Пространство имен концентратора событий**: имя пространства имен 
   - **Имя концентратора событий**: имя концентратора событий в выбранном пространстве имен 
   - **Имя политики концентратора событий** (по умолчанию создать новое): присвоить имя политике 
   - **Группа потребителей концентратора событий** (по умолчанию для создания): укажите имя группы потребителей  
     - Рекомендуется создать группу потребителей и политику для каждого нового задания Azure Stream Analytics, которое вы создадите здесь. Группы потребителей допускают только пять одновременных средств чтения, поэтому для каждого задания выделяется выделенная группа потребителей, что позволяет избежать ошибок, которые могут возникнуть из-за превышения этого ограничения. Выделенная политика позволяет поворачивать ключ или отзывать разрешения без влияния на другие ресурсы.

    ![Создание задания Stream Analytics](media/sql-database-stream-analytics/create-job-output.png)

5. Выберите таблицу, в которую необходимо передавать данные потоковой передачи. После этого нажмите кнопку **создать**.
   - **Имя пользователя**, **пароль**: введите учетные данные для проверки подлинности SQL Server. Выберите **Проверка**.
   - **Таблица**: выберите **создать** или **использовать существующий**. В этом потоке выберите **создать**. При запуске задания Stream Analytics будет создана новая таблица.

    ![Создание задания Stream Analytics](media/sql-database-stream-analytics/create.png)

6. Откроется страница запроса со следующими сведениями:

   - **Входные** данные (источник входных событий), из которого будут приема данных  
   - **Выходная** таблица, в которой будут храниться преобразованные данные 
   - Пример [запроса SAQL](../stream-analytics/stream-analytics-stream-analytics-query-patterns.md) с инструкцией SELECT. 
   - **Предварительный просмотр ввода**: показывает моментальный снимок последних входящих данных из источника входных событий.  
     - Тип сериализации в данных определяется автоматически (JSON/CSV). Вы можете вручную изменить его, а также в JSON/CSV/AVRO. 
     - Вы можете просмотреть входящие данные в формате таблицы или необработанном формате. 
     - Если данные не являются актуальными, выберите **Обновить** , чтобы просмотреть последние события. 
     - Выберите **выбрать диапазон времени** , чтобы проверить запрос по определенному диапазону входящих событий. 
     - Выберите **Отправить пример входных данных** , чтобы протестировать запрос, ПЕРЕДАВ пример JSON/CSV-файла. Дополнительные сведения о тестировании запроса SAQL см. в разделе [тестирование Azure Stream Analytics задания с помощью демонстрационных данных](../stream-analytics/stream-analytics-test-query.md). 

    ![тестовый запрос](media/sql-database-stream-analytics/test-query.png)


   - **Результаты теста**: выберите **тестовый запрос** , чтобы просмотреть результаты потоковой передачи. 

    ![Результаты теста](media/sql-database-stream-analytics/test-results.png)

   - **Схема результатов теста**: показывает схему результатов потокового запроса после тестирования. Убедитесь, что схема результатов теста соответствует выходной схеме. 

    ![Схема результатов теста](media/sql-database-stream-analytics/test-results-schema.png)


   - **Выходная схема**: содержит схему таблицы, выбранной на шаге 5 (Новая или существующая).
     - Создать: Если вы выбрали этот параметр на шаге 5, схема пока не будет отображена до запуска задания потоковой передачи. При создании новой таблицы выберите соответствующий индекс таблицы. Дополнительные сведения об индексировании таблиц см. в разделе [Описание кластеризованных и некластеризованных индексов](/sql/relational-databases/indexes/clustered-and-nonclustered-indexes-described/).
    - Использовать существующий: Если вы выбрали этот параметр на шаге 5, вы увидите схему выбранной таблицы. 
 
7. После завершения создания & тестирования запроса выберите **Сохранить запрос**. Выберите **запустить Stream Analytics задание** , чтобы начать прием преобразованных данных в таблицу SQL. После завершения выполнения следующих полей **запустите** задание. 
   - **Время начала вывода**: определяет время первого вывода задания.  
     - Теперь задание начнется сейчас и будет обрабатывать новые входящие данные.
     - Custom: задание будет запущено, но будет обрабатывать данные с определенного момента времени (который может быть в прошлом или будущем). Дополнительные сведения см. [в разделе Запуск задания Azure Stream Analytics](../stream-analytics/start-job.md).
   - **Единицы потоковой передачи**: цена за Azure Stream Analytics оценивается по числу единиц потоковой передачи, необходимых для обработки данных в службе. Дополнительные сведения см. в разделе [цены на Azure Stream Analytics](https://azure.microsoft.com/pricing/details/stream-analytics/). 
   - **Обработка ошибок выходных данных**:  
     - Повтор. при возникновении ошибки Azure Stream Analytics пытается записать событие бессрочно до тех пор, пока запись не будет выполнена. Время ожидания для повторных попыток не задано. В конечном итоге обработку всех последующих событий блокирует событие, которое Azure Stream Analytics безуспешно пытается записать. Это политика обработки ошибок вывода по умолчанию. 
     - Drop: Azure Stream Analytics приведет к удалению любого выходного события, которое приводит к ошибке преобразования данных. Восстановить удаленные события для повторной обработки позже невозможно. Для всех временных ошибок (например, сбоев сети) выполняется повторная попытка независимо от конфигурации политики обработки ошибок вывода. 
   - **Параметры вывода базы данных SQL**. параметр для наследования схемы секционирования предыдущего шага запроса для включения полной параллельной топологии с несколькими модулями записи в таблицу. Дополнительные сведения см. в статье [Вывод данных Azure Stream Analytics в базу данных SQL Azure](../stream-analytics/stream-analytics-sql-output-perf.md).
   - **Максимальное число пакетов**: Рекомендуемый верхний предел числа записей, отправляемых при каждой транзакции с массовыми вставками.  
    Дополнительные сведения об обработке ошибок вывода см. [в разделе политики ошибок вывода в Azure Stream Analytics](../stream-analytics/stream-analytics-output-error-policy.md).  

    ![запустить задание](media/sql-database-stream-analytics/start-job.png)

8. После запуска задания в списке будет отображаться выполняемое задание, и вы сможете выполнить следующие действия. 
   - **Запуск и завершение задания**. Если задание выполняется, вы можете его прерывать. Если задание остановлено, можно запустить задание. 
   - **Изменить задание**: можно изменить запрос. Если вы хотите внести дополнительные изменения в задание ex, добавьте дополнительные входные и выходные данные, а затем откройте задание в Stream Analytics. Параметр "Изменить" отключен при выполнении задания. 
   - **Предварительная версия выходной таблицы**: можно просмотреть таблицу в редакторе SQL запросов. 
   - **Откройте в Stream Analytics**: Откройте задание в Stream Analytics службе, чтобы просмотреть сведения об отслеживании задания, отладки. 


    ![задания Stream Analytics](media/sql-database-stream-analytics/jobs.png)






## <a name="next-steps"></a>Дальнейшие действия

- [Документация по Stream Analytics](https://docs.microsoft.com/azure/stream-analytics/)
- [Шаблоны решений Azure Stream Analytics](../stream-analytics/stream-analytics-solution-patterns.md)
