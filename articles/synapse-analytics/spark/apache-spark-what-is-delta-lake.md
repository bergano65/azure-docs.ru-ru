---
title: Сведения о Delta Lake
description: Обзор разностной версии Lake и принцип ее работы в рамках Azure синапсе Analytics
services: synapse-analytics
author: euangMS
ms.service: synapse-analytics
ms.topic: conceptual
ms.subservice: spark
ms.date: 04/15/2020
ms.author: euang
ms.reviewer: euang
ms.openlocfilehash: 6a38b61ee03aa4853526586ca60542bd3641b66f
ms.sourcegitcommit: 32c521a2ef396d121e71ba682e098092ac673b30
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/25/2020
ms.locfileid: "91249405"
---
# <a name="what-is-delta-lake"></a>Сведения о Delta Lake

Azure синапсе Analytics совместима с Linux Foundation Delta Lake. Дельта Lake — это уровень хранилища с открытым кодом, который приносит транзакции ACID (атомарность, согласованность, изоляция и устойчивость) для Apache Spark и больших рабочих нагрузок данных.

Текущая версия Delta Lake, входящая в состав Azure синапсе, имеет языковую поддержку для Scala, PySpark и .NET. В нижней части страницы имеются ссылки на более подробные примеры и документацию.

## <a name="key-features"></a>Основные возможности

| Компонент | Описание |
| --- | --- |
| **Транзакции ACID** | Озера данных обычно заполняются с помощью нескольких процессов и конвейеров, некоторые из которых записывают данные параллельно с чтением. До разностной версии Lake и добавления транзакций инженеры по обработке данных должны были выполнить процесс, подверженный ошибкам вручную, чтобы обеспечить целостность данных. Дельта Lake приносит привычные транзакции ACID в озера данных. Он предоставляет возможности сериализации, самый высокий уровень изоляции. Дополнительные сведения [см. в статье разностного Lake: Распаковка журнала транзакций](https://databricks.com/blog/2019/08/21/diving-into-delta-lake-unpacking-the-transaction-log.html).|
| **Обработка масштабируемых метаданных** | В больших данных даже метаданные могут быть "большими данными". Дельта Lake обрабатывает метаданные так же, как данные, используя распределенную вычислительную мощность Spark для обработки всех своих метаданных. В результате Дельта Lake может работать с петабайтного уровня таблицами с миллиардами разделов и файлов. |
| **Время поездок (управление версиями данных)** | Возможность «отменить» изменение или вернуться к предыдущей версии является одной из основных функций транзакций. Разностная версия Lake предоставляет моментальные снимки данных, позволяющие вернуться к более ранним версиям данных для аудита, отката или воспроизведения экспериментов. Дополнительные сведения см. в статье о переносе [разностного времени для больших озера данных](https://databricks.com/blog/2019/02/04/introducing-delta-time-travel-for-large-scale-data-lakes.html). |
| **Открыть формат** | Apache Parquet — это базовый формат для Delta Lake, позволяющий использовать эффективные схемы сжатия и кодирования, которые являются собственными для формата. |
| **Единый пакет и источник потоковой передачи и приемник** | Таблица в Delta Lake — это как пакетная таблица, так и источник потоковой передачи и приемник. Прием потоковых данных, историческая обратная передача и Интерактивные запросы работают только за пределами поля. |
| **Принудительное применение схемы** | Применение схемы позволяет убедиться, что типы данных верны и присутствуют необходимые столбцы, предотвращая несогласованность данных. Дополнительные сведения см [. в разделе погружение в Delta Lake: применение схемы & развитие](https://databricks.com/blog/2019/09/24/diving-into-delta-lake-schema-enforcement-evolution.html) |
| **Развитие схемы** | Дельта Lake позволяет вносить изменения в схему таблицы, которая может применяться автоматически, без необходимости написания языка DDL для миграции. Дополнительные сведения см [. в разделе погружение в Delta Lake: применение схемы & развитие](https://databricks.com/blog/2019/09/24/diving-into-delta-lake-schema-enforcement-evolution.html) |
| **Журнал аудита** | В журнале операций с разностной операцией Lake регистрируются сведения обо всех изменениях, внесенных в данные, что обеспечивает полный журнал аудита изменений. |
| **Обновления и удаления** | Delta Lake поддерживает Scala/Java/Python и API SQL для различных функций. Поддержка операций слияния, обновления и удаления помогает удовлетворить требования соответствия. Дополнительные сведения см. в статьях [объявление о выпуске разностного Lake 0.6.1](https://delta.io/news/delta-lake-0-6-1-released/),  [объявление выпуска для разностной версии Lake 0,7](https://delta.io/news/delta-lake-0-7-0-released/) и [простых, надежных операции Upsert и удалений в разностных таблицах с помощью интерфейсов API Python](https://databricks.com/blog/2019/10/03/simple-reliable-upserts-and-deletes-on-delta-lake-tables-using-python-apis.html), включая фрагменты кода для команд DML, Update и DELETE. |
| **100% совместим с Apache Spark API** | Разработчики могут использовать разностную версию Lake с существующими конвейерами данных с минимальными изменениями, так как они полностью совместимы с существующими реализациями Spark. |

Более полную документацию см. на [странице документации по Delta Lake](https://docs.delta.io/latest/delta-intro.html).

Дополнительные сведения см. на странице [проекта Delta Lake](https://github.com/delta-io/delta).

## <a name="next-steps"></a>Дальнейшие действия

- [Документация по .NET для Apache Spark](/dotnet/spark?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json)
- [Azure Synapse Analytics](https://docs.microsoft.com/azure/synapse-analytics)
