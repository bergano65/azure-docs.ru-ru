---
title: Автоматическое масштабирование экземпляров Apache Spark
description: Использование компонента автомасштабирования Azure Synapse для автоматического масштабирования экземпляров Apache Spark
author: euangMS
ms.author: euang
ms.reviewer: euang
services: synapse-analytics
ms.service: synapse-analytics
ms.topic: conceptual
ms.subservice: spark
ms.date: 03/31/2020
ms.openlocfilehash: c043941543088d9bdbfd535f372e2335e1ba55a5
ms.sourcegitcommit: 829d951d5c90442a38012daaf77e86046018e5b9
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/09/2020
ms.locfileid: "87500357"
---
# <a name="automatically-scale-azure-synapse-analytics-apache-spark-pools"></a>Автоматическое масштабирование пулов Apache Spark в Azure Synapse Analytics

Компонент автомасштабирования пулов Apache Spark для Azure Synapse Analytics автоматически масштабирует количество узлов в экземпляре кластера в большую и меньшую сторону. При создании пула Apache Spark для Azure Synapse Analytics можно задать минимальное и максимальное количество узлов, если выбран компонент автомасштабирования. Автомасштабирование отслеживает требования к ресурсам, зависящие от нагрузки, и масштабирует количество узлов соответствующим образом. За использование этой функции дополнительная плата не взимается.

## <a name="metrics-monitoring"></a>Мониторинг метрик

Компонент автомасштабирования постоянно выполняет мониторинг кластера и собирает следующие метрики:

|Метрика|Описание|
|---|---|
|Total Pending CPU (Общее число ожидающих ЦП)|Общее число ядер, необходимое для запуска выполнения всех ожидающих узлов.|
|Total Pending Memory (Общий объем ожидающей памяти)|Общий объем памяти (в МБ), необходимый для запуска выполнения всех ожидающих узлов.|
|Total Free CPU (Общее число свободных ЦП)|Сумма всех неиспользуемых ядер на активных узлах.|
|Total Free Memory (Общий объем свободной памяти)|Суммарный объем неиспользуемой памяти (в МБ) на активных узлах.|
|Used Memory per Node (Объем используемой памяти на каждом узле)|Нагрузка на узел. Узел, на котором используется 10 ГБ памяти, пребывает под большей нагрузкой, чем узел с 2 ГБ используемой памяти.|

Эти метрики проверяются каждые 30 секунд. Компонент автомасштабирования увеличивает и уменьшает масштаб на основе этих метрик.

## <a name="load-based-scale-conditions"></a>Условия масштабирования на основе нагрузки

При обнаружении следующих условий компонент автомасштабирования будет выдавать запрос на масштабирование.

|Вертикальное масштабирование|Вертикальное уменьшение масштаба|
|---|---|
|Общее число ожидающих ЦП больше, чем общее число свободных ЦП в течение более чем 1 минуты.|Общее число ожидающих ЦП меньше, чем общее число свободных ЦП в течение более чем 2 минут.|
|Общий объем ожидающей памяти больше, чем общее число свободной памяти в течение более чем 1 минуты.|Общий объем ожидающей памяти меньше, чем общий объем свободной памяти в течение более чем 2 минут.|

Для увеличения масштаба служба автомасштабирования Azure Synapse вычисляет, сколько новых узлов нужно для удовлетворения текущих требований к ЦП и памяти, а затем выдает запрос на увеличение масштаба, чтобы добавить необходимое число узлов.

Для уменьшения масштаба служба автомасштабирования выдает запрос на удаление определенного количества узлов в зависимости от количества исполнителей, количества владельцев приложений на узел и текущих требований к ЦП и памяти. Служба также определяет, какие узлы являются кандидатами на удаление в зависимости от текущего состояния выполнения задания. При вертикальном уменьшении масштаба сначала узлы выводятся из эксплуатации, а затем они удаляются из кластера.

## <a name="get-started"></a>Начало работы

### <a name="create-a-spark-pool-with-autoscaling"></a>Создание пула Spark с автомасштабированием

Чтобы включить компонент автомасштабирования, выполните следующие действия как часть обычного процесса создания пула.

1. На вкладке **Основные сведения** установите флажок **Включить автомасштабирование**.
1. Введите нужные значения для следующих свойств:  

    * **Мин.**  — минимальное количество узлов.
    * **Макс.**  — максимальное количество узлов.

Начальное число узлов будет минимальным. Это значение определяет начальный размер экземпляра при его создании. Минимальное число узлов не может быть меньше трех.

## <a name="best-practices"></a>Рекомендации

### <a name="consider-the-latency-of-scale-up-or-scale-down-operations"></a>Учитывайте задержку операций вертикального увеличения или уменьшения масштаба

Выполнение операции масштабирования может занять от 1 до 5 минут.

### <a name="prepare-for-scaling-down"></a>Подготовка к уменьшению масштаба

Во время масштабирования экземпляра процесс автомасштабирования переместит узлы в состояние списания, чтобы новые исполнители не могли запуститься на этом узле.

Выполняемые задания будут по-прежнему выполняться и завершаться. Ожидающие задания будут ожидать включения в расписания в обычном порядке с меньшим количеством доступных узлов.

## <a name="next-steps"></a>Дальнейшие действия

Краткое руководство по настройке нового пула Spark: [Создание пула Spark](../quickstart-create-apache-spark-pool-portal.md)
