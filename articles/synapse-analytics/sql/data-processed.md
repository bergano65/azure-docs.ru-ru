---
title: Управление затратами для несерверного пула SQL
description: В этом документе описывается, как управлять стоимостью бессерверного пула SQL и как рассчитывается обрабатываемые данные при запросе данных в службе хранилища Azure.
services: synapse analytics
author: filippopovic
ms.service: synapse-analytics
ms.topic: conceptual
ms.subservice: sql
ms.date: 11/05/2020
ms.author: fipopovi
ms.reviewer: jrasnick
ms.openlocfilehash: 8a26f8ced5e91810f8cadff0a27796dc817e6517
ms.sourcegitcommit: b4880683d23f5c91e9901eac22ea31f50a0f116f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/11/2020
ms.locfileid: "94491590"
---
# <a name="cost-management-for-serverless-sql-pool-in-azure-synapse-analytics"></a>Управление затратами для несерверного пула SQL в Azure синапсе Analytics

В этой статье объясняется, как оценить и контролировать затраты на бессерверный пул SQL в Azure синапсе Analytics:
- Оценка объема данных, обработанных перед выдачей запроса
- Использование функции управления затратами для задания бюджета

Изучите, что затраты на бессерверный пул SQL в Azure синапсе Analytics являются частью ежемесячных затрат в счете Azure. Если вы используете другие службы Azure, вам будет выставлен счет за все службы и ресурсы Azure, используемые в вашей подписке Azure, в том числе на сторонние службы. В этой статье описывается планирование и управление затратами для несерверного пула SQL в Azure синапсе Analytics.

## <a name="data-processed"></a>Обработанные данные

*Обработанные данные* — это объем данных, которые система временно сохраняет во время выполнения запроса. Обработанные данные состоят из следующих количеств:

- Объем данных, считанных из хранилища. Эта сумма включает:
  - Чтение данных при чтении данных.
  - Чтение данных при чтении метаданных (для форматов файлов, содержащих метаданные, например Parquet).
- Объем данных в промежуточных результатах. Эти данные передаются между узлами во время выполнения запроса. Она включает в себя перенос данных в конечную точку в несжатом формате. 
- Объем данных, записываемых в хранилище. Если для экспорта результирующего набора в хранилище используется CETAS, то объем записанных данных добавляется к объему данных, обрабатываемых для части SELECT CETAS.

Чтение файлов из хранилища обеспечивает высокую степень оптимизации. Процесс использует:

- Упреждающая выборка, которая может добавить некоторую нагрузку на объем считанных данных. Если запрос считывает файл целиком, дополнительная нагрузка не взимается. Если файл читается частично, как в первых N запросах, то с помощью функции предварительного получения считывается еще несколько данных.
- Оптимизированное средство синтаксического анализа значений с разделителями-запятыми (CSV). Если для чтения CSV-файлов используется PARSER_VERSION = "2.0", то объем данных, считанных из хранилища, немного увеличивается. Оптимизированное средство синтаксического анализа CSV считывает файлы параллельно, в виде фрагментов одинакового размера. Фрагменты не обязательно содержат целые строки. Чтобы обеспечить синтаксический анализ всех строк, оптимизированный синтаксический анализатор CSV также считывает небольшие фрагменты смежных фрагментов. В этом процессе добавляется небольшой объем издержек.

## <a name="statistics"></a>Статистика

Оптимизатор запросов пула SQL, не являющийся сервером, использует статистику для создания оптимальных планов выполнения запросов. Статистику можно создать вручную. В противном случае серверный пул SQL автоматически создает их. В любом случае статистика создается путем выполнения отдельного запроса, возвращающего конкретный столбец с указанной частотой выборки. Этот запрос имеет связанный объем обработанных данных.

Если вы запускаете тот же или любой другой запрос, который может выиграть от создания статистики, то по возможности повторно использует статистику. Дополнительные данные для создания статистики не обработаны.

При создании статистики для столбца Parquet из файлов считывается только соответствующий столбец. При создании статистики для столбца CSV все файлы считываются и анализируются.

## <a name="rounding"></a>Округление

Объем обработанных данных округляется до ближайших МЕГАБАЙТов на запрос. Каждый запрос содержит не менее 10 МБ обрабатываемых данных.

## <a name="what-data-processed-doesnt-include"></a>Какие данные не включаются в обработку

- Метаданные уровня сервера (например, имена для входа, роли и учетные данные уровня сервера).
- Базы данных, создаваемые в конечной точке. Эти базы данных содержат только метаданные (такие как пользователи, роли, схемы, представления, встроенные функции с табличным значением [возвращающие табличное], хранимые процедуры, учетные данные уровня базы данных, внешние источники данных, форматы внешних файлов и внешние таблицы).
  - Если вы используете вывод схемы, то фрагменты файлов считываются для определения имен столбцов и типов данных, а объем считанных данных добавляется к объему обработанных данных.
- Инструкции языка описания данных DDL, за исключением инструкции CREATE STATISTICS, поскольку она обрабатывает данные из хранилища на основе указанного процента выборки.
- Запросы только с метаданными.

## <a name="reducing-the-amount-of-data-processed"></a>Уменьшение объема обработанных данных

Можно оптимизировать объем обрабатываемых данных по запросу и повысить производительность путем секционирования и преобразования данных в сжатый формат на основе столбцов, например Parquet.

## <a name="examples"></a>Примеры

Представьте себе три таблицы.

- Таблица population_csv создана на 5 ТБ CSV-файлов. Файлы упорядочены по пяти столбцам одинакового размера.
- Таблица population_parquet содержит те же данные, что и таблица population_csv. Он имеет 1 ТБ файлов Parquet. Эта таблица меньше предыдущей, так как данные сжимаются в формате Parquet.
- Таблица very_small_csv создана на базе файлов CSV размером 100 КБ.

**Запрос 1**. Выбор суммы (совокупности) из population_csv

Этот запрос считывает и анализирует файлы целиком, чтобы получить значения для столбца Population. Узлы обрабатывают фрагменты этой таблицы, а сумма совокупности для каждого фрагмента передается между узлами. Окончательная сумма передается в конечную точку. 

Этот запрос обрабатывает 5 ТБ данных и небольшой объем ресурсов для передачи сумм фрагментов.

**Запрос 2**. Выбор суммы (совокупности) из population_parquet

При запросе сжатых и основанных на столбцах форматов, таких как Parquet, данные считываются меньше, чем в запросе 1. Вы видите этот результат, так как несерверный пул SQL считывает один сжатый столбец, а не весь файл. В этом случае считывается 0,2 ТБ. (Пять столбцов одинакового размера — 0,2 ТБ.) Узлы обрабатывают фрагменты этой таблицы, а сумма совокупности для каждого фрагмента передается между узлами. Окончательная сумма передается в конечную точку. 

Этот запрос обрабатывает 0,2 ТБ плюс небольшой объем издержек для передачи сумм фрагментов.

**Запрос 3**. Выберите * из population_parquet

Этот запрос считывает все столбцы и передает все данные в несжатом формате. Если формат сжатия 5:1, то запрос обрабатывает 6 ТБ, так как считывает 1 ТБ и передает 5 ТБ несжатых данных.

**Запрос 4**. Выбор счетчика (*) из very_small_csv

Этот запрос считывает файлы целиком. Общий размер файлов в хранилище для этой таблицы — 100 КБ. Узлы обрабатывают фрагменты этой таблицы, а сумма для каждого фрагмента передается между узлами. Окончательная сумма передается в конечную точку. 

Этот запрос обрабатывает немного более 100 КБ данных. Объем данных, обработанных для этого запроса, округляется до 10 МБ, как указано в разделе [округления](#rounding) этой статьи.

## <a name="cost-control"></a>Управление затратами

Функция управления затратами в бессерверном пуле SQL позволяет задать бюджет для объема обработанных данных. Вы можете задать бюджет в ТЕРАБАЙТах данных, обработанных в течение дня, недели и месяца. В то же время может быть установлен один или несколько бюджетов. Чтобы настроить управление затратами для несерверного пула SQL, можно использовать синапсе Studio или T-SQL.

## <a name="configure-cost-control-for-serverless-sql-pool-in-synapse-studio"></a>Настройка управления затратами для бессерверного пула SQL в синапсе Studio
 
Чтобы настроить управление затратами для несерверного пула SQL в синапсе Studio, перейдите к элементу управление в меню слева, а не выберите пункт пул SQL в разделе Пулы аналитиков. При наведении на серверный пул SQL вы увидите значок Управление затратами. Щелкните этот значок.

![Навигация по контролю затрат](./media/data-processed/cost-control-menu.png)

Когда вы щелкните значок управления затратами, появится боковая панель:

![Конфигурация управления затратами](./media/data-processed/cost-control-sidebar.png)

Чтобы задать один или несколько бюджетов, сначала выберите Включить переключатель для нужного бюджета, а не Введите целочисленное значение в текстовом поле. Единицей измерения для этого значения является TBs. После настройки бюджетов вы хотите нажать кнопку применить в нижней части боковой панели. Итак, бюджет установлен.

## <a name="configure-cost-control-for-serverless-sql-pool-in-t-sql"></a>Настройка управления затратами для несерверного пула SQL в T-SQL

Чтобы настроить управление затратами для пула SQL без сервера в T-SQL, необходимо выполнить одну или несколько следующих хранимых процедур.

```sql
sp_set_data_processed_limit
    @type = N'daily',
    @limit_tb = 1

sp_set_data_processed_limit
    @type= N'weekly',
    @limit_tb = 2

sp_set_data_processed_limit
    @type= N'monthly',
    @limit_tb = 3334
```

Чтобы увидеть текущую конфигурацию, выполните следующую инструкцию T-SQL:

```sql
SELECT * FROM sys.configurations
WHERE name like 'Data processed %';
```

Чтобы узнать, сколько данных было обработано в течение текущего дня, недели или месяца, выполните следующую инструкцию T-SQL:

```sql
SELECT * FROM sys.dm_external_data_processed
```

## <a name="next-steps"></a>Следующие шаги

Сведения о том, как оптимизировать запросы на производительность, см. в статье рекомендации [по использованию бессерверного пула SQL](best-practices-sql-on-demand.md).
