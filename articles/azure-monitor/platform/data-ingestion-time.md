---
title: Время приема данных журнала в Azure Monitor | Документация Майкрософт
description: Описание различных факторов, которые влияют на задержку при сборе данных журнала в Azure Monitor.
services: log-analytics
documentationcenter: ''
author: bwren
manager: carmonm
editor: tysonn
ms.service: log-analytics
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: infrastructure-services
ms.date: 07/18/2019
ms.author: bwren
ms.openlocfilehash: 5947c4c28736f8488ea0e48941214df42c6af72a
ms.sourcegitcommit: 36e9cbd767b3f12d3524fadc2b50b281458122dc
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/20/2019
ms.locfileid: "69639500"
---
# <a name="log-data-ingestion-time-in-azure-monitor"></a>Время приема данных журнала в Azure Monitor
Azure Monitor — это высокомасштабируемая служба, которая обслуживает тысячи клиентов, ежемесячно отправляющих стремительными темпами терабайты данных. Часто возникают вопросы о времени, в течение которого собранные данные журнала становятся доступными. В этой статье объясняются факторы, влияющие на эту задержку.

## <a name="typical-latency"></a>Обычная задержка
Задержка — это время, в течение которого данные создаются в отслеживаемой системе, и время, в течение которого они становятся доступными для анализа в Azure Monitor. Обычная задержка для приема данных журнала составляет от 2 до 5 минут. Конкретная задержка для определенных данных зависит от различных факторов, описанных ниже.


## <a name="factors-affecting-latency"></a>Факторы, влияющие на задержку
Общее время приема для конкретного набора данных можно разделить на следующие высокоуровневые составляющие. 

- Время агента — время на обнаружение события, его сбора и отправки в точку приема Azure Monitor в виде записи журнала. В большинстве случаев этот процесс обрабатывается агентом.
- Время конвейера — время, необходимое конвейеру приема для обработки записи журнала. Сюда входит анализ свойств события и возможное добавление вычисляемых данных.
- Время индексирования — время, затраченное на прием записи журнала в хранилище больших данных Azure Monitor.

Далее приводятся сведения о различных видах задержки, представленных в этом процессе.

### <a name="agent-collection-latency"></a>Задержка агента сбора данных
Агенты и решения по управлению используют разные стратегии для сбора данных с виртуальной машины, что может повлиять на задержку. Вот несколько конкретных примеров.

- Сбор событий Windows, событий системного журнала и метрик производительности выполняется немедленно. Счетчики производительности Linux опрашиваются с 30-секундным интервалом.
- Сбор данных журналов служб IIS и настраиваемых журналов происходит при изменении метки времени. Сбор данных журналов служб IIS зависит от [расписания переключения, настроенного в службах IIS](data-sources-iis-logs.md). 
- Решение репликации Active Directory выполняет свою оценку каждые пять дней, а решение оценки Active Directory оценивает инфраструктуру Active Directory еженедельно. Агент собирает данные этих журналов только после завершения оценки.

### <a name="agent-upload-frequency"></a>Частота отправки данных агентом
Подтверждая простоту своего функционала, агент Log Analytics помещает журналы в буфер и периодически отправляет их в Azure Monitor. В зависимости от типа данных частота отправки меняется от 30 секунд до 2 минут. Большая часть данных отправляется меньше чем через минуту. Состояние сети может отрицательно повлиять на задержку при достижении этими данными точки приема Azure Monitor.

### <a name="azure-activity-logs-diagnostic-logs-and-metrics"></a>Журналы действий Azure, журналы диагностики и метрики
Отправка данных Azure для обработки в точку приема Log Analytics занимает некоторое время:

- Получение данных из журналов диагностики занимает от 2 до 15 минут, в зависимости от службы Azure. Ознакомьтесь с [запросом ниже](#checking-ingestion-time), чтобы изучить задержку в своей среде.
- Отправка метрик платформы Azure в точку приема Log Analytics занимает 3 минуты.
- Отправка данных журнала действий в точку приема данных Log Analytics займет от 10 до 15 минут.

Когда данные станут доступны в точке приема, потребуется от 2 до 5 минут дополнительно, чтобы они стали доступны для запроса.

### <a name="management-solutions-collection"></a>Сбор данных решениями по управлению
Некоторые решения не собирают свои данные с агента и могут использовать метод сбора, приводящий к дополнительной задержке. Некоторые решения собирают данные через регулярные интервалы, не предпринимая попыток сбора данных в режиме, близком к реальному времени. Вот несколько конкретных примеров.

- Решение Office 365 опрашивает журналы действий с помощью API действий управления Office 365, который в настоящее время не дает гарантий задержки в режиме, близком к реальному времени.
- Решение Windows Analytics (например, для поддержки обновлений) собирает данные ежедневно.

Частоту сбора данных решением см. в документации к каждому решению.

### <a name="pipeline-process-time"></a>Время обработки конвейером
После того как записи журнала поступают в конвейер Azure Monitor (как определено в свойстве [_TimeReceived](log-standard-properties.md#_timereceived) ), они записываются во временное хранилище, чтобы обеспечить изоляцию клиентов и убедиться, что данные не теряются. Как правило, этот процесс добавляет еще около 5–15 секунд задержки. В некоторых решениях по управлению реализованы более сложные алгоритмы по объединению данных и получению аналитических сведений по мере потокового поступления данных. Например, решение по мониторингу производительности сети собирает входящие данные через 3-минутные интервалы, добавляя тем самым 3-минутную задержку. Другой процесс, который приводит к увеличению задержки — это процесс, который обрабатывает пользовательские журналы. В некоторых случаях этот процесс может добавить задержку в несколько минут для журналов, собранных из файлов с помощью агента.

### <a name="new-custom-data-types-provisioning"></a>Подготовка новых типов пользовательских данных
При создании нового типа пользовательских данных из [настраиваемого журнала](data-sources-custom-logs.md) или [API сборщика данных](data-collector-api.md) система формирует выделенный контейнер хранилища. Это однократное увеличение нагрузки, которое возникает только при первом входе этого типа данных.

### <a name="surge-protection"></a>Защита от пиковых нагрузок
Наивысшим приоритетом Azure Monitor является сохранность данных клиента, поэтому система оснащена встроенной защитой от резкого увеличения объемов данных. Сюда входят буферы, гарантирующие, что даже при огромный нагрузке система продолжит работать. При обычной нагрузке эти средства управления добавляют задержку меньше минуты, но в экстремальных условиях и при критических сбоях они могут добавлять значительное время, обеспечивая при этом безопасность данных.

### <a name="indexing-time"></a>Время индексации
На каждой платформе больших данных существует встроенный баланс между предоставлением возможностей анализа и расширенных функций поиска и немедленным предоставлением доступа к данным. Azure Monitor позволяет выполнять мощные запросы к миллионам записей и получать результаты через несколько секунд. Это стало возможным благодаря существенному преобразованию данных во время их приема и их хранению в уникальных компактных структурах. Система помещает данные в буфер до тех пор, пока их не будет достаточно для создания этих структур. Это должно быть сделано до появления записей журнала в результатах поиска.

Сейчас этот процесс занимает около 5 минут при небольшом объеме данных. При более высокой скорости передачи данных задача выполняется быстрее. Это кажется нелогичным, но данный процесс позволяет оптимизировать задержку для производственных рабочих нагрузок большого объема.



## <a name="checking-ingestion-time"></a>Проверка времени приема
В различных условиях время приема может меняться для разных ресурсов. Запросы журналов можно использовать для идентификации конкретного поведения среды. В следующей таблице показано, как можно определить разное время для записи, когда она создается и отправляется в Azure Monitor.

| Шаг | Свойство или функция | Комментарии |
|:---|:---|:---|
| Запись, созданная в источнике данных | [TimeGenerated](log-standard-properties.md#timegenerated-and-timestamp) <br>Если источник данных не задает это значение, он будет установлен в то же время, что и _TimeReceived. |
| Запись, полученная конечной точкой приема Azure Monitor | [_TimeReceived](log-standard-properties.md#_timereceived) | |
| Запись, сохраненная в рабочей области и доступная для запросов | [ingestion_time()](/azure/kusto/query/ingestiontimefunction) | |

### <a name="ingestion-latency-delays"></a>Задержки приема данных
Можно измерять задержку конкретной записи, сравнивая результат функции [ingestion_time ()](/azure/kusto/query/ingestiontimefunction) со свойством _timegenerated_ . Эти данные можно использовать в различных агрегатах, чтобы определить поведение при задержке приема данных. Изучите некоторый процентиль времени приема для получения аналитических сведений по большому объему данных. 

Например, следующий запрос показывает, на каких компьютерах имелось наибольшее время приема за предыдущие 8 часов: 

``` Kusto
Heartbeat
| where TimeGenerated > ago(8h) 
| extend E2EIngestionLatency = ingestion_time() - TimeGenerated 
| extend AgentLatency = _TimeReceived - TimeGenerated 
| summarize percentiles(E2EIngestionLatency,50,95), percentiles(AgentLatency,50,95) by Computer 
| top 20 by percentile_E2EIngestionLatency_95 desc
```

Предыдущие проверки процентилей хорошо подходят для поиска общих тенденций в задержке. Чтобы указать краткосрочный пик в задержке, использование максимального значения (`max()`) может быть более эффективным.

Если вы хотите детализировать время приема для определенного компьютера за определенный период времени, используйте следующий запрос, который также визуализирует данные за последний день в графе: 


``` Kusto
Heartbeat 
| where TimeGenerated > ago(24h) //and Computer == "ContosoWeb2-Linux"  
| extend E2EIngestionLatencyMin = todouble(datetime_diff("Second",ingestion_time(),TimeGenerated))/60 
| extend AgentLatencyMin = todouble(datetime_diff("Second",_TimeReceived,TimeGenerated))/60 
| summarize percentiles(E2EIngestionLatencyMin,50,95), percentiles(AgentLatencyMin,50,95) by bin(TimeGenerated,30m) 
| render timechart
```
 
Используйте следующий запрос, чтобы отобразить время приема компьютера по стране или региону, в котором они находятся, на основе их IP-адреса: 

``` Kusto
Heartbeat 
| where TimeGenerated > ago(8h) 
| extend E2EIngestionLatency = ingestion_time() - TimeGenerated 
| extend AgentLatency = _TimeReceived - TimeGenerated 
| summarize percentiles(E2EIngestionLatency,50,95),percentiles(AgentLatency,50,95) by RemoteIPCountry 
```
 
У различных типов данных, исходящих от агента, может быть разное время задержки приема, поэтому предыдущие запросы могут использоваться с другими типами. Используйте следующий запрос для изучения времени приема разных служб Azure. 

``` Kusto
AzureDiagnostics 
| where TimeGenerated > ago(8h) 
| extend E2EIngestionLatency = ingestion_time() - TimeGenerated 
| extend AgentLatency = _TimeReceived - TimeGenerated 
| summarize percentiles(E2EIngestionLatency,50,95), percentiles(AgentLatency,50,95) by ResourceProvider
```

### <a name="resources-that-stop-responding"></a>Ресурсы, которые перестали отвечать на запросы 
В некоторых случаях ресурс может остановить отправку данных. Чтобы понять, отправляет ли ресурс данные или нет, просмотрите его самую последнюю запись, которую можно определить стандартным полем _TimeGenerated_.  

В таблице _по пакету пульса_ вы можете проверить доступность виртуальной машины, так как агент отправляет пакет пульса каждую минуту. Используйте следующий запрос, чтобы получить список активных компьютеров, которые в ближайшее время не передавали отчет пакета пульса. 

``` Kusto
Heartbeat  
| where TimeGenerated > ago(1d) //show only VMs that were active in the last day 
| summarize NoHeartbeatPeriod = now() - max(TimeGenerated) by Computer  
| top 20 by NoHeartbeatPeriod desc 
```

## <a name="next-steps"></a>Следующие шаги
* Ознакомьтесь со страницей [Соглашение об уровне обслуживания для Log Analytics](https://azure.microsoft.com/support/legal/sla/log-analytics/v1_1/).

