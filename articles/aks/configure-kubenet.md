---
title: Настройка сети kubenet в Службе Azure Kubernetes (AKS)
description: Узнайте, как настроить сеть kubenet (базовую) в Службе Azure Kubernetes (AKS), чтобы развернуть кластер AKS в существующей виртуальной сети и подсети.
services: container-service
ms.topic: article
ms.date: 06/02/2020
ms.reviewer: nieberts, jomore
ms.openlocfilehash: 82745d4f86a440c671e73ac3c74702a4a0c56b2d
ms.sourcegitcommit: 99955130348f9d2db7d4fb5032fad89dad3185e7
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/04/2020
ms.locfileid: "93348208"
---
# <a name="use-kubenet-networking-with-your-own-ip-address-ranges-in-azure-kubernetes-service-aks"></a>Использование сети kubenet с пользовательскими диапазонами IP-адресов в Службе Azure Kubernetes (AKS)

По умолчанию в кластерах AKS используется [kubenet][kubenet], а виртуальная сеть и подсеть Azure создаются автоматически. При использовании *kubenet* узлы получают IP-адрес из подсети виртуальной сети Azure. Модули pod получают IP-адреса из логически различающегося адресного пространства в подсеть виртуальной сети Azure узлов. Преобразование сетевых адресов (NAT) настраивается таким образом, чтобы модули pod могли получить доступ к ресурсам в виртуальной сети Azure. Исходный IP-адрес трафика преобразуется в первичный IP-адрес узла. Такой подход значительно уменьшает количество IP-адресов, которые необходимо зарезервировать в пространстве сети для объектов pod.

С помощью [сетевого интерфейса контейнеров Azure (CNI)][cni-networking] каждый объект pod получает IP-адрес из подсети, и к этому объекту pod можно получить прямой доступ. Эти IP-адреса должны быть уникальными во всей сети, и их следует планировать заранее. Для каждого узла предусмотрен параметр конфигурации, в котором указывается максимальное число объектов pod, которые он поддерживает. Затем на каждом узле заранее резервируется эквивалентное число IP-адресов для этого узла. Этот подход требует дополнительного планирования и часто приводит к исчерпанию IP-адресов или необходимости повторно создавать кластеры в подсети большего размера по мере увеличения потребностей вашего приложения. Можно настроить максимальное развертывание модулей Pod на узле при создании кластера или при создании новых пулов узлов. Если вы не укажете Максподс при создании пулов узлов, вы получите значение по умолчанию 110 для кубенет.

В этой статье показано, как с помощью сети *kubenet* создать и использовать подсеть виртуальной сети для кластера AKS. Дополнительные сведения о сетях см. в статье [Основные понятия сети в Службе Azure Kubernetes (AKS)][aks-network-concepts].

## <a name="prerequisites"></a>Обязательные условия

* Виртуальная сеть для кластера AKS должна разрешать исходящее подключение к Интернету.
* Не создавайте больше одного кластера AKS в одной подсети.
* Кластеры AKS не могут использовать `169.254.0.0/16` , `172.30.0.0/16` , `172.31.0.0/16` или `192.0.2.0/24` для диапазона адресов службы Kubernetes, диапазона адресов Pod или диапазона адресов виртуальной сети кластера.
* Субъект-служба, используемая кластером AKS, должна иметь по крайней мере роль [участника сети](../role-based-access-control/built-in-roles.md#network-contributor) в подсети в виртуальной сети. Кроме того, для создания субъекта-службы и назначения ему разрешений необходимо иметь соответствующие разрешения, например владелец подписки. Если вы хотите определить [пользовательскую роль](../role-based-access-control/custom-roles.md) вместо того, чтобы использовать встроенную роль участника сети, требуются следующие разрешения:
  * `Microsoft.Network/virtualNetworks/subnets/join/action`
  * `Microsoft.Network/virtualNetworks/subnets/read`

> [!WARNING]
> Для использования пулов узлов Windows Server необходимо использовать Azure CNI. Использование кубенет в качестве сетевой модели недоступно для контейнеров Windows Server.

## <a name="before-you-begin"></a>Подготовка к работе

Требуется Azure CLI версии 2.0.65 или более поздней. Чтобы узнать версию, выполните команду `az --version`. Если вам необходимо выполнить установку или обновление, см. статью [Установка Azure CLI 2.0][install-azure-cli].

## <a name="overview-of-kubenet-networking-with-your-own-subnet"></a>Общие сведения о сети kubenet с использованием пользовательской подсети

Во многих средах виртуальные сети и подсети уже определены и для них выделены диапазоны IP-адресов. Эти ресурсы виртуальной сети используются для поддержки нескольких служб и приложений. Чтобы установить сетевое подключение, в кластерах AKS можно использовать *kubenet* (базовую сеть) или Azure CNI ( *расширенную сеть* ).

При использовании *kubenet* IP-адрес в подсети виртуальной сети получают только узлы. Объекты Pod не могут взаимодействовать напрямую. Для подключения между объектами pod в узлах применяются определяемая пользователем маршрутизация (UDR) и IP-пересылка. По умолчанию конфигурация пересылки определяемые пользователем маршруты и IP-адресов создается и обслуживается службой AKS, но вы можете создать [собственную таблицу маршрутов для настраиваемого управления маршрутами][byo-subnet-route-table]. Можно также развернуть объекты pod за службой, которая получает назначенный IP-адрес и распределяет нагрузку трафика для приложения. На приведенной ниже схеме показано, как узлы AKS (но не объекты pod) получают IP-адрес в подсети виртуальной сети:

![Модель сети kubenet с кластером AKS](media/use-kubenet/kubenet-overview.png)

Azure поддерживает не более 400 маршрутов в UDR, поэтому в кластере AKS не может быть больше 400 узлов. AKS [виртуальные узлы][virtual-nodes] и политики сети Azure не поддерживаются в *кубенет*.  Вы можете использовать [политики сети Калико][calico-network-policies], так как они поддерживаются в кубенет.

Благодаря *Azure CNI* каждый объект pod получает IP-адрес в IP-подсети и может напрямую взаимодействовать с другими объектами pod и службами. Размер кластеров может соответствовать размеру указанного диапазона IP-адресов. Тем не менее диапазон IP-адресов следует планировать заранее. Все эти IP-адреса используются узлами AKS в зависимости от максимального числа поддерживаемых объектов pod. В *Azure CNI* поддерживаются дополнительные сетевые функции и сценарии, такие как [виртуальные узлы][virtual-nodes] или политики сети (Azure или Калико).

### <a name="limitations--considerations-for-kubenet"></a>Ограничения & рекомендации для кубенет

* В проектировании кубенет требуется дополнительный прыжок, что значительно увеличивает задержку связи с Pod.
* Таблицы маршрутов и определяемые пользователем маршруты необходимы для использования кубенет, что повышает сложность операций.
* Прямая адресация Pod не поддерживается для кубенет из-за кубенет проектирования.
* В отличие от кластеров Azure CNI, несколько кластеров кубенет не могут совместно использовать подсеть.
* Функции, **не поддерживаемые в кубенет** , включают:
   * [Политики сети Azure](use-network-policies.md#create-an-aks-cluster-and-enable-network-policy), но Калико сетевые политики поддерживаются в кубенет
   * [Пулы узлов Windows](./windows-faq.md)
   * [Надстройка виртуальных узлов](virtual-nodes.md#network-requirements)

### <a name="ip-address-availability-and-exhaustion"></a>Доступность и исчерпание IP-адресов

При применении *Azure CNI* распространенной проблемой является слишком малый диапазон назначенных IP-адресов для последующего добавления дополнительных узлов при масштабировании или обновлении кластера. Кроме того, группа специалистов по работе с сетями также не сможет обеспечить достаточно большой диапазон IP-адресов в соответствии с прогнозируемыми требованиями приложения.

В этом случае можно создать кластер AKS, в котором используется *kubenet* , и подключиться к существующей подсети виртуальной сети. Такой подход позволяет узлам получать определенные IP-адреса без необходимости заранее резервировать большое количество IP-адресов для всех потенциальных объектов pod, которые могут выполняться в кластере.

Благодаря *kubenet* можно использовать гораздо меньший диапазон IP-адресов и поддерживать большие кластеры и требования приложения. Например, даже с диапазоном IP-адресов */27* в подсети можно запустить кластер 20-25 узлов с достаточным пространством для масштабирования или обновления. Этот размер кластера будет поддерживать до *2200–2750*  объектов pod (по умолчанию максимум 110 объектов pod на каждом узле). Максимальное число модулей Pod на узел, которое можно настроить с помощью *кубенет* в AKS, — 110.

Приведенные ниже базовые расчеты показывают разницу между моделями сети.

- **kubenet**. Простой диапазон IP-адресов */24* может поддерживать до *251* узла в кластере (каждая подсеть виртуальной сети Azure резервирует первые три IP-адреса для операций управления).
  - Это число узлов может поддерживать до *27 610* объектов pod (по умолчанию максимум 110 объектов pod на каждом узле с *kubenet* ).
- **Azure CNI**. Такой же базовый диапазон подсети */24* поддерживает только до *8* узлов в кластере.
  - Это число узлов может поддерживать только до *240* объектов pod (по умолчанию максимум 30 объектов pod на каждом узле с *Azure CNI* ).

> [!NOTE]
> В этих максимальных значениях не учитываются операции обновления или масштабирования. На практике не рекомендуется запускать максимальное количество узлов, которые поддерживает диапазон IP-адресов подсети. Следует оставить несколько IP-адресов для использования во время операций масштабирования или обновления.

### <a name="virtual-network-peering-and-expressroute-connections"></a>Пиринг виртуальных сетей и подключения ExpressRoute

Для подключения к локальным ресурсам и в случае с *kubenet* , и в случае с *Azure CNI* можно использовать [пиринг виртуальных сетей Azure][vnet-peering] или [подключения ExpressRoute][express-route]. Следует тщательно планировать диапазоны IP-адресов, чтобы избежать перекрытия и неправильной маршрутизации трафика. Например, во многих локальных сетях используется диапазон *10.0.0.0/8* , который объявляется через подключение ExpressRoute. Рекомендуется создавать кластеры AKS в подсетях виртуальной сети Azure за пределами этого диапазона адресов, например *172.16.0.0/16*.

### <a name="choose-a-network-model-to-use"></a>Выбор модели сети

При выборе сетевого подключаемого модуля для кластера AKS обычно учитывается баланс гибкости и потребностей в расширенной конфигурации. Приведенные ниже рекомендации помогут понять, какая из моделей сети больше всего подходит для конкретной ситуации.

Используйте *kubenet* в следующих случаях:

- У вас ограниченное пространство IP-адресов.
- Большая часть обмена данными между объектами pod происходит в пределах кластера.
- Дополнительные функции AKS, такие как виртуальные узлы или политика сети Azure, не требуются.  Используйте [политики сети Калико][calico-network-policies].

Используйте *Azure CNI* в следующих случаях:

- У вас есть достаточный диапазон IP-адресов.
- Объекты pod обмениваются данными в основном с ресурсами за пределами кластера.
- Вы не хотите управлять определяемыми пользователем маршрутами для подключения к Pod.
- Вам потребуется AKS дополнительные функции, такие как виртуальные узлы или политика сети Azure.  Используйте [политики сети Калико][calico-network-policies].

Дополнительные сведения о выборе используемой сетевой модели см. в разделе [Сравнение моделей сети и их области поддержки][network-comparisons].

## <a name="create-a-virtual-network-and-subnet"></a>Создание виртуальной сети и подсети

Чтобы приступить к работе с *kubenet* и собственной подсетью виртуальной сети, сначала создайте группу ресурсов с помощью команды [az group create][az-group-create]. В следующем примере создается группа ресурсов с именем *myResourceGroup* в расположении *eastus*.

```azurecli-interactive
az group create --name myResourceGroup --location eastus
```

Если у вас нет существующей виртуальной сети и подсети, создайте эти сетевые ресурсы с помощью команды [az network vnet create][az-network-vnet-create]. В следующем примере виртуальная сеть называется *myVnet* с префиксом адреса *192.168.0.0/16*. Подсеть создается с именем *мякссубнет* с префиксом адреса *192.168.1.0/24*.

```azurecli-interactive
az network vnet create \
    --resource-group myResourceGroup \
    --name myAKSVnet \
    --address-prefixes 192.168.0.0/16 \
    --subnet-name myAKSSubnet \
    --subnet-prefix 192.168.1.0/24
```

## <a name="create-a-service-principal-and-assign-permissions"></a>Создание субъекта-службы и назначение разрешений

Для взаимодействия с API-интерфейсами Azure кластеру AKS требуется субъект-служба Azure Active Directory. Субъект-служба должен иметь разрешения на управление виртуальной сетью и подсетью, которые используются узлами AKS. Создайте субъект-службу с помощью команды [az ad sp create-for-rbac][az-ad-sp-create-for-rbac]:

```azurecli-interactive
az ad sp create-for-rbac --skip-assignment
```

В приведенном ниже примере выходных данных показан идентификатор приложения и пароль для субъекта-службы. Эти значения используются в дополнительных действиях, чтобы назначить роль субъекту-службе, а затем создать кластер AKS:

```azurecli
az ad sp create-for-rbac --skip-assignment
```

```output
{
  "appId": "476b3636-5eda-4c0e-9751-849e70b5cfad",
  "displayName": "azure-cli-2019-01-09-22-29-24",
  "name": "http://azure-cli-2019-01-09-22-29-24",
  "password": "a1024cd7-af7b-469f-8fd7-b293ecbb174e",
  "tenant": "72f998bf-85f1-41cf-92ab-2e7cd014db46"
}
```

Чтобы назначить правильное делегирование в оставшихся действиях, получите необходимые идентификаторы ресурсов с помощью команд [az network vnet show][az-network-vnet-show] и [az network vnet subnet show][az-network-vnet-subnet-show]. Эти идентификаторы ресурсов хранятся как переменные и указываются в оставшихся действиях:

```azurecli-interactive
VNET_ID=$(az network vnet show --resource-group myResourceGroup --name myAKSVnet --query id -o tsv)
SUBNET_ID=$(az network vnet subnet show --resource-group myResourceGroup --vnet-name myAKSVnet --name myAKSSubnet --query id -o tsv)
```

Теперь назначьте субъекту-службе разрешения *участника сети* кластеров AKS в виртуальной сети с помощью команды [AZ Role назначение Create][az-role-assignment-create] . Укажите собственное значение *\<appId>* , как показано в выходных данных предыдущей команды, чтобы создать субъект-службу.

```azurecli-interactive
az role assignment create --assignee <appId> --scope $VNET_ID --role "Network Contributor"
```

## <a name="create-an-aks-cluster-in-the-virtual-network"></a>Создание кластера AKS в виртуальной сети

Вы создали виртуальную сеть и подсеть, а также создали и назначили разрешения для субъекта-службы, чтобы использовать эти сетевые ресурсы. Теперь создайте кластер AKS в виртуальной сети и подсети с помощью команды [az aks create][az-aks-create]. Определите собственный субъект-службу *\<appId>* и *\<password>* , как показано в выходных данных предыдущей команды, чтобы создать субъект-службу.

Приведенные ниже диапазоны IP-адресов также определяются в процессе создания кластера:

* *--service-cidr* используется для назначения IP-адреса внутренним службам в кластере AKS. Этот диапазон IP-адресов должен быть адресным пространством, которое не используется в сетевом окружении, включая любые локальные сети при подключении или планировании подключения к виртуальным сетям Azure с помощью Express Route или VPN-подключения типа "сеть — сеть".

* Адрес *--dns-service-ip* должен быть адресом *.10* диапазона IP-адресов вашей службы.

* Диапазон *--pod-cidr* должен быть большим адресным пространством, которое не используется где-либо еще в сетевой среде. Этот диапазон включает в себя любые локальные сетевые диапазоны при подключении или планировании подключения к виртуальным сетям Azure с помощью Express Route или VPN-подключения типа "сеть — сеть".
    * Этот диапазон адресов должен быть достаточно большим, чтобы вместить количество узлов, до которых вы планируете масштабировать среду. Этот диапазон адресов нельзя изменить после развертывания кластера, если потребуются адреса для дополнительных узлов.
    * Диапазон IP-адресов Pod используется для назначения адресного пространства *(/24* ) каждому узлу в кластере. В следующем примере параметр *--Pod-CIDR* для *10.244.0.0/16* назначает первый узел *10.244.0.0/24* , второй узел *10.244.1.0/24* и третий узел *10.244.2.0/24*.
    * При масштабировании или обновлении кластера платформа Azure продолжает назначать диапазон IP-адресов объектов pod каждому новому узлу.
    
* Параметр *--DOCKER-Bridge-Address* позволяет узлам AKS взаимодействовать с базовой платформой управления. Этот IP-адрес не должен находиться в пределах диапазона IP-адресов виртуальной сети вашего кластера и перекрывать другие диапазоны адресов, используемые в сети.

```azurecli-interactive
az aks create \
    --resource-group myResourceGroup \
    --name myAKSCluster \
    --node-count 3 \
    --network-plugin kubenet \
    --service-cidr 10.0.0.0/16 \
    --dns-service-ip 10.0.0.10 \
    --pod-cidr 10.244.0.0/16 \
    --docker-bridge-address 172.17.0.1/16 \
    --vnet-subnet-id $SUBNET_ID \
    --service-principal <appId> \
    --client-secret <password>
```

> [!Note]
> Если вы хотите включить кластер AKS для включения [политики сети Калико][calico-network-policies] , можно использовать следующую команду.

```azurecli-interactive
az aks create \
    --resource-group myResourceGroup \
    --name myAKSCluster \
    --node-count 3 \
    --network-plugin kubenet --network-policy calico \
    --service-cidr 10.0.0.0/16 \
    --dns-service-ip 10.0.0.10 \
    --pod-cidr 10.244.0.0/16 \
    --docker-bridge-address 172.17.0.1/16 \
    --vnet-subnet-id $SUBNET_ID \
    --service-principal <appId> \
    --client-secret <password>
```

При создании кластера AKS группа безопасности сети и таблица маршрутов создаются автоматически. Эти сетевые ресурсы управляются плоскостью управления AKS. Группа безопасности сети автоматически связывается с виртуальными сетевыми адаптерами на узлах. Таблица маршрутов автоматически связывается с подсетью виртуальной сети. Правила групп безопасности сети и таблицы маршрутов автоматически обновляются по мере создания и предоставления служб.

## <a name="bring-your-own-subnet-and-route-table-with-kubenet"></a>Перенесите собственную подсеть и таблицу маршрутов с помощью кубенет

При использовании кубенет Таблица маршрутов должна существовать в подсетях кластера. AKS поддерживает подключение существующей подсети и таблицы маршрутов.

Если ваша пользовательская подсеть не содержит таблицу маршрутов, AKS создает ее и добавляет к ней правила в течение жизненного цикла кластера. Если пользовательская подсеть содержит таблицу маршрутов при создании кластера, AKS подтверждает существующую таблицу маршрутов во время операций кластера и добавляет или обновляет правила для операций поставщика облачных служб.

> [!WARNING]
> Настраиваемые правила могут быть добавлены в таблицу настраиваемых маршрутов и обновлены. Однако правила добавляются поставщиком облачных служб Kubernetes, которые не должны обновляться или удаляться. Правила, такие как 0.0.0.0/0, должны всегда существовать в данной таблице маршрутов и сопоставляться с целевым объектом шлюза Интернета, например NVA или другим шлюзом исходящего трафика. Будьте внимательны при обновлении правил, изменяемых только настраиваемыми правилами.

Дополнительные сведения о настройке [пользовательской таблицы маршрутов][custom-route-table].

Кубенет Networking требует упорядоченных правил таблицы маршрутов для успешного маршрута запросов. Из-за такой структуры таблицы маршрутов должны быть тщательно сохранены для каждого кластера, который его использует. Несколько кластеров не могут совместно использовать таблицу маршрутов, так как Pod Цидрс из разных кластеров могут перекрываться, что приводит к непредвиденным и нарушенным маршрутизации. При настройке нескольких кластеров в одной виртуальной сети или выделении виртуальной сети для каждого кластера необходимо учитывать следующие ограничения.

Ограничения

* Разрешения должны быть назначены перед созданием кластера. Убедитесь, что вы используете субъект-службу с разрешениями на запись в настраиваемой подсети и пользовательской таблице маршрутов.
* Управляемые удостоверения в настоящее время не поддерживаются для пользовательских таблиц маршрутов в кубенет.
* Перед созданием кластера AKS необходимо связать настраиваемую таблицу маршрутов с подсетью.
* Не удается обновить связанный ресурс таблицы маршрутов после создания кластера. Хотя ресурс таблицы маршрутов невозможно обновить, настраиваемые правила можно изменить в таблице маршрутов.
* Каждый кластер AKS должен использовать одну уникальную таблицу маршрутов для всех подсетей, связанных с кластером. Нельзя повторно использовать таблицу маршрутов с несколькими кластерами из-за возможности перекрытия Цидрс Pod и конфликтующих правил маршрутизации.

После создания настраиваемой таблицы маршрутов и связывания ее с подсетью в виртуальной сети можно создать новый кластер AKS, использующий таблицу маршрутов.
Необходимо использовать идентификатор подсети, где планируется развернуть кластер AKS. Эта подсеть также должна быть связана с пользовательской таблицей маршрутов.

```azurecli-interactive
# Find your subnet ID
az network vnet subnet list --resource-group
                            --vnet-name
                            [--subscription]
```

```azurecli-interactive
# Create a kubernetes cluster with with a custom subnet preconfigured with a route table
az aks create -g MyResourceGroup -n MyManagedCluster --vnet-subnet-id MySubnetID
```

## <a name="next-steps"></a>Дальнейшие действия

При развертывании кластера AKS в подсети существующей виртуальной сети его можно использовать в обычном режиме. Приступите к [созданию приложений с помощью Azure dev Spaces][dev-spaces], [развертыванию существующих приложений с помощью Helm][use-helm]или [созданию новых приложений с помощью Helm][develop-helm].

<!-- LINKS - External -->
[dev-spaces]: ../dev-spaces/index.yml
[cni-networking]: https://github.com/Azure/azure-container-networking/blob/master/docs/cni.md
[kubenet]: https://kubernetes.io/docs/concepts/cluster-administration/network-plugins/#kubenet
[Calico-network-policies]: https://docs.projectcalico.org/v3.9/security/calico-network-policy

<!-- LINKS - Internal -->
[install-azure-cli]: /cli/azure/install-azure-cli
[aks-network-concepts]: concepts-network.md
[az-group-create]: /cli/azure/group#az-group-create
[az-network-vnet-create]: /cli/azure/network/vnet#az-network-vnet-create
[az-ad-sp-create-for-rbac]: /cli/azure/ad/sp#az-ad-sp-create-for-rbac
[az-network-vnet-show]: /cli/azure/network/vnet#az-network-vnet-show
[az-network-vnet-subnet-show]: /cli/azure/network/vnet/subnet#az-network-vnet-subnet-show
[az-role-assignment-create]: /cli/azure/role/assignment#az-role-assignment-create
[az-aks-create]: /cli/azure/aks#az-aks-create
[byo-subnet-route-table]: #bring-your-own-subnet-and-route-table-with-kubenet
[develop-helm]: quickstart-helm.md
[use-helm]: kubernetes-helm.md
[virtual-nodes]: virtual-nodes-cli.md
[vnet-peering]: ../virtual-network/virtual-network-peering-overview.md
[express-route]: ../expressroute/expressroute-introduction.md
[network-comparisons]: concepts-network.md#compare-network-models
[custom-route-table]: ../virtual-network/manage-route-table.md