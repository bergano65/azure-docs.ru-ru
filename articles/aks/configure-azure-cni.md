---
title: Настройка сети Azure CNI в Службе Azure Kubernetes (AKS)
description: Узнайте, как настроить сеть Azure CNI (расширенную) в Службе Azure Kubernetes (AKS), включая развертывание кластера AKS в существующую виртуальную сеть и подсеть.
services: container-service
author: mlearned
ms.service: container-service
ms.topic: article
ms.date: 06/03/2019
ms.author: mlearned
ms.openlocfilehash: 3683c9fa7810083d26527275a1235df5336d1c65
ms.sourcegitcommit: cd70273f0845cd39b435bd5978ca0df4ac4d7b2c
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/18/2019
ms.locfileid: "71097820"
---
# <a name="configure-azure-cni-networking-in-azure-kubernetes-service-aks"></a>Настройка сети Azure CNI в Службе Azure Kubernetes (AKS)

По умолчанию кластеры AKS используют [кубенет][kubenet], и для вас создаются виртуальная сеть и подсеть. При использовании *kubenet* узлы получают IP-адрес из подсети виртуальной сети. Затем настраивается преобразование сетевых адресов (NAT) на узлах, а модули получают IP-адрес, "скрытый" за IP-адресом узла. Такой подход уменьшает количество IP-адресов, которые необходимо зарезервировать в пространстве сети для модулей pod.

Благодаря [сетевому интерфейсу контейнеров Azure (CNI)][cni-networking]каждый модуль получает IP-адрес из подсети, к которому можно получить доступ напрямую. Эти IP-адреса должны быть уникальными во всей сети, и их следует планировать заранее. Для каждого узла предусмотрен параметр конфигурации, в котором указывается максимальное число объектов pod, которые он поддерживает. Затем на каждом узле заранее резервируется эквивалентное число IP-адресов для этого узла. Этот подход требует дополнительного планирования и часто приводит к исчерпанию IP-адресов или необходимости повторно создавать кластеры в подсети большего размера по мере увеличения потребностей вашего приложения.

В этой статье показано, как использовать сеть *Azure CNI*, чтобы создавать и использовать подсеть виртуальной сети для кластера AKS. Дополнительные сведения о сетевых параметрах и вопросах см. в разделе [Основные понятия сети для Kubernetes и AKS][aks-network-concepts].

## <a name="prerequisites"></a>Предварительные требования

* Виртуальная сеть для кластера AKS должна разрешать исходящее подключение к Интернету.
* Не создавайте больше одного кластера AKS в одной подсети.
* Кластеры AKS не могут `169.254.0.0/16`использовать `172.30.0.0/16`, `172.31.0.0/16`, или `192.0.2.0/24` для диапазона адресов службы Kubernetes.
* Субъект-служба, используемый кластером AKS, должен иметь по крайней мере разрешения [Участник сетей](../role-based-access-control/built-in-roles.md#network-contributor) в подсети в виртуальной сети. Если вы хотите определить [пользовательскую роль](../role-based-access-control/custom-roles.md) вместо того, чтобы использовать встроенную роль участника сети, требуются следующие разрешения:
  * `Microsoft.Network/virtualNetworks/subnets/join/action`
  * `Microsoft.Network/virtualNetworks/subnets/read`

## <a name="plan-ip-addressing-for-your-cluster"></a>Планирование назначения IP-адресов для кластера

Для кластеров, настроенных с помощью сети Azure CNI, требуется дополнительное планирование. Размер виртуальной сети и подсети должен быть достаточным для количества контейнеров pod, которые будут одновременно запускаться, а также соответствовать количеству узлов в кластере.

IP-адреса для контейнеров pod и узлов кластера назначаются из определенной подсети в виртуальной сети. Каждый узел настраивается с помощью основного IP-адреса. По умолчанию 30 дополнительных IP-адресов предварительно настроены с помощью CNI Azure, которые назначаются для модулей, которые запланированы на узле. При масштабировании кластера каждый узел настраивается аналогичным образом с использованием IP-адресов из подсети. Вы также можете просмотреть [Максимальное число контейнеров pod на узле](#maximum-pods-per-node).

> [!IMPORTANT]
> При выборе необходимого количества IP-адресов следует учитывать операции обновления и масштабирования. Если задать диапазон IP-адресов, который поддерживает только фиксированное число узлов, обновить или масштабировать кластер будет невозможно.
>
> - При **обновлении** кластера AKS в нем развертывается новый узел. Службы и рабочие нагрузки теперь выполняются на новом узле, а старый узел удаляется из кластера. Для выполнения этого процесса последовательного обновления требуется, чтобы был доступен как минимум один дополнительный блок IP-адресов. Количество узлов будет равно `n + 1`.
>   - Это особенно важно при использовании пулов узлов Windows Server (в настоящее время в предварительной версии в AKS). Узлы Windows Server в AKS не применяют обновления Windows автоматически, вместо этого выполняется обновление пула узлов. Это обновление развертывает новые узлы с помощью последнего образа базового узла и исправлений безопасности для Windows Server 2019. Дополнительные сведения об обновлении пула узлов Windows Server см. в статье [Обновление пула узлов в AKS][nodepool-upgrade].
>
> - При **масштабировании** кластера AKS в него развертывается новый узел. Службы и рабочие нагрузки теперь выполняются на новом узле. При выборе диапазона IP-адресов следует учитывать, как может понадобиться увеличить количество узлов и контейнеров pod, которые кластер может поддерживать. Также следует включить один дополнительный узел для операций обновления. Количество узлов будет равно `n + number-of-additional-scaled-nodes-you-anticipate + 1`.

Если ожидается, что узлы будут запускать максимальное количество контейнеров pod и регулярно уничтожать и развертывать их, также следует учитывать несколько дополнительных IP-адресов на каждом узле. Учтите, что из-за этих дополнительных IP-адресов удаление службы, освобождение IP-адреса для новой службы, развертывание и получение адреса может занять несколько секунд.

План IP-адреса для кластера AKS содержит виртуальную сеть, по крайней мере одну подсеть для узлов и контейнеров pod, а также диапазон адресов службы Kubernetes.

| Диапазон адресов / ресурс Azure | Установления размера и ограничения |
| --------- | ------------- |
| Виртуальная сеть | Виртуальная сеть Azure может достигать размера /8, но ограничиваться 65 536 настроенными IP-адресами. |
| Subnet | Подсеть должна быть достаточно большой, чтобы разместить узлы, контейнеры pod и все ресурсы Kubernetes и Azure, которые могут быть выделены в кластере. Например, если развертывается внутренний Azure Load Balancer, его внешние IP-адреса выделяются из подсети кластера, а не из публичных IP-адресов. При выборе размера подсети следует также учитывать операции обновления учетной записи и будущие потребности в масштабировании.<p />Для вычисления *минимального* размера подсети, включая дополнительный узел для операции обновления, используйте следующую формулу: `(number of nodes + 1) + ((number of nodes + 1) * maximum pods per node that you configure)`.<p/>Пример для кластера из 50 узлов: `(51) + (51  * 30 (default)) = 1,581` (/21 или больше)<p/>Пример для кластера из 50 узлов, в котором предусмотрено увеличение масштаба на 10 дополнительных узлов: `(61) + (61 * 30 (default)) = 1,891` (/21 или больше).<p>Если не указать максимальное число контейнеров pod на каждом узле при создании кластера, оно будет иметь значение *30*. Минимальное число требуемых IP-адресов на основе этого значения. При расчете минимального числа требуемых IP-адресов на другое максимальное значение см. раздел [Настройка максимального числа контейнеров pod на каждом узле](#configure-maximum---new-clusters), чтобы присвоить это значение при развертывании кластера. |
| Диапазон адресов службы Kubernetes | Этот диапазон не должен использоваться элементом виртуальной сети или элементом, подключенным к ней. Адрес службы CIDR должен иметь размер меньше /12. |
| IP-адрес службы доменных имен (DNS) Kubernetes | IP-адрес в пределах диапазона адресов службы Kubernetes, который будет использоваться службой обнаружения кластеров (kube-dns). Не используйте первый IP-адрес из своего диапазона адресов, например .1. Первый адрес в диапазоне подсети используется для адреса *kubernetes.default.svc.cluster.local*. |
| Адрес моста Docker | IP-адрес (в нотации CIDR), используемый в качестве IP-адреса моста Docker на узлах. Эта CIDR привязана к количеству контейнеров на узле. По умолчанию — 172.17.0.1/16. |

## <a name="maximum-pods-per-node"></a>Максимальное число контейнеров pod на узле

Максимальное число модулей Pod на узел в кластере AKS — 250. Максимальное количество контейнеров pod *по умолчанию* для каждого узла зависит от сети *kubenet*, *Azure CNI* и метода развертывания кластера.

| Метод развертывания | По умолчанию Kubenet | По умолчанию Azure CNI | Настройка при развертывании |
| -- | :--: | :--: | -- |
| Azure CLI | 110 | 30 | Да (до 250) |
| Шаблон Resource Manager | 110 | 30 | Да (до 250) |
| Портал | 110 | 30 | Нет |

### <a name="configure-maximum---new-clusters"></a>Настройка максимального числа. Новые кластеры

Вы можете настроить максимальное число элементов pod на узел *только во время развертывания кластера*. При развертывании с Azure CLI или с помощью шаблона диспетчер ресурсов можно задать максимальное значение для каждого узла в 250.

| Сети | Минимум | Максимум |
| -- | :--: | :--: |
| Azure CNI | 30 | 250 |
| кубенет | 30 | 110 |

> [!NOTE]
> Минимальное значение в приведенной выше таблице строго применяется службой AKS. Нельзя задать значение Максподс ниже минимального значения, как это сделать, чтобы предотвратить запуск кластера.

* **Azure CLI.** Укажите аргумент при развертывании кластера с помощью команды [AZ AKS Create.][az-aks-create] `--max-pods` Максимальное значение — 250.
* **Шаблон Resource Manager.** При развертывании кластера с помощью шаблона Resource Manager укажите в объекте [ManagedClusterAgentPoolProfile] свойство `maxPods`. Максимальное значение — 250.
* **Портал Azure**: При развертывании кластера с помощью портала Azure изменить максимальное количество элементов pod на узел невозможно. Кластеры сети Azure CNI ограничены 30 моделями pod на узел при развертывании с помощью портала Azure.

### <a name="configure-maximum---existing-clusters"></a>Настройка максимального числа. Имеющиеся кластеры

Невозможно изменить максимальное количество контейнеров pod на узле в имеющемся кластере AKS. Вы можете изменить количество только во время изначального развертывания кластера.

## <a name="deployment-parameters"></a>Параметры развертывания

При создании кластера AKS для сети Azure CNI можно настроить следующие параметры.

**Виртуальная сеть.** Виртуальная сеть, в которую нужно развернуть кластер Kubernetes. Если для кластера необходимо создать новую виртуальную сеть, выберите *Создать новый* и следуйте инструкциям раздела *Создание виртуальной сети*. Дополнительные сведения об ограничениях и квотах для виртуальной сети Azure см. в статье [Подписка Azure, границы, квоты и ограничения службы](../azure-subscription-service-limits.md#azure-resource-manager-virtual-networking-limits).

**Подсеть.** Подсеть виртуальной сети, в которую нужно развернуть кластер. Если для кластера необходимо создать подсеть в виртуальной сети, выберите *Создать новый* и следуйте инструкциям раздела *Создание подсети*. Для гибридных подключений диапазон адресов не должен перекрываться другими виртуальными сетями в среде.

**Диапазон адресов службы Kubernetes.** Это набор виртуальных IP-адресов, которые Kubernetes назначает внутренним [службам][services] в кластере. Можно использовать любой диапазон частных адресов, который отвечает следующим требованиям:

* Должен быть за пределами диапазона IP-адресов виртуальной сети вашего кластера.
* Не должен пересекаться с диапазоном других виртуальных сетей, с которыми связан кластер виртуальной сети.
* не должен перекрываться с какими-либо локальными IP-адресами.
* Не должно находиться в диапазоне `169.254.0.0/16` `172.31.0.0/16`, `172.30.0.0/16`, или`192.0.2.0/24`

Не рекомендуется указывать диапазон адресов службы в той же виртуальной сети, что и кластер, хотя технически это возможно. Перекрывающиеся диапазоны IP-адресов могут привести к непредсказуемому поведению. Дополнительные сведения см. в разделе этой статьи [с вопросами и ответами](#frequently-asked-questions). Дополнительные сведения о Kubernetes Services см. в разделе [службы][services] в документации Kubernetes.

**IP-адрес службы доменных имен (DNS) Kubernetes.**  IP-адрес службы доменных имен (DNS) кластера. Этот адрес должен быть в пределах *диапазона адресов службы Kubernetes*. Не используйте первый IP-адрес из своего диапазона адресов, например .1. Первый адрес в диапазоне подсети используется для адреса *kubernetes.default.svc.cluster.local*.

**Адрес моста Docker.** Сетевой адрес моста DOCKER представляет сетевой адрес моста *docker0* по умолчанию, который имеется во всех установках DOCKER. Хотя мост *docker0* не используется кластерами AKS или модулями Pod, необходимо задать этот адрес, чтобы продолжить поддержку таких сценариев, как *Сборка DOCKER* в кластере AKS. Необходимо выбрать CIDR для сетевого адреса моста DOCKER, так как в противном случае DOCKER выберет подсеть автоматически, которая может конфликтовать с другими Цидрс. Необходимо выбрать адресное пространство, не конфликтующее с остальной частью Цидрс в ваших сетях, включая службу кластера CIDR и CIDR.

## <a name="configure-networking---cli"></a>Настройка сети с помощью интерфейса командной строки

При создании кластера AKS с помощью Azure CLI вы можете также настроить сеть Azure CNI. Используйте указанные ниже команды для создания кластера AKS с включенной сетью Azure CNI.

Сначала получите идентификатор ресурса существующей подсети, к которой будет присоединен кластер AKS.

```azurecli-interactive
$ az network vnet subnet list \
    --resource-group myVnet \
    --vnet-name myVnet \
    --query "[0].id" --output tsv

/subscriptions/<guid>/resourceGroups/myVnet/providers/Microsoft.Network/virtualNetworks/myVnet/subnets/default
```

Используйте команду [AZ AKS Create][az-aks-create] с `--network-plugin azure` аргументом, чтобы создать кластер с расширенными сетевыми возможностями. Измените значение `--vnet-subnet-id`, указав идентификатор подсети, полученный на предыдущем шаге.

```azurecli-interactive
az aks create \
    --resource-group myResourceGroup \
    --name myAKSCluster \
    --network-plugin azure \
    --vnet-subnet-id <subnet-id> \
    --docker-bridge-address 172.17.0.1/16 \
    --dns-service-ip 10.2.0.10 \
    --service-cidr 10.2.0.0/24 \
    --generate-ssh-keys
```

## <a name="configure-networking---portal"></a>Настройка сети с помощью портала

На следующем снимке экрана на портале Azure показан пример настройки этих параметров во время создания кластера AKS.

![Конфигурация расширенного сетевого взаимодействия на портале Azure][portal-01-networking-advanced]

## <a name="frequently-asked-questions"></a>Часто задаваемые вопросы

Следующие вопросы и ответы относятся к конфигурации сети **Azure CNI**.

* *Можно ли развернуть виртуальные машины в подсети моего кластера?*

  Нет. Развертывание виртуальных машин в подсети, используемой кластером Kubernetes, не поддерживается. Виртуальные машины можно развернуть в одной и той же виртуальной сети, но в разных подсетях.

* *Можно ли настроить политики сети для каждого контейнера pod?*

  Да, сетевая политика Kubernetes доступна в AKS. Чтобы приступить к работе, см. раздел Защита трафика между модулями Pod с [помощью сетевых политик в AKS][network-policy].

* *Можно ли настроить максимальное число контейнеров pod, развертываемых на узел?*

  Да, при развертывании кластера с помощью Azure CLI или шаблона Resource Manager. См. статью [Конфигурация сети в службе Azure Kubernetes (AKS)](#maximum-pods-per-node).

  Невозможно изменить максимальное количество контейнеров pod в узле в имеющемся кластере.

* *Как настроить дополнительные свойства для подсети, созданной во время создания кластера AKS? Например, конечные точки службы.*

  Полный список свойств для виртуальной сети и подсетей, создаваемых во время создания кластера AKS, можно настроить на странице стандартной конфигурации виртуальной сети на портале Azure.

* *Можно ли использовать другую подсеть в виртуальной сети кластера для* **диапазона адресов службы Kubernetes**?

  Не рекомендуется, но эта конфигурация возможна. Диапазон адресов службы — это набор виртуальных IP-адресов, которые Kubernetes присваивает внутренним службам в кластере. Сеть Azure не видит адреса в диапазоне IP-адресов службы кластера Kubernetes. Из-за этого позже возможно создать подсеть в виртуальной сети кластера, которая пересекается с диапазоном адресов службы. При возникновении такого пересекания Kubernetes может присвоить службе IP-адрес, который уже используется другим ресурсом в подсети, что приводит к непредсказуемому поведению или сбоям. Убедившись, что диапазон адресов используется за пределами виртуальной сети кластера, можно избежать такого риска пересечений.

## <a name="next-steps"></a>Следующие шаги

Узнайте больше о сетевом взаимодействии в AKS из следующих статей:

- [Использование статического IP-адреса с подсистемой балансировки нагрузки Службы контейнеров Azure (AKS)](static-ip.md)
- [Использование внутренней подсистемы балансировки нагрузки со Службой контейнеров Azure (AKS)](internal-lb.md)

- [Создание базового контроллера входящего трафика с внешним сетевым подключением][aks-ingress-basic]
- [Включение надстройки маршрутизации приложений HTTP][aks-http-app-routing]
- [Создание контроллера входящего трафика, использующего внутреннюю, частную сеть и IP-адрес][aks-ingress-internal]
- [Создание контроллера входящего трафика с динамическим общедоступным IP-адресом и Настройка шифрования для автоматического создания сертификатов TLS][aks-ingress-tls]
- [Создание контроллера входящего трафика со статическим общедоступным IP-адресом и Настройка шифрования для автоматического создания сертификатов TLS][aks-ingress-static-tls]

### <a name="aks-engine"></a>Обработчик AKS

[Подсистема Azure Kubernetes Service Engine (подсистема AKS)][aks-engine] — это проект с открытым кодом, который создает шаблоны Azure Resource Manager, которые можно использовать для развертывания кластеров Kubernetes в Azure.

Кластеры Kubernetes, созданные с помощью подсистемы AKS, поддерживают подключаемые модули [кубенет][kubenet] и [Azure CNI][cni-networking] . Таким образом, обработчик AKS поддерживает оба сценария сети.

<!-- IMAGES -->
[advanced-networking-diagram-01]: ./media/networking-overview/advanced-networking-diagram-01.png
[portal-01-networking-advanced]: ./media/networking-overview/portal-01-networking-advanced.png

<!-- LINKS - External -->
[aks-engine]: https://github.com/Azure/aks-engine
[services]: https://kubernetes.io/docs/concepts/services-networking/service/
[portal]: https://portal.azure.com
[cni-networking]: https://github.com/Azure/azure-container-networking/blob/master/docs/cni.md
[kubenet]: https://kubernetes.io/docs/concepts/cluster-administration/network-plugins/#kubenet

<!-- LINKS - Internal -->
[az-aks-create]: /cli/azure/aks?view=azure-cli-latest#az-aks-create
[aks-ssh]: ssh.md
[ManagedClusterAgentPoolProfile]: /azure/templates/microsoft.containerservice/managedclusters#managedclusteragentpoolprofile-object
[aks-network-concepts]: concepts-network.md
[aks-ingress-basic]: ingress-basic.md
[aks-ingress-tls]: ingress-tls.md
[aks-ingress-static-tls]: ingress-static-ip.md
[aks-http-app-routing]: http-application-routing.md
[aks-ingress-internal]: ingress-internal-ip.md
[network-policy]: use-network-policies.md
[nodepool-upgrade]: use-multiple-node-pools.md#upgrade-a-node-pool
[network-comparisons]: concepts-network.md#compare-network-models
