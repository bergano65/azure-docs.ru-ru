---
title: Проверка пропускной способности VPN для виртуальной сети Microsoft Azure | Документы Майкрософт
description: Этот документ помогает пользователю проверить пропускную способность сети от своих локальных ресурсов до виртуальной машины Azure.
services: vpn-gateway
author: cherylmc
manager: jasmc
ms.service: vpn-gateway
ms.topic: troubleshooting
ms.date: 05/29/2019
ms.author: radwiv
ms.reviewer: chadmat;genli
ms.openlocfilehash: 1531bbe97c842fbae2ffe7df41f19a3a7be689d5
ms.sourcegitcommit: 920ad23613a9504212aac2bfbd24a7c3de15d549
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/15/2019
ms.locfileid: "68228339"
---
# <a name="how-to-validate-vpn-throughput-to-a-virtual-network"></a>Порядок проверки пропускной способности VPN для виртуальной сети

Подключение к VPN-шлюзу позволяет установить защищенное распределенное соединение между виртуальной сетью в Azure и локальной ИТ-инфраструктурой.

В этой статье описано, как проверить пропускную способность сети от локальных ресурсов до виртуальной машины Azure.

> [!NOTE]
> Эта статья помогает диагностировать и устранить распространенные проблемы. Если вам не удается решить проблему с помощью приведенных ниже сведений, [обратитесь в службу поддержки](https://portal.azure.com/?#blade/Microsoft_Azure_Support/HelpAndSupportBlade).

## <a name="overview"></a>Обзор

Подключение к VPN-шлюзу состоит из следующих компонентов:

* Локальное VPN-устройство (просмотрите список проверенных [VPN-устройств](vpn-gateway-about-vpn-devices.md#devicetable)).
* Общедоступный Интернет
* VPN-шлюз Azure
* Azure

На следующей схеме показано логическое подключение между локальной сетью и виртуальной сетью Azure через VPN.

![Логическое подключение сети клиента к сети MSFT с помощью VPN](./media/vpn-gateway-validate-throughput-to-vnet/VPNPerf.png)

## <a name="calculate-the-maximum-expected-ingressegress"></a>Расчет максимального ожидаемого исходящего и входящего трафика

1. Определите базовые требования приложения к пропускной способности.
1. Определите предел пропускной способности для VPN-шлюза Azure. Дополнительные сведения см. в разделе "номера SKU шлюзов" раздела [о VPN-шлюзе](vpn-gateway-about-vpngateways.md#gwsku).
1. Определите [рекомендованную пропускную способность](../virtual-machines/virtual-machines-windows-sizes.md) для используемого размера виртуальной машины Azure.
1. Определите пропускную способность поставщика услуг Интернета (ISP).
1. Вычислите ожидаемую пропускную способность, выполнив наименьшую пропускную способность виртуальной машины, VPN-шлюза или поставщика услуг Интернета. измеряется в Мбит/с (/), деленная на восемь (8).

Если вычисленная пропускная способность не соответствует требованиям базовой пропускной способности приложения, необходимо увеличить пропускную способность ресурса, который вы определили как узкое место. Чтобы изменить размер VPN-шлюза Azure, см. статью [Изменение SKU шлюза](vpn-gateway-about-vpn-gateway-settings.md#gwsku). Чтобы изменить размер виртуальной машины, см. статью [Изменение размера виртуальной машины](../virtual-machines/virtual-machines-windows-resize-vm.md). Если вы не столкнулись с ожидаемой пропускной способностью Интернета, вы также можете обратиться к поставщику услуг Интернета.

> [!NOTE]
> Пропускная способность VPN-шлюза — это совокупность всех Сите-то-сите\внет-то-внет или подключений типа "точка — сеть".

## <a name="validate-network-throughput-by-using-performance-tools"></a>Проверка пропускной способности сети с помощью средств повышения производительности

Эту проверку следует выполнять в часы пониженной нагрузки, так как насыщенность пропускной способности туннеля VPN при тестировании не позволяет получить точные результаты.

Для этого теста мы используем средство iPerf, которое работает в Windows и Linux, а также имеет режимы клиента и сервера. Он ограничен 3Gbps для виртуальных машин Windows.

Это средство не выполняет операции чтения и записи на диск. Оно лишь создает самостоятельно сформированный TCP-трафик с одного конца на другой. Она создает статистику на основе эксперимента, которая измеряет пропускную способность, доступную между узлами клиента и сервера. При тестировании между двумя узлами один узел выступает в качестве сервера, а другой узел выступает в качестве клиента. После завершения этого теста рекомендуется обратить роли узлов, чтобы протестировать пропускную способность для загрузки и загрузки на обоих узлах.

### <a name="download-iperf"></a>Скачивание iPerf

Скачайте [iPerf](https://iperf.fr/download/iperf_3.1/iperf-3.1.2-win64.zip). Дополнительные сведения см. в [документации по iPerf](https://iperf.fr/iperf-doc.php).

 > [!NOTE]
 > Продукты сторонних производителей, обсуждаемые в этой статье, изготовлены компаниями, которые не зависят от корпорации Майкрософт. Корпорация Майкрософт не дает никаких гарантий, явных или подразумеваемых, относительно производительности или надежности таких продуктов.

### <a name="run-iperf-iperf3exe"></a>Запуск iPerf (iperf3.exe)

1. Включите правило NSG/ACL, разрешающее такой трафик (для тестирования общедоступного IP-адреса на виртуальной машине Azure).

1. На обоих узлах включите исключение брандмауэра для порта 5001.

   **Windows:** Выполните следующую команду от имени администратора:

   ```CMD
   netsh advfirewall firewall add rule name="Open Port 5001" dir=in action=allow protocol=TCP localport=5001
   ```

   Чтобы удалить правило после окончания тестирования, выполните следующую команду:

   ```CMD
   netsh advfirewall firewall delete rule name="Open Port 5001" protocol=TCP localport=5001
   ```

   **Azure Linux:** Образы Linux в Azure имеют разрешающие брандмауэры. Когда приложение прослушивает порт, прохождение трафика разрешается. Для защищенных пользовательских образов может потребоваться явно открыть нужные порты. В число распространенных брандмауэров уровня ОС для Linux входят `iptables`, `ufw` и `firewalld`.

1. На узле сервера перейдите в каталог, куда извлекается iperf3.exe. Затем запустите iPerf в режиме сервера и настройте его для прослушивания порта 5001 в виде следующих команд:

   ```CMD
   cd c:\iperf-3.1.2-win65

   iperf3.exe -s -p 5001
   ```

   > [!Note]
   > Порт 5001 можно настроить для учета определенных ограничений брандмауэра в вашей среде.

1. На узле клиента перейдите в каталог, куда извлекается средство iperf, и выполните следующую команду:

   ```CMD
   iperf3.exe -c <IP of the iperf Server> -t 30 -p 5001 -P 32
   ```

   Клиент направляет на сервер 30 секунд трафика через порт 5001. Флаг "-P" указывает на то, что мы создаем 32 одновременных подключений к узлу сервера.

   Ниже представлены выходные данные для этого примера:

   ![Вывод](./media/vpn-gateway-validate-throughput-to-vnet/06theoutput.png)

1. (НЕОБЯЗАТЕЛЬНО) Чтобы сохранить результаты тестирования, выполните следующую команду:

   ```CMD
   iperf3.exe -c IPofTheServerToReach -t 30 -p 5001 -P 32  >> output.txt
   ```

1. После выполнения описанных выше действий выполните те же действия с ролями в обратном порядке, чтобы узел сервера стал клиентским узлом, и наоборот.

> [!Note]
> Iperf — не единственный инструмент. [NTTTCP — это альтернативное решение для тестирования](https://docs.microsoft.com/azure/virtual-network/virtual-network-bandwidth-testing).

## <a name="test-vms-running-windows"></a>Тестирование виртуальных машин под Windows

### <a name="load-latteexe-onto-the-vms"></a>Загрузка латте. exe на виртуальные машины

Скачайте последнюю версию [латте. exe.](https://gallery.technet.microsoft.com/Latte-The-Windows-tool-for-ac33093b)

Рассмотрите возможность помещения латте. exe в отдельную папку, например`c:\tools`

### <a name="allow-latteexe-through-the-windows-firewall"></a>Разрешить латте. exe через брандмауэр Windows

На приемнике создайте правило разрешения в брандмауэре Windows, чтобы разрешить поступление трафика латте. exe. Проще всего разрешать всей программе латте. exe по имени, а не разрешать передачу конкретных TCP-портов.

### <a name="allow-latteexe-through-the-windows-firewall-like-this"></a>Разрешить латте. exe через брандмауэр Windows, как это сделать

`netsh advfirewall firewall add rule program=<PATH>\latte.exe name="Latte" protocol=any dir=in action=allow enable=yes profile=ANY`

Например, если вы скопировали латте. exe в папку «c:\Tools», это будет команда

`netsh advfirewall firewall add rule program=c:\tools\latte.exe name="Latte" protocol=any dir=in action=allow enable=yes profile=ANY`

### <a name="run-latency-tests"></a>Запуск тестов задержки

Запустите латте. exe на ПРИЕМНИКе (запустите из CMD-файла, а не из PowerShell):

`latte -a <Receiver IP address>:<port> -i <iterations>`

Вокруг предел 65 тысяч итераций достаточно долго, чтобы возвращать репрезентативные результаты.

Любой доступный номер порта прекрасно подходит.

Если виртуальная машина имеет IP-адрес 10.0.0.4, она будет выглядеть следующим образом:

`latte -c -a 10.0.0.4:5005 -i 65100`

Запуск латте. exe на отправителю (запуск из CMD, а не из PowerShell)

`latte -c -a <Receiver IP address>:<port> -i <iterations>`

Результирующая команда такая же, как и в получателе, за исключением добавления "-c" для указания на то, что это "клиент" или "отправитель"

`latte -c -a 10.0.0.4:5005 -i 65100`

Дождитесь результатов. В зависимости от того, насколько далеко находятся виртуальные машины, выполнение может занять несколько минут. Рекомендуется начинать с меньшего количества итераций для проверки успешности перед выполнением длинных тестов.

## <a name="test-vms-running-linux"></a>Тестирование виртуальных машин под управлением Linux

Используйте [соккперф](https://github.com/mellanox/sockperf) для тестирования виртуальных машин.

### <a name="install-sockperf-on-the-vms"></a>Установка Соккперф на виртуальных машинах

На виртуальных машинах Linux (как отправитель, так и получатель) выполните следующие команды, чтобы подготовить Соккперф на виртуальных машинах.

#### <a name="centos--rhel---install-git-and-other-helpful-tools"></a>CentOS/RHEL — установка GIT и другие полезные средства

`sudo yum install gcc -y -q`
`sudo yum install git -y -q`
`sudo yum install gcc-c++ -y`
`sudo yum install ncurses-devel -y`
`sudo yum install -y automake`

#### <a name="ubuntu---install-git-and-other-helpful-tools"></a>Ubuntu. Установка GIT и других полезных средств

`sudo apt-get install build-essential -y`
`sudo apt-get install git -y -q`
`sudo apt-get install -y autotools-dev`
`sudo apt-get install -y automake`

#### <a name="bash---all"></a>Bash-ALL

Из командной строки bash (предполагается, что Git установлен)

`git clone https://github.com/mellanox/sockperf`
`cd sockperf/`
`./autogen.sh`
`./configure --prefix=`

Выполнение выполняется медленнее, может занять несколько минут

`make`

Сделать установку быстрой

`sudo make install`

### <a name="run-sockperf-on-the-vms"></a>Запуск Соккперф на виртуальных машинах

#### <a name="sample-commands-after-installation-serverreceiver---assumes-servers-ip-is-10004"></a>Примеры команд после установки. Сервер или получатель — предполагается, что IP-адрес сервера — 10.0.0.4

`sudo sockperf sr --tcp -i 10.0.0.4 -p 12345 --full-rtt`

#### <a name="client---assumes-servers-ip-is-10004"></a>Клиент — предполагается, что IP-адрес сервера — 10.0.0.4

`sockperf ping-pong -i 10.0.0.4 --tcp -m 1400 -t 101 -p 12345  --full-rtt`

> [!Note]
> Убедитесь в отсутствии промежуточных прыжков (например, виртуального устройства) во время проверки пропускной способности между виртуальной машиной и шлюзом.
> В случае неудовлетворительных результатов (с точки зрения общей пропускной способности), поступающих из предыдущих тестов iPERF/NTTTCP, ознакомьтесь со следующей статьей, чтобы понять основные факторы, которые следует учитывать при возникновении возможных корневых причин проблемы. https://docs.microsoft.com/azure/virtual-network/virtual-network-tcpip-performance-tuning

В частности, анализ трассировок записи пакетов (Wireshark/сетевой монитор), собранных параллельно от клиента и сервера во время этих тестов, поможет в оценке неисправной производительности. Эти трассировки могут включать потери пакетов, высокую задержку, размер MTU. фрагментация, окно TCP 0, фрагменты неупорядоченного кода и т. д.

## <a name="address-slow-file-copy-issues"></a>Решение проблем с низкой скоростью при копировании файлов

Даже если общая пропускная способность, оцененная с помощью предыдущих шагов (iPERF/NTTTCP/и т. д.), была хорошей, вы можете столкнуться с задержкой файлов скопировав при использовании проводника или при перетаскивании через сеанс RDP. Обычно эта проблема вызвана одним или обоими следующими факторами:

* Приложения для копирования файлов, такие как проводник и RDP, не используют несколько потоков при копировании. Для повышения производительности используйте многопоточное приложение, например [Richcopy](https://technet.microsoft.com/magazine/2009.04.utilityspotlight.aspx), которое копирует файлы с помощью 16 или 32 потоков. Чтобы изменить число используемых потоков в Richcopy, выберите **Action** (Действие) > **Copy options** (Параметры копирования) > **File copy** (Копирование файлов).

   ![Проблемы с задержкой копирования файлов](./media/vpn-gateway-validate-throughput-to-vnet/Richcopy.png)<br>

   > [!Note]
   > Не все приложения работают одинаково, а не все приложения и процессы используют все потоки. При выполнении теста можно увидеть, что некоторые потоки пусты и не будут предоставлять точные результаты пропускной способности.
   > Чтобы проверить производительность передачи файлов приложения, используйте многопоточность, увеличив число потоков в ходе последующего или уменьшения, чтобы найти оптимальную пропускную способность передачи приложения или файла.

* Недостаточная скорость чтения и записи виртуальной машины. Дополнительные сведения см. в статье [Устранение неполадок службы хранилища Azure](../storage/common/storage-e2e-troubleshooting.md).

## <a name="on-premises-device-external-facing-interface"></a>Внешний интерфейс для локального устройства

Упоминали подсети локальных диапазонов, которые должны быть доступны в Azure через VPN в шлюзе локальной сети. Одновременно определите адресное пространство виртуальной сети в Azure для локального устройства.

* **Шлюз на основе маршрута**: Политика или селектор трафика для VPN на основе маршрутов настроены как «любой — к — любому» (или подстановочные знаки).

* **Шлюз на основе политики**: VPN на основе политики шифруют и направляют пакеты через туннели IPsec на основе комбинаций префиксов адресов между местной сетью и виртуальной сетью Azure. Политика (или селектор трафика) обычно определяется как список доступа в конфигурации VPN.

* Подключения **усеполицибаседтраффикселектор** : ("UsePolicyBasedTrafficSelectors". чтобы $true подключения, Настройте VPN-шлюз Azure для подключения к БРАНДМАУЭРу VPN на основе политики в локальной среде. При включении PolicyBasedTrafficSelectors необходимо убедиться, что у VPN-устройства есть соответствующие селекторы трафика, определенные с помощью всех сочетаний префиксов локальной сети (локального сетевого шлюза), и из префиксов виртуальной сети Azure, а не Any-To-Any.

Неправильная конфигурация может привести к частому отключению в туннеле, падению пакета, неверной пропускной способности и задержке.

## <a name="check-latency"></a>Проверить задержку

Можно проверить задержку с помощью следующих средств:

* винмтр
* ткптрацерауте
* `ping`и `psping` (эти средства могут обеспечить хорошую оценку RTT, но их нельзя использовать во всех случаях).

![Проверить задержку](./media/vpn-gateway-validate-throughput-to-vnet/08checkinglatency.png)

Если вы заметили пиковую задержку на любом из прыжков перед вводом магистрали сети MS, вы можете продолжить дальнейшее расследование с поставщиком услуг Интернета.

Если большое и необычное увеличение задержки Заметится с прыжков в "msn.net", обратитесь в службу поддержки Майкрософт для дальнейшего исследования.

## <a name="next-steps"></a>Следующие шаги

Для получения дополнительных сведений или справки ознакомьтесь со следующей ссылкой:

* [Служба технической поддержки Майкрософт](https://portal.azure.com/?#blade/Microsoft_Azure_Support/HelpAndSupportBlade)
