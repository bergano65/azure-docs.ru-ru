---
title: Преобразование данных с помощью потока данных сопоставления управляемой виртуальной сети фабрики данных Azure
description: В этом руководстве содержатся пошаговые инструкции по использованию фабрики данных Azure для преобразования данных с помощью потоков данных сопоставления.
author: dcstwh
ms.author: weetok
ms.reviewer: makromer
ms.service: data-factory
ms.topic: conceptual
ms.custom: seo-lt-2019
ms.date: 01/15/2021
ms.openlocfilehash: a5c93244862d72f9c8ea2928c41e699302b1752b
ms.sourcegitcommit: 25d1d5eb0329c14367621924e1da19af0a99acf1
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/16/2021
ms.locfileid: "98249449"
---
# <a name="transform-data-securely-by-using-mapping-data-flow"></a>Безопасное преобразование данных с помощью потока данных сопоставления

[!INCLUDE[appliesto-adf-xxx-md](includes/appliesto-adf-xxx-md.md)]

Если вы еще не работали с фабрикой данных Azure, ознакомьтесь со статьей [Введение в фабрику данных Azure](./introduction.md).

В этом руководстве вы будете использовать пользовательский интерфейс фабрики данных для создания конвейера, который копирует и преобразует данные *из источника Azure Data Lake Storage 2-го поколения в приемник Data Lake Storage 2-го поколения (разрешающий доступ только к выбранным сетям)* с помощью сопоставления потока данных в [виртуальной сети, управляемой фабрикой данных](managed-virtual-network-private-endpoint.md). Вы можете развернуть шаблон конфигурации в этом учебнике при преобразовании данных с помощью сопоставления потока данных.

Вот какие шаги выполняются в этом руководстве:

> [!div class="checklist"]
>
> * Создали фабрику данных.
> * Создание конвейера с действием потока данных.
> * Создание потока данных сопоставления с четырьмя преобразованиями.
> * тестовый запуск конвейера;
> * Наблюдение за действием потока данных.

## <a name="prerequisites"></a>Предварительные требования

* **Подписка Azure**. Если у вас еще нет подписки Azure, создайте [бесплатную учетную запись](https://azure.microsoft.com/free/) Azure, прежде чем начинать работу.
* **Учетная запись хранения Azure**. Data Lake Storage используется в качестве хранилища данных *источника* и *приемника* . Если у вас нет учетной записи хранения, создайте ее, следуя действиям в [этом разделе](../storage/common/storage-account-create.md?tabs=azure-portal). *Убедитесь, что получить доступ к учетной записи хранения можно только из выбранных сетей.* 

Файл, который будет преобразован в этом учебнике, moviesDB.csv, который можно найти на [сайте содержимого GitHub](https://raw.githubusercontent.com/djpmsft/adf-ready-demo/master/moviesDB.csv). Чтобы получить файл из GitHub, скопируйте его содержимое в текстовый редактор по своему усмотрению, чтобы сохранить его локально в виде CSV-файла. Сведения о передаче файла в учетную запись хранения см. [в разделе Отправка больших двоичных объектов с помощью портал Azure](../storage/blobs/storage-quickstart-blobs-portal.md). Примеры будут ссылаться на контейнер с именем **Sample-Data**.

## <a name="create-a-data-factory"></a>Создание фабрики данных

На этом шаге вы создадите фабрику данных и откроете пользовательский интерфейс фабрики данных, чтобы создать конвейер в фабрике данных.

1. Откройте Microsoft Edge или Google Chrome. Сейчас только эти браузеры поддерживают пользовательский интерфейс фабрики данных.
1. В меню слева выберите **Создать ресурс** > **Аналитика** > **Фабрика данных**.
1. На странице **Новая фабрика данных** в поле **Имя** введите **ADFTutorialDataFactory**.

   Имя фабрики данных должно быть *глобально уникальным*. Если вы увидите следующую ошибку касательно значения имени, введите другое имя фабрики данных (например, yournameADFTutorialDataFactory). Дополнительные сведения о правилах именования артефактов фабрики данных см. в статье [Фабрика данных Azure — правила именования](naming-rules.md).

1. Выберите **подписку** Azure, в рамках которой вы хотите создать фабрику данных.
1. Для **группы ресурсов** выполните одно из следующих действий:

    * Выберите **Использовать существующую** и укажите существующую группу ресурсов в раскрывающемся списке.
    * Выберите **Создать новую** и укажите имя группы ресурсов. 
         
    Сведения о группах ресурсов см. в статье [Общие сведения об Azure Resource Manager](../azure-resource-manager/management/overview.md). 
1. В качестве **версии** выберите **V2**.
1. В поле **Расположение** выберите расположение фабрики данных. В раскрывающемся списке отображаются только поддерживаемые расположения. Хранилища данных (например, служба хранилища Azure и база данных SQL Azure) и расчеты (например, Azure HDInsight), используемые фабрикой данных, могут находиться в других регионах.

1. Нажмите кнопку **создания**.
1. После завершения создания вы увидите уведомление в центре уведомлений. Выберите **Перейти к ресурсу**, чтобы открыть страницу **фабрики данных**.
1. Выберите **Создание и мониторинг**, чтобы запустить на отдельной вкладке пользовательский интерфейс фабрики данных.

## <a name="create-an-azure-ir-in-data-factory-managed-virtual-network"></a>Создание Azure IR в виртуальной сети, управляемой фабрикой данных

На этом шаге вы создадите Azure IR и включите управляемую виртуальную сеть фабрики данных.

1. На портале фабрики данных перейдите к разделу **Управление** и **выберите Создать, чтобы** создать новый Azure IR.

   ![Снимок экрана, показывающий создание нового Azure IR.](./media/tutorial-copy-data-portal-private/create-new-azure-ir.png)
1. На странице **Настройка среды выполнения интеграции** выберите, какую среду выполнения интеграции следует создать на основе требуемых возможностей. В этом руководстве выберите **Azure,** локальное размещение и нажмите кнопку **продолжить**. 
1. Выберите **Azure** и нажмите кнопку **"продолжить"** , чтобы создать среду выполнения интеграции Azure.

   ![Снимок экрана, на котором показано новое Azure IR.](./media/tutorial-copy-data-portal-private/azure-ir.png)

1. В разделе **Virtual network configuration (Preview)** (Конфигурация виртуальной сети (предварительная версия)) выберите **Включить**.

   ![Снимок экрана, показывающий включение нового Azure IR.](./media/tutorial-copy-data-portal-private/enable-managed-vnet.png)

1. Щелкните **Создать**.

## <a name="create-a-pipeline-with-a-data-flow-activity"></a>Создание конвейера с действием потока данных

На этом шаге вы создадите конвейер, содержащий действие потока данных.

1. На странице **Начало работы** выберите **Create pipeline** (Создать конвейер).

   ![Снимок экрана: создание конвейера.](./media/doc-common-process/get-started-page.png)

1. На панели свойств конвейера введите **трансформмовиес** в поле имя конвейера.
1. На верхней панели фабрики подвиньте ползунок **Отладка потока данных** на. Режим отладки позволяет выполнять интерактивное тестирование логики преобразования в динамическом кластере Spark. Для прогрева кластеров потоков данных требуется пять – семь минут. Сначала включите **отладку потока данных** , если планируется разработка потока данных. Дополнительные сведения см. в разделе [режим отладки](./concepts-data-flow-debug-mode.md).

    ![Снимок экрана, на котором показан ползунок отладки потока данных.](media/tutorial-data-flow-private/dataflow-debug.png)
1. В области **действия** разверните узел **Перемещение и преобразование**. Перетащите действие **поток данных** из панели на холст конвейера.

1. Во всплывающем окне **Добавление потока данных** выберите **создать новый поток данных** , а затем выберите **сопоставление потока данных**. По завершении нажмите кнопку **ОК** .

    ![Снимок экрана, показывающий поток данных сопоставления.](media/tutorial-data-flow-private/mapping-dataflow.png)

1. Назовите **трансформмовиес** потока данных на панели Свойства.

## <a name="build-transformation-logic-in-the-data-flow-canvas"></a>Логика преобразования "сборка" на холсте потока данных

После создания потока данных он будет автоматически отправлен на холст потока данных. На этом шаге вы создадите поток данных, который принимает moviesDB.csvный файл в Data Lake Storage и суммирует среднюю оценку комедиес с 1910 до 2000. Затем этот файл будет записан обратно в Data Lake Storage.

### <a name="add-the-source-transformation"></a>Добавление преобразования «источник»

На этом шаге вы настроите Data Lake Storage 2-го поколения в качестве источника.

1. В холсте потока данных добавьте источник, выбрав поле **Добавить источник** .

1. Присвойте имя исходному **мовиесдб**. Выберите **создать** , чтобы создать новый исходный набор данных.

1. Выберите **Azure Data Lake Storage 2-го поколения** и нажмите кнопку **продолжить**.

1. Выберите **DelimitedText** и нажмите кнопку **продолжить**.

1. Назовите свой набор данных **мовиесдб**. В раскрывающемся списке связанная служба выберите **создать**.

1. На экране создания связанной службы присвойте имя связанной службе Data Lake Storage 2-го поколения **ADLSGen2** и укажите метод проверки подлинности. Затем введите учетные данные подключения. В этом руководстве мы используем **ключ учетной записи** для подключения к нашей учетной записи хранения. 

1. Обязательно включите режим **Интерактивная разработка**. Включение может занять около минуты.

    ![Снимок экрана: режим "Интерактивная разработка".](./media/tutorial-data-flow-private/interactive-authoring.png)

1. Выберите **Test connection** (Проверить подключение). Она не должна быть выполнена, так как учетная запись хранения не обеспечивает доступ к ней без создания и утверждения частной конечной точки. В сообщении об ошибке должна присутствовать ссылка, по которой вы можете перейти к интерфейсу создания управляемой частной конечной точки. В качестве альтернативы можно перейти непосредственно на вкладку **Управление** и выполнить инструкции в [этом разделе](#create-a-managed-private-endpoint) , чтобы создать управляемую закрытую конечную точку.

1. Не закрывая это диалоговое окно, перейдите к учетной записи хранения.

1. Следуйте инструкциям в [этом разделе](#approval-of-a-private-link-in-a-storage-account), чтобы утвердить частную ссылку.

1. Вернитесь к диалоговому окну. Выберите **Проверить соединение**, а затем нажмите кнопку **Создать**, чтобы развернуть связанную службу.

1. На экране создания набора данных введите, где находится файл, в поле **путь к файлу** . В этом руководстве файл moviesDB.csv находится в **образце контейнера — данные**. Так как файл содержит заголовки, установите флажок **Первая строка в качестве заголовка** . Выберите **из подключения или хранилища** , чтобы импортировать схему заголовка непосредственно из файла в хранилище. По завершении нажмите кнопку **ОК** .

    ![Снимок экрана, на котором показан исходный путь.](media/tutorial-data-flow-private/source-file-path.png)

1. Если кластер отладки запущен, перейдите на вкладку **Предварительный просмотр данных** в окне Преобразование источника и выберите **Обновить** , чтобы получить моментальный снимок данных. Вы можете использовать предварительный просмотр данных, чтобы убедиться, что преобразование настроено правильно.

    ![Снимок экрана, на котором показана вкладка "предварительный просмотр данных".](media/tutorial-data-flow-private/data-preview.png)

#### <a name="create-a-managed-private-endpoint"></a>Создание управляемой частной конечной точки

Если вы не использовали гиперссылку при проверке предыдущего подключения, перейдите по пути. Здесь вам нужно создать управляемую частную конечную точку, которая будет подключаться к созданной связанной службе.

1. Перейдите на вкладку **Управление**.

   > [!NOTE]
   > Вкладка **Управление** может быть доступна не для всех экземпляров фабрики данных. Если она не отображается, вы можете получить доступ к частным конечным точкам, выбрав **Создание** > **Подключения** > **Частная конечная точка**.

1. Перейдите в раздел **Managed private endpoints** (Управляемые частные конечные точки).
1. В разделе **управляемых частных конечных точек** выберите **+ Создать**.

    ![Снимок экрана: кнопка "Создать" в разделе Managed private endpoints (Управляемые частные конечные точки).](./media/tutorial-data-flow-private/new-managed-private-endpoint.png) 

1. Выберите плитку **Azure Data Lake Storage 2-го поколения** из списка и нажмите кнопку **продолжить**.
1. Введите имя созданной учетной записи хранения.
1. Нажмите кнопку **создания**.
1. Через несколько секунд для созданной частной ссылки отобразится состояние ожидания утверждения.
1. Выберите созданную частную конечную точку. Вы увидите гиперссылку, которая ведет к интерфейсу утверждения частной конечной точки на уровне учетной записи хранения.

    ![Снимок экрана, на котором показана панель "Управление частной конечной точкой".](./media/tutorial-data-flow-private/manage-private-endpoint.png) 

#### <a name="approval-of-a-private-link-in-a-storage-account"></a>Утверждение частной ссылки в учетной записи хранения

1. В разделе **Параметры** для учетной записи хранения выберите **Подключения частных конечных точек**.

1. Установите флажок для созданной закрытой конечной точки и нажмите кнопку **утвердить**.

    ![Снимок экрана, на котором показана кнопка утверждения закрытой конечной точки.](./media/tutorial-data-flow-private/approve-private-endpoint.png)

1. Добавьте описание и выберите **Да**.
1. Вернитесь к разделу **Managed private endpoints** (Управляемые частные конечные точки) на вкладке **Управление** для Фабрики данных.
1. Через минуту вы должны увидеть утверждение для частной конечной точки.

### <a name="add-the-filter-transformation"></a>Добавление преобразования «фильтр»

1. Рядом с исходным узлом на холсте потока данных щелкните значок "плюс", чтобы добавить новое преобразование. Первое добавляемое преобразование — это **Фильтр**.

    ![Снимок экрана, показывающий Добавление фильтра.](media/tutorial-data-flow-private/add-filter.png)
1. Назовите преобразование фильтра **филтереарс**. Выберите поле Выражение рядом с полем **Фильтр** , чтобы открыть построитель выражений. Здесь вы укажете условие фильтрации.

    ![Снимок экрана, на котором показано Филтереарс.](media/tutorial-data-flow-private/filter-years.png)
1. Построитель выражений потока данных позволяет интерактивно создавать выражения для использования в различных преобразованиях. Выражения могут включать встроенные функции, столбцы из входной схемы и определяемые пользователем параметры. Дополнительные сведения о построении выражений см. в разделе [Построитель выражений потока данных](./concepts-data-flow-expression-builder.md).

    * В этом руководстве вы хотите отфильтровать фильмы в жанре комедия, который появился между годами 1910 и 2000. Поскольку год в настоящее время является строкой, его необходимо преобразовать в целое число с помощью ```toInteger()``` функции. Используйте операторы "больше или равно" (>=) и "меньше или равно" (<=) для сравнения со значениями литерального года 1910 и 2000. Объедините эти выражения вместе с оператором AND (&&). Выражение выйдет следующим образом:

        ```toInteger(year) >= 1910 && toInteger(year) <= 2000```

    * Чтобы узнать, какие фильмы являются комедиес, можно воспользоваться ```rlike()``` функцией, чтобы найти шаблон "комедия" в столбцах жанров. Объединение выражения рлике с сравнением year для получения:

        ```toInteger(year) >= 1910 && toInteger(year) <= 2000 && rlike(genres, 'Comedy')```

    * Если кластер отладки активен, можно проверить логику, нажав кнопку **Обновить** , чтобы увидеть результат выражения по сравнению с используемыми входными данными. Существует несколько прав на выполнение этой логики с помощью языка выражений потока данных.

        ![Снимок экрана, на котором показано критерий фильтра.](media/tutorial-data-flow-private/filter-expression.png)

    * После завершения работы с выражением нажмите кнопку **сохранить и завершить** .

1. Получите **Предварительный просмотр данных** , чтобы убедиться, что фильтр работает правильно.

    ![Снимок экрана, на котором показан предварительный просмотр отфильтрованных данных.](media/tutorial-data-flow-private/filter-data.png)

### <a name="add-the-aggregate-transformation"></a>Добавление преобразования «Статистическая обработка»

1. Следующее преобразование, которое вы добавите, является преобразованием « **Статистическая обработка** » в **модификаторе схемы**.

    ![Снимок экрана, показывающий Добавление статистического выражения.](media/tutorial-data-flow-private/add-aggregate.png)
1. Назовите **аггрегатекомедиратинг** преобразования «Статистическая обработка». На вкладке **Группировать по** выберите **год** из раскрывающегося списка, чтобы сгруппировать агрегаты по году, который появился в фильме.

    ![Снимок экрана, на котором показана Агрегатная группа.](media/tutorial-data-flow-private/group-by-year.png)
1. Перейдите на вкладку **статистические выражения** . В левом текстовом поле Назовите столбец Aggregate **аверажекомедиратинг**. Выберите поле правого выражения, чтобы ввести статистическое выражение с помощью построителя выражений.

    ![Снимок экрана, показывающий имя статистического столбца.](media/tutorial-data-flow-private/name-column.png)
1. Чтобы получить среднее значение **рейтинга** столбца, используйте ```avg()``` агрегатную функцию. Поскольку **Оценка** является строкой и ```avg()``` принимает числовой ввод, необходимо преобразовать значение в число с помощью ```toInteger()``` функции. Это выражение выглядит следующим образом:

    ```avg(toInteger(Rating))```

1. По завершении нажмите кнопку **сохранить и завершить** .

    ![Снимок экрана, на котором показано сохранение статистического выражения.](media/tutorial-data-flow-private/save-aggregate.png)
1. Перейдите на вкладку **Предварительный просмотр данных** , чтобы просмотреть выходные данные преобразования. Обратите внимание, что здесь есть только два столбца: **year** и **аверажекомедиратинг**.

### <a name="add-the-sink-transformation"></a>Добавление преобразования приемника

1. Затем необходимо добавить преобразование « **приемник** » в **место назначения**.

    ![Снимок экрана, показывающий Добавление приемника.](media/tutorial-data-flow-private/add-sink.png)
1. Присвойте имя **приемнику** приемника. Выберите **создать** , чтобы создать набор данных приемника.

    ![Снимок экрана, показывающий создание приемника.](media/tutorial-data-flow-private/create-sink.png)
1. На странице **новый набор данных** выберите **Azure Data Lake Storage 2-го поколения** и нажмите кнопку **продолжить**.

1. На странице **Выбор формата** выберите **DelimitedText** и нажмите кнопку **продолжить**.

1. Назовите свой набор данных приемника **мовиессинк**. Для связанной службы выберите ту же связанную службу **ADLSGen2** , которая была создана для преобразования источника. Введите выходную папку для записи данных. В этом руководстве мы запишем **выходные** данные папки в **образце контейнера — Data**. Папка не должна существовать заранее и может быть создана динамически. Установите флажок **Первая строка в качестве заголовка** и выберите **нет** для **импорта схемы**. Нажмите кнопку **ОК**.

    ![Снимок экрана, на котором показан путь к приемнику.](media/tutorial-data-flow-private/sink-file-path.png)

Теперь вы завершили сборку потока данных. Все готово для запуска в конвейере.

## <a name="run-and-monitor-the-data-flow"></a>Запуск и мониторинг потока данных

Вы можете выполнить отладку конвейера перед его публикацией. На этом шаге запускается Отладка конвейера потока данных. Пока в предварительной версии данных не записываются данные, отладочный запуск будет записывать данные в место назначения приемника.

1. Перейдите на холст конвейера. Выберите **Отладка** , чтобы запустить запуск отладки.

1. Отладка конвейера действий потока данных использует активный кластер отладки, но для инициализации по-прежнему требуется не менее минуты. Ход выполнения можно отслеживать с помощью вкладки **вывод** . После успешного выполнения щелкните значок очков для сведений о выполнении.

1. На странице сведения можно увидеть количество строк и время, потраченное на каждый шаг преобразования.

    ![Снимок экрана, на котором показан запуск мониторинга.](media/tutorial-data-flow-private/run-details.png)
1. Выберите преобразование, чтобы получить подробные сведения о столбцах и секционировании данных.

Если вы выполнили это руководство правильно, в папку приемника должны быть записаны 83 строк и 2 столбца. Проверить правильность данных можно, проверив хранилище BLOB-объектов.

## <a name="summary"></a>Сводка

В этом руководстве вы использовали пользовательский интерфейс фабрики данных для создания конвейера, который копирует и преобразует данные из источника Data Lake Storage 2-го поколения в приемник Data Lake Storage 2-го поколения (разрешив доступ только к выбранным сетям) с помощью сопоставления потока данных в [виртуальной сети, управляемой фабрикой данных](managed-virtual-network-private-endpoint.md).