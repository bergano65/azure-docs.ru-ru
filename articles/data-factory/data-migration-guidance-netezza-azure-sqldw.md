---
title: Перенос данных с локального сервера Netezza в Azure с помощью фабрики данных Azure | Документация Майкрософт
description: Используйте фабрику данных Azure для переноса данных с локального сервера Netezza в Azure.
services: data-factory
documentationcenter: ''
author: dearandyxu
ms.author: yexu
ms.reviewer: ''
manager: ''
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.topic: conceptual
ms.date: 9/03/2019
ms.openlocfilehash: 9ea8326b10536cb91b9dc67f637664f0fc055e74
ms.sourcegitcommit: fad368d47a83dadc85523d86126941c1250b14e2
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/19/2019
ms.locfileid: "71122832"
---
# <a name="use-azure-data-factory-to-migrate-data-from-an-on-premises-netezza-server-to-azure"></a>Перенос данных с локального сервера Netezza в Azure с помощью фабрики данных Azure 

Фабрика данных Azure предоставляет производительный, надежный и экономичный механизм переноса данных с локального сервера Netezza в учетную запись хранения Azure или базу данных хранилища данных SQL Azure. 

Эта статья содержит следующие сведения для инженеров и разработчиков данных:

> [!div class="checklist"]
> * Производительность 
> * Устойчивость к копированию
> * Безопасность сети
> * Архитектура высокого уровня решения 
> * Рекомендации по реализации  

## <a name="performance"></a>Производительность

Фабрика данных Azure предлагает бессерверную архитектуру, обеспечивающую параллелизм на различных уровнях. Если вы являетесь разработчиком, это означает, что вы можете создавать конвейеры для полного использования полосы пропускания сети и базы данных, чтобы максимально увеличить пропускную способность перемещения данных для вашей среды.

![Диаграмма производительности](media/data-migration-guidance-netezza-azure-sqldw/performance.png)

Приведенная выше схема может интерпретироваться следующим образом:

- Одно действие копирования может воспользоваться преимуществами масштабируемых ресурсов вычислений. При использовании Azure Integration Runtime можно указать [до 256 диус](https://docs.microsoft.com/azure/data-factory/copy-activity-performance#data-integration-units) для каждого действия копирования в бессерверном режиме. С помощью локальной среды выполнения интеграции (с локальным размещением) можно вручную масштабировать компьютер или масштабировать его на несколько компьютеров ([до четырех узлов](https://docs.microsoft.com/azure/data-factory/create-self-hosted-integration-runtime#high-availability-and-scalability)), и одно действие копирования распределяет свой раздел по всем узлам. 

- Одно действие копирования считывает и выполняет запись в хранилище данных с помощью нескольких потоков. 

- Поток управления фабрики данных Azure может запускать несколько операций копирования параллельно. Например, он может запускать их с помощью [цикла for each](https://docs.microsoft.com/azure/data-factory/control-flow-for-each-activity). 

Дополнительные сведения см. в разделе Краткое информация о [производительности и масштабируемости действий копирования](https://docs.microsoft.com/azure/data-factory/copy-activity-performance).

## <a name="resilience"></a>Устойчивость

В рамках одного действия копирования фабрика данных Azure имеет встроенный механизм повторных попыток, позволяющий ему управлять определенным уровнем временных сбоев в хранилищах данных или в базовой сети.

При копировании данных между хранилищами данных источника и приемника с помощью действия копирования фабрики данных Azure существует два способа обработки несовместимых строк. Можно либо прервать, либо завершить действие копирования или продолжить копирование остальных данных, пропуская несовместимые строки данных. Кроме того, чтобы узнать причину сбоя, можно зарегистрировать несовместимые строки в хранилище BLOB-объектов Azure или Azure Data Lake Store, исправить данные в источнике данных и повторить действие копирования.

## <a name="network-security"></a>Безопасность сети 

По умолчанию фабрика данных Azure передает данные с локального сервера Netezza в учетную запись хранения Azure или базу данных хранилища данных SQL Azure, используя зашифрованное соединение по протоколу HTTPS. HTTPS обеспечивает шифрование данных при передаче и предотвращает атаки перехвата и атак типа "злоумышленник в середине".

Кроме того, если вы не хотите, чтобы данные передавались через общедоступный Интернет, вы можете повысить безопасность, передавая данные через частный пиринг через канал Azure Express Route. 

В следующем разделе описывается достижение более высокого уровня безопасности.

## <a name="solution-architecture"></a>Архитектура решения

В этом разделе обсуждаются два способа переноса данных.

### <a name="migrate-data-over-the-public-internet"></a>Перенос данных через общедоступный Интернет

![Перенос данных через общедоступный Интернет](media/data-migration-guidance-netezza-azure-sqldw/solution-architecture-public-network.png)

Приведенная выше схема может интерпретироваться следующим образом:

- В этой архитектуре данные безопасно передаются с помощью протокола HTTPS через общедоступный Интернет.

- Для достижения этой архитектуры необходимо установить среду выполнения интеграции фабрики данных Azure (локальное размещение) на компьютере под управлением Windows, который находится за корпоративным брандмауэром. Убедитесь, что эта среда выполнения интеграции может напрямую обращаться к серверу Netezza. Чтобы полностью использовать пропускную способность сети и хранилища данных для копирования данных, можно вручную увеличить масштаб компьютера или выполнить масштабирование на нескольких компьютерах.

- С помощью этой архитектуры можно перенести исходные данные моментального снимка и разностные данные.

### <a name="migrate-data-over-a-private-network"></a>Перенос данных через частную сеть 

![Перенос данных через частную сеть](media/data-migration-guidance-netezza-azure-sqldw/solution-architecture-private-network.png)

Приведенная выше схема может интерпретироваться следующим образом:

- В этой архитектуре данные переносятся по ссылке частного пиринга через экспресс-маршрут Azure, и данные никогда не проходят через общедоступный Интернет. 

- Для достижения этой архитектуры необходимо установить среду выполнения интеграции фабрики данных Azure (локальное размещение) на виртуальной машине Windows в виртуальной сети Azure. Чтобы полностью использовать пропускную способность сети и хранилища данных для копирования данных, можно вручную увеличить масштаб виртуальной машины или выполнить масштабирование на нескольких виртуальных машинах.

- С помощью этой архитектуры можно перенести исходные данные моментального снимка и разностные данные.

## <a name="implement-best-practices"></a>Реализация рекомендаций 

### <a name="manage-authentication-and-credentials"></a>Управление проверкой подлинности и учетными данными 

- Для проверки подлинности в Netezza можно использовать [проверку подлинности ODBC с помощью строки подключения](https://docs.microsoft.com/azure/data-factory/connector-netezza#linked-service-properties). 

- Для проверки подлинности в хранилище BLOB-объектов Azure: 

   - Мы настоятельно рекомендуем использовать [управляемые удостоверения для ресурсов Azure](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#managed-identity). Управляемые удостоверения, созданные на основе автоматически управляемого удостоверения фабрики данных Azure в Azure Active Directory (Azure AD), позволяют настраивать конвейеры без необходимости указывать учетные данные в определении связанной службы.  

   - Кроме того, вы можете пройти проверку подлинности в хранилище BLOB-объектов Azure, используя [субъект](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#service-principal-authentication), [подпись общего доступа](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#shared-access-signature-authentication)или [ключ учетной записи хранения](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#account-key-authentication). 

- Для проверки подлинности в Azure Data Lake Storage 2-го поколения: 

   - Мы настоятельно рекомендуем использовать [управляемые удостоверения для ресурсов Azure](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage#managed-identity).
   
   - Также можно использовать [субъект-службу](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage#service-principal-authentication) или [ключ учетной записи хранения](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage#account-key-authentication). 

- Для проверки подлинности в хранилище данных SQL Azure выполните следующие действия.

   - Мы настоятельно рекомендуем использовать [управляемые удостоверения для ресурсов Azure](https://docs.microsoft.com/azure/data-factory/connector-azure-sql-data-warehouse#managed-identity).
   
   - Также можно использовать [субъект-службу](https://docs.microsoft.com/azure/data-factory/connector-azure-sql-data-warehouse#service-principal-authentication) или [проверку подлинности SQL](https://docs.microsoft.com/azure/data-factory/connector-azure-sql-data-warehouse#sql-authentication).

- Если управляемые удостоверения для ресурсов Azure не используются, настоятельно рекомендуется [хранить учетные данные в Azure Key Vault](https://docs.microsoft.com/azure/data-factory/store-credentials-in-key-vault) , чтобы упростить централизованное управление ключами и их вращение без изменения связанных служб фабрики данных Azure. Это также один из рекомендаций [по интеграции и откомпакт-диску](https://docs.microsoft.com/azure/data-factory/continuous-integration-deployment#best-practices-for-cicd). 

### <a name="migrate-initial-snapshot-data"></a>Перенос исходных данных моментальных снимков 

Для небольших таблиц (т. е. таблиц с объемом менее 100 ГБ или, которые могут быть перенесены в Azure в течение двух часов) можно создать для каждой таблицы данные загрузки каждого задания копирования. Для повышения пропускной способности можно запустить несколько заданий копирования фабрики данных Azure для параллельной загрузки отдельных таблиц. 

В каждом задании копирования для выполнения параллельных запросов и копирования данных по секциям можно также достичь определенного уровня параллелизма, используя [ `parallelCopies` параметр свойства](https://docs.microsoft.com/azure/data-factory/copy-activity-performance#parallel-copy) с одним из следующих параметров секции данных:

- Чтобы повысить эффективность, мы рекомендуем начать с среза данных.  Убедитесь, что значение в `parallelCopies` параметре меньше, чем общее число секций срезов данных в таблице на сервере Netezza.  

- Если объем всех секций срезов данных по-прежнему большой (например, 10 ГБ или больше), мы рекомендуем переключиться на динамический раздел диапазона. Этот параметр обеспечивает большую гибкость при определении количества секций и объема каждой секции по столбцу секционирования, верхней и нижней границам.

Для больших таблиц (т. е. таблиц с томом размером 100 ГБ или выше или которые *не могут* быть перенесены в Azure в течение двух часов) рекомендуется секционировать данные по пользовательскому запросу, а затем каждый раз копировать копию задания по одной секции. Для повышения пропускной способности можно одновременно запустить несколько заданий копирования в фабрике данных Azure. Для каждого целевого объекта задания копирования, загружая одну секцию по пользовательскому запросу, можно увеличить пропускную способность, включив параллелизм через срез данных или динамический диапазон. 

В случае сбоя любого задания копирования из-за временной ошибки сети или хранилища данных можно повторно выполнить задание копирования, завершившееся сбоем, чтобы перезагрузить эту конкретную секцию из таблицы. Другие задания копирования, которые загружают другие секции, не затрагиваются.

При загрузке данных в базу данных хранилища данных SQL Azure мы рекомендуем включить Polybase в задании копирования с помощью хранилища BLOB-объектов Azure в качестве промежуточного хранения.

### <a name="migrate-delta-data"></a>Перенос разностных данных 

Чтобы указать новые или обновленные строки из таблицы, используйте столбец timestamp или инкрементный ключ в схеме. Затем можно сохранить Последнее значение в качестве верхнего предела во внешней таблице, а затем использовать его для фильтрации разностных данных при следующей загрузке данных. 

Каждая таблица может использовать другой столбец подложки для обнаружения новых или обновленных строк. Мы рекомендуем создать внешнюю таблицу управления. В таблице каждая строка представляет одну таблицу на сервере Netezza с его именем столбца подложки и значением верхнего предела. 

### <a name="configure-a-self-hosted-integration-runtime"></a>Настройка локальной среды выполнения интеграции

Если вы выполняете миграцию данных с сервера Netezza в Azure, независимо от того, находится ли сервер в локальной среде в рамках брандмауэра или среды виртуальной сети, необходимо установить локальную IR на компьютере Windows или виртуальной машине, который используется для Перемещение данных. При установке локальной среды IR рекомендуется использовать следующий подход:

- Для каждого компьютера или виртуальной машины Windows Начните с конфигурации 32 виртуальных ЦП и 128 ГБ памяти. Вы можете следить за использованием ЦП и памяти на IR-компьютере во время переноса данных, чтобы узнать, требуется ли дальнейшее масштабирование компьютера для повышения производительности или уменьшения масштаба компьютера, чтобы сэкономить затраты.

- Кроме того, можно выполнить горизонтальное масштабирование, связав до четырех узлов с одним локальным IR. Одно задание копирования, которое выполняется для саморазмещенного IR, автоматически применяет все узлы виртуальной машины для параллельного копирования данных. Для обеспечения высокой доступности Начните с четырех узлов виртуальных машин, чтобы избежать единой точки отказа во время переноса данных.

### <a name="limit-your-partitions"></a>Ограничение секций

Рекомендуется провести проверку концепции производительности с помощью репрезентативного примера набора данных, чтобы можно было определить подходящий размер раздела для каждого действия копирования. Мы рекомендуем загрузить каждую секцию в Azure в течение двух часов.  

Чтобы скопировать таблицу, начните с одного действия копирования с единой, размещенной на собственном компьютере IR. Постепенно увеличивайте значение `parallelCopies` в зависимости от количества секций срезов данных в таблице. Узнайте, можно ли загрузить всю таблицу в Azure в течение двух часов в соответствии с пропускной способностью, полученной в результате задания копирования. 

Если его невозможно загрузить в Azure в течение двух часов, а емкость автономного узла IR и хранилища данных не используется полностью, постепенно увеличивайте количество одновременных операций копирования, пока не достигнет ограничения сети или ограничения пропускной способности хранилища данных. #d0. 

Отслеживайте использование ЦП и памяти на автономном IR-компьютере и будьте готовы к увеличению масштаба компьютера или масштабированию на нескольких компьютерах, когда вы видите, что ЦП и память полностью используются. 

При возникновении ошибок регулирования, о которых сообщает действие копирования в фабрике данных Azure, сократите параллелизм или `parallelCopies` настройку в фабрике данных Azure или попробуйте увеличить ограничения пропускной способности сети или операций ввода-вывода в секунду, а также хранилища данных. 


### <a name="estimate-your-pricing"></a>Оценка цен 

Рассмотрим следующий конвейер, который создается для переноса данных с локального сервера Netezza в базу данных хранилища данных SQL Azure:

![Ценовой конвейер](media/data-migration-guidance-netezza-azure-sqldw/pricing-pipeline.png)

Предположим, что выполняются следующие условия: 

- Общий объем данных составляет 50 терабайт (ТБ). 

- Мы переносим данные с помощью архитектуры первого решения (сервер Netezza находится в локальной среде, защищенном брандмауэром).

- Том 50 ТБ делится на секции 500, и каждое действие копирования перемещает один раздел.

- Для каждого действия копирования настраивается один автономный IR-объект на четыре компьютера и достигается пропускная способность 20 мегабайт в секунду (Мбит/с). (В рамках действия `parallelCopies` копирования имеет значение 4, и каждый поток для загрузки данных из таблицы достигает пропускной способности 5 Мбит/с.)

- Параметр параллелизма ForEach имеет значение 3, а суммарная пропускная способность — 60 Мбит/с.

- В итоге выполнение миграции займет 243 часа.

На основе приведенных выше предположений мы рассмотрим предполагаемую цену: 

![Таблица цен](media/data-migration-guidance-netezza-azure-sqldw/pricing-table.png)

> [!NOTE]
> В приведенной выше таблице указаны гипотетические цены. Реальная цена зависит от фактической пропускной способности в вашей среде. Цена на компьютере с Windows (с установленным локальным IR) не включена. 

### <a name="additional-references"></a>Дополнительные ссылки

Дополнительные сведения см. в следующих статьях и руководствах:

- [Перенос данных из локальной базы данных реляционного хранилища данных в Azure с помощью фабрики данных Azure](https://azure.microsoft.com/mediahandler/files/resourcefiles/data-migration-from-on-premise-relational-data-warehouse-to-azure-data-lake-using-azure-data-factory/Data_migration_from_on-prem_RDW_to_ADLS_using_ADF.pdf)
- [Соединитель Netezza](https://docs.microsoft.com/azure/data-factory/connector-netezza)
- [Соединитель ODBC](https://docs.microsoft.com/azure/data-factory/connector-odbc)
- [Соединитель хранилища BLOB-объектов Azure](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage)
- [Copy data to or from Azure Data Lake Storage Gen2 Preview using Azure Data Factory (Preview)](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage) (Копирование данных в Azure Data Lake Storage Gen2 (предварительная версия) или из него с помощью фабрики данных Azure)
- [Перемещение данных в хранилище данных Azure SQL и из него с помощью фабрики данных Azure](https://docs.microsoft.com/azure/data-factory/connector-azure-sql-data-warehouse).
- [Краткое руководств по настройке производительности действий копирования](https://docs.microsoft.com/azure/data-factory/copy-activity-performance)
- [Создание и настройка локальной среды выполнения интеграции](https://docs.microsoft.com/azure/data-factory/create-self-hosted-integration-runtime)
- [Высокая доступность и масштабируемость локальной среды выполнения интеграции](https://docs.microsoft.com/azure/data-factory/create-self-hosted-integration-runtime#high-availability-and-scalability)
- [Вопросы безопасности перемещения данных](https://docs.microsoft.com/azure/data-factory/data-movement-security-considerations)
- [Хранение учетных данных в Azure Key Vault](https://docs.microsoft.com/azure/data-factory/store-credentials-in-key-vault)
- [Добавочное копирование данных из одной таблицы](https://docs.microsoft.com/azure/data-factory/tutorial-incremental-copy-portal)
- [Добавочное копирование данных из нескольких таблиц](https://docs.microsoft.com/azure/data-factory/tutorial-incremental-copy-multiple-tables-portal)
- [Страница с ценами на фабрику данных Azure](https://azure.microsoft.com/pricing/details/data-factory/data-pipeline/)

## <a name="next-steps"></a>Следующие шаги

- [Копирование файлов из нескольких контейнеров с помощью фабрики данных Azure](solution-template-copy-files-multiple-containers.md)
