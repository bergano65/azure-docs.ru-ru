---
title: Формат Parquet в фабрике данных Azure
description: В этом разделе описывается, как работать с форматом Parquet в фабрике данных Azure.
author: linda33wj
manager: shwang
ms.reviewer: craigg
ms.service: data-factory
ms.workload: data-services
ms.topic: conceptual
ms.date: 06/05/2020
ms.author: jingwang
ms.openlocfilehash: 9ad0ccdabd0320d8821d0760ca9802db37049149
ms.sourcegitcommit: 877491bd46921c11dd478bd25fc718ceee2dcc08
ms.contentlocale: ru-RU
ms.lasthandoff: 07/02/2020
ms.locfileid: "84611067"
---
# <a name="parquet-format-in-azure-data-factory"></a>Формат Parquet в фабрике данных Azure
[!INCLUDE[appliesto-adf-asa-md](includes/appliesto-adf-asa-md.md)]

Если вы хотите **проанализировать файлы Parquet или записать данные в формат Parquet**, следуйте этой статье. 

Формат Parquet поддерживается для следующих соединителей: [Amazon S3](connector-amazon-simple-storage-service.md), [большой двоичный объект Azure](connector-azure-blob-storage.md), [Azure Data Lake Storage 1-го поколения](connector-azure-data-lake-store.md), [Azure Data Lake Storage 2-го поколения](connector-azure-data-lake-storage.md), [хранилище файлов Azure](connector-azure-file-storage.md), [Файловая система](connector-file-system.md), [FTP](connector-ftp.md), [Google Cloud Storage](connector-google-cloud-storage.md), [HDFS](connector-hdfs.md), [http](connector-http.md)и [SFTP](connector-sftp.md).

## <a name="dataset-properties"></a>Свойства набора данных

Полный список разделов и свойств, доступных для определения наборов данных, см. в статье о [наборах данных](concepts-datasets-linked-services.md). В этом разделе содержится список свойств, поддерживаемых набором данных Parquet.

| Свойство.         | Описание                                                  | Обязательно |
| ---------------- | ------------------------------------------------------------ | -------- |
| type             | Свойство Type набора данных должно иметь значение **Parquet**. | Да      |
| location         | Параметры расположения файлов. Каждый файловый соединитель имеет собственный тип расположения и поддерживаемые свойства в разделе `location` . **См. сведения в статье о соединителе. раздел свойств набора данных >**. | Да      |
| компрессионкодек | Кодек сжатия, используемый при записи в файлы Parquet. При чтении из файлов Parquet фабрики данных автоматически определяют кодек сжатия на основе метаданных файла.<br>Поддерживаются следующие типы: "**нет**", "**gzip**", "**Привязка**" (по умолчанию) и "**LZO**". Примечание. в настоящее время действие копирования не поддерживает LZO, когда файлы Parquet для чтения и записи. | Нет       |

> [!NOTE]
> Пробелы в имени столбца не поддерживаются для файлов Parquet.

Ниже приведен пример набора данных Parquet в хранилище BLOB-объектов Azure.

```json
{
    "name": "ParquetDataset",
    "properties": {
        "type": "Parquet",
        "linkedServiceName": {
            "referenceName": "<Azure Blob Storage linked service name>",
            "type": "LinkedServiceReference"
        },
        "schema": [ < physical schema, optional, retrievable during authoring > ],
        "typeProperties": {
            "location": {
                "type": "AzureBlobStorageLocation",
                "container": "containername",
                "folderPath": "folder/subfolder",
            },
            "compressionCodec": "snappy"
        }
    }
}
```

## <a name="copy-activity-properties"></a>Свойства действия копирования

Полный список разделов и свойств, используемых для определения действий, см. в статье [Конвейеры и действия в фабрике данных Azure](concepts-pipelines-activities.md). В этом разделе содержится список свойств, поддерживаемых источником и приемником Parquet.

### <a name="parquet-as-source"></a>Parquet в качестве источника

В разделе *** \* Источник \* *** действия копирования поддерживаются следующие свойства.

| Свойство.      | Описание                                                  | Обязательно |
| ------------- | ------------------------------------------------------------ | -------- |
| type          | Свойство Type источника действия копирования должно иметь значение **паркуетсаурце**. | Да      |
| сторесеттингс | Группа свойств для чтения данных из хранилища данных. Каждый файловый соединитель имеет собственные Поддерживаемые параметры чтения в разделе `storeSettings` . Дополнительные **сведения см. в статье о соединителе — > свойства действия копирования**. | Нет       |

### <a name="parquet-as-sink"></a>Parquet в качестве приемника

В разделе *** \* приемника \* *** действия копирования поддерживаются следующие свойства.

| Свойство.      | Описание                                                  | Обязательно |
| ------------- | ------------------------------------------------------------ | -------- |
| type          | Свойство Type источника действия копирования должно иметь значение **паркуетсинк**. | Да      |
| сторесеттингс | Группа свойств для записи данных в хранилище данных. Каждый соединитель на основе файлов имеет собственные Поддерживаемые параметры записи в `storeSettings` . Дополнительные **сведения см. в статье о соединителе — > свойства действия копирования**. | Нет       |

## <a name="mapping-data-flow-properties"></a>Свойства потока данных для сопоставления

В статье сопоставление потоков данных можно выполнять чтение и запись в формате Parquet в следующих хранилищах данных: [хранилище BLOB-объектов Azure](connector-azure-blob-storage.md#mapping-data-flow-properties), [Azure Data Lake Storage 1-го поколения](connector-azure-data-lake-store.md#mapping-data-flow-properties)и [Azure Data Lake Storage 2-го поколения](connector-azure-data-lake-storage.md#mapping-data-flow-properties).

### <a name="source-properties"></a>Свойства источника

В таблице ниже перечислены свойства, поддерживаемые источником Parquet. Эти свойства можно изменить на вкладке **Параметры источника** .

| name | Описание | Обязательное значение | Допустимые значения | Свойство сценария потока данных |
| ---- | ----------- | -------- | -------------- | ---------------- |
| Формат | Формат должен быть`parquet` | да | `parquet` | format |
| Подстановочные пути | Будут обработаны все файлы, соответствующие пути с подстановочными знаками. Переопределяет папку и путь к файлу, заданные в наборе данных. | Нет | String[] | вилдкардпасс |
| Корневой путь раздела | Для секционированных файловых данных можно ввести корневой путь к разделу, чтобы считывать секционированные папки в виде столбцов. | Нет | Строка | партитионрутпас |
| Список файлов | Указывает, указан ли источник на текстовый файл, в котором перечислены обрабатываемые файлы | Нет | `true` или `false` | fileList |
| Столбец для хранения имени файла | Создать новый столбец с именем и путем к исходному файлу | Нет | Строка | ровурлколумн |
| После завершения | Удалите или переместите файлы после обработки. Путь к файлу начинается с корня контейнера | Нет | Delete: `true` или`false` <br> Поместить`[<from>, <to>]` | пуржефилес <br> мовефилес |
| Фильтровать по дате последнего изменения | Выберите фильтр файлов в зависимости от времени последнего изменения | Нет | Отметка времени | modifiedAfter <br> modifiedBefore |

### <a name="source-example"></a>Пример исходного кода

Приведенный ниже рисунок представляет собой пример конфигурации источника Parquet в сопоставлении потоков данных.

![Источник Parquet](media/data-flow/parquet-source.png)

Связанный сценарий потока данных:

```
source(allowSchemaDrift: true,
    validateSchema: false,
    rowUrlColumn: 'fileName',
    format: 'parquet') ~> ParquetSource
```

### <a name="sink-properties"></a>Свойства приемника

В таблице ниже перечислены свойства, поддерживаемые источником Parquet. Эти свойства можно изменить на вкладке **Параметры источника** .

| name | Описание | Обязательное значение | Допустимые значения | Свойство сценария потока данных |
| ---- | ----------- | -------- | -------------- | ---------------- |
| Формат | Формат должен быть`parquet` | да | `parquet` | format |
| Очистить папку | Если конечная папка будет удалена перед записью | Нет | `true` или `false` | truncate |
| Параметр имени файла | Формат имени записанных данных. По умолчанию по одному файлу на раздел в формате`part-#####-tid-<guid>` | Нет | Шаблон: строка <br> На секцию: String [] <br> Как данные в столбце: строка <br> Вывод в один файл:`['<fileName>']` | filePattern <br> партитионфиленамес <br> ровурлколумн <br> партитионфиленамес |

### <a name="sink-example"></a>Пример приемника

Приведенный ниже рисунок представляет собой пример конфигурации приемника Parquet в сопоставлении потоков данных.

![Приемник Parquet](media/data-flow/parquet-sink.png)

Связанный сценарий потока данных:

```
ParquetSource sink(
    format: 'parquet',
    filePattern:'output[n].parquet',
    truncate: true,
    allowSchemaDrift: true,
    validateSchema: false,
    skipDuplicateMapInputs: true,
    skipDuplicateMapOutputs: true) ~> ParquetSink
```

## <a name="data-type-support"></a>Поддержка типов данных

В настоящее время сложные типы данных Parquet не поддерживаются (например, MAP, LIST, STRUCT).

## <a name="using-self-hosted-integration-runtime"></a>Использование Integration Runtime с автономным размещением

> [!IMPORTANT]
> Для копирования с помощью автономных Integration Runtime например, между локальными и облачными хранилищами данных, если вы не копируете файлы Parquet **как есть**, необходимо установить **64-разрядный пакет JRE 8 (среда выполнения Java) или OpenJDK** и **Microsoft Visual C++ 2010** на своем IR-компьютере. Дополнительные сведения см. в следующем абзаце.

Для копирования, выполняемой на автономной среде IR с Parquet File Serialization/десериализацией, ADF находит среду выполнения Java, предварительно проверяя реестр *`(SOFTWARE\JavaSoft\Java Runtime Environment\{Current Version}\JavaHome)`* для JRE, если она не найдена, а вторая проверяет системную переменную *`JAVA_HOME`* для OpenJDK.

- **Для использования JRE**: для 64-разрядного IR требуется 64-разрядный JRE. Ее можно найти [здесь](https://go.microsoft.com/fwlink/?LinkId=808605).
- **Чтобы использовать OpenJDK**, она поддерживается с версии IR 3,13. Упакуйте jvm.dll со всеми другими необходимыми сборками OpenJDK на компьютере с локальной IR и соответственно установите системную переменную среды JAVA_HOME.
- **Чтобы установить распространяемый пакет Visual C++ 2010**, распространяемый пакет Visual C++ 2010 не устанавливается с ЛОКАЛЬными инфракрасными установками. Ее можно найти [здесь](https://www.microsoft.com/download/details.aspx?id=14632).

> [!TIP]
> Если вы копируете данные в формат Parquet или из формата Parquet с помощью локальной среди выполнения интеграции и возникает ошибка: "Ошибка при вызове Java, сообщение: **java.lang.OutOfMemoryError:Java heap space**", можно добавить переменную среды `_JAVA_OPTIONS` в компьютере, на котором размещена локальная среда выполнения интеграции для настройки минимального и максимального размера кучи для виртуальной машины Java, чтобы расширить возможности такой копии, а затем повторно запустить конвейер.

![Установка размера кучи виртуальной машины Java на локальной среде выполнения интеграции](./media/supported-file-formats-and-compression-codecs/set-jvm-heap-size-on-selfhosted-ir.png)

Пример: установите переменную `_JAVA_OPTIONS` со значением `-Xms256m -Xmx16g`. Флаг `Xms` указывает начальный пул выделения памяти для виртуальной машины Java (JVM), а `Xmx` указывает максимальный пул выделения памяти. Это означает, что JVM будет запущена с объемом памяти `Xms` и сможет использовать не более `Xmx` объема памяти. По умолчанию ADF использует min 64 МБ и максимальное значение 1 ГБ.

## <a name="next-steps"></a>Дальнейшие шаги

- [Действие копирования в фабрике данных Azure](copy-activity-overview.md)
- [Поток данных для сопоставления](concepts-data-flow-overview.md)
- [Действие поиска](control-flow-lookup-activity.md)
- [Действие получения метаданных в Фабрике данных Azure](control-flow-get-metadata-activity.md)
