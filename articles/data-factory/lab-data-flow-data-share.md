---
title: Интеграция данных с помощью Фабрики данных Azure и Azure Data Share
description: Копирование, преобразование и совместное использование данных с помощью Фабрики данных Azure и Azure Data Share
author: djpmsft
ms.author: daperlov
ms.service: data-factory
ms.topic: tutorial
ms.custom: seo-lt-2019
ms.date: 01/08/2020
ms.openlocfilehash: 1c8958062c7430f98db0925c2b3996887bfe5548
ms.sourcegitcommit: fb3c846de147cc2e3515cd8219d8c84790e3a442
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/27/2020
ms.locfileid: "92637366"
---
# <a name="data-integration-using-azure-data-factory-and-azure-data-share"></a>Интеграция данных с помощью Фабрики данных Azure и Azure Data Share

[!INCLUDE[appliesto-adf-asa-md](includes/appliesto-adf-asa-md.md)]

По мере того, как клиенты приступают к реализации своих современных проектов по созданию хранилищ данных и аналитики, им требуется не только больше данных, но и большая прозрачность по всему пространству данных. В этом семинаре подробно описано, как усовершенствования Фабрики данных Azure и Azure Data Share упрощают интеграцию данных и управление ими в Azure. 

Усовершенствования в Azure Data Factory позволят вашим инженерам-разработчикам данных уверенно привносить больше данных, а значит, и больше ценности в ваше предприятие — от создания безкодовых ETL/ELT до полного представления о ваших данных. Azure Data Share позволяет управлять общим доступом к межкорпоративным данным.

В этом семинаре вы будете использовать Фабрику данных Azure (ADF) для приема данных из службы "База данных SQL Azure" в Azure Data Lake Storage 2-го поколения (ADLS 2-го поколения). После загрузки данных в lake, вы будете преобразовывать их с помощью потоков данных сопоставления, собственной службы преобразования фабрики данных, и погружать их в Azure Synapse Analytics (ранее — Хранилище данных SQL). Затем вы поделитесь таблицей с преобразованными данными и некоторыми дополнительными данными, используя Azure Data Share. 

В этой тестовой службе используются данные такси Нью-Йорка. Чтобы импортировать их в базу данных в службе "База данных SQL", скачайте [BACPAC-файл данных о такси](https://github.com/djpmsft/ADF_Labs/blob/master/sample-data/taxi-data.bacpac).

## <a name="prerequisites"></a>Предварительные требования

* **Подписка Azure** : Если у вас еще нет подписки Azure, [создайте бесплатную учетную запись](https://azure.microsoft.com/free/), прежде чем начинать работу.

* **База данных SQL Azure** . Если у вас нет SQL DB, ознакомьтесь со сведениями о [создании учетной записи SQL DB](../azure-sql/database/single-database-create-quickstart.md?tabs=azure-portal)

* **Учетная запись хранения Azure Data Lake Storage 2-го поколения** . Если у вас нет учетной записи хранения ADLS 2-го поколения, ознакомьтесь со сведениями о [создании учетной записи хранения ADLS 2-го поколения](../storage/common/storage-account-create.md).

* **Azure Synapse Analytics (ранее — Хранилище данных SQL)** . Если у вас нет Azure Synapse Analytics (ранее — Хранилище данных SQL), ознакомьтесь со сведениями о [создании экземпляра Azure Synapse Analytics](../synapse-analytics/sql-data-warehouse/create-data-warehouse-portal.md).

* **Azure Data Factory** . Если вы не создали фабрику данных, ознакомьтесь со сведениями о [создании фабрики данных](./quickstart-create-data-factory-portal.md).

* **Azure Data Share** . Если вы еще не создали общий ресурс данных, ознакомьтесь со сведениями о [создании общего ресурса данных](../data-share/share-your-data.md#create-a-data-share-account).

## <a name="set-up-your-azure-data-factory-environment"></a>Настройка среды Фабрики данных Azure

В этом разделе вы узнаете, как получить доступ к пользовательскому интерфейсу Фабрики данных Azure (пользовательский интерфейс ADF) с портала Azure. В пользовательском интерфейсе ADF вы настраиваете три взаимосвязанных службы для каждого из используемых нами хранилищ данных: Azure SQL DB, ADLS 2-го поколения и Azure Synapse Analytics.

В Фабрике данных Azure связанные службы определяют данные о подключении ко внешним ресурсам. В настоящее время Фабрика данных Azure поддерживает более 85 соединителей.

### <a name="open-the-azure-data-factory-ux"></a>Открытие пользовательского интерфейса Фабрики данных Azure

1. Откройте [портал Azure](https://portal.azure.com) в Microsoft Edge или Google Chrome.
1. Используя строку поиска в верхней части страницы, выполните поиск по словам "Фабрики данных"

    ![Портал 1](media/lab-data-flow-data-share/portal1.png)
1. Щелкните ресурс фабрики данных, чтобы открыть его колонку.

    ![Портал 2](media/lab-data-flow-data-share/portal2.png)
1. Щелкните **Author and Monitor** (Создание и мониторинг), чтобы открыть пользовательский интерфейс ADF. Доступ к пользовательскому интерфейсу ADF также можно получить на сайте adf.azure.com.

    ![Портал 3](media/lab-data-flow-data-share/portal3.png)
1. Вас будет перенаправлено на домашнюю страницу пользовательского интерфейса ADF. На этой странице содержатся руководства, видео-инструкции и ссылки на учебники для изучения концепций фабрики данных. Нажмите на значок карандаша на левой боковой панели, чтобы начать создание.

    ![Настройка портала](media/lab-data-flow-data-share/configure1.png)

### <a name="create-an-azure-sql-database-linked-service"></a>Создание связанной службы Базы данных SQL Azure

1. На странице редактирования создаются такие ресурсы фабрики данных, как конвейеры, наборы данных, потоки данных, триггеры и связанные службы. Нажмите кнопку **Соединения** в нижнем правом углу, чтобы создать связанную службу.

    ![Настройка портала 2](media/lab-data-flow-data-share/configure2.png)
1. Щелкните **Новый** на вкладке подключений, чтобы добавить новую связанную службу.

    ![Настройка портала 3](media/lab-data-flow-data-share/configure3.png)
1. Первой связанной службой, которую вы настроите, является база данных SQL Azure. С помощью строки поиска можно отфильтровать список хранилищ данных. Щелкните плитку **База данных SQL Azure** и нажмите "Продолжить".

    ![Настройка портала 4](media/lab-data-flow-data-share/configure4.png)
1. В панели конфигурации базы данных SQL введите "SQLDB" в качестве имени связанной службы. Введите свои учетные данные, чтобы обеспечить подключение фабрики данных к базе данных. Если вы используете проверку подлинности SQL, введите имя сервера, базу данных, имя пользователя и пароль. Правильность сведений о подключении можно проверить, нажав **Тестирование подключения** . После завершения нажмите **Создать** .

    ![Настройка портала 5](media/lab-data-flow-data-share/configure5.png)

### <a name="create-an-azure-synapse-analytics-linked-service"></a>Создание связанной службы Azure Synapse Analytics

1. Повторите этот же процесс, чтобы добавить связанную службу Azure Synapse Analytics. Щелкните **Новый** на вкладке подключений. Выберите плитку **Azure Synapse Analytics (ранее — Хранилище данных SQL)** и нажмите "Продолжить".

    ![Настройка портала 6](media/lab-data-flow-data-share/configure6.png)
1. На панели конфигурации связанной службы введите "SQLDW" в качестве имени связанной службы. Введите свои учетные данные, чтобы обеспечить подключение фабрики данных к базе данных. Если вы используете проверку подлинности SQL, введите имя сервера, базу данных, имя пользователя и пароль. Правильность сведений о подключении можно проверить, нажав **Тестирование подключения** . После завершения нажмите **Создать** .

    ![Настройка портала 7](media/lab-data-flow-data-share/configure7.png)

### <a name="create-an-azure-data-lake-storage-gen2-linked-service"></a>Создание связанной службы Azure Data Lake Storage 2-го поколения

1. Последней связанной службой, необходимой для этой тестовой службы, является Azure Data Lake Storage 2-го поколения.  Щелкните **Новый** на вкладке подключений. Выберите плитку **Azure Data Lake Storage 2-го поколения** и нажмите "Продолжить".

    ![Настройка портала 8](media/lab-data-flow-data-share/configure8.png)
1. В панели конфигурации связанной службы введите "ADLSGen2" в качестве имени связанной службы. Если вы используете аутентификацию с помощью проверки подлинности ключей учетных записей, выберите вашу учетную запись для ADLS 2-го поколения из раскрывающегося списка **Имя учетной записи хранилища** . Правильность сведений о подключении можно проверить, нажав **Тестирование подключения** . После завершения нажмите **Создать** .

    ![Настройка портала 9](media/lab-data-flow-data-share/configure9.png)

### <a name="turn-on-data-flow-debug-mode"></a>Включение режима отладки потоков данных

В разделе *Преобразование данных с помощью функции потоков данных сопоставления* вы будете создавать потоки данных для сопоставления. Перед построением потоков данных сопоставления рекомендовано включить режим отладки, который позволяет в считанные секунды протестировать логику преобразования на активном кластере spark.

Чтобы включить отладку, щелкните ползунок **Data flow debug** (Отладка потока данных) в верхней панели фабрики. Нажмите кнопку "ОК", когда появится всплывающее диалоговое окно подтверждения. Запуск кластера займет около 5-7 минут. Продолжайте выполнять действия раздела *Передача данных из базы данных SQL Azure в ADLS 2-го поколения, используя функцию копирования* во время инициализации.

![Настройка портала 10](media/lab-data-flow-data-share/configure10.png)

## <a name="ingest-data-using-the-copy-activity"></a>Прием данных с помощью действия копирования

В этом разделе вы создадите конвейер с действием копирования, который загрузит одну таблицу из базы данных SQL Azure в учетную запись хранилища ADLS 2-го поколения. Вы узнаете, как добавлять конвейер, настраивать набор данных и отлаживать конвейер через пользовательский интерфейс ADF. Шаблон конфигурации, используемый в этом разделе, применяется к копированию из реляционного хранилища данных в файловое хранилище данных.

В Фабрике данных Azure конвейеры являются логической группой действий, которые совместно выполняют задачу. Действие определяет операцию, выполняемую для данных. Набор данных указывает на данные, которые нужно использовать в связанной службе.

### <a name="create-a-pipeline-with-a-copy-activity"></a>Создание конвейера с действием копирования

1. Щелкните значок "плюс" на панели ресурсов фабрики, чтобы открыть меню нового ресурса. Выберите **Конвейер** .

    ![Копирование портала 1](media/lab-data-flow-data-share/copy1.png)
1. Во вкладке **Общие** холста конвейера выберите описательное имя для конвейера, например "IngestAndTransformTaxiData".

    ![Копирование портала 2](media/lab-data-flow-data-share/copy2.png)
1. В панели действий холста конвейера откройте меню-гармошку **Move and Transform** (Перемещение и преобразование) и перетащите действие **Копирование данных** на холст. Назовите действие копирования описательным именем, например "IngestIntoADLS".

    ![Копирование портала 3](media/lab-data-flow-data-share/copy3.png)

### <a name="configure-azure-sql-db-source-dataset"></a>Настройка исходного набора данных базы данных SQL Azure

1. Выберите вкладку **Источник** действия копирования. Щелкните **Создать** , чтобы создать набор данных. Вашим источником будет таблица "dbo.TripData", расположенная в связанной службе "SQLDB", настроенной ранее.

    ![Копирование портала 4](media/lab-data-flow-data-share/copy4.png)
1. Выполните поиск по **База данных SQL Azure** и щелкните "Продолжить".

    ![Копирование портала 5](media/lab-data-flow-data-share/copy5.png)
1. Вызовите набор данных "TripData". Выберите "SQLDB" в качестве связанной службы. Выберите "dbo.TripData" из раскрывающегося списка имени таблицы. Импортируйте схему **From connection/store** (из подключения/хранилища). Щелкните "OK", когда все будет готово.

    ![Копирование портала 6](media/lab-data-flow-data-share/copy6.png)

Вы успешно создали свой первый исходный набор данных! Убедитесь, что в настройках источника в поле запроса на использование выбрано значение по умолчанию **Таблица** .

### <a name="configure-adls-gen2-sink-dataset"></a>Настройка приемного набора данных ADLS 2-го поколения

1. Выберите вкладку **Приемник** действия копирования. Щелкните **Создать** , чтобы создать набор данных.

    ![Копирование портала 7](media/lab-data-flow-data-share/copy7.png)
1. Выполните поиск по фразе **Azure Data Lake Storage 2-го поколения** и нажмите "Продолжить".

    ![Копирование портала 8](media/lab-data-flow-data-share/copy8.png)
1. Во время записи в CSV-файл выберите **DelimitedText** на панели выбора формата. Нажмите "Продолжить".

    ![Копирование портала 9](media/lab-data-flow-data-share/copy9.png)
1. Назовите приемный набор данных "TripDataCSV". Выберите "ADLSGen2" в качестве связанной службы. Введите расположение для записи CSV-файла. Данные можно, например, записать в файл `trip-data.csv` контейнера `staging-container`. Установите **Использовать первую строку в качестве заголовка** на true, если хотите, чтобы выходные данные имели заголовки. Поскольку в месте назначения еще нет файла, установите для пункта **Импорт схемы** значение **Нет** . Щелкните "OK", когда все будет готово.

    ![Копирование портала 10](media/lab-data-flow-data-share/copy10.png)

### <a name="test-the-copy-activity-with-a-pipeline-debug-run"></a>Тестирование действия копирования с помощью запуска отладки конвейера

1. Выполните отладку, чтобы проверить корректность работы действия копирования, нажав **Отладка** в верхней части холста конвейера. Выполнение отладки позволяет выполнить сквозную проверку конвейера, либо проверку до точки останова, прежде чем опубликовать его в службе фабрики данных.

    ![Копирование портала 11](media/lab-data-flow-data-share/copy11.png)
1. Чтобы следить за выполнением отладки, перейдите на вкладку **Выходные данные** холста конвейера. Экран мониторинга будет автоматически обновляться каждые 20 секунд или после ручного нажатия кнопки обновления. Деятельность копирования имеет специальное представление мониторинга, доступ к которому можно получить, щелкнув по значку очков в колонке **Действия** .

    ![Копирование портала 12](media/lab-data-flow-data-share/copy12.png)
1. Представление мониторинга копирования предоставляет сведения о процессе выполнения и характеристиках производительности. Вы можете просматривать такие сведения, как прочитанные/записанные данные, прочитанные/записанные строки, прочитанные/записанные файлы и пропускная способность. Если все настроено правильно, вы должны увидеть 49 999 строк, записанных в одном файле в вашем приемнике ADLS.

    ![Копирование портала 13](media/lab-data-flow-data-share/copy13.png)
1. Прежде чем перейти к следующему разделу, возьмите во внимание, что здесь предполагается публикация ваших изменений в службе фабрики данных, нажав **Опубликовать все** в верхней панели фабрики. Хотя в этой тестовой службе и не обсуждалось, Фабрика данных Azure поддерживает полную git-интеграцию. Интеграция Git позволяет выполнять управление версиями, итеративное сохранение в репозитории, а также совместную работу в фабрике данных. Дополнительные сведения см. [Source Control in Azure Data Factory](./source-control.md#troubleshooting-git-integration) (Система управления версиями в фабрике данных Azure).

    ![Публикация портала 1](media/lab-data-flow-data-share/publish1.png)

## <a name="transform-data-using-mapping-data-flow"></a>Преобразование данных с помощью функции сопоставления потоков данных

Теперь, когда вы успешно скопировали данные в Azure Data Lake Storage, пришло время объединить и скомпоновать эти данные в хранилище данных. Мы будем использовать поток данных сопоставления, визуально разработанную службу преобразования Фабрики данных Azure. Потоки данных сопоставления позволяют пользователям разрабатывать логические безкодовые преобразования и выполнять их на кластерах spark, управляемых службой ADF.

Поток данных, созданный в этом шаге, присоединяется к набору данных "TripDataCSV" из предыдущего раздела с таблицей "dbo.TripFares", хранящейся в "SQLDB" на основе четырех ключевых столбцов. Затем данные суммируются по столбцу `payment_type` для вычисления среднего значения по определенным полям и записываются в таблицу Azure Synapse Analytics.

### <a name="add-a-data-flow-activity-to-your-pipeline"></a>Добавление действия потока данных в конвейер

1. В панели действий холста конвейера откройте меню-гармошку **Move and Transform** (Перемещение и преобразование) и перетащите действие **Поток данных** на холст.

    ![Поток данных портала 1](media/lab-data-flow-data-share/dataflow1.png)
1. В открывшейся боковой панели выберите **Create new data flow** (Создать новый поток данных) и выберите **Поток данных для сопоставления** . Нажмите кнопку **ОК** .

    ![Поток данных портала 2](media/lab-data-flow-data-share/dataflow2.png)
1. Вы будете направлены на холст потока данных, где будет выполняться создание логики преобразования. На вкладке "Общие" назовите свой поток данных "JoinAndAggregateData".

    ![Поток данных портала 3](media/lab-data-flow-data-share/dataflow3.png)

### <a name="configure-your-trip-data-csv-source"></a>Настройка источника CSV-файла данных путешествия

1. Первое, что вы хотите сделать — это настроить два преобразования источника. Первый источник будет указывать на "TripDataCSV" набора данных DelimitedText. Чтобы добавить преобразование источника, нажмите на поле **Добавить источник** на холсте.

    ![Поток данных портала 4](media/lab-data-flow-data-share/dataflow4.png)
1. Назовите источник "TripDataCSV" и выберите набор данных "TripDataCSV" из раскрывающегося списка источника. Если вы помните, вы не импортировали схему изначально при создании этого набора данных, поскольку в нем не было данных. Так как `trip-data.csv` теперь существует, нажмите **Изменить** , чтобы перейти на вкладку настроек набора данных.

    ![Поток данных портала 5](media/lab-data-flow-data-share/dataflow5.png)
1. Перейдите на вкладку **Схема** и щелкните **Импорт схемы** . Выберите **From connection/store** (Из подключения/хранилища), чтобы импортировать непосредственно из хранилища файлов. Должны появиться 14 столбцов строки типа.

    ![Поток данных портала 6](media/lab-data-flow-data-share/dataflow6.png)
1. Вернитесь к потоку данных "JoinAndAggregateData". Если ваш отладочный кластер запущен (обозначен зеленым кружком рядом с ползунком отладки), вы можете получить моментальный снимок данных во вкладке **Предварительный просмотр данных** . Нажмите **Обновить** , чтобы получить данные предварительного просмотра.

    ![Поток данных портала 7](media/lab-data-flow-data-share/dataflow7.png)

> [!Note]
> В предварительном просмотре данные не записываются.

### <a name="configure-your-trip-fares-sql-db-source"></a>Настройка источника базы данных SQL на тарифы на путешествие

1. Второй источник, который вы добавляете, будет указывать на таблицу базы данных SQL "dbo.TripFares". Под источником "TripDataCSV" будет еще одно поле **Добавить источник** . Щелкните его, чтобы добавить новое преобразование источника.

    ![Поток данных портала 8](media/lab-data-flow-data-share/dataflow8.png)
1. Назовите этот источник "TripFaresSQL". Щелкните **Создать** рядом с полем набора данных источника, чтобы создать новый набор данных базы данных SQL.

    ![Поток данных портала 9](media/lab-data-flow-data-share/dataflow9.png)
1. Выберите плитку **База данных SQL Azure** и нажмите "Продолжить". *Примечание. Вы можете заметить, что многие соединители в фабрике данных не поддерживаются в потоке данных для сопоставления. Чтобы преобразовать данные из одного из этих источников, загрузите их в поддерживаемый источник с помощью действия копирования* .

    ![Поток данных портала 10](media/lab-data-flow-data-share/dataflow10.png)
1. Вызовите набор данных "TripFares". Выберите "SQLDB" в качестве связанной службы. Выберите "dbo.TripFares" из раскрывающегося списка имени таблицы. Импортируйте схему **From connection/store** (из подключения/хранилища). Щелкните "OK", когда все будет готово.

    ![Поток данных портала 11](media/lab-data-flow-data-share/dataflow11.png)
1. Чтобы проверить свои данные, вызовите предварительный просмотр данных на вкладке **Предварительный просмотр данных** .

    ![Поток данных портала 12](media/lab-data-flow-data-share/dataflow12.png)

### <a name="inner-join-tripdatacsv-and-tripfaressql"></a>Внутреннее соединение TripDataCSV и TripFaresSQL

1. Чтобы добавить новое преобразование, нажмите на значок плюса в правом нижнем углу "TripDataCSV". В разделе **Multiple inputs/outputs** (Несколько входных/выходных данных) выберите **Присоединить** .

    ![Соединение портала 1](media/lab-data-flow-data-share/join1.png)
1. Назовите преобразование соединения "InnerJoinWithTripFares". Выберите "TripFaresSQL" из правого раскрывающегося списка потока. Выберите в качестве типа соединения **Внутреннее** . Дополнительные сведения о различных типах соединения в потоке данных для сопоставления см. [join types](./data-flow-join.md#join-types) (Типы соединения).

    С помощью раскрывающегося списка **Join conditions** (Условия соединения) выберите, какие столбцы из каждого потока нужно сопоставить. Чтобы добавить дополнительное условие присоединения, нажмите на значок плюса рядом с существующим условием. По умолчанию все условия соединения объединены с оператором "И", что означает, что для совпадения нужно выполнить все условия. В этой тестовой службе мы хотим сопоставить столбцы `medallion`, `hack_license`, `vendor_id`, и `pickup_datetime`

    ![Соединение портала 2](media/lab-data-flow-data-share/join2.png)
1. Убедитесь, что успешно соединили 25 колонок, используя предварительный просмотр данных.

    ![Соединение портала 3](media/lab-data-flow-data-share/join3.png)

### <a name="aggregate-by-payment_type"></a>Агрегирование по payment_type

1. После завершения преобразования соединения добавьте преобразование статической обработки, нажав на иконку плюса рядом с "InnerJoinWithTripFares". Выберите **Статическая обработка** в разделе **Schema modifier** (Модификатор схемы).

    ![Агрегирование портала 1](media/lab-data-flow-data-share/agg1.png)
1. Назовите преобразование статистической обработки "AggregateByPaymentType". Выберите `payment_type` как группу по столбцам.

    ![Агрегирование портала 2](media/lab-data-flow-data-share/agg2.png)
1. Перейдите на вкладку **Статистические выражения** . Здесь вам нужно указать два агрегирования:
    * Средний тариф, сгруппированный по типу оплаты;
    * Общее расстояние поездки, сгруппированное по типу оплаты.

    Сначала вы создадите выражение "средний тариф". В текстовом поле с пометкой **Add or select a column** (Добавить или выбрать столбец), введите "average_fare".

    ![Агрегирование портала 3](media/lab-data-flow-data-share/agg3.png)
1. Чтобы ввести выражение агрегирования, щелкните по синей рамке с пометкой **Ввести выражение** . Это откроет конструктор выражений потока данных, инструмент, используемый для визуального создания выражений потока данных с использованием входной схемы, встроенных функций и операций, а также определяемых пользователем параметров. Дополнительные сведения о возможностях конструктора выражений см. [Build expressions in mapping data flow](./concepts-data-flow-expression-builder.md)(Создание выражений в потоке данных сопоставления).

    Чтобы получить средний тариф, используйте функцию агрегации `avg()` для агрегирования столбца `total_amount`, приведенного к целому числу с `toInteger()`. В языке выражения потока данных это определяется как `avg(toInteger(total_amount))`. После завершения настройки нажмите **Сохранить и завершить** .

    ![Агрегирование портала 4](media/lab-data-flow-data-share/agg4.png)
1. Чтобы добавить дополнительное агрегатное выражение, щелкните значок "плюс" рядом с `average_fare`. Выберите **Добавить столбец** .

    ![Агрегирование портала 5](media/lab-data-flow-data-share/agg5.png)
1. В текстовом поле с пометкой **Add or select a column** (Добавить или выбрать столбец), введите "total_trip_distance". Аналогично к последнему шагу, откройте построитель выражений, чтобы ввести выражение.

    Чтобы получить данные об общей дистанции поездки, используйте функцию агрегации `sum()` для агрегирования столбца `trip_distance`, приведенного к целому числу с `toInteger()`. В языке выражения потока данных это определяется как `sum(toInteger(trip_distance))`. После завершения настройки нажмите **Сохранить и завершить** .

    ![Агрегирование портала 6](media/lab-data-flow-data-share/agg6.png)
1. Протестируйте логику преобразования на вкладке **Предварительный просмотр данных** . Как видите, строк и столбцов значительно меньше, чем раньше. Только три столбца "Группировать по" и "Агрегирование", определенные в этом преобразовании, продолжают передавать данные в нисходящем направлении. Так как в образце всего пять групп типа оплаты, выводится только пять строк.

    ![Агрегирование портала 7](media/lab-data-flow-data-share/agg7.png)

### <a name="configure-you-azure-synapse-analytics-sink"></a>Настройка приемника Azure Synapse Analytics

1. Теперь,после завершения логики преобразования, мы готовы к передаче данных в таблицу Azure Synapse Analytics. Добавьте преобразование "приемник" в раздел **Назначение** .

    ![Приемник портала 1](media/lab-data-flow-data-share/sink1.png)
1. Назовите приемник "SQLDWSink". Щелкните **Новый** рядом с полем набора данных приемника, чтобы создать новый набор данных Azure Synapse Analytics.

    ![Приемник портала 2](media/lab-data-flow-data-share/sink2.png)

1. Выберите плитку **Azure Synapse Analytics (ранее — Хранилище данных SQL)** и нажмите "Продолжить".

    ![Приемник портала 3](media/lab-data-flow-data-share/sink3.png)
1. Вызовите набор данных "AggregatedTaxiData". Выберите "SQLDW" в качестве связанной службы. Выберите **Создать таблицу** и назовите новую таблицу "dbo.AggregateTaxiData". Щелкните "OK", когда все будет готово

    ![Приемник портала 4](media/lab-data-flow-data-share/sink4.png)
1. Перейдите на вкладку **Параметры** приемника. Поскольку мы создаем новую таблицу, необходимо выбрать **Recreate table** (Создать таблицу повторно) в разделе действия таблицы. Снимите флажок с пункта **Enable staging** (Включить промежуточный процесс), который переключает поведение на построковую вставку или вставку в пакет.

    ![Приемник портала 5](media/lab-data-flow-data-share/sink5.png)

Вы успешно создали свой поток данных. Теперь пора выполнить его в действии конвейера.

### <a name="debug-your-pipeline-end-to-end"></a>Комплексная отладка конвейера

1. Вернитесь на вкладку конвейера **IngestAndTransformData** . Обратите внимание на зеленое поле в действии копирования "IngestIntoADLS". Перетащите его в действие потока данных "JoinAndAggregateData". При этом создается "при успешном выполнении", что приводит к выполнению действия потока данных только в том случае, если копирование прошло успешно.

    ![Конвейер портала 1](media/lab-data-flow-data-share/pipeline1.png)
1. Как и для действия копирования, щелкните **Отладка** , чтобы выполнить отладку. Для выполнения отладки действие потока данных будет использовать активный кластер отладки, а не запускать новый. Выполнение этого конвейера займет несколько минут.

    ![Конвейер портала 2](media/lab-data-flow-data-share/pipeline2.png)
1. Как и в случае с действием копирования, поток данных имеет специальное представление мониторинга, доступ к которому осуществляется с помощью иконки "Очки" по завершении действия.

    ![Конвейер портала 3](media/lab-data-flow-data-share/pipeline3.png)
1. В представлении мониторинга можно увидеть упрощенный граф потока данных, а также время выполнения и строки на каждом этапе выполнения. Если все сделано правильно, то в этой деятельности вы должны были объединить 49 999 строк в пять.

    ![Конвейер портала 4](media/lab-data-flow-data-share/pipeline4.png)
1. Вы можете нажать на преобразование, чтобы получить дополнительные сведения о его выполнении, такую как сведения о секционировании и новых/обновленных/удаленных столбцах.

    ![Конвейер портала 5](media/lab-data-flow-data-share/pipeline5.png)

Теперь часть, посвященную фабрике данных в этой тестовой службе завершено. Опубликуйте свои ресурсы, если хотите использовать их с помощью триггеров. Вы успешно запустили конвейер, который передавал данные из базы данных SQL Azure в Azure Data Lake Storage с помощью действия копирования, а затем объединили эти данные в Azure Synapse Analytics. Чтобы убедиться, что данные успешно записаны, взгляните на SQL Server.

## <a name="share-data-using-azure-data-share"></a>Совместное использование данных с помощью Azure Data Share

В этом разделе вы узнаете, как настроить новый общий ресурс данных с помощью портала Azure. Это приведет к созданию нового общего ресурса данных, который будет содержать наборы из Azure Data Lake Store 2-го поколения и Azure Synapse Analytics (ранее — Хранилище данных SQL Azure). Затем вы настроите расписание моментальных снимков, которое предоставит потребителям данных возможность автоматически обновлять данные, к которым для них предоставлен общий доступ. После этого вы отправите приглашение получателям доступа к общему ресурсу данных. 

После создания общего ресурса данных вы переключите джойстик и станете *потребителем данных* . Будучи потребителем данных, вы пройдете через процесс принятия приглашения к общему ресурсу данных, настраивая место получения данных, и сопоставляя наборы данных с различными местами хранения. Затем вы активируете моментальный снимок, который скопирует данные общего ресурса в указанное место назначения. 

### <a name="sharing-data-data-provider-flow"></a>Совместный доступ (поток поставщика данных)

1. Откройте портал Azure в Microsoft Edge или Google Chrome.

1. Используя строку поиска в верхней части страницы, выполните поиск по фразе **Общие ресурсы данных** .

    ![Реклама портала](media/lab-data-flow-data-share/portal-ads.png)

1. Выберите учетную запись общего ресурса данных со словом "Provider" в имени. Например, **DataProvider0102** . 

1. Выберите команду **Начать совместное использование данных** .

    ![Начало сеанса совместного доступа](media/lab-data-flow-data-share/ads-start-sharing.png)

1. Выберите **+Cоздать** , чтобы начать настройку нового общий ресурс данных общей папки данных. 

1. Укажите для параметра **Имя общего ресурса** имя по своему усмотрению. Это имя общего ресурса, которое будет отображаться потребителем данных, поэтому обязательно присвойте ему описательное имя, например TaxiData.

1. В разделе **Описание** введите предложение, описывающее содержимое общего ресурса данных. Общий ресурс данных будет содержать данные о поездках в международном масштабе, которые хранятся в ряде хранилищ, включая Azure Synapse Analytics и Azure Data Lake Store. 

1. В разделе **Условия использования** укажите набор условий, которым должен соответствовать потребитель данных. Некоторые примеры включают "Не распространять эти данные за пределы организации" или "Обратиться к юридическому соглашению". 

    ![Предоставление сведений](media/lab-data-flow-data-share/ads-details.png)

1. Выберите **Continue** (Продолжить). 

1. Выберите **Добавить наборы данных** 

    ![Добавление набора данных 1](media/lab-data-flow-data-share/add-dataset.png)

1. Щелкните **Azure Synapse Analytics** (ранее — Хранилище данных SQL Azure), чтобы выбрать таблицу из Azure Synapse Analytics, в которую попали ваши преобразования Фабрики данных.

    ![Добавление набора данных SQL](media/lab-data-flow-data-share/add-dataset-sql.png)

> [!NOTE]
> Хранилище данных SQL, известное как Azure Synapse Analytics

1. Прежде,чем продолжить, вам предоставят скрипт для выполнения. Предоставленный сценарий создает пользователя в базе данных SQL, чтобы позволить MSI Azure Data Share аутентифицироваться от его имени. 

> [!IMPORTANT]
> Перед запуском сценария вы должны настроить доступ к серверу SQL в качестве администратора доменных служб Active Directory. 

1. Откройте новую вкладку и перейдите на портал Azure. Скопируйте предоставленный скрипт для создания пользователя в базе данных, для данных которой вы хотите предоставить общий доступ. Сделайте это, войдя в базу данных EDW с помощью Обозревателя запросов (предварительная версия) с помощью проверки подлинности AAD. 

    Вам нужно будет изменить скрипт так, чтобы созданный пользователь содержался в скобках. Например:
    
    создайте пользователя [dataprovider-xxxx] из внешней учетной записи;  exec sp_addrolemember db_owner, [dataprovider-xxxx];
    
1. Вернитесь к Azure Data Share, в котором вы добавляли наборы данных в общий ресурс данных. 

1. Выберите **EDW** , а затем **AggregatedTaxiData** для таблицы. 

1. Выберите **Добавить набор данных**

    Теперь у нас есть таблица SQL, которая является частью набора данных. Далее мы добавим дополнительные наборы данных из Azure Data Lake Store. 

1. Выберите **Добавить набор данных** , а затем нажмите **Azure Data Lake Store 2-го поколения**

    ![Добавление набора данных ADLS](media/lab-data-flow-data-share/add-dataset-adls.png)

1. Щелкните **Далее** .

1. Разверните *wwtaxidata* . Разверните *Сведения о такси в Бостоне* . Обратите внимание, что вы можете предоставить общий доступ к данным вплоть до уровня файлов. 

1. Выберите папку *Сведения о такси в Бостоне* , чтобы добавить всю папку в общий ресурс данных. 

1. Выберите **Добавить наборы данных**

1. Просмотрите добавленные наборы данных. К вашему общему ресурсу данных должна быть добавлена таблица SQL и папка ADLS 2-го поколения. 

1. Выберите **Продолжить**

1. На этом экране вы можете добавить получателей для общего доступа к данным. Получатели, которых вы добавите, получат приглашения для доступа к общему ресурсу данных. Для работы в этой тестовой службе необходимо добавить 2 адреса электронной почты:

    1. Адрес электронной почты подписки Azure, с помощью которой вы выполнили вход. 

        ![Добавление получателей](media/lab-data-flow-data-share/add-recipients.png)

    1. Добавьте вымышленного потребителя данных с именем *janedoe@fabrikam.com* .

1. На этом экране можно настроить пункт "Параметр моментального снимка" для потребителя данных. Это позволит им получать регулярные обновления ваших данных в указанный вами промежуток времени. 

1. Проверьте параметр **Расписание моментальных снимков** и настройте почасовое обновление данных с помощью раскрывающегося списка *Повторение* .  

1. Нажмите кнопку **создания** .

    Теперь вы имеете активный общий ресурс данных. Просмотрим, что выступает поставщиком данных при создании общего ресурса данных. 

1. Выберите созданный общий доступ к данным под заголовком **DataProvider** . Вы можете перейти к нему, выбрав **Отправленные общие папки** в **Общий ресурс данных** . 

1. Нажмите на пункт "Расписание моментальных снимков". Вы можете отключить расписание снимков по вашему выбору. 

1. Откройте вкладку **Наборы данных** . После создания этого ресурса вы сможете добавить к нему дополнительные наборы данных. 

1. Выберите вкладку **Подписки на общий ресурс** . Подписки на общий ресурс еще не существуют, потому что потребитель данных еще не принял ваше приглашение.

1. Откройте вкладку **Приглашения** . Здесь вы увидите список ожидающих приглашений. 

    ![Ожидающие приглашения](media/lab-data-flow-data-share/pending-invites.png)

1. Выберите приглашение для *janedoe@fabrikam.com* . Выберите "Удалить" Если ваш получатель еще не принял приглашение, он больше не сможет этого сделать. 

1. Выберите вкладку **Журнал** . Пока данные не отображаются, потому что потребитель данных еще не принял ваше приглашение и не активировал моментальный снимок. 

### <a name="receiving-data-data-consumer-flow"></a>Получение данных (Поток потребителя данных)

Теперь, после просмотра общего ресурса данных, мы готовы поменять контекст и переключить на работу в качестве потребителя данных. 

В вашем почтовом ящике должно быть приглашение Azure Data Share от Microsoft Azure. Запустите Outlook Web Access (outlook.com) и войдите в систему, используя учетные данные, предоставленные для вашей подписки Azure.

В письме, которое вы должны были получить, нажмите "Просмотреть приглашение >". На данном этапе вы будете имитировать опыт потребителя данных при принятии приглашения поставщиков данных на доступ к их общему ресурсу данных. 

![Приглашение по электронной почте](media/lab-data-flow-data-share/email-invite.png)

Может появиться запрос на выбор подписки. Убедитесь, что выбрали подписку, с помощью которой работали в этой тестовой службе. 

1. Щелкните на приглашение под названием *DataProvider* . 

1. На этом экране "Приглашения" вы увидите различные сведения об общем ресурсе данных, который был настроен ранее в качестве поставщика данных. Просмотрите детали и примите условия использования, если они предоставлены.

1. Выберите подписку и группу ресурсов, уже существующие в тестовой службе. 

1. Для пункта **Учетная запись Data Share** выберите **DataConsumer** . Кроме того, вы можете создать новую учетную запись Data Share. 

1. Рядом с **Received share name** (Имя полученного общего ресурса), вы заметите, что по умолчанию имя ресурса — это имя, указанное поставщиком данных. Дайте ресурсу понятное имя, которое описывает данные, которые вы собираетесь получить, например **TaxiDataShare** .

    ![Способы принятия приглашения](media/lab-data-flow-data-share/consumer-accept.png)

1. Вы можете выбрать между вариантами **Accept and configure now** (Принять и настроить) или **Accept and configure later** (Принять и настроить позже). При выборе "Принять и настроить", вам нужно будет указать учетную запись хранения, в которую следует скопировать все данные. Если вы выберете "Принять и настроить позже", наборы данных в общем ресурсе будут распакованы, и вам нужно будет сопоставить их вручную. Мы выберем это позже. 

1. Выберите **Accept and configure later** (Принять и настроить позже). 

    При настройке этой опции создается подписка на общий ресурс, но не выполняется размещение данных, так как ни один из пунктов назначения не сопоставлен. 

    Далее мы настроим сопоставления набора данных для общего ресурса данных. 

1. Выберите "Received Share" (Полученный общий ресурс) (имя, которое вы указали на шаге 5).

    Действие **Активировать моментальный снимок** будет выделено серым цветом, однако общий ресурс будет активен. 

1. Выберите вкладку **Наборы данных** . Обратите внимание, что каждый набор данных является несопоставленным, что означает, что у него нет назначения для копирования данных. 

    ![Несопоставленные наборы данных](media/lab-data-flow-data-share/unmapped.png)

1. Выберите таблицу Azure Synapse Analytics, а затем — **+ Сопоставить с целевым объектом** .

1. В правой части экрана выберите раскрывающийся список **Целевой тип данных** . 

    Вы можете сопоставить данные SQL с широким спектром хранилищ данных. В этом примере мы будем выполнять сопоставление с Базой данных SQL Azure.

    ![mapping](media/lab-data-flow-data-share/mapping-options.png)
    
    (Дополнительно) Выберите **Azure Data Lake Store 2-го поколения** в качестве целевого типа данных. 
    
    (Дополнительно) Выберите подписку, группу ресурсов и учетную запись хранения, в которой вы работали. 
    
    (Дополнительно) Вы можете выбрать получение данных в озере данных в формате CSV или parquet. 

1. Рядом с **Целевой тип данных** выберите Базу данных SQL. 

1. Выберите подписку, группу ресурсов и учетную запись хранения, в которой вы работали. 

    ![Сопоставление в sql](media/lab-data-flow-data-share/map-to-sqldb.png)

1. Перед тем, как продолжить, необходимо создать нового пользователя в SQL Server, запустив предоставленный скрипт. Скопируйте предоставленный скрипт в буфер обмена. 

1. Откройте новую вкладку с порталом Azure. Не закрывайте существующую вкладку, так как вам нужно будет вернуться к ней чуть позже. 

1. В новой открытой вкладке перейдите к пункту **Базы данных SQL** .

1. Выберите базу данных SQL (она должна быть единственной в вашей подписке). Следите за тем, чтобы не выбрать хранилище данных. 

1. Выберите **Редактор запросов (предварительная версия)**

1. Чтобы войти в Редактор запросов следует использовать проверку подлинности AAD. 

1. Выполните запрос, предоставленный в общем ресурсе данных (скопированный в буфер обмена на шаге 14). 

    Эта команда позволяет службе Azure Data Share использовать управляемые удостоверения для Служб Azure, чтобы выполнять проверку подлинности на SQL Server и иметь возможность копировать в него данные. 

1. Вернитесь на исходную вкладку и выберите **Сопоставить с целевым объектом** .

1. Затем выберите папку Azure Data Lake 2-го поколения, которая является частью набора данных, и сопоставьте ее с учетной записью хранилища BLOB-объектов Azure. 

    ![носителей.](media/lab-data-flow-data-share/storage-map.png)

    Теперь, когда все наборы данных сопоставлены, вы готовы начать получать данные от поставщика данных. 

    ![Сопоставлено](media/lab-data-flow-data-share/all-mapped.png)
    
1. Выберите **Сведения** . 

    Обратите внимание, что пункт **Активировать моментальный снимок** больше не выделяется серым цветом, поскольку общий ресурс данных теперь имеет назначения, в которые нужно копировать данные.

1. Выберите "Активировать моментальный снимок" — > "Полная копия". 

    ![триггер](media/lab-data-flow-data-share/trigger-full.png)

    Это приведет к копированию данных в новую учетную запись общего ресурса данных. В реальной ситуации эти данные поступают от стороннего производителя. 

    Потребуется около 3-5 минут, чтобы получить данные. Ход выполнения можно отслеживать, щелкнув вкладку **Журнал** . 

    Пока вы ждете, перейдите к исходному общему ресурсу данных (DataProvider) и просмотрите состояние вкладки **Подписки на общий ресурс** и **Журнал** . Обратите внимание, что теперь существует активная подписка, и как поставщик данных вы также можете отслеживать время получения потребителем данных доступа к общему ресурсу данных. 

1. Вернитесь к общему ресурсу данных потребителя данных. Сразу после успешной активации перейдите к целевой базе данных SQL и озеру данных, чтобы проверить, что данные передано в соответствующие хранилища. 

Поздравляем, вы завершили работу с тестовой службой!