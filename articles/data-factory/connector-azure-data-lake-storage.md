---
title: Копирование и преобразование данных в Azure Data Lake Storage 2-го поколения
description: Узнайте, как с помощью Фабрики данных Azure копировать данные в хранилище Azure Data Lake Storage 2-го поколения и из него, а также преобразовывать данные в Azure Data Lake Storage 2-го поколения.
services: data-factory
ms.author: jingwang
author: linda33wj
manager: shwang
ms.reviewer: douglasl
ms.service: data-factory
ms.workload: data-services
ms.topic: conceptual
ms.custom: seo-lt-2019
ms.date: 07/09/2020
ms.openlocfilehash: 7a17e9b0de3e77b2f6b8bf3c6eb55503d34c359c
ms.sourcegitcommit: f844603f2f7900a64291c2253f79b6d65fcbbb0c
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/10/2020
ms.locfileid: "86223726"
---
# <a name="copy-and-transform-data-in-azure-data-lake-storage-gen2-using-azure-data-factory"></a>Копирование данных в Azure Data Lake Storage 2-го поколения и их преобразование с помощью Фабрики данных Azure

[!INCLUDE[appliesto-adf-asa-md](includes/appliesto-adf-asa-md.md)]

Azure Data Lake Storage 2-го поколения (ADLS 2-го поколения) — это набор возможностей аналитики больших данных, созданный на основе [хранилища BLOB-объектов Azure](../storage/blobs/storage-blobs-introduction.md). С его помощью можно работать с данными с использованием парадигмы файловой системы или хранилища объектов.

В этой статье описано, как копировать данные в хранилище Azure Data Lake Storage 2-го поколения и из него с помощью действия копирования в Фабрике данных Azure, а также как преобразовывать данные в Azure Data Lake Storage 2-го поколения с помощью Потока данных. Дополнительные сведения о Фабрике данных Azure см. во [вводной статье](introduction.md).

>[!TIP]
>Дополнительные сведения о сценарии миграции озера данных или хранилища данных см. в статье [Использование фабрики данных Azure для переноса данных из озера данных или хранилища данных в Azure](data-migration-guidance-overview.md).

## <a name="supported-capabilities"></a>Поддерживаемые возможности

Этот соединитель Azure Data Lake Storage 2-го поколения предназначен для выполнения следующих действий.

- [Действие копирования](copy-activity-overview.md) с использованием матрицы [поддерживаемых источников и приемников](copy-activity-overview.md).
- [Поток данных для сопоставления](concepts-data-flow-overview.md)
- [Действие поиска](control-flow-lookup-activity.md)
- [Действие получения метаданных в Фабрике данных Azure](control-flow-get-metadata-activity.md)
- [Действие удаления](delete-activity.md)

Используя этот соединитель для действия копирования, можно:

- копировать данные в хранилище Azure Data Lake Storage 2-го поколения или из него с использованием аутентификации на основе ключа учетной записи, субъекта-службы или управляемых удостоверений для ресурсов Azure;
- копировать файлы "как есть" или создавать файлы с использованием [поддерживаемых форматов файла и кодеков сжатия](supported-file-formats-and-compression-codecs.md);
- [сохранять метаданные файла во время копирования](#preserve-metadata-during-copy);
- [сохранять списки управления доступом](#preserve-acls) при копировании данных из Azure Data Lake Storage 1-го или 2-го поколения.

>[!IMPORTANT]
>Если включить параметр **Разрешить доверенным службам Майкрософт доступ к этой учетной записи хранения** в настройках брандмауэра службы хранилища Azure, то при попытке использовать среду выполнения интеграции Azure для подключения к Azure Data Lake Storage 2-го поколения потребуется использовать [аутентификацию на основе управляемого удостоверения](#managed-identity) для ADLS 2-го поколения.


## <a name="get-started"></a>Начало работы

>[!TIP]
>Пошаговое руководство по использованию соединителя Azure Data Lake Storage 2-го поколения см. в статье [Загрузка данных в Azure Data Lake Storage 2-го поколения](load-azure-data-lake-storage-gen2.md).

[!INCLUDE [data-factory-v2-connector-get-started](../../includes/data-factory-v2-connector-get-started.md)]

Следующие разделы содержат сведения о свойствах, которые используются для определения сущностей Фабрики данных, характерных для Azure Data Lake Storage 2-го поколения.

## <a name="linked-service-properties"></a>Свойства связанной службы

Соединитель Azure Data Lake Storage 2-го поколения поддерживает приведенные ниже типы аутентификации. Дополнительные сведения см. в соответствующих разделах:

- [Проверка подлинности на основе ключа учетной записи](#account-key-authentication)
- [Проверка подлинности субъекта-службы](#service-principal-authentication)
- [Проверка подлинности на основе управляемого удостоверения службы](#managed-identity)

>[!NOTE]
>Если при использовании PolyBase для загрузки данных в хранилище данных SQL в исходном или промежуточном Data Lake Storage 2-го поколения настроена конечная точка виртуальной сети, необходимо использовать аутентификацию на основе управляемого удостоверения в соответствии с требованиями PolyBase. Дополнительные предварительные требования к конфигурации см. в разделе [Проверка подлинности с использованием управляемого удостоверения](#managed-identity).

### <a name="account-key-authentication"></a>Проверка подлинности на основе ключа учетной записи

При использовании проверки подлинности на основе ключа учетной записи поддерживаются следующие свойства.

| Свойство | Описание | Обязательно |
|:--- |:--- |:--- |
| type | Для свойства type необходимо задать значение **AzureBlobFS**. |Да |
| url | Конечная точка для Azure Data Lake Storage 2-го поколения вида `https://<accountname>.dfs.core.windows.net`. | Да |
| accountKey | Ключ учетной записи для Azure Data Lake Storage 2-го поколения. Пометьте это поле как SecureString, чтобы безопасно хранить его в фабрике данных, или [добавьте ссылку на секрет, хранящийся в Azure Key Vault](store-credentials-in-key-vault.md). |Да |
| connectVia | [Среда выполнения интеграции](concepts-integration-runtime.md), используемая для подключения к хранилищу данных. Вы можете использовать среду выполнения интеграции Azure или локальную среду IR (если хранилище данных расположено в частной сети). Если это свойство не задано, используется Azure Integration Runtime по умолчанию. |Нет |

>[!NOTE]
>Дополнительная конечная точка файловой системы ADLS не поддерживается при использовании аутентификации на основе ключа учетной записи. Можно использовать другие типы аутентификации.

**Пример**.

```json
{
    "name": "AzureDataLakeStorageGen2LinkedService",
    "properties": {
        "type": "AzureBlobFS",
        "typeProperties": {
            "url": "https://<accountname>.dfs.core.windows.net", 
            "accountkey": { 
                "type": "SecureString", 
                "value": "<accountkey>" 
            }
        },
        "connectVia": {
            "referenceName": "<name of Integration Runtime>",
            "type": "IntegrationRuntimeReference"
        }
    }
}
```

### <a name="service-principal-authentication"></a>Проверка подлинности субъекта-службы

Чтобы использовать аутентификацию на основе субъекта-службы, выполните следующие действия.

1. Чтобы зарегистрировать сущность приложения в Azure Active Directory (Azure AD), необходимо следовать указаниям из раздела [Регистрация приложения в клиенте Azure AD](../storage/common/storage-auth-aad-app.md#register-your-application-with-an-azure-ad-tenant). Запишите следующие значения, которые используются для определения связанной службы:

    - Идентификатор приложения
    - Ключ приложения
    - Tenant ID

2. Предоставьте правильное разрешение субъекту-службе. Примеры использования разрешения в Data Lake Storage 2-го поколения см. в статье [Списки управления доступом для файлов и каталогов](../storage/blobs/data-lake-storage-access-control.md#access-control-lists-on-files-and-directories).

    - **В качестве источника**. В Обозревателе службы хранилища предоставьте как минимум разрешение **Выполнение** для ВСЕХ вышестоящих папок и файловой системы, а также разрешение **Чтение** для копируемых файлов. Можно также в Системе управления идентификацией и доступом (IAM) назначить по крайней мере роль **Модуль чтения данных BLOB-объектов хранилища**.
    - **В качестве приемника**. В Обозревателе службы хранилища предоставьте как минимум разрешение **Выполнение** для ВСЕХ вышестоящих папок и файловой системы, а также разрешение **Запись** для папки приемника. Можно также в Системе управления идентификацией и доступом (IAM) назначить по крайней мере роль **Участник для данных BLOB-объектов хранилища**.

>[!NOTE]
>Если вы используете пользовательский интерфейс Фабрики данных и не назначили для субъекта-службы роль "Модуль чтения данных BLOB-объектов хранилища" или "Участник для данных BLOB-объектов хранилища" в IAM, то при проверке подключения или просмотре папок выберите "Test connection to file path" (Проверить подключение к пути к файлу) или "Browse from specified path" (Обзор по указанному пути) и укажите путь с разрешением **Чтение и выполнение**, чтобы продолжить.

Приведенные ниже свойства поддерживаются в связанной службе.

| Свойство | Описание | Обязательно |
|:--- |:--- |:--- |
| type | Для свойства type необходимо задать значение **AzureBlobFS**. |Да |
| url | Конечная точка для Azure Data Lake Storage 2-го поколения вида `https://<accountname>.dfs.core.windows.net`. | Да |
| servicePrincipalId | Укажите идентификатора клиента приложения. | Да |
| servicePrincipalKey | Укажите ключ приложения. Пометьте это поле как `SecureString`, чтобы безопасно хранить его в Фабрике данных. Вы можете также [указать секрет, хранящийся в Azure Key Vault](store-credentials-in-key-vault.md). | Да |
| tenant | Укажите сведения о клиенте (доменное имя или идентификатор клиента), в котором находится приложение. Эти сведения можно получить, наведя указатель мыши на правый верхний угол страницы портала Azure. | Да |
| connectVia | [Среда выполнения интеграции](concepts-integration-runtime.md), используемая для подключения к хранилищу данных. Вы можете использовать среду выполнения интеграции Azure или локальную среду IR (если хранилище данных расположено в частной сети). Если не указано другое, используется среда выполнения интеграции Azure по умолчанию. |Нет |

**Пример**.

```json
{
    "name": "AzureDataLakeStorageGen2LinkedService",
    "properties": {
        "type": "AzureBlobFS",
        "typeProperties": {
            "url": "https://<accountname>.dfs.core.windows.net", 
            "servicePrincipalId": "<service principal id>",
            "servicePrincipalKey": {
                "type": "SecureString",
                "value": "<service principal key>"
            },
            "tenant": "<tenant info, e.g. microsoft.onmicrosoft.com>" 
        },
        "connectVia": {
            "referenceName": "<name of Integration Runtime>",
            "type": "IntegrationRuntimeReference"
        }
    }
}
```

### <a name="managed-identities-for-azure-resources-authentication"></a><a name="managed-identity"></a> Управляемые удостоверения для аутентификации ресурсов Azure

Фабрика данных может быть связана с [управляемым удостоверением для ресурсов Azure](data-factory-service-identity.md), которое представляет эту фабрику данных. Это управляемое удостоверение можно напрямую использовать для аутентификации Azure Data Lake Storage 2-го поколения так же, как собственный субъект-службу. Оно разрешает назначенной фабрике обращаться к данным и копировать их из хранилища Azure Data Lake Storage 2-го поколения и в него.

Чтобы использовать управляемые удостоверения для аутентификации ресурсов Azure, выполните следующие действия.

1. [Получите управляемое удостоверение Фабрики данных](data-factory-service-identity.md#retrieve-managed-identity), скопировав значение **идентификатора объекта управляемого удостоверения**, созданного вместе с фабрикой.

2. Предоставьте соответствующее разрешение управляемому удостоверению. Примеры использования разрешения в Data Lake Storage 2-го поколения см. в статье [Списки управления доступом для файлов и каталогов](../storage/blobs/data-lake-storage-access-control.md#access-control-lists-on-files-and-directories).

    - **В качестве источника**. В Обозревателе службы хранилища предоставьте как минимум разрешение **Выполнение** для ВСЕХ вышестоящих папок и файловой системы, а также разрешение **Чтение** для копируемых файлов. Можно также в Системе управления идентификацией и доступом (IAM) назначить по крайней мере роль **Модуль чтения данных BLOB-объектов хранилища**.
    - **В качестве приемника**. В Обозревателе службы хранилища предоставьте как минимум разрешение **Выполнение** для ВСЕХ вышестоящих папок и файловой системы, а также разрешение **Запись** для папки приемника. Можно также в Системе управления идентификацией и доступом (IAM) назначить по крайней мере роль **Участник для данных BLOB-объектов хранилища**.

>[!NOTE]
>Если вы используете пользовательский интерфейс Фабрики данных и не назначили для управляемого удостоверения роль "Модуль чтения данных BLOB-объектов хранилища" или "Участник для данных BLOB-объектов хранилища" в IAM, то при проверке подключения или просмотре папок выберите "Test connection to file path" (Проверить подключение к пути к файлу) или "Browse from specified path" (Обзор по указанному пути) и укажите путь с разрешением **Чтение и выполнение**, чтобы продолжить.

>[!IMPORTANT]
>Если вы используете Polybase для загрузки данных из Data Lake Storage 2-го поколения в хранилище данных SQL, то при использовании проверки подлинности с помощью управляемого удостоверения для Data Lake Storage 2-го поколения убедитесь, что вы также выполняйте шаги 1 и 2 в [этом руководстве](../azure-sql/database/vnet-service-endpoint-rule-overview.md#impact-of-using-vnet-service-endpoints-with-azure-storage) , чтобы 1) зарегистрировать в Azure Active Directory (Azure AD) и 2) назначить роль участника данных BLOB-объекта хранилища на сервере. остальные обрабатываются фабрикой данных. Если хранилище Azure Data Lake Storage 2-го поколения настроено с использованием конечной точки виртуальной сети Azure, чтобы использовать PolyBase для загрузки данных из него, требуется аутентификация на основе управляемого удостоверения в соответствии с требованиями PolyBase.

Приведенные ниже свойства поддерживаются в связанной службе.

| Свойство | Описание | Обязательно |
|:--- |:--- |:--- |
| type | Для свойства type необходимо задать значение **AzureBlobFS**. |Да |
| url | Конечная точка для Azure Data Lake Storage 2-го поколения вида `https://<accountname>.dfs.core.windows.net`. | Да |
| connectVia | [Среда выполнения интеграции](concepts-integration-runtime.md), используемая для подключения к хранилищу данных. Вы можете использовать среду выполнения интеграции Azure или локальную среду IR (если хранилище данных расположено в частной сети). Если не указано другое, используется среда выполнения интеграции Azure по умолчанию. |Нет |

**Пример**.

```json
{
    "name": "AzureDataLakeStorageGen2LinkedService",
    "properties": {
        "type": "AzureBlobFS",
        "typeProperties": {
            "url": "https://<accountname>.dfs.core.windows.net", 
        },
        "connectVia": {
            "referenceName": "<name of Integration Runtime>",
            "type": "IntegrationRuntimeReference"
        }
    }
}
```

## <a name="dataset-properties"></a>Свойства набора данных

Полный список разделов и свойств, доступных для определения наборов данных, см. в разделе [Наборы данных в фабрике данных Azure](concepts-datasets-linked-services.md).

[!INCLUDE [data-factory-v2-file-formats](../../includes/data-factory-v2-file-formats.md)] 

Ниже перечислены свойства, которые поддерживаются для Azure Data Lake Storage 2-го поколения в настройках `location` в наборе данных на основе формата.

| Свойство   | Описание                                                  | Обязательно |
| ---------- | ------------------------------------------------------------ | -------- |
| type       | Для свойства type в разделе `location` в наборе данных должно быть задано значение **AzureBlobFSLocation**. | Да      |
| fileSystem | Имя файловой системы Azure Data Lake Storage 2-го поколения.                              | Нет       |
| folderPath | Путь к папке в заданной файловой системе. Если вы хотите использовать подстановочный знак для фильтрации папок, пропустите этот параметр и укажите его в параметрах источника действия. | Нет       |
| fileName   | Имя файла по заданному пути к папке в указанной файловой системе. Если вы хотите использовать подстановочный знак для фильтрации файлов, пропустите этот параметр и укажите его в параметрах источника действия. | Нет       |

**Пример**.

```json
{
    "name": "DelimitedTextDataset",
    "properties": {
        "type": "DelimitedText",
        "linkedServiceName": {
            "referenceName": "<Data Lake Storage Gen2 linked service name>",
            "type": "LinkedServiceReference"
        },
        "schema": [ < physical schema, optional, auto retrieved during authoring > ],
        "typeProperties": {
            "location": {
                "type": "AzureBlobFSLocation",
                "fileSystem": "filesystemname",
                "folderPath": "folder/subfolder"
            },
            "columnDelimiter": ",",
            "quoteChar": "\"",
            "firstRowAsHeader": true,
            "compressionCodec": "gzip"
        }
    }
}
```

## <a name="copy-activity-properties"></a>Свойства действия копирования

Полный список разделов и свойств, используемых для определения действий, доступен в разделах [Действие копирования в фабрике данных Azure](copy-activity-overview.md#configuration) и [Конвейеры и действия в фабрике данных Azure](concepts-pipelines-activities.md). Этот раздел содержит список свойств, поддерживаемых источником и приемником Data Lake Storage Gen2.

### <a name="azure-data-lake-storage-gen2-as-a-source-type"></a>Azure Data Lake Storage 2-го поколения как тип источника

[!INCLUDE [data-factory-v2-file-formats](../../includes/data-factory-v2-file-formats.md)] 

Существует несколько вариантов копирования данных из ADLS 2-го поколения:

- копирование из указанного пути в наборе данных;
- фильтр с подстановочными знаками для пути к папке или имени файла (см. сведения в разделах `wildcardFolderPath` и `wildcardFileName`);
- копирование набора файлов, определенных в заданном текстовом файле (см. сведения в разделе `fileListPath`).

Ниже перечислены свойства, которые поддерживаются для Azure Data Lake Storage 2-го поколения в настройках `storeSettings` в источнике копирования на основе формата.

| Свойство                 | Описание                                                  | Обязательно                                      |
| ------------------------ | ------------------------------------------------------------ | --------------------------------------------- |
| type                     | Для свойства type в разделе `storeSettings` необходимо задать значение **AzureBlobFSReadSettings**. | Да                                           |
| ***Поиск файлов для копирования:*** |  |  |
| ВАРИАНТ 1. Статический путь<br> | Копирование из указанной файловой системы или пути к папке либо файлу, которые указаны в наборе данных. Если вы хотите скопировать все файлы из файловой системы или папки, дополнительно укажите для `wildcardFileName` значение `*`. |  |
| ВАРИАНТ 2. Подстановочный знак<br>- wildcardFolderPath | Путь к папке с подстановочными знаками в заданной файловой системе, настроенный в наборе данных для фильтрации исходных папок. <br>Допустимые подстановочные знаки: `*` (соответствует нулю или большему количеству знаков) и `?` (соответствует нулю или одному знаку). Для экранирования используйте `^`, если фактическое имя папки содержит подстановочный знак или escape-символ. <br>Дополнительные примеры приведены в разделе [Примеры фильтров папок и файлов](#folder-and-file-filter-examples). | Нет                                            |
| ВАРИАНТ 2. Подстановочный знак<br>- wildcardFileName | Имя файла с подстановочными знаками в заданной файловой системе с параметрами folderPath или wildcardFolderPath для фильтрации исходных папок. <br>Допустимые подстановочные знаки: `*` (соответствует нулю или большему количеству знаков) и `?` (соответствует нулю или одному знаку). Для экранирования используйте `^`, если фактическое имя папки содержит подстановочный знак или escape-символ.  Дополнительные примеры приведены в разделе [Примеры фильтров папок и файлов](#folder-and-file-filter-examples). | Да |
| ВАРИАНТ 3. Список файлов<br>- fileListPath | Указывает, что нужно скопировать заданный набор файлов. Укажите текстовый файл, содержащий список файлов, которые необходимо скопировать, по одному файлу в строке, который является относительным путем к пути, настроенному в наборе данных.<br/>При использовании этого параметра не указывайте имя файла в наборе данных. Ознакомьтесь с дополнительными примерами в разделе [Примеры списков файлов](#file-list-examples). |Нет |
| ***Дополнительные параметры:*** |  | |
| recursive | Указывает, следует ли читать данные рекурсивно из вложенных папок или только из указанной папки. Обратите внимание, что если для свойства recursive задано значение true, а приемником является файловое хранилище, пустые папки и вложенные папки не создаются в приемнике. <br>Допустимые значения: **true** (по умолчанию) и **false**.<br>Это свойство не применяется при настройке `fileListPath`. |Нет |
| делетефилесафтеркомплетион | Указывает, будут ли удалены двоичные файлы из исходного хранилища после успешного перемещения в целевое хранилище. Файл удаляется для каждого файла, поэтому при сбое действия копирования вы увидите, что некоторые файлы уже скопированы в место назначения и удалены из источника, а остальные остаются в исходном хранилище. <br/>Это свойство допустимо только в сценариях двоичного копирования, где хранилища источников данных являются BLOB-объектами, ADLS 1-го поколения, ADLS 2-го поколения, S3, облачное хранилище Google, файл, файл Azure, SFTP или FTP. Значение по умолчанию: false. |Нет |
| modifiedDatetimeStart    | Фильтр файлов на основе атрибута: последнее изменение. <br>Файлы будут выбраны, если время их последнего изменения находится в диапазоне времени `modifiedDatetimeStart` и `modifiedDatetimeEnd`. Время представлено часовым поясом UTC в формате "2018-12-01T05:00:00Z". <br> Свойства могут иметь значение NULL, что означает, что фильтр атрибутов файла не будет применяться к набору данных.  Если для параметра `modifiedDatetimeStart` задано значение даты и времени, но параметр `modifiedDatetimeEnd` имеет значение NULL, то будут выбраны файлы, чей атрибут последнего изменения больше указанного значения даты и времени или равен ему.  Если для параметра `modifiedDatetimeEnd` задано значение даты и времени, но параметр `modifiedDatetimeStart` имеет значение NULL, то будут выбраны все файлы, чей атрибут последнего изменения меньше указанного значения даты и времени.<br/>Это свойство не применяется при настройке `fileListPath`. | Нет                                            |
| modifiedDatetimeEnd      | То же, что и выше.                                               | Нет                                            |
| maxConcurrentConnections | Количество одновременных подключений к хранилищу. Укажите, только если требуется ограничить одновременные подключения к хранилищу данных. | Нет                                            |

**Пример**.

```json
"activities":[
    {
        "name": "CopyFromADLSGen2",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<Delimited text input dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<output dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "DelimitedTextSource",
                "formatSettings":{
                    "type": "DelimitedTextReadSettings",
                    "skipLineCount": 10
                },
                "storeSettings":{
                    "type": "AzureBlobFSReadSettings",
                    "recursive": true,
                    "wildcardFolderPath": "myfolder*A",
                    "wildcardFileName": "*.csv"
                }
            },
            "sink": {
                "type": "<sink type>"
            }
        }
    }
]
```

### <a name="azure-data-lake-storage-gen2-as-a-sink-type"></a>Azure Data Lake Storage Gen2 как тип приемника

[!INCLUDE [data-factory-v2-file-formats](../../includes/data-factory-v2-file-formats.md)] 

Ниже перечислены свойства, которые поддерживаются для Azure Data Lake Storage 2-го поколения в настройках `storeSettings` в приемнике копирования на основе формата.

| Свойство                 | Описание                                                  | Обязательно |
| ------------------------ | ------------------------------------------------------------ | -------- |
| type                     | Для свойства type в разделе `storeSettings` необходимо задать значение **AzureBlobFSWriteSettings**. | Да      |
| copyBehavior             | Определяет поведение копирования, когда источником являются файлы из файлового хранилища данных.<br/><br/>Допустимые значения:<br/><b>— PreserveHierarchy (по умолчанию)</b>. Сохраняет иерархию файлов в целевой папке. Относительный путь исходного файла в исходной папке идентичен относительному пути целевого файла в целевой папке.<br/><b>— FlattenHierarchy</b>. Все файлы из исходной папки размещаются на первом уровне в целевой папке. Целевые файлы имеют автоматически сформированные имена. <br/><b>— MergeFiles</b>. Объединяет все файлы из исходной папки в один файл. Если указано имя файла, то оно присваивается объединенному файлу. В противном случае присваивается автоматически созданное имя файла. | Нет       |
| blockSizeInMB | Укажите размер блока в МБ, используемый для записи данных в Azure Data Lake Storage 2-го поколения. Узнайте больше [о блочных BLOB-объектaх](https://docs.microsoft.com/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs#about-block-blobs). <br/>Допустимое значение — **от 4 МБ до 100 МБ**. <br/>По умолчанию ADF автоматически определяет размер блока на основе типа и данных исходного хранилища. Для недвоичного копирования в ADLS 2-го поколения размер блока по умолчанию составляет 100 МБ, поэтому для размещения не более 4,95 ТБ данных. Если объем данных не слишком велик, это может оказаться неоптимальным, особенно при использовании локальной среды выполнения интеграции с плохой сетью, что приводит к истечению времени ожидания или проблемам с производительностью. Можно явно указать размер блока, а также убедиться, что значение параметра blockSizeInMB*50000 достаточно велико для хранения данных, в противном случае выполнение действия копирования завершится ошибкой. | Нет |
| maxConcurrentConnections | Количество одновременных подключений к хранилищу данных. Укажите, только если требуется ограничить одновременные подключения к хранилищу данных. | Нет       |

**Пример**.

```json
"activities":[
    {
        "name": "CopyToADLSGen2",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<input dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<Parquet output dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "<source type>"
            },
            "sink": {
                "type": "ParquetSink",
                "storeSettings":{
                    "type": "AzureBlobFSWriteSettings",
                    "copyBehavior": "PreserveHierarchy"
                }
            }
        }
    }
]
```

### <a name="folder-and-file-filter-examples"></a>Примеры фильтров папок и файлов

В этом разделе описываются результаты применения фильтров с подстановочными знаками к пути папки и имени файла.

| folderPath | fileName | recursive | Структура исходной папки и результат фильтрации (извлекаются файлы, выделенные **полужирным** шрифтом)|
|:--- |:--- |:--- |:--- |
| `Folder*` | (Пусто, используйте значение по умолчанию) | false | ПапкаA<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл1.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл2.json**<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3.csv<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5.csv<br/>Другая_папкаB<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл6.csv |
| `Folder*` | (Пусто, используйте значение по умолчанию) | Да | ПапкаA<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл1.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл2.json**<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл3.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл4.json**<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл5.csv**<br/>Другая_папкаB<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл6.csv |
| `Folder*` | `*.csv` | false | ПапкаA<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл1.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3.csv<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5.csv<br/>Другая_папкаB<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл6.csv |
| `Folder*` | `*.csv` | Да | ПапкаA<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл1.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл3.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл5.csv**<br/>Другая_папкаB<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл6.csv |

### <a name="file-list-examples"></a>Примеры списков файлов

В этом разделе описывается результирующее поведение при использовании пути к списку файлов в источнике действия копирования.

Предположим, что у вас есть следующая исходная структура папок и вы хотите скопировать файлы, выделенные полужирным шрифтом.

| Пример исходной структуры                                      | Содержимое файла FileListToCopy.txt                             | Конфигурация ADF                                            |
| ------------------------------------------------------------ | --------------------------------------------------------- | ------------------------------------------------------------ |
| filesystem<br/>&nbsp;&nbsp;&nbsp;&nbsp;ПапкаA<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл1.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл2.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл3.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл5.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;Метаданные<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FileListToCopy.txt | Файл1.csv<br>Вложенная_папка1/Файл3.csv<br>Вложенная_папка1/Файл5.csv | **В наборе данных:**<br>- файловая система: `filesystem`<br>- путь к папке: `FolderA`<br><br>**В источнике действия копирования:**<br>— Путь к списку файлов: `filesystem/Metadata/FileListToCopy.txt` <br><br>Путь к списку файлов указывает на текстовый файл в том же хранилище данных, содержащий список файлов, которые необходимо скопировать, указав по одному файлу в строке с относительным путем к пути, заданному в наборе данных. |


### <a name="some-recursive-and-copybehavior-examples"></a>Некоторые примеры recursive и copyBehavior

В данном разделе описываются результаты выполнения операции копирования при использовании различных сочетаний значений recursive и copyBehavior.

| recursive | copyBehavior | Структура папок источника | Результаты цели |
|:--- |:--- |:--- |:--- |
| true |preserveHierarchy | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая "Папка1" создается с такой же структурой, как и исходная папка:<br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 |
| true |flattenHierarchy | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой: <br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл1"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл2"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл3"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл4"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл5" |
| Да |mergeFiles | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой: <br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Содержимое файлов "Файл1", "Файл2", "Файл3", "Файл4" и "Файл5" объединяется в один файл с автоматически созданным именем. |
| false |preserveHierarchy | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой: <br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/><br/>Папка "Вложенная_папка1" с файлами "Файл3", "Файл4" и "Файл5" не будет включена в эту папку. |
| false |flattenHierarchy | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой: <br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл1"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл2"<br/><br/>Папка "Вложенная_папка1" с файлами "Файл3", "Файл4" и "Файл5" не будет включена в эту папку. |
| false |mergeFiles | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой: <br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Содержимое файлов "Файл1" и "Файл2" объединяется в один файл с автоматически созданным именем. автоматически созданное имя для "Файл1"<br/><br/>Папка "Вложенная_папка1" с файлами "Файл3", "Файл4" и "Файл5" не будет включена в эту папку. |

## <a name="preserve-metadata-during-copy"></a>Сохранение метаданных файла во время копирования

При копировании файлов из Amazon S3/BLOB-объекта Azure или Azure Data Lake Storage 2-го поколения в Azure Data Lake Storage 2-го поколения или BLOB-объект Azure можно сохранить метаданные файла вместе с данными. Подробнее см. в разделе [Сохранение метаданных](copy-activity-preserve-metadata.md#preserve-metadata).

## <a name="preserve-acls-from-data-lake-storage-gen1gen2"></a><a name="preserve-acls"></a> Сохранение списков управления доступом из Data Lake Storage 1-го или 2-го поколения

При копировании файлов из Azure Data Lake Storage 1-го или 2-го поколения в ADLS 2-го поколения можно сохранить списки управления доступом POSIX вместе с данными. Узнайте больше в разделе [Сохранение списков управления доступом из Data Lake Storage 1-го или 2-го поколения](copy-activity-preserve-metadata.md#preserve-acls).

>[!TIP]
>Пошаговые инструкции и рекомендации по копированию данных из Azure Data Lake Storage 1-го поколения в Azure Data Lake Storage 2-го поколения см. в статье [Копирование данных из Azure Data Lake Storage 1-го поколения в Azure Data Lake Storage 2-го поколения с помощью Фабрики данных Azure](load-azure-data-lake-storage-gen2-from-gen1.md).

## <a name="mapping-data-flow-properties"></a>Свойства потока данных для сопоставления

При преобразовании данных в сопоставление потоков данных можно считывать и записывать файлы из Azure Data Lake Storage 2-го поколения в следующих форматах:
* [Avro](format-avro.md#mapping-data-flow-properties)
* [Общая модель данных (Предварительная версия)](format-common-data-model.md#mapping-data-flow-properties)
* [Текст с разделителями](format-delimited-text.md#mapping-data-flow-properties)
* [Разностная версия](format-delta.md#mapping-data-flow-properties)
* [Excel](format-excel.md#mapping-data-flow-properties)
* [JSON](format-json.md#mapping-data-flow-properties)
* [Parquet](format-parquet.md#mapping-data-flow-properties)

Конкретные параметры форматирования находятся в документации по этому формату. Дополнительные сведения см. в статье [Преобразование источника в преобразование потока данных сопоставления](data-flow-source.md) и [приемника в потоке данных сопоставления](data-flow-sink.md).

### <a name="source-transformation"></a>Преобразование источника

В преобразовании источника можно выполнять чтение из контейнера, папки или отдельного файла в Azure Data Lake Storage 2-го поколения. Настройки управления чтением файлов находятся на вкладке **Параметры источника**. 

![Параметры источника](media/data-flow/sourceOptions1.png "Параметры источника")

**Путь с подстановочными знаками.** Использование шаблона с подстановочными знаками позволяет указать потоку ADF, что необходимо перебрать каждую соответствующую папку и файл в одном преобразовании источника. Это эффективный способ обработки нескольких файлов в одном потоке. Добавьте несколько шаблонов сопоставления с подстановочными знаками с помощью значка плюса ("+"), который появляется при наведении указателя мыши на существующий шаблон с подстановочными знаками.

В исходном контейнере выберите файлы, соответствующие шаблону. В наборе данных можно указать только контейнер. Путь с подстановочными знаками должен также включать путь к папке из корневой папки.

Примеры подстановочных знаков:

* ```*``` — представляет любой набор символов;
* ```**``` — представляет рекурсивную вложенность каталога;
* ```?``` — заменяет один символ;
* ```[]``` — соответствует одному или нескольким символам в квадратных скобках;

* ```/data/sales/**/*.csv``` — возвращает все файлы CSV в папке /data/sales;
* ```/data/sales/20??/**/``` — возвращает все файлы, созданные в 20 веке;
* ```/data/sales/*/*/*.csv``` — возвращает файлы CSV, расположенные двумя уровнями ниже папки /data/sales;
* ```/data/sales/2004/*/12/[XY]1?.csv``` — возвращает все файлы CSV, созданные в декабре 2004 года, которые начинаются с X или Y с двузначным числом в качестве префикса.

**Корневой путь раздела.** Если в источнике файлов имеются секционированные папки формата ```key=value``` (например, year=2019), то верхний уровень этого дерева секционированной папки можно назначить имени столбца в потоке данных.

Во-первых, задайте подстановочный знак, чтобы включить все пути, которые являются в секционированных папках, а также конечные файлы, которые вы хотите прочитать.

![Параметры исходного файла раздела](media/data-flow/partfile2.png "Параметр файла раздела")

Для определения верхнего уровня структуры папок используйте параметр "Корневой путь раздела". При просмотре содержимого данных с помощью предварительного просмотра данных вы увидите, что ADF добавит разрешенные разделы, найденные на каждом уровне папок.

![Корневой путь раздела](media/data-flow/partfile1.png "Предварительный просмотр корневого пути раздела")

**Список файлов.** Это набор файлов. Создайте текстовый файл, который включает список относительных путей файлов для обработки. Укажите на этот текстовый файл.

**Столбец для хранения имени файла.** Сохраните имя исходного файла в столбце данных. Укажите здесь новое имя столбца для хранения строки имени файла.

**После завершения.** Укажите, что делать после завершения: ничего не делать с исходным файлом после выполнения потока данных, удалить или переместить исходные файлы. Пути для перемещения являются относительными.

Чтобы переместить исходные файлы в другое расположение после обработки, сначала выберите "Переместить" для операции с файлом. Затем задайте исходный каталог. Если вы не используете подстановочные знаки в пути, исходным каталогом будет та же папка, что и исходная папка.

Если у вас есть исходный путь с подстановочным знаком, синтаксис будет выглядеть следующим образом.

```/data/sales/20??/**/*.csv```

В качестве исходной папки можно указать

```/data/sales```

В качестве целевой папки можно указать

```/backup/priorSales```

В этом случае все файлы, источником которых является папка /data/sales, перемещаются в папку /backup/priorSales.

> [!NOTE]
> Операции с файлами выполняются только в том случае, если поток данных выполняется из запуска конвейера (отладка конвейера или запуск выполнения) с использованием действия выполнения потока данных в конвейере. Операции с файлами *не* выполняются в режиме отладки потока данных.

**Фильтровать по дате последнего изменения.** Вы можете отфильтровать обрабатываемые файлы, указав диапазон дат последнего изменения. Все значения даты и времени указаны в формате UTC. 

### <a name="sink-properties"></a>Свойства приемника

В преобразовании приемника можно выполнять запись в контейнер или папку в хранилище Azure Data Lake Storage 2-го поколения. Настройки управления записью файлов находятся на вкладке **Параметры**.

![Параметры приемника](media/data-flow/file-sink-settings.png "параметры приемника")

**Очистить папку.** Определяет, следует ли удалять конечную папку перед записью данных.

**Параметр имени файла.** Определяет способ присвоения имени целевым файлам в папке назначения. Доступные параметры имени файла:
   * **По умолчанию**: разрешить Spark присваивать имена файлам на основе значений по умолчанию PART.
   * **Шаблон**: введите шаблон, в котором перечислены выходные файлы для каждого раздела. Например, при использовании шаблона **loans[n].csv** будут создаваться файлы loans1.csv, loans2.csv и т. д.
   * **На один раздел**: введите имя файла для одного раздела.
   * **Как данные в столбце**: задайте для выходного файла значение столбца. Путь задается относительно контейнера набора данных, а не папки назначения. Если в наборе данных имеется путь к папке, он будет переопределен.
   * **Вывод в один файл**: объединение секционированных выходных файлов в один именованный файл. Путь задается относительно папки набора данных. Имейте в виду, что операция слияния может завершиться сбоем в зависимости от размера узла. Этот параметр не рекомендуется использовать для больших наборов данных.

**Все в кавычках:** указывает, следует ли заключать все значения в кавычки

## <a name="lookup-activity-properties"></a>Свойства действия поиска

Подробные сведения об этих свойствах см. в разделе [Действие поиска](control-flow-lookup-activity.md).

## <a name="getmetadata-activity-properties"></a>Свойства действия GetMetadata

Подробные сведения об этих свойствах см. в разделе [Действие GetMetadata](control-flow-get-metadata-activity.md) 

## <a name="delete-activity-properties"></a>Свойства действия удаления

Подробные сведения об этих свойствах см. в разделе [Действие удаления](delete-activity.md)

## <a name="legacy-models"></a>Устаревшие модели

>[!NOTE]
>Следующие модели по-прежнему поддерживаются на условиях "как есть" для обеспечения обратной совместимости. Новую модель, упомянутую в разделах выше, рекомендуется использовать в дальнейшем. Пользовательский интерфейс создания ADF был изменен для создания новой модели.

### <a name="legacy-dataset-model"></a>Устаревшая модель набора данных

| Свойство | Описание | Обязательно |
|:--- |:--- |:--- |
| type | Свойство type для набора данных должно иметь значение **AzureBlobFSFile**. |Да |
| folderPath | Путь к папке в Azure Data Lake Storage 2-го поколения. Если это свойство не указано, будет использоваться корневая папка. <br/><br/>Фильтр подстановочных знаков не поддерживается. Допустимые подстановочные знаки: `*` (соответствует нулю или нескольким символам) и `?` (соответствует нулю или одному символу). Используйте `^` для экранирования знаков, если фактическое имя папки содержит подстановочный знак или этот escape-символ. <br/><br/>Примеры: filesystem/folder/. Дополнительные примеры приведены в разделе [Примеры фильтров папок и файлов](#folder-and-file-filter-examples). |Нет |
| fileName | Имя или фильтр постановочных знаков для файлов по указанному folderPath. Если этому свойству не присвоить значение, набор данных будет указывать на все файлы в папке. <br/><br/>Допустимые подстановочные знаки для фильтра: `*` (соответствует нулю или нескольким символам) и `?` (соответствует нулю или одному символу).<br/>Пример 1. `"fileName": "*.csv"`<br/>Пример 2. `"fileName": "???20180427.txt"`<br/>Используйте `^` для экранирования символов, если фактическое имя файла содержит подстановочный знак или этот escape-символ.<br/><br/>Если fileName для выходного набора данных не указан, а **preserveHierarchy** не указан в приемнике действия, действие копирования автоматически создаст имя файла по следующему шаблону: "*Data.[GUID идентификатора выполнения действия].[GUID, если поведение — FlattenHierarchy].[формат, если настроено].[сжатие, если настроено]* ". Например: "Data.0a405f8a-93ff-4c6f-b3be-f69616f1df7a.txt.gz". При копировании из табличного источника с использованием имени таблицы вместо запроса формат имени будет таким: " *[имя таблицы].[фoрмат].[сжатие, если настроено]* ". Например: "MyTable.csv". |Нет |
| modifiedDatetimeStart | Фильтр файлов на основе атрибута времени последнего изменения. Файлы будут выбраны, если время их последнего изменения находится в диапазоне времени с `modifiedDatetimeStart` до `modifiedDatetimeEnd`. Время представлено часовым поясом UTC в формате "2018-12-01T05:00:00Z". <br/><br/> Включение этого параметра в случае, если требуется использовать фильтр файлов с огромными объемами файлов, влияет на общую производительность перемещения данных. <br/><br/> Свойства могут иметь значение NULL. Это означает, что фильтры атрибута файла не применяются к набору данных. Если для параметра `modifiedDatetimeStart` задано значение даты и времени, но параметр `modifiedDatetimeEnd` имеет значение NULL, то выбираются файлы, чей атрибут времени последнего изменения больше указанного значения даты и времени или равен ему. Если для параметра `modifiedDatetimeEnd` задано значение даты и времени, но параметр `modifiedDatetimeStart` имеет значение NULL, то выбираются файлы, чей атрибут времени последнего изменения меньше указанного значения даты и времени.| нет |
| modifiedDatetimeEnd | Фильтр файлов на основе атрибута времени последнего изменения. Файлы будут выбраны, если время их последнего изменения находится в диапазоне времени с `modifiedDatetimeStart` до `modifiedDatetimeEnd`. Время представлено часовым поясом UTC в формате "2018-12-01T05:00:00Z". <br/><br/> Включение этого параметра в случае, если требуется использовать фильтр файлов с огромными объемами файлов, влияет на общую производительность перемещения данных. <br/><br/> Свойства могут иметь значение NULL. Это означает, что фильтры атрибута файла не применяются к набору данных. Если для параметра `modifiedDatetimeStart` задано значение даты и времени, но параметр `modifiedDatetimeEnd` имеет значение NULL, то выбираются файлы, чей атрибут времени последнего изменения больше указанного значения даты и времени или равен ему. Если для параметра `modifiedDatetimeEnd` задано значение даты и времени, но параметр `modifiedDatetimeStart` имеет значение NULL, то выбираются файлы, чей атрибут времени последнего изменения меньше указанного значения даты и времени.| нет |
| format | Если требуется скопировать файлы между файловыми хранилищами "как есть" (двоичное копирование), можно пропустить раздел форматирования в определениях входного и выходного наборов данных.<br/><br/>Если необходимо проанализировать или создать файлы определенного формата, поддерживаются следующие форматы файлов: **TextFormat**, **JsonFormat**, **AvroFormat**, **OrcFormat** и **ParquetFormat**. Свойству **type** в разделе **format** необходимо присвоить одно из этих значений. Дополнительные сведения см. в разделах о [текстовом формате](supported-file-formats-and-compression-codecs-legacy.md#text-format), [формате JSON](supported-file-formats-and-compression-codecs-legacy.md#json-format), [формате Avro](supported-file-formats-and-compression-codecs-legacy.md#avro-format), [формате ORC](supported-file-formats-and-compression-codecs-legacy.md#orc-format) и [формате Parquet](supported-file-formats-and-compression-codecs-legacy.md#parquet-format). |Нет (только для сценария двоичного копирования) |
| compression | Укажите тип и уровень сжатия данных. Дополнительные сведения см. в разделе [Поддержка сжатия](supported-file-formats-and-compression-codecs-legacy.md#compression-support).<br/>Поддерживаемые типы: **GZip**, **Deflate**, **BZip2** и **ZipDeflate**.<br/>Поддерживаемые уровни: **Optimal** и **Fastest**. |Нет |

>[!TIP]
>Чтобы скопировать все файлы в папке, укажите только **folderPath**.<br>Чтобы скопировать один файл с заданным именем, укажите **folderPath** с путем к папке и **fileName** с именем файла.<br>Чтобы скопировать подмножество файлов в папке, укажите **folderPath** с частью папки и **fileName** с фильтром подстановочных знаков. 

**Пример**.

```json
{
    "name": "ADLSGen2Dataset",
    "properties": {
        "type": "AzureBlobFSFile",
        "linkedServiceName": {
            "referenceName": "<Azure Data Lake Storage Gen2 linked service name>",
            "type": "LinkedServiceReference"
        },
        "typeProperties": {
            "folderPath": "myfilesystem/myfolder",
            "fileName": "*",
            "modifiedDatetimeStart": "2018-12-01T05:00:00Z",
            "modifiedDatetimeEnd": "2018-12-01T06:00:00Z",
            "format": {
                "type": "TextFormat",
                "columnDelimiter": ",",
                "rowDelimiter": "\n"
            },
            "compression": {
                "type": "GZip",
                "level": "Optimal"
            }
        }
    }
}
```

### <a name="legacy-copy-activity-source-model"></a>Устаревшая модель источника действия копирования

| Свойство | Описание | Обязательно |
|:--- |:--- |:--- |
| type | Свойство type источника действия копирования должно иметь значение **AzureBlobFSSource**. |Да |
| recursive | Указывает, следует ли читать данные рекурсивно из вложенных папок или только из указанной папки. Если для свойства recursive задано значение true, а приемником является файловое хранилище, то пустые папки и вложенные папки в приемнике не создаются.<br/>Допустимые значения: **true** (по умолчанию) и **false**. | Нет |
| maxConcurrentConnections | Количество одновременных подключений к хранилищу данных. Укажите, только если требуется ограничить одновременные подключения к хранилищу данных. | Нет |

**Пример**.

```json
"activities":[
    {
        "name": "CopyFromADLSGen2",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<ADLS Gen2 input dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<output dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "AzureBlobFSSource",
                "recursive": true
            },
            "sink": {
                "type": "<sink type>"
            }
        }
    }
]
```

### <a name="legacy-copy-activity-sink-model"></a>Устаревшая модель приемника действия копирования

| Свойство | Описание | Обязательно |
|:--- |:--- |:--- |
| type | Свойство type приемника действия копирования должно иметь значение **AzureBlobFSSink**. |Да |
| copyBehavior | Определяет поведение копирования, когда источником являются файлы из файлового хранилища данных.<br/><br/>Допустимые значения:<br/><b>— PreserveHierarchy (по умолчанию)</b>. Сохраняет иерархию файлов в целевой папке. Относительный путь исходного файла в исходной папке идентичен относительному пути целевого файла в целевой папке.<br/><b>— FlattenHierarchy</b>. Все файлы из исходной папки размещаются на первом уровне в целевой папке. Целевые файлы имеют автоматически сформированные имена. <br/><b>— MergeFiles</b>. Объединяет все файлы из исходной папки в один файл. Если указано имя файла, то оно присваивается объединенному файлу. В противном случае присваивается автоматически созданное имя файла. | Нет |
| maxConcurrentConnections | Количество одновременных подключений к хранилищу данных. Укажите, только если требуется ограничить одновременные подключения к хранилищу данных. | Нет |

**Пример**.

```json
"activities":[
    {
        "name": "CopyToADLSGen2",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<input dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<ADLS Gen2 output dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "<source type>"
            },
            "sink": {
                "type": "AzureBlobFSSink",
                "copyBehavior": "PreserveHierarchy"
            }
        }
    }
]
```

## <a name="next-steps"></a>Дальнейшие действия

В таблице [Поддерживаемые хранилища данных и форматы](copy-activity-overview.md#supported-data-stores-and-formats) приведен список хранилищ данных, которые поддерживаются в качестве источников и приемников для действия копирования в фабрике данных.
