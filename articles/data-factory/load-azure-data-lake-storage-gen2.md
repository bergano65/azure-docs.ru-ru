---
title: Загрузка данных в Azure Data Lake Storage Gen2
description: Копирование данных в Azure Data Lake Storage 2-го поколения с помощью Фабрики данных Azure
services: data-factory
documentationcenter: ''
ms.author: jingwang
author: linda33wj
manager: shwang
ms.reviewer: douglasl
ms.service: data-factory
ms.workload: data-services
ms.topic: conceptual
ms.custom: seo-lt-2019
ms.date: 06/08/2020
ms.openlocfilehash: 8f8cfef5ed98682a1d03f7d36caa2008f4ff03b6
ms.sourcegitcommit: 829d951d5c90442a38012daaf77e86046018e5b9
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/09/2020
ms.locfileid: "84660481"
---
# <a name="load-data-into-azure-data-lake-storage-gen2-with-azure-data-factory"></a>Загрузка данных в Azure Data Lake Storage 2-го поколения с помощью Фабрики данных Azure

[!INCLUDE[appliesto-adf-xxx-md](includes/appliesto-adf-xxx-md.md)]

Azure Data Lake Storage 2-го поколения — это набор возможностей аналитики больших данных, созданных на основе [хранилища BLOB-объектов Azure](../storage/blobs/storage-blobs-introduction.md). Она позволяет работать с данными с использованием как файловой системы, так и парадигмы хранения объектов.

Фабрика данных Azure (ADF) — это полностью управляемая облачная служба интеграции данных. Эту службу можно использовать для заполнения озера данными из богатого набора локальных и облачных хранилищ данных и экономии времени при создании аналитических решений. Дополнительные сведения о поддерживаемых соединителях, см. в таблице [Поддерживаемые хранилища данных и форматы](copy-activity-overview.md#supported-data-stores-and-formats).

Фабрика данных Azure предлагает масштабируемое и управляемое решение для перемещения данных. Благодаря архитектуре горизонтального масштабирования ADF, фабрика данных Azure может использовать высокую пропускную способность для приема данных. Дополнительные сведения см. в руководстве [по настройке производительности действия копирования](copy-activity-performance.md).

В этой статье показано, как с помощью средства копирования данных службы "Фабрика данных" загружать данные из _службы Amazon Web Services S3_ в _Azure Data Lake Storage Gen2_. Чтобы копировать данные из других типов хранилищ, необходимо выполнить аналогичные шаги.

>[!TIP]
>См. дополнительные сведения о [копировании данных из Azure Data Lake Storage 1-го поколения в Azure Data Lake Storage 2-го поколения](load-azure-data-lake-storage-gen2-from-gen1.md).

## <a name="prerequisites"></a>Предварительные требования

* Подписка Azure. Если у вас еще нет подписки Azure, [создайте бесплатную учетную запись](https://azure.microsoft.com/free/), прежде чем начинать работу.
* Учетная запись хранения Azure с включенным Data Lake Storage 2-го поколения. Если у вас нет учетной записи хранения, [Создайте учетную запись](https://ms.portal.azure.com/#create/Microsoft.StorageAccount-ARM).
* Учетная запись AWS с контейнером S3, в котором содержатся данные. В этой статье показано, как скопировать данные из Amazon S3. Вы можете использовать другие хранилища данных, выполнив аналогичные действия.

## <a name="create-a-data-factory"></a>Создание фабрики данных

1. В меню слева выберите **Создать ресурс** > **Данные и аналитика** > **Фабрика данных**.
   
   ![Выбор фабрики данных в области "Создать"](./media/doc-common-process/new-azure-data-factory-menu.png)

2. На странице **Новая фабрика данных** укажите значения для следующих полей:
 
    * **Name** (Имя). Введите глобальное уникальное имя фабрики данных Azure. Если появляется сообщение об ошибке "имя фабрики данных *йоурдатафакторинаме* недоступно", введите другое имя для фабрики данных. Например, вы можете использовать имя _**ваше_имя**_**ADFTutorialDataFactory**. Попробуйте создать фабрику данных еще раз. Правила именования артефактов службы "Фабрика данных" см. в [этой](naming-rules.md) статье.
    * **Подписка**: Выберите подписку Azure, в рамках которой нужно создать фабрику данных. 
    * **Группа ресурсов**. Выберите существующую группу ресурсов из раскрывающегося списка или щелкните вариант **Создать новую** и введите имя группы ресурсов. Сведения о группах ресурсов см. в статье, где описывается [использование групп ресурсов для управления ресурсами Azure](../azure-resource-manager/management/overview.md).  
    * **Версия.** Выберите **V2**.
    * **Расположение.** Укажите расположение фабрики данных. В раскрывающемся списке отображаются только поддерживаемые расположения. Хранилища данных, используемые в фабрике данных, могут находиться в других расположениях и регионах. 

3. Нажмите кнопку **создания**.

4. После создания перейдите к фабрике данных. Вы увидите домашнюю страницу **фабрики данных**, как показано на следующем изображении: 
   
   ![Домашняя страница фабрики данных](./media/doc-common-process/data-factory-home-page.png)

   Выберите плитку **Создание и мониторинг**, чтобы открыть на отдельной вкладке приложение интеграции данных.

## <a name="load-data-into-azure-data-lake-storage-gen2"></a>Загрузка данных в Azure Data Lake Storage Gen2

1. На странице Начало **работы** выберите плитку **копирование данных** , чтобы запустить средство копирование данных.

2. На странице **Свойства** укажите **CopyFromAmazonS3ToADLS** в поле **имя задачи** и нажмите кнопку **Далее**.

    ![Страница свойств](./media/load-azure-data-lake-storage-gen2/copy-data-tool-properties-page.png)
3. На странице **исходное хранилище данных** щелкните **+ создать новое соединение**. Выберите **Amazon S3** из коллекции соединителей и нажмите кнопку **продолжить**.
    
    ![Страница "Исходное хранилище данных S3"](./media/load-azure-data-lake-storage-gen2/source-data-store-page-s3.png)
    
4. На странице **Новая связанная служба (Amazon S3)** выполните следующие действия.

   1. Укажите **идентификатор ключа доступа**.
   2. Укажите **секретный ключ доступа**.
   3. Нажмите кнопку **проверить подключение** , чтобы проверить параметры, а затем выберите **создать**.

      ![Указать учетную запись Amazon S3](./media/load-azure-data-lake-storage-gen2/specify-amazon-s3-account.png)
   4. Будет создано новое подключение AmazonS3. Выберите **Далее**. 

5. На странице **Choose the input file or folder** (Выбор файла или папки входных данных) перейдите в папку и файл, которые необходимо скопировать. Выберите папку или файл, а затем щелкните **выбрать**.

    ![Выбор файла или папки входных данных](./media/load-azure-data-lake-storage-gen2/choose-input-folder.png)

6. Укажите поведение копирования, проверив параметры **рекурсивного** и **двоичного копирования** . Выберите **Далее**.

    ![Укажите выходную папку.](./media/load-azure-data-lake-storage-gen2/specify-binary-copy.png)
    
7. На странице **целевое хранилище данных** щелкните **+ создать подключение**, а затем выберите **Azure Data Lake Storage 2-го поколения**и нажмите кнопку **продолжить**.

    ![Страница целевого хранилища данных](./media/load-azure-data-lake-storage-gen2/destination-data-storage-page.png)

8. На странице **Новая связанная служба (Azure Data Lake Storage 2-го поколения)** выполните следующие действия.

   1. Из раскрывающегося списка "Имя учетной записи хранения" выберите соответствующую учетную запись Data Lake Storage 2-го поколения.
   2. Выберите **создать** , чтобы создать подключение. Выберите **Далее**.   

        ![Выбор учетной записи Data Lake Storage 2-го поколения](./media/load-azure-data-lake-storage-gen2/specify-azure-data-lake-storage.png)

9. На странице **Выбор выходного файла или папки** введите **copyfroms3** в качестве имени выходной папки и нажмите кнопку **Далее**. ADF создаст соответствующую ADLS 2-го поколения файловую систему и вложенные папки во время копирования, если она не существует.

    ![Укажите выходную папку.](./media/load-azure-data-lake-storage-gen2/specify-adls-path.png)

10. На странице **Параметры** нажмите кнопку **Далее** , чтобы использовать параметры по умолчанию.

    ![Страница параметров](./media/load-azure-data-lake-storage-gen2/copy-settings.png)

11. На странице **Сводка** проверьте параметры и нажмите кнопку **Далее**.

    ![Страница "Сводка"](./media/load-azure-data-lake-storage-gen2/copy-summary.png)

12. На **странице развертывания** выберите **Мониторинг**, чтобы отслеживать созданный конвейер (задачу). 
 
13. После успешного выполнения конвейера вы увидите запуск конвейера, который активируется ручным триггером. Ссылки в столбце **Имя конвейера** позволят вам просмотреть подробные сведения о действиях и повторно выполнить конвейер.

    ![Мониторинг выполнений конвейера](./media/load-azure-data-lake-storage-gen2/monitor-pipeline-runs.png)

14. Чтобы просмотреть запуски действий, связанные с выполнением конвейера, щелкните ссылку **CopyFromAmazonS3ToADLS** в СТОЛБЦЕ имя конвейера. Чтобы увидеть сведения об операции копирования, щелкните ссылку **Сведения** (значок очков) в столбце Название действия. Можно отслеживать такие сведения, как объем данных, скопированных из источника в приемник, пропускная способность данных, шаги выполнения с соответствующей длительностью и используемая конфигурация.
 
    ![Мониторинг выполнений действий](./media/load-azure-data-lake-storage-gen2/monitor-activity-runs.png)
    
    ![Мониторинг сведений о выполнении действия](./media/load-azure-data-lake-storage-gen2/monitor-activity-run-details.png)

15. Чтобы обновить список, нажмите кнопку Обновить. Выберите **Все запуски конвейеров** в верхней части окна, чтобы вернуться к представлению "Выполнения конвейеров".

16. Убедитесь, что данные скопированы в Data Lake Storage Gen2.

## <a name="next-steps"></a>Дальнейшие действия

* [Действие копирования в фабрике данных Azure](copy-activity-overview.md)
* [Copy data to or from Azure Data Lake Storage Gen2 Preview using Azure Data Factory (Preview)](connector-azure-data-lake-storage.md) (Копирование данных в Azure Data Lake Storage Gen2 (предварительная версия) или из него с помощью фабрики данных Azure)
