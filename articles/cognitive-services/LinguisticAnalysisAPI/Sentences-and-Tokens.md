---
title: Предложения и лексемы — API лингвистического анализа
titlesuffix: Azure Cognitive Services
description: Сведения о разделении предложений и выделении лексем в API лингвистического анализа.
services: cognitive-services
author: DavidLiCIG
manager: nitinme
ms.service: cognitive-services
ms.subservice: linguistic-analysis
ms.topic: conceptual
ms.date: 03/21/2016
ms.author: davl
ROBOTS: NOINDEX
ms.openlocfilehash: 435513023cf74bbc259cb922220d5f9940452d79
ms.sourcegitcommit: 90cec6cccf303ad4767a343ce00befba020a10f6
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 02/07/2019
ms.locfileid: "55879400"
---
# <a name="sentence-separation-and-tokenization"></a>Разделение предложений и лексемы

> [!IMPORTANT]
> Поддержка предварительной версии Лингвистического анализа прекращена 9 августа 2018 г. Мы рекомендуем использовать [модули текстовой аналитики Машинного обучения Azure](https://docs.microsoft.com/azure/machine-learning/studio-module-reference/text-analytics) для анализа и обработки текста.

## <a name="background-and-motivation"></a>Предыстория и мотивация

Первый шаг лингвистического анализа текста заключается в том, чтобы разбить его на предложения и лексемы.

### <a name="sentence-separation"></a>Разделение предложения

На первый взгляд кажется, что разбивка текста на предложения проста: просто найдите метки конца предложения и там прервите предложение.
Однако эти метки часто являются сложными и неоднозначными.

Рассмотрим следующий пример текста:

> What did you say?!? I didn't hear about the director's "new proposal." It's important to Mr. and Mrs. Smith.

This text contains three sentences:

- What did you say?!?
- I didn't hear about the director's "new proposal."
- It's important to Mr. and Mrs. Smith.

Обратите внимание, что концы предложений отмечены совершенно по-разному.
Первое заканчивается комбинацией вопросительных и восклицательных знаков (иногда называемых лигатурой из вопросительных и восклицательных знаков).
Второе заканчивается точкой или полной остановкой, но следующая цитата должна быть втянута в предыдущее предложение.
В третьем предложении вы можете увидеть, как точка может использоваться для обозначения сокращений.
Глядя только на пунктуацию, вы получаете хороший набор примеров, но для определения истинных границ предложения требуется дальнейшая работа.

### <a name="tokenization"></a>Выделение лексем

Следующая задача — разбить эти предложения на лексемы.
В большинстве случаев английские лексемы разделяются пробелами.
(Поиск лексем или слов в английском языке гораздо проще, чем в китайском, где практически не используются пробелы между словами.
Первое предложение может быть написано как "Чтовысказали?")

Есть несколько сложных случаев.
Во-первых, пунктуация часто (но не всегда) должна отделяться от окружающего контекста.
Во-вторых, есть английские *сокращения*, такие как "didn't" или "it's", где слова были сжаты и сокращены в мелкие кусочки.
Цель выделения лексем состоит в том, чтобы разбить последовательность символов на слова.

Вернемся к примерам предложений выше.
Теперь мы разместили "центральную точку" (&middot;) между каждой отдельной лексемой.

- What &middot; did &middot; you &middot; say &middot; ?!?
- I &middot; did &middot; n't &middot; hear &middot; about &middot; the &middot; director &middot; 's &middot; " &middot; new &middot; proposal &middot; . &middot; "
- It &middot; 's &middot; important &middot; to &middot; Mr. &middot; and &middot; Mrs. &middot; Smith &middot; .

Обратите внимание, что большинство лексем — это слова, которые можно найти в словаре (например, *важный*, *директор*).
Другие исключительно состоят из знаков препинания.
Наконец, есть более необычные лексемы, которые представляют собой такие сокращения как *n't* вместо *not*, притяжательный падеж *'s* и т. д.
Такое выделение лексем позволяет нам обрабатывать слово *didn't* и словосочетание *did not* более последовательно.

## <a name="specification"></a>Спецификация

Важно принимать последовательные решения о том, что включает в себя предложение и лексема.
Мы полагаемся на спецификацию из [Penn Treebank](https://catalog.ldc.upenn.edu/LDC99T42) (некоторые дополнительные сведения доступны на ftp://ftp.cis.upenn.edu/pub/treebank/public_html/tokenization.html).
