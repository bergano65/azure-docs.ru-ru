---
title: Создание пользовательской службы голосовой речи
titleSuffix: Azure Cognitive Services
description: Когда вы будете готовы отправить данные, перейдите на пользовательский голосовой портал. Создайте или выберите пользовательский голосовой проект. Проект должен иметь доступ к нужному языку, языку и свойствам пола в качестве данных, которые вы предполагали использовать для обучения речи.
services: cognitive-services
author: erhopf
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 11/04/2019
ms.author: erhopf
ms.openlocfilehash: 370b5005f27fbfe6ee8fc96d6dd7e467a581ec67
ms.sourcegitcommit: c22327552d62f88aeaa321189f9b9a631525027c
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/04/2019
ms.locfileid: "73464608"
---
# <a name="create-a-custom-voice"></a>Создание пользовательского голоса

В разделе [Подготовка данных для пользовательского голоса](how-to-custom-voice-prepare-data.md)описаны различные типы данных, которые можно использовать для обучения настраиваемого голоса и различных требований к формату. После подготовки данных можно приступить к их передаче на [Пользовательский голосовой портал](https://aka.ms/custom-voice-portal)или через API пользовательского речевого обучения. Здесь описаны шаги обучения пользовательского голоса с помощью портала.

> [!NOTE]
> На этой странице предполагается, что у вас есть чтение начало [работы с пользовательским голосовым стандартом](how-to-custom-voice.md) и [Подготовка данных для пользовательского голоса](how-to-custom-voice-prepare-data.md), а также создание пользовательского голосового проекта.

Проверьте языки, поддерживаемые для пользовательского голоса: [язык для настройки](language-support.md#customization).

## <a name="upload-your-datasets"></a>Обновление наборов данных

Когда вы будете готовы отправить данные, перейдите на [Пользовательский голосовой портал](https://aka.ms/custom-voice-portal). Создайте или выберите пользовательский голосовой проект. Проект должен иметь доступ к нужному языку, языку и свойствам пола в качестве данных, которые вы предполагали использовать для обучения речи. Например, выберите `en-GB`, если звуковые записи выполняются на английском языке с диакритическими знаками Великобритании.

Перейдите на вкладку **данные** и нажмите кнопку **отправить данные**. В мастере выберите правильный тип данных, соответствующий подготовленным данным.

Каждый передаваемый набор данных должен соответствовать требованиям к выбранному типу данных. Важно правильно отформатировать данные перед их отправкой. Это гарантирует, что данные будут правильно обрабатываться настраиваемой службой Voice. Перейдите к разделу [Подготовка данных для пользовательского голоса](how-to-custom-voice-prepare-data.md) и убедитесь, что данные были отформатированы правильно.

> [!NOTE]
> Бесплатная подписка (F0). пользователи могут загружать два набора данных одновременно. Пользователи стандартной подписки (S0) могут загружать пять наборов данных одновременно. Если вы достигли предела, подождите, пока завершится импортирование хотя бы одного из наборов данных. Затем повторите попытку.

> [!NOTE]
> Максимальное количество наборов данных, которые могут быть импортированы на подписку, составляет 10. zip-файлы для бесплатных подписок (F0) и 500 для пользователей стандартной подписки (S0).

После нажатия кнопки "Отправить" автоматически проверяются наборы данных. Проверка данных включает ряд проверок звуковых файлов, чтобы проверить формат файла, размер и частоту выборки. Исправьте ошибки, если они есть, и повторите отправку. Когда запрос на импорт данных будет успешно инициирован, в таблице данных должна появиться запись, соответствующая только что загруженному набору данных.

В следующей таблице приведены состояния обработки импортированных наборов данных.

| Состояние | Значение |
| ----- | ------- |
| Обработка | Набор данных получен и обрабатывается. |
| Успешно | Набор данных проверен и теперь может использоваться для создания модели голоса. |
| Сбой | Не удалось обработать набор данных во время обработки по нескольким причинам, например ошибки в файлах, проблемы с данными или сетевые проблемы. |

После завершения проверки можно увидеть общее число сопоставленных фразы продолжительностью для каждого набора данных в столбце **фразы продолжительностью** . Если выбранный тип данных требует длительного сегментирования, этот столбец отражает только фразы продолжительностью, которые мы сегментированы в зависимости от ваших записей или с помощью службы транскрипции речи. Вы можете дополнительно загрузить набор данных с проверкой, чтобы просмотреть подробные результаты фразы продолжительностью успешно импортированы и записи о сопоставлении. Указание. для завершения обработки данных может потребоваться больше часа.

Для наборов данных EN-US и zh-CN можно дополнительно скачать отчет, чтобы проверить результаты произношения и уровень шума для каждой записи. Оценка произношению дается в диапазоне от 0 до 100. Оценка ниже 70 обычно означает ошибку в речи или несоответствие в сценарии. Заметный акцент уменьшает оценку произношения и влияет на созданный цифровой голос.

Более высокий коэффициент сигнала и шума (SNR) обозначает более низкий уровень шума в звуковом файле. Обычно SNR выше 50 можно достичь, производя запись в профессиональных студиях. Звуковой файл с SNR менее 20 может привести к явному шуму в созданном голосе.

Рассмотрите возможность повторной записи любых высказываний с низкой оценкой произношения или слабым SNR. Если повторная запись невозможна, исключите эти высказывания из набора данных.

## <a name="build-your-custom-voice-model"></a>Создание пользовательской модели речи

После проверки набора данных его можно использовать для создания пользовательской модели речи.

1.  Переход к **тексту в речь > пользовательских голосовых > обучения**.

2.  Нажмите кнопку **обучение модели**.

3.  Затем введите **имя** и **Описание** , помогающие определить эту модель.

    Тщательно выбирайте имя. Имя, которое здесь вводится, будет использоваться, чтобы указать голос в запросе на синтез речи, как часть входных данных SSML. Допускаются только буквы, цифры и некоторые знаки препинания, такие как-, \_и (","). Используйте разные имена для разных моделей голоса.

    В поле **Description** (Описание) обычно записываются имена наборов данных, которые используются для создания модели.

4.  На странице **выбор обучающих данных** выберите один или несколько наборов данных, которые вы хотите использовать для обучения. Проверьте число фразы продолжительностью, прежде чем отправлять их. Вы можете начать с любого числа фразы продолжительностью для голосов и моделей en-US и zh-CN. Для других языков необходимо выбрать более 2 000 фразы продолжительностью, чтобы иметь возможность обучать голоса.

    > [!NOTE]
    > Дубликаты звуковых имен будут удалены из обучения. Убедитесь, что выбранные наборы данных не содержат одинаковые имена звуков в нескольких ZIP-файлах.

    > [!TIP]
    > Для результатов качества требуется использование наборов данных одного и того же динамика. Когда наборы данных, отправленные для обучения, содержат общее количество менее 6 000 различных фразы продолжительностью, вы обучите свою модель голоса с помощью метода статистического синтеза параметрической. Если объем обучающих данных превышает общее число 6 000 различных фразы продолжительностью, вы начнете процесс обучения с помощью метода синтеза конкатенации. Как правило, технология объединения может привести к более естественным результатам, а также к более качественным голосовым. Если вы хотите обучить модель с помощью новейшей технологии нейронного TTS, которая может создать цифровой голос, эквивалентный общедоступным [нейронным](language-support.md#neural-voices)голосовым технологиям, [обратитесь к настраиваемой голосовым командам](https://go.microsoft.com/fwlink/?linkid=2108737) .

5.  Нажмите кнопку **обучение** , чтобы начать создание модели речи.

В таблице обучения отображается новая запись, соответствующая вновь созданной модели. В таблице также отображается состояние: обработка, успешно, с ошибками.

Отображаемое состояние отражает процесс преобразования набора данных в голосовую модель, как показано ниже.

| Состояние | Значение |
| ----- | ------- |
| Обработка | Создается модель речи. |
| Успешно | Ваша модель голоса создана и может быть развернута. |
| Сбой | Не удалось обучить модель голоса по нескольким причинам, например незамеченные проблемы с данными или проблемы с сетью. |

Время обучения зависит от объема обработанных звуковых данных. Обычный диапазон времени варьируется от 30 минут для сотен выражений до 40 часов — для 20 000 выражений. После того как обучение модели будет завершено, можно приступить к тестированию.

> [!NOTE]
> Бесплатная подписка (F0). пользователи могут одновременно обучать один голосовый шрифт. Пользователи стандартной подписки (S0) могут одновременно обучать три голоса. Если вы достигли предела, подождите, пока хотя бы один из ваших голосов завершит обучение, а затем повторите попытку.

> [!NOTE]
> Максимальное число моделей, разрешенных для обучения на подписку, составляет 10 моделей для бесплатных пользователей подписки (F0) и 100 для пользователей стандартной подписки (S0).

Если вы используете функцию обучения нейронных голосовых операций, вы можете выбрать модель, оптимизированную для сценариев потоковой передачи в реальном времени, или алгоритм нейронной жизни HD, оптимизированный для асинхронного [синтеза длинных аудио](long-audio-api.md).  

## <a name="test-your-voice-model"></a>Тестирование модели голоса

После успешного создания голос можно протестировать перед развертыванием.

1.  Переход к **тексту в речь > тестирование пользовательских голосовых >** .

2.  Нажмите кнопку **добавить тест**.

3.  Выберите одну или несколько моделей, которые вы хотите протестировать.

4.  Укажите текст, с которым должны говориться голоса. Если выбрано тестирование нескольких моделей одновременно, то для тестирования различных моделей будет использоваться один и тот же текст.

    > [!NOTE]
    > Язык текста должен быть таким же, что и язык голоса. Можно тестировать только успешно обученные модели. На этом шаге поддерживается только обычный текст.

5.  Щелкните **Создать**.

После отправки тестового запроса вы вернетесь на тестовую страницу. Теперь таблица содержит запись, соответствующую новому запросу, и столбец состояния. Синтезирование голоса может занять несколько минут. Когда в столбце состояние будет указано значение **успех**, можно воспроизвести звук или загрузить текстовые входные данные (txt-файл) и аудио (файл с расширением. wav), а также дополнительно аудитион второй для качества.

Результаты теста можно также найти на странице сведений каждой модели, выбранной для тестирования. Перейдите на вкладку " **обучение** " и щелкните имя модели, чтобы ввести страницу сведений о модели.

## <a name="create-and-use-a-custom-voice-endpoint"></a>Создание и использование пользовательской конечной точки голоса

После того как вы успешно создали и протестировали свою голосовую модель, она развертывается в пользовательской конечной точке службы "Преобразование текста в речь". Затем эта конечная точка используется вместо обычной конечной точки при выполнении запросов службы "Преобразование текста в речь" через REST API. Пользовательская конечная точка может быть вызвана только подпиской, которая использовалась для развертывания шрифта.

Чтобы создать новую настраиваемую конечную точку голосовой связи, перейдите в раздел Преобразование **текста в речь > настраиваемого голосового > развертывания**. Выберите **Добавить конечную точку** и введите **имя** и **Описание** пользовательской конечной точки. Затем выберите пользовательскую голосовую модель, которую нужно связать с этой конечной точкой.

После нажатия кнопки **Добавить** в таблице конечная точка появится запись для новой конечной точки. Создание конечной точки может занять несколько минут. Если состояние развертывания — **Удачно**, конечная точка готова к использованию.

> [!NOTE]
> У пользователей бесплатной подписки (F0) может быть развернута только одна модель. Пользователи стандартной подписки (S0) могут создавать до 50 конечных точек, каждый из которых имеет собственный пользовательский Voice.

> [!NOTE]
> Для использования пользовательского голоса необходимо указать имя модели голоса, использовать настраиваемый URI непосредственно в HTTP-запросе и использовать ту же подписку для прохождения проверки подлинности службы TTS.

После развертывания конечной точки имя конечной точки отображается в виде ссылки. Щелкните ссылку, чтобы отобразить сведения, относящиеся к конечной точке, такие как ключ конечной точки, URL-адрес конечной точки и пример кода.

Тестирование конечной точки в сети также доступно через портал настраиваемых пользовательских голосовых моделей. Чтобы проверить конечную точку, выберите **проверить конечную точку** на странице **сведений о конечной точке** . Откроется страница тестирования конечной точки. Введите текст для озвучивания (в текстовом поле в формате обычного текста или [SSML](speech-synthesis-markup.md) ). Нажмите кнопку **Воспроизведение**, чтобы прослушать текст с помощью пользовательской голосовой модели. Для этой функции тестирования будет использоваться плата за использование пользовательского синтеза речи.

Пользовательская конечная точка функционально идентична стандартной конечной точке, используемой для запросов преобразования текста в речь. Дополнительные сведения см. в статье о [REST API](rest-text-to-speech.md).

## <a name="next-steps"></a>Дальнейшие действия

* [Руководство. запись образцов голоса](record-custom-voice-samples.md)
* [Справочник по API преобразования текста в речь](rest-text-to-speech.md)
* [Длинный аудио API](long-audio-api.md)
