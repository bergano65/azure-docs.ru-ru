---
title: Создание пользовательской службы голосовой речи
titleSuffix: Azure Cognitive Services
description: Когда вы будете готовы отправить данные, перейдите на пользовательский голосовой портал. Создайте или выберите пользовательский голосовой проект. Проект должен использовать правильный язык, язык и региональные параметры, а также свойства пола в качестве данных, которые будут использоваться для обучения речи.
services: cognitive-services
author: erhopf
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 11/04/2019
ms.author: erhopf
ms.openlocfilehash: 262a96c0c316987d0245ed29836f6a013c4339d1
ms.sourcegitcommit: 65cef6e5d7c2827cf1194451c8f26a3458bc310a
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/19/2021
ms.locfileid: "98573162"
---
# <a name="create-a-custom-voice"></a>Создание пользовательского голоса

В разделе [Подготовка данных для пользовательского голоса](how-to-custom-voice-prepare-data.md)описаны различные типы данных, которые можно использовать для обучения настраиваемого голоса и различных требований к формату. После подготовки данных можно приступить к их передаче на [Пользовательский голосовой портал](https://aka.ms/custom-voice-portal)или через API пользовательского речевого обучения. Здесь описаны шаги обучения пользовательского голоса с помощью портала.

> [!NOTE]
> На этой странице предполагается, что у вас есть чтение начало [работы с пользовательским голосовым стандартом](how-to-custom-voice.md) и [Подготовка данных для пользовательского голоса](how-to-custom-voice-prepare-data.md), а также создание пользовательского голосового проекта.

Проверьте языки, поддерживаемые для пользовательского голоса: [язык для настройки](language-support.md#customization).

## <a name="upload-your-datasets"></a>Обновление наборов данных

Когда вы будете готовы отправить данные, перейдите на [Пользовательский голосовой портал](https://aka.ms/custom-voice-portal). Создайте или выберите пользовательский голосовой проект. Проект должен использовать правильный язык, язык и региональные параметры, а также свойства пола в качестве данных, которые будут использоваться для обучения речи. Например, выберите, `en-GB` Если звуковые записи выполняются на английском языке с диакритическими знаками Великобритании.

Перейдите на вкладку **данные** и нажмите кнопку **отправить данные**. В мастере выберите правильный тип данных, соответствующий подготовленным данным.

Каждый передаваемый набор данных должен соответствовать требованиям к выбранному типу данных. Важно правильно отформатировать данные перед их отправкой. Это гарантирует, что данные будут правильно обрабатываться настраиваемой службой Voice. Перейдите к разделу [Подготовка данных для пользовательского голоса](how-to-custom-voice-prepare-data.md) и убедитесь, что данные были отформатированы правильно.

> [!NOTE]
> Бесплатная подписка (F0). пользователи могут загружать два набора данных одновременно. Пользователи стандартной подписки (S0) могут загружать пять наборов данных одновременно. Если вы достигли предела, подождите, пока завершится импортирование хотя бы одного из наборов данных. Затем повторите попытку.

> [!NOTE]
> Максимальное количество наборов данных, которые могут быть импортированы на подписку, составляет 10. zip-файлы для бесплатных подписок (F0) и 500 для пользователей стандартной подписки (S0).

После нажатия кнопки "Отправить" автоматически проверяются наборы данных. Проверка данных включает ряд проверок звуковых файлов, чтобы проверить формат файла, размер и частоту выборки. Исправьте ошибки, если они есть, и повторите отправку. Когда запрос на импорт данных будет успешно инициирован, в таблице данных должна появиться запись, соответствующая только что загруженному набору данных.

В следующей таблице приведены состояния обработки импортированных наборов данных.

| State | Значение |
| ----- | ------- |
| Обработка | Набор данных получен и обрабатывается. |
| Выполнено | Набор данных проверен и теперь может использоваться для создания модели голоса. |
| Сбой | Не удалось обработать набор данных во время обработки по нескольким причинам, например ошибки в файлах, проблемы с данными или сетевые проблемы. |

После завершения проверки можно увидеть общее число сопоставленных фразы продолжительностью для каждого набора данных в столбце **фразы продолжительностью** . Если выбранный тип данных требует длительного сегментирования, этот столбец отражает только фразы продолжительностью, которые мы сегментированы в зависимости от ваших записей или с помощью службы транскрипции речи. Вы можете дополнительно загрузить набор данных с проверкой, чтобы просмотреть подробные результаты фразы продолжительностью успешно импортированы и записи о сопоставлении. Указание. для завершения обработки данных может потребоваться больше часа.

В представлении сведений о данных можно дополнительно проверить оценки произношения и уровень шума для каждого набора данных. Оценка произношению дается в диапазоне от 0 до 100. Оценка ниже 70 обычно означает ошибку в речи или несоответствие в сценарии. Заметный акцент уменьшает оценку произношения и влияет на созданный цифровой голос.

Более высокий коэффициент сигнала и шума (SNR) обозначает более низкий уровень шума в звуковом файле. Обычно SNR выше 50 можно достичь, производя запись в профессиональных студиях. Звуковой файл с SNR менее 20 может привести к явному шуму в созданном голосе.

Рассмотрите возможность повторной записи любых высказываний с низкой оценкой произношения или слабым SNR. Если повторная запись невозможна, исключите эти высказывания из набора данных.

> [!NOTE]
> Это необходимо, если вы используете настраиваемый нейронный язык, необходимо зарегистрировать его на вкладке " **проголосует голоса** ". При подготовке сценария записи убедитесь, что вы включили следующее предложение, чтобы получить подтверждение голоса с использованием голосовых данных, чтобы создать модель TTS и создать искусственный голос. «I [штат, имя и фамилия] Помните, что записи о моем голоса будут использоваться [региону название компании] для создания и использования искусственной версии моего голоса».
Это предложение будет использоваться для проверки того, выполняются ли записи в обучающих наборах данных тем же лицом, которое делает согласие. [Узнайте больше о том, как будут обрабатываться данные и как выполняется проверка голоса](https://aka.ms/CNV-data-privacy). 

## <a name="build-your-custom-voice-model"></a>Создание пользовательской модели речи

После проверки набора данных его можно использовать для создания пользовательской модели речи.

1.  Переход к **тексту в речь > пользовательского голоса > [имя проекта] > модель**.

2.  Нажмите кнопку **обучение модели**.

3.  Затем введите **имя** и **Описание** , помогающие определить эту модель.

    Тщательно выбирайте имя. Имя, которое здесь вводится, будет использоваться, чтобы указать голос в запросе на синтез речи, как часть входных данных SSML. Допускаются только буквы, цифры и некоторые знаки препинания, такие как-, \_ и (', '). Используйте разные имена для разных моделей голоса.

    Обычно поле **Описание** используется для записи имен наборов данных, которые использовались для создания модели.

4.  На странице **выбор обучающих данных** выберите один или несколько наборов данных, которые вы хотите использовать для обучения. Проверьте число фразы продолжительностью, прежде чем отправлять их. Вы можете начать с любого числа фразы продолжительностью для моделей en-US и zh-CN, используя адаптивный метод обучения. Для других языков необходимо выбрать более 2 000 фразы продолжительностью, чтобы иметь возможность обучать голоса с помощью стандартного уровня, включая методы "Статистическая дисперсия" и "сцепленные", а также более 300 фразы продолжительностью для обучения настраиваемой нейронной речи. 

    > [!NOTE]
    > Дубликаты звуковых имен будут удалены из обучения. Убедитесь, что выбранные наборы данных не содержат одинаковые имена звуков в нескольких ZIP-файлах.

    > [!TIP]
    > Для результатов качества требуется использование наборов данных одного и того же динамика. Для разных методов обучения требуется разный размер данных для обучения. Для обучения модели с помощью метода "Статистическая дисперсия" требуется по крайней мере 2 000 уникальных фразы продолжительностью. Для метода "сцепление" это 6 000 фразы продолжительностью, а для "нейрона" минимальным требованием к размеру данных является 300 фразы продолжительностью.

5. Выберите **метод обучения** на следующем шаге. 

    > [!NOTE]
    > Если вы хотите обучить нейронный голос, необходимо указать профиль с учетом голоса, содержащийся в файле согласия пользователя, которому предоставлено уведомление о распознавании речи, чтобы обучить пользовательскую голосовую модель. Настраиваемая нейронная речь доступна с ограниченным доступом. Убедитесь, что вы понимаете [требования к ответственному AI](https://aka.ms/gating-overview) и [применяете доступ к нему](https://aka.ms/customneural). 
    
    На этой странице можно также выбрать, чтобы отправить скрипт для тестирования. Сценарий тестирования должен быть txt-файлом, размер которого меньше 1 МБ. Поддерживаемый формат кодирования включает ANSI/ASCII, UTF-8, UTF-8-BOM, UTF-16-LE или UTF-16-быть. Каждый абзац utterance приведет к созданию отдельного звука. Если вы хотите объединить все предложения в один звук, сделайте их одним абзацем. 

6. Нажмите кнопку **обучение** , чтобы начать создание модели речи.

В таблице обучения отображается новая запись, соответствующая вновь созданной модели. В таблице также отображается состояние: обработка, успешно, с ошибками.

Отображаемое состояние отражает процесс преобразования набора данных в голосовую модель, как показано ниже.

| State | Значение |
| ----- | ------- |
| Обработка | Создается модель речи. |
| Выполнено | Ваша модель голоса создана и может быть развернута. |
| Сбой | Не удалось обучить модель голоса по нескольким причинам, например незамеченные проблемы с данными или проблемы с сетью. |

Время обучения зависит от объема обработанных звуковых данных и выбранного метода обучения. Оно может варьироваться от 30 минут до 40 часов. После того как обучение модели будет завершено, можно приступить к тестированию. 

> [!NOTE]
> Бесплатная подписка (F0). пользователи могут одновременно обучать один голосовый шрифт. Пользователи стандартной подписки (S0) могут одновременно обучать три голоса. Если вы достигли предела, подождите, пока хотя бы один из ваших голосов завершит обучение, а затем повторите попытку.

> [!NOTE]
> Обучение пользовательских нейронов не является бесплатным. Ознакомьтесь с [ценами](https://azure.microsoft.com/pricing/details/cognitive-services/speech-services/) на этой странице. 

> [!NOTE]
> Максимальное число моделей, разрешенных для обучения на подписку, составляет 10 моделей для бесплатных пользователей подписки (F0) и 100 для пользователей стандартной подписки (S0).

Если вы используете функцию обучения нейронных голосовых операций, вы можете выбрать модель, оптимизированную для сценариев потоковой передачи в реальном времени, или алгоритм нейронной жизни HD, оптимизированный для асинхронного [синтеза длинных аудио](long-audio-api.md).  

## <a name="test-your-voice-model"></a>Тестирование модели голоса

Каждое обучение будет автоматически формировать 100 образцов, чтобы помочь вам протестировать модель. После успешной сборки голоса модель можно проверить перед развертыванием для использования.

1.  Переход к **тексту в речь > пользовательского голоса > [имя проекта] > модель**.

2.  Щелкните имя модели, которую нужно протестировать.

3.  На странице сведения о модели на вкладке **тестирование** можно найти образцы звуковых данных. 

Качество голоса зависит от ряда факторов, в том числе от размера обучающих данных, качества записи, точности файла транскрипции, от того, насколько хорошо записанный голоса в обучающих данных соответствует индивидуальному варианту созданного голоса для вашего предполагаемого варианта использования и т. д. Ознакомьтесь [с дополнительными сведениями о возможностях и ограничениях нашей технологии и рекомендациями по улучшению качества модели](https://aka.ms/CNV-limits). 

## <a name="create-and-use-a-custom-voice-endpoint"></a>Создание и использование пользовательской конечной точки голоса

После того как вы успешно создали и протестировали свою голосовую модель, она развертывается в пользовательской конечной точке службы "Преобразование текста в речь". Затем эта конечная точка используется вместо обычной конечной точки при выполнении запросов службы "Преобразование текста в речь" через REST API. Пользовательская конечная точка может быть вызвана только подпиской, которая использовалась для развертывания шрифта.

Чтобы создать новую настраиваемую конечную точку голосовой связи, перейдите в раздел Преобразование **текста в речь > настраиваемую конечную точку голосовой >**. Выберите **Добавить конечную точку** и введите **имя** и **Описание** пользовательской конечной точки. Затем выберите пользовательскую голосовую модель, которую нужно связать с этой конечной точкой.

После нажатия кнопки **Добавить** в таблице конечная точка появится запись для новой конечной точки. Создание конечной точки может занять несколько минут. Когда состояние развертывания будет **завершено**, конечная точка будет готова к использованию.

Вы можете **приостановить** и **возобновить** работу конечной точки, если вы не используете ее все время. Когда конечная точка активируется повторно после приостановки, URL-адрес конечной точки остается прежним, поэтому вам не нужно изменять код в приложениях. 

Можно также обновить конечную точку до новой модели. Чтобы изменить модель, убедитесь, что новая модель имеет имя, совпадающее с той, которую нужно обновить. 

> [!NOTE]
> У пользователей бесплатной подписки (F0) может быть развернута только одна модель. Пользователи стандартной подписки (S0) могут создавать до 50 конечных точек, каждый из которых имеет собственный пользовательский Voice.

> [!NOTE]
> Для использования пользовательского голоса необходимо указать имя модели голоса, использовать настраиваемый URI непосредственно в HTTP-запросе и использовать ту же подписку для прохождения проверки подлинности службы TTS.

После развертывания конечной точки имя конечной точки отображается в виде ссылки. Щелкните ссылку, чтобы отобразить сведения, относящиеся к конечной точке, такие как ключ конечной точки, URL-адрес конечной точки и пример кода.

Тестирование конечной точки в сети также доступно через портал настраиваемых пользовательских голосовых моделей. Чтобы проверить конечную точку, выберите **проверить конечную точку** на странице **сведений о конечной точке** . Откроется страница тестирования конечной точки. Введите текст для озвучивания (в текстовом поле в формате обычного текста или [SSML](speech-synthesis-markup.md) ). Нажмите кнопку **Воспроизведение**, чтобы прослушать текст с помощью пользовательской голосовой модели. Для этой функции тестирования будет использоваться плата за использование пользовательского синтеза речи.

Пользовательская конечная точка функционально идентична стандартной конечной точке, используемой для запросов преобразования текста в речь. Дополнительные сведения см. в статье о [REST API](rest-text-to-speech.md).

## <a name="next-steps"></a>Следующие шаги

* [Руководство. запись образцов голоса](record-custom-voice-samples.md)
* [Справочник по API преобразования текста в речь](rest-text-to-speech.md)
* [Длинный аудио API](long-audio-api.md)
