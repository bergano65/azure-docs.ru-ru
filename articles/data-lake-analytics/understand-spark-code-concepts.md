---
title: Ознакомьтесь с Apache Spark концепциями кода для разработчиков Azure Data Lake Analytics U-SQL.
description: В этой статье описываются Apache Spark концепции, которые помогут разработчикам U-SQL понять концепции кода Spark.
author: guyhay
ms.author: guyhay
ms.reviewer: jasonh
ms.service: data-lake-analytics
ms.topic: conceptual
ms.custom: Understand-apache-spark-code-concepts
ms.date: 10/15/2019
ms.openlocfilehash: 3d15afc26c876c6e4d2d7244e26f0b13ced59a58
ms.sourcegitcommit: dbde4aed5a3188d6b4244ff7220f2f75fce65ada
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/19/2019
ms.locfileid: "74184743"
---
# <a name="understand-apache-spark-code-for-u-sql-developers"></a>Знакомство с Apache Spark кодом для разработчиков U-SQL

В этом разделе содержатся рекомендации по преобразованию скриптов U-SQL в Apache Spark.

- Он начинается с [сравнения парадигм обработки двух языков](#understand-the-u-sql-and-spark-language-and-processing-paradigms)
- Содержит советы по выполнению следующих действий:
   - [Скрипты преобразования](#transform-u-sql-scripts) , включая [выражения набора строк](#transform-u-sql-rowset-expressions-and-sql-based-scalar-expressions) U-SQL
   - [Код .NET](#transform-net-code)
   - [Типы данных](#transform-typed-values)
   - [Объекты каталога](#transform-u-sql-catalog-objects).

## <a name="understand-the-u-sql-and-spark-language-and-processing-paradigms"></a>Общие сведения о языке U-SQL и Spark и парадигмах обработки

Прежде чем приступить к переносу сценариев U-SQL Azure Data Lake Analytics в Spark, полезно разобраться в общем языке и обосновании концепций обработки двух систем.

U-SQL — это похожий на SQL язык декларативных запросов, использующий парадигму потока данных и позволяющий легко внедрять и масштабировать пользовательский код, написанный на .NET ( C#например,), Python и R. Пользовательские расширения могут реализовывать простые выражения или определяемые пользователем функции, но также могут предоставить пользователю возможность реализовывать такие, называемые пользовательскими операторами, которые реализуют пользовательские операторы для выполнения преобразований на уровне наборов строк, извлечений и запись выходных данных.

Spark — это платформа с горизонтальным масштабированием, предлагающая несколько языковых привязок в Scala, Java, Python, .NET и т. д., где вы в основном пишете свой код на одном из этих языков, создавайте абстракции данных, которые называются отказоустойчивыми распределенными наборами (RDD), кадрами и DataSets и Затем для их преобразования используйте LINQ-похожий доменный язык (DSL). Он также предоставляет SparkSQL в качестве декларативного подязыка для абстракций кадров данных и DataSet. DSL предоставляет две категории операций, преобразований и действий. Применение преобразований к абстракциям данных не приводит к выполнению преобразования, а создает план выполнения, который будет отправлен для оценки с помощью действия (например, запись результата во временную таблицу или файл или печать результат).

Таким образом, при преобразовании скрипта U-SQL в программу Spark необходимо решить, какой язык будет использоваться по крайней мере для создания абстракции кадра данных (в настоящее время это наиболее часто используемая Абстракция данных) и нужно ли написать декларативный преобразования потоков данных с использованием DSL или SparkSQL. В некоторых более сложных случаях может потребоваться разделить скрипт U-SQL на последовательность Spark и другие действия, реализованные с помощью пакетной службы Azure или функции Azure.

Более того, Azure Data Lake Analytics предлагает U-SQL в среде службы бессерверных заданий, в то время как Azure Databricks и Azure HDInsight предлагают Spark в форме службы кластеров. При преобразовании приложения необходимо принять во внимание последствия создания, изменения размера, масштабирования и списания кластеров.

## <a name="transform-u-sql-scripts"></a>Преобразование скриптов U-SQL

Скрипты U-SQL соответствуют следующему шаблону обработки:

1. Данные считываются из неструктурированных файлов с помощью инструкции `EXTRACT`, определения расположения или набора файлов, встроенного или определяемого пользователем средства извлечения и требуемой схемы или из таблиц U-SQL (управляемых или внешних таблиц). Он представляется в виде набора строк.
2. Наборы строк преобразуются в несколько инструкций U-SQL, которые применяют выражения U-SQL к наборам строк и создают новые наборы строк.
3. Наконец, результирующие наборы строк выводятся в любые файлы с помощью инструкции `OUTPUT`, указывающей расположение (s), встроенное или определяемое пользователем средство вывода или в таблицу U-SQL.

Сценарий оценивается отложенным, то есть каждый шаг извлечения и преобразования состоит из дерева выражений и глобально оценивается (поток данных).

Программы Spark похожи на те, которые используют соединители Spark для чтения и создания кадров данных, а затем применяют преобразования к кадрам данных с помощью LINQ-подобного DSL или SparkSQL, а затем записывают результат в файлы, временные таблицы Spark, Некоторые типы языков программирования или консоль.

## <a name="transform-net-code"></a>Преобразование кода .NET

Язык выражений U-SQL — C# это и предоставляет разнообразные способы масштабирования пользовательского кода .NET.

Поскольку в настоящее время Spark не поддерживает исполнение кода .NET, необходимо либо переписать выражения в эквивалентное выражение Spark, Scala, Java или Python, либо найти способ вызова кода .NET. Если в скрипте используются библиотеки .NET, доступны следующие варианты.

- Преобразовывать код .NET в Scala или Python.
- Разделите скрипт U-SQL на несколько шагов, в которых используются процессы пакетной службы Azure для применения преобразований .NET (если можно получить приемлемую шкалу).
- Используйте языковую привязку .NET, доступную в открытом источнике с именем Моебиус. Этот проект находится в неподдерживаемом состоянии.

В любом случае, если в скриптах U-SQL используется большой объем логики .NET, свяжитесь с нами через представителя учетной записи Майкрософт, чтобы получить дополнительные указания.

Следующие сведения относятся к различным случаям использования .NET и C# в скриптах U-SQL.

### <a name="transform-scalar-inline-u-sql-c-expressions"></a>Преобразование скалярных выражений U-SQL C# в строки преобразования

Язык выражений U-SQL — C#. Многие из скалярных выражений U-SQL реализуются изначально для повышения производительности, в то время как более сложные выражения могут выполняться путем вызова в .NET Framework.

Spark имеет собственный язык скалярных выражений (как часть DSL или в SparkSQL) и позволяет вызывать определяемые пользователем функции, написанные на его языке размещения.

Если у вас есть скалярные выражения в U-SQL, сначала следует найти наиболее подходящее скалярное выражение Spark, чтобы получить максимальную производительность, а затем сопоставлять другие выражения в определяемую пользователем функцию языка размещения Spark по своему усмотрению.

Имейте в виду, что C# .NET и имеет разную семантику типов, чем языки размещения Spark и язык DSL для Spark. Дополнительные сведения о различиях в системе типов см. [ниже](#transform-typed-values) .

### <a name="transform-user-defined-scalar-net-functions-and-user-defined-aggregators"></a>Преобразование определяемых пользователем скалярных функций .NET и определяемых пользователем агрегатов

U-SQL предоставляет способы вызова произвольных скалярных функций .NET и вызова определяемых пользователем агрегатов, написанных на платформе .NET.

Spark также предлагает поддержку определяемых пользователем функций и пользовательских агрегатов, написанных на большинстве языков размещения, которые можно вызывать из DSL и SparkSQL.

### <a name="transform-user-defined-operators-udos"></a>Преобразование определяемых пользователем операторов (Udo)

U-SQL предоставляет несколько категорий определяемых пользователем операторов (Udo), таких как средства извлечения, средства вывода, модулей сжатия, процессоры, средств применения и средства объединения, которые могут быть написаны на .NET (и в некоторой степени в Python и R).

Spark не предоставляет такую же модель расширяемости для операторов, но имеет аналогичные возможности для некоторых.

Аналогом для средств извлечения и вывода Spark является соединители Spark. Для многих средств извлечения U-SQL вы можете найти эквивалентный соединитель в сообществе Spark. Для других пользователей вам потребуется написать пользовательский соединитель. Если средство извлечения U-SQL является сложным и использует несколько библиотек .NET, может быть предпочтительнее создать соединитель в Scala, который использует взаимодействие для вызова библиотеки .NET, которая выполняет фактическую обработку данных. В этом случае необходимо развернуть среду выполнения .NET Core в кластере Spark и убедиться, что ссылки на библиотеки .NET .NET Standard соответствуют требованиям 2,0.

Другие типы Udo U-SQL потребуется переписывать с помощью определяемых пользователем функций и агрегатов, а также семантически подходящих выражений для рассылки Spark или SparkSQL. Например, процессор может быть сопоставлен с ВЫБОРкой различных вызовов UDF, упакованных в виде функции, принимающей в качестве аргумента кадр данных и возвращающей кадр данных.

### <a name="transform-u-sqls-optional-libraries"></a>Преобразование необязательных библиотек U-SQL

U-SQL предоставляет набор необязательных и демонстрационных библиотек, которые предлагают поддержку [Python](data-lake-analytics-u-sql-python-extensions.md), [R](data-lake-analytics-u-sql-r-extensions.md), [JSON, XML, Avro](https://github.com/Azure/usql/tree/master/Examples/DataFormats)и некоторых возможностей работы со [средствами](data-lake-analytics-u-sql-cognitive.md).

Spark предлагает собственные возможности интеграции Python и R, pySpark и Spark, а также предоставляет соединители для чтения и записи JSON, XML и AVRO.

Если необходимо преобразовать скрипт, ссылающийся на библиотеки наличных служб, мы рекомендуем связаться с нами через представителя учетных записей Майкрософт.

## <a name="transform-typed-values"></a>Преобразование типизированных значений

Поскольку система типов U-SQL основана на системе типов .NET, а Spark имеет собственную систему типов, на которую влияет привязка языка узла, необходимо убедиться, что типы, на которых вы используете, закрываются, а для определенных типов — диапазоны типов. , точность и (или) масштаб могут немного отличаться. Более того, U-SQL и Spark обрабатывают `null` значения по-разному.

### <a name="data-types"></a>Типы данных

В следующей таблице приведены эквивалентные типы в Spark, Scala и PySpark для заданных типов U-SQL.

| U-SQL | Spark |  Scala | PySpark |
| ------ | ------ | ------ | ------ |
|`byte`       ||||
|`sbyte`      |`ByteType` |`Byte` | `ByteType`|
|`int`        |`IntegerType` |`Int` | `IntegerType`|
|`uint`       ||||
|`long`       |`LongType` |`Long` | `LongType`|
|`ulong`      ||||
|`float`      |`FloatType` |`Float` | `FloatType`|
|`double`     |`DoubleType` |`Double` | `DoubleType`|
|`decimal`    |`DecimalType` |`java.math.BigDecimal` | `DecimalType`|
|`short`      |`ShortType` |`Short` | `ShortType`|
|`ushort`     ||||
|`char`   | |`Char`||
|`string` |`StringType` |`String` |`StringType` |
|`DateTime`   |`DateType`, `TimestampType` |`java.sql.Date`, `java.sql.Timestamp` | `DateType`, `TimestampType`|
|`bool`   |`BooleanType` |`Boolean` | `BooleanType`|
|`Guid`   ||||
|`byte[]` |`BinaryType` |`Array[Byte]` | `BinaryType`|
|`SQL.MAP<K,V>`   |`MapType(keyType, valueType, valueContainsNull)` |`scala.collection.Map` | `MapType(keyType, valueType, valueContainsNull=True)`|
|`SQL.ARRAY<T>`   |`ArrayType(elementType, containsNull)` |`scala.collection.Seq` | `ArrayType(elementType, containsNull=True)`|

Дополнительные сведения см. в следующих источниках.

- [org. Apache. Spark. SQL. types](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.types.package)
- [Spark SQL и типы кадров данных](https://spark.apache.org/docs/latest/sql-reference.html#data-types)
- [Типы значений Scala](https://www.scala-lang.org/api/current/scala/AnyVal.html)
- [pyspark. SQL. types](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.types)

### <a name="treatment-of-null"></a>Обработка значения NULL

В Spark типы по умолчанию допускают значения NULL в U-SQL. вы явно помечаете скалярный, а не объект как допускающий значение null. Хотя Spark позволяет определить столбец как не допускающий значения NULL, он не будет применять ограничение и [может привести к неправильному результату](https://medium.com/@weshoffman/apache-spark-parquet-and-troublesome-nulls-28712b06f836).

В Spark значение NULL указывает на неизвестное значение. Значение Spark NULL отличается от любого значения, включая само себя. Сравнение двух значений NULL в Spark или между значением NULL и любым другим значением возвращает Unknown, так как значение каждого значения NULL неизвестно.  

Это поведение отличается от U-SQL, что соответствует C# семантике, где `null` отличается от любого значения, но равно самому себе.  

Таким образом, инструкция SparkSQL `SELECT`, использующая `WHERE column_name = NULL`, возвращает нулевые строки, даже если в `column_name`есть значения NULL, в то время как в U-SQL он возвращал строки, где `column_name` имеет значение `null`. Аналогично, инструкция Spark `SELECT`, использующая `WHERE column_name != NULL`, возвращает нулевые строки, даже если в `column_name`есть значения, отличные от NULL, в то время как в U-SQL она возвращала строки, которые имеют значение, отличное от NULL. Таким же, если требуется семантика проверки значений NULL в U-SQL, следует использовать [IsNull](https://spark.apache.org/docs/2.3.0/api/sql/index.html#isnull) и [isnotnull](https://spark.apache.org/docs/2.3.0/api/sql/index.html#isnotnull) соответственно (или их эквивалент DSL).

## <a name="transform-u-sql-catalog-objects"></a>Преобразование объектов каталога U-SQL

Одно из основных различий заключается в том, что скрипты U-SQL могут использовать свои объекты каталога, многие из которых не имеют прямого эквивалента Spark.

Spark обеспечивает поддержку концепций мета хранилища Hive, главным образом базы данных и таблицы, позволяющие сопоставлять базы данных и схемы U-SQL с базами данных Hive, а также таблицы U-SQL в таблицы Spark (см. раздел [Перемещение данных, хранящихся в таблицах u-SQL](understand-spark-data-formats.md#move-data-stored-in-u-sql-tables), но не поддерживает представления, функции с табличным значением (возвращающие табличное), хранимые процедуры, сборки U-SQL, внешние источники данных и т. д.

Объекты кода U-SQL, такие как представления, возвращающие табличное, хранимые процедуры и сборки, можно моделировать с помощью функций кода и библиотек в Spark и ссылаться на них с помощью функции языка узла и механизмов абстракции процедур (например, путем импорта Модули Python или ссылки на Scala функции).

Если каталог U-SQL используется для совместного использования данных и объектов кода в проектах и командах, необходимо использовать эквивалентные механизмы для совместного использования (например, Maven для совместного использования объектов кода).

## <a name="transform-u-sql-rowset-expressions-and-sql-based-scalar-expressions"></a>Преобразование выражений набора строк U-SQL и скалярных выражений на основе SQL

Базовый язык U-SQL преобразует наборы строк и основан на SQL. Ниже приведен неисчерпывающий список наиболее распространенных выражений набора строк, предлагаемых в U-SQL:

- `SELECT`/`FROM`/`WHERE`/`GROUP BY`+ Aggregates +`HAVING`/`ORDER BY`+`FETCH`
- `INNER`/`OUTER`/`CROSS`/`SEMI` выражения `JOIN`
- выражения `CROSS`/`OUTER` `APPLY`
- выражения `PIVOT`/`UNPIVOT`
- Конструктор набора строк `VALUES`

- Выражения наборов `UNION`/`OUTER UNION`/`INTERSECT`/`EXCEPT`

Кроме того, U-SQL предоставляет разнообразные скалярные выражения на основе SQL, такие как

- `OVER` выражениях окон
- разнообразные встроенные агрегаты и ранжирующие функции (`SUM`, `FIRST` и т. д.).
- Некоторые из наиболее известных скалярных выражений SQL: `CASE`, `LIKE`, (`NOT`) `IN`, `AND`, `OR` и т. д.

Для большинства из этих выражений Spark предлагает эквивалентные выражения в обеих формах DSL и SparkSQL. Некоторые выражения, не поддерживаемые изначально в Spark, придется переписывать, используя сочетание собственных выражений Spark и семантически эквивалентных шаблонов. Например, `OUTER UNION` необходимо преобразовать в эквивалентное сочетание проекций и объединений.

Из-за различной обработки значений NULL соединение U-SQL всегда будет соответствовать строке, если оба сравниваемых столбца содержат значение NULL, тогда как соединение в Spark не будет соответствовать таким столбцам, если не будут добавлены явные проверки NULL.

## <a name="transform-other-u-sql-concepts"></a>Преобразование других концепций U-SQL

U-SQL также предлагает множество других функций и концепций, таких как Федеративные запросы к SQL Server базам данных, параметрам, скалярным значениям и переменным лямбда-выражений, системным переменным `OPTION` указаниям.

### <a name="federated-queries-against-sql-server-databasesexternal-tables"></a>Федеративные запросы к SQL Server базам данных и внешним таблицам

U-SQL предоставляет источник данных и внешние таблицы, а также прямые запросы к базе данных SQL Azure. Хотя Spark не предоставляет одинаковые абстракции объектов, он предоставляет [соединитель Spark для базы данных SQL Azure](../sql-database/sql-database-spark-connector.md) , который можно использовать для выполнения запросов к базам данных SQL.

### <a name="u-sql-parameters-and-variables"></a>Параметры и переменные U-SQL

Параметры и пользовательские переменные имеют эквивалентные понятия в Spark и их языках размещения.

Например, в Scala можно определить переменную с ключевым словом `var`:

```
var x = 2 * 3;
println(x)
```

Системные переменные U-SQL (переменные, начинающиеся с `@@`) можно разделить на две категории:

- Настраиваемые системные переменные, для которых можно задать конкретные значения, влияющие на поведение сценариев
- Информационные системные переменные, которые запрашивать сведения об уровне системы и заданий

Большинство настраиваемых системных переменных не имеют прямого эквивалента в Spark. Некоторые информационные системные переменные могут быть смоделированы путем передачи информации в качестве аргументов во время выполнения задания, другие могут иметь эквивалентную функцию на языке размещения Spark.

### <a name="u-sql-hints"></a>Указания U-SQL

U-SQL предлагает несколько синтаксических способов предоставления подсказок оптимизатору запросов и подсистеме выполнения.  

- Установка системной переменной U-SQL
- предложение `OPTION`, связанное с выражением набора строк для предоставления указания данных или плана
- указание о соединении в синтаксисе выражения JOIN (например, `BROADCASTLEFT`)

Оптимизатор запросов, основанный на стоимости Spark, обладает собственными возможностями для предоставления подсказок и настройки производительности запросов. См. соответствующую документацию.

## <a name="next-steps"></a>Дополнительная информация

- [Общие сведения о форматах данных Spark для разработчиков U-SQL](understand-spark-data-formats.md)
- [.NET для Apache Spark](https://docs.microsoft.com/dotnet/spark/what-is-apache-spark-dotnet)
- [Обновление решений аналитики больших данных с Azure Data Lake Storage 1-го поколения до Azure Data Lake Storage 2-го поколения](../storage/blobs/data-lake-storage-upgrade.md)
- [Преобразование данных с помощью действия Spark в фабрике данных Azure](../data-factory/transform-data-using-spark.md)
- [Преобразование данных с помощью действия Hadoop Hive в фабрике данных Azure](../data-factory/transform-data-using-hadoop-hive.md)
- [Что такое Apache Spark в Azure HDInsight](../hdinsight/spark/apache-spark-overview.md)
