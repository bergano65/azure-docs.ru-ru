---
title: Руководство. Перенос данных в учетную запись API Cassandra в Azure Cosmos DB
description: В этом руководстве описано использование команды CQL Copy и Spark для копирования данных из Apache Cassandra в учетную запись API Cassandra в Azure Cosmos DB.
author: kanshiG
ms.service: cosmos-db
ms.component: cosmosdb-cassandra
ms.author: govindk
ms.topic: tutorial
ms.date: 12/03/2018
ms.reviewer: sngun
Customer intent: As a developer, I want to migrate my existing Cassandra workloads to Azure Cosmos DB so that the overhead to manage resources, clusters, and garbage collection is automatically handled by Azure Cosmos DB.
ms.openlocfilehash: 604cab3bed73366ce28c8bb35b63df6379985cfb
ms.sourcegitcommit: b0f39746412c93a48317f985a8365743e5fe1596
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 12/04/2018
ms.locfileid: "52867473"
---
# <a name="tutorial-migrate-your-data-to-cassandra-api-account-in-azure-cosmos-db"></a>Руководство. Перенос данных в учетную запись API Cassandra в Azure Cosmos DB

Как у разработчика у вас могут существовать рабочие нагрузки Cassandra, выполняемые локально или в облаке, и может понадобиться перенести их в Azure. Такие рабочие нагрузки можно перенести в учетную запись API Cassandra в Azure Cosmos DB. В этом руководстве приведены инструкции к различным методам переноса данных Apache Cassandra в учетную запись API Cassandra в Azure Cosmos DB.

В рамках этого руководства рассматриваются следующие задачи:

> [!div class="checklist"]
> * Планирование миграции
> * Предварительные требования для миграции
> * Перенос данных с помощью команды cqlsh COPY
> * Перенос данных с помощью Spark

Если у вас еще нет подписки Azure, [создайте бесплатную учетную запись Azure](https://azure.microsoft.com/free/?WT.mc_id=A261C142F), прежде чем начинать работу.

## <a name="prerequisites-for-migration"></a>Предварительные требования для миграции

* **Оцените требования к пропускной способности.** Прежде чем переносить данные в учетную запись API Cassandra в Azure Cosmos DB, следует оценить потребности в пропускной способности рабочей нагрузки. Как правило, рекомендуется начинать со средней пропускной способности, требуемой для операций CRUD, а затем включить дополнительную пропускную способность, необходимую для операций извлечения, преобразования и загрузки (ETL) или операций, для которых характерны резкие скачки. Для планирования миграции необходимо знать следующее. 

   * **Текущий или предполагаемый размер данных**. Определяет минимальные требования к размеру базы данных и пропускной способности. Если вы оцениваете размер данных для нового приложения, можно предположить, что данные равномерно распределены по строкам, и получить примерное значение путем умножения на размер данных. 

   * **Требуемая пропускная способность.** Приблизительная пропускная способность для операций чтения (запрос, получение) и записи (изменение, удаление, вставка). Это значение необходимо для вычисления требуемого количества единиц, а также размера данных в устойчивом состоянии.  

   * **Схема.** Подключитесь к существующему кластеру Cassandra с помощью cqlsh и экспортируйте схему из Cassandra. 

     ```bash
     cqlsh [IP] "-e DESC SCHEMA" > orig_schema.cql
     ```

   Определив требования существующей рабочей нагрузки, необходимо создать учетную запись Azure Cosmos, базу данных и контейнеры в соответствии с полученными требованиями к пропускной способности.  

   * **Определите стоимость ЕЗ для операции.** Определить ЕЗ можно с помощью любого из пакетов SDK, поддерживаемого API Cassandra. В этом примере мы используем для оценки затрат версию .NET.

     ```csharp
     var tableInsertStatement = table.Insert(sampleEntity);
     var insertResult = await tableInsertStatement.ExecuteAsync();

     foreach (string key in insertResult.Info.IncomingPayload)
       {
          byte[] valueInBytes = customPayload[key];
          string value = Encoding.UTF8.GetString(valueInBytes);
          Console.WriteLine($"CustomPayload:  {key}: {value}");
       }
     ```

* **Выделите требуемую пропускную способность**. Azure Cosmos DB поддерживает автоматическое масштабирование хранилища и пропускной способности по мере роста требований. Вы можете оценить требуемую вам пропускную способность с помощью [калькулятора единиц запроса Azure Cosmos DB](https://www.documentdb.com/capacityplanner). 

* **Создайте таблицы в учетной записи API Cassandra.** Прежде чем начать миграцию данных, предварительно создайте все таблицы с помощью портала Azure или cqlsh. Если вы выполняете перенос в учетную запись Azure Cosmos, обладающую пропускной способностью уровня базы данных, при создании контейнеров Azure Cosmos обязательно укажите ключ раздела.

* **Увеличьте пропускную способность**. Продолжительность миграции данных зависит от пропускной способности, которую вы предоставите для таблиц в Azure Cosmos DB. Увеличьте пропускную способность на время выполнения миграции. Более высокая пропускная способность позволяет избежать ограничения скорости и выполнить перенос быстрее. После переноса уменьшите пропускную способность для экономии расходов. Также рекомендуется разместить учетную запись Azure Cosmos в том же регионе, где находится база данных-источник. 

* **Включите SSL**. В Azure Cosmos DB реализуются строгие требования и стандарты безопасности. Обязательно включите SSL при взаимодействии с учетной записью. При использовании CQL с SSH у вас есть возможность предоставить сведения SSL.

## <a name="options-to-migrate-data"></a>Варианты миграции данных

Вы можете переместить данные из существующих рабочих нагрузок Cassandra в Azure Cosmos DB следующим образом:

* [с помощью команды cqlsh COPY](#using-cqlsh-copy-command);  
* [с помощью Spark](#using-spark). 

## <a name="migrate-data-using-cqlsh-copy-command"></a>Перенос данных с помощью команды cqlsh COPY

[Команда CQL COPY](http://cassandra.apache.org/doc/latest/tools/cqlsh.html#cqlsh) используется для копирования локальных данных в учетную запись API Cassandra в Azure Cosmos DB. Выполните указанные ниже действия, чтобы копировать данные.

1. Получение сведений о строке подключения для учетной записи API Cassandra

   * Войдите на [портал Azure](https://portal.azure.com) и перейдите в учетную запись Azure Cosmos.

   * Откройте область **Строка подключения**, которая содержит все сведения, необходимые для подключения к учетной записи API Cassandra из cqlsh.

2. Войдите в cqhsh, используя полученные на портале сведения о подключении.

3. Используйте команду CQL COPY, чтобы скопировать локальные данные в учетную запись API Cassandra.

   ```bash
   COPY exampleks.tablename FROM filefolderx/*.csv 
   ```

## <a name="migrate-data-using-spark"></a>Перенос данных с помощью Spark 

Для переноса данных в учетную запись API Cassandra с помощью Spark следуйте приведенным ниже инструкциям.

- Подготовьте [кластер Azure Databricks](cassandra-spark-databricks.md) или [кластер HDInsight](cassandra-spark-hdinsight.md). 

- Переместите данные в целевую конечную точку API Cassandra с помощью [табличной операции копирования](cassandra-spark-table-copy-ops.md). 

Перенос данных с помощью заданий Spark рекомендуется, если у вас есть данные, хранимые в существующем кластере в виртуальных машинах Azure или в любом другом облаке. Для этого следует настроить Spark в качестве промежуточного звена для однократного или регулярного приема данных. Можно ускорить миграцию с помощью подключений Azure ExpressRoute между локальной сетью и Azure. 

## <a name="clean-up-resources"></a>Очистка ресурсов

Можно удалить группу ресурсов, учетную запись Azure Cosmos и все связанные ресурсы, когда они больше не нужны. Для этого выберите группу ресурсов для виртуальной машины, выберите **Удалить** и подтвердите имя удаляемой группы ресурсов.

## <a name="next-steps"></a>Дополнительная информация

Из этого руководства вы узнали, как перенести данные в учетную запись API Cassandra в Azure Cosmos DB. Теперь можно перейти к следующей статье, чтобы узнать о других понятиях Azure Cosmos DB.

> [!div class="nextstepaction"]
> [Настраиваемые уровни согласованности данных в Azure Cosmos DB](../cosmos-db/consistency-levels.md)


