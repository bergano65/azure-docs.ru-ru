---
title: Часто задаваемые вопросы об автомасштабировании подготовленной пропускной способности в Azure Cosmos DB
description: Часто задаваемые вопросы об автомасштабировании подготовленной пропускной способности для баз данных и контейнеров Azure Cosmos DB
author: deborahc
ms.author: dech
ms.service: cosmos-db
ms.topic: conceptual
ms.date: 05/10/2020
ms.openlocfilehash: b398f739189232f39a2fee06fc6e6ff0d53348f0
ms.sourcegitcommit: fdec8e8bdbddcce5b7a0c4ffc6842154220c8b90
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/19/2020
ms.locfileid: "83656612"
---
# <a name="frequently-asked-questions-about-autoscale-provisioned-throughput-in-azure-cosmos-db"></a>Часто задаваемые вопросы об автомасштабировании подготовленной пропускной способности в Azure Cosmos DB

Автомасштабирование подготовленной пропускной способности позволяет Azure Cosmos DB автоматически контролировать и масштабировать число единиц запросов в секунду в вашей базе данных или контейнере в зависимости от их использования. Эта статья содержит ответы на часто задаваемые вопросы об автомасштабировании.

## <a name="frequently-asked-questions"></a>Часто задаваемые вопросы

### <a name="what-is-the-difference-between-autopilot-and-autoscale-in-azure-cosmos-db"></a>В чем разница между "автопилотом" и "автомасштабированием" в Azure Cosmos DB?
"Автомасштабирование" или "автомасштабирование подготовленной пропускной способности" — это обновленное имя функции, ранее известной как "автопилот". В текущий выпуск автомасштабирования мы добавили новые функции, включая возможность настройки любой максимальной пропускной способности в ЕЗ/с и программную поддержку. 

### <a name="what-happens-to-databases-or-containers-created-in-the-previous-autopilot-tier-model"></a>Что происходит с базами данных или контейнерами, созданными в предыдущей модели с уровнем автопилота?
Ресурсы, созданные с использованием предыдущей модели уровней, автоматически поддерживаются и новой моделью автомасштабирования с возможностью настройки любой максимальной пропускной способности. Верхняя граница уровня становится новым максимальным значением ЕЗ/с, что в итоге обеспечивает тот же диапазон масштабирования. 

Например, если ранее был выбран уровень с масштабированием от 400 и 4000 ЕЗ/с, то теперь база данных или контейнер будут показывать максимальную пропускную способность 4000 ЕЗ/с, что соответствует масштабированию от 400 до 4000 ЕЗ/с. Это максимальное значение EЗ/с можно изменить на любое пользовательское значение, соответствующее вашей рабочей нагрузке. 

### <a name="how-quickly-will-autoscale-scale-up-and-down-based-on-spikes-in-traffic"></a>Как быстро автомасштабирование реагирует на пики трафика?
При использовании автомасштабирования система масштабирует пропускную способность (ЕЗ/с) `T` в диапазоне от `0.1 * Tmax` до `Tmax` в зависимости от входящего трафика. Поскольку масштабирование происходит автоматически и мгновенно, выполнение всех запросов в пределах подготовленной пропускной способности `Tmax` осуществляется без задержки. 

### <a name="how-do-i-determine-what-rus-the-system-is-currently-scaled-to"></a>Как определить, до какого уровня EЗ/c масштабирована система в текущий момент?
Определить подготовленный максимум автомасштабирования и текущую пропускную способность в ЕЗ/с, до которой масштабирована система, позволяет [служба метрик Azure Monitor](how-to-choose-offer.md#measure-and-monitor-your-usage). 

### <a name="what-is-the-pricing-for-autoscale"></a>Сколько стоит автомасштабирование?
За каждый час вам будет выставляться счет за наибольшую пропускную способность `T`, до которой система была масштабирована за этот час. Если ресурс не получал запросы в течение часа или его масштаб не достиг показателя `0.1 * Tmax`, вам будет выставлен счет за минимальный показатель `0.1 * Tmax`. Дополнительные сведения см. на [странице цен](https://azure.microsoft.com/pricing/details/cosmos-db/) на Azure Cosmos DB. 

### <a name="how-does-autoscale-show-up-on-my-bill"></a>Как автомасштабирование отображается в счете?
В учетных записях с одним источником автомасштабирование (за 100 ЕЗ/с) стоит в 1,5 раза дороже стандартной пропускной способности, подготовленной вручную. В счете будет указано актуальное число единиц измерения стандартной подготовленной пропускной способности. Оно будет умножено на 1,5. Например, если в течение часа система масштабировалась максимум до 6000 ЕЗ/с, за этот час вам будет выставлен счет на 60 * 1,5 = 90 единиц измерения.

В учетных записях с несколькими источниками автомасштабирование (за 100 ЕЗ/с) стоит столько же, сколько и стандартная пропускная способность, подготовленная вручную. В счете вы будет указано актуальное число единиц измерения из нескольких источников. Поскольку стоимость одинакова, при использовании автомасштабирования в счете будет отображаться такое же количество, как и при стандартной пропускной способности.

### <a name="does-autoscale-work-with-reserved-capacity"></a>Работает ли автомасштабирование с зарезервированной емкостью?
Да. Если вы покупаете зарезервированную емкость для учетной записи с одним источником, скидка на резервирование ресурсов автомасштабирования применяется к объему использованных вами единиц с коэффициентом 1,5 * [коэффициент для соответствующего региона](../cost-management-billing/reservations/understand-cosmosdb-reservation-charges.md#reservation-discount-per-region). 

Зарезервированная емкость для учетной записи с несколькими источниками работает одинаково и с автомасштабированием, и со стандартной пропускной способностью, подготовленной вручную. См. раздел [Зарезервированная емкость в Azure Cosmos DB](cosmos-db-reserved-capacity.md).

### <a name="does-autoscale-work-with-free-tier"></a>Работает ли автомасштабирование на уровне "Бесплатный"?
Да. На уровне "Бесплатный" можно использовать автомасштабирование пропускной способности в контейнере. Поддержка баз данных с автомасштабированием общей пропускной способности и пользовательской настройкой максимального количества единиц запрос в секунду пока недоступна. См. [примеры выставления счетов за автомасштабирование на уровне "Бесплатный"](understand-your-bill.md#billing-examples-with-free-tier-accounts).

### <a name="is-autoscale-supported-for-all-apis"></a>Все ли API поддерживают автомасштабирование?
Да, автомасштабирование поддерживают все API: Core (SQL), Gremlin, Table, Cassandra и API для MongoDB.

### <a name="is-autoscale-supported-for-multi-master-accounts"></a>Поддерживают ли автомасштабирование учетные записи с несколькими источниками?
Да. В каждом регионе, который добавляется в учетную запись Azure Cosmos DB, доступно максимальное количество единиц запросов в секунду. 

### <a name="how-do-i-enable-autoscale-on-new-databases-or-containers"></a>Как включить автомасштабирование для новых баз данных или контейнеров?
Инструкции по включению автомасштабирования см. в [этой статье](how-to-provision-autoscale-throughput.md).

### <a name="can-i-enable-autoscale-on-an-existing-database-or-a-container"></a>Можно ли включить автомасштабирование в уже существующей базе данных или контейнере?
Да. Вы также можете по мере необходимости переключаться между автомасштабированием и стандартной пропускной способностью, подготовленной вручную. Пока во всех API для выполнения этих операций можно использовать только [портал Azure](how-to-provision-autoscale-throughput.md#enable-autoscale-on-existing-database-or-container).

### <a name="how-does-the-migration-between-autoscale-and-standard-manual-provisioned-throughput-work"></a>Как работает переключение между автомасштабированием и стандартной пропускной способностью, подготовленной вручную?
Изменение типа пропускной способности — это процесс, который выполняется в два этапа. Сначала вы отправляете запрос об изменении параметров пропускной способности на автомасштабирование или пропускную способность, подготовленную вручную. В обоих случаях система автоматически определит и установит начальное значение ЕЗ/с, исходя из текущих параметров пропускной способности и хранилища. На этом этапе никакое пользовательское значение ЕЗ/с не принимается. Затем, после того как обновление будет завершено, вы сможете [изменить значение EЗ/c](#can-i-change-the-max-rus-on-the-database-or-container) в соответствии с вашей рабочей нагрузкой. 

**Переход со стандартной пропускной способности, подготовленной вручную, на автомасштабирование**

Для контейнера рассчитайте начальный максимум ЕЗ/с для автомасштабирования по следующей формуле: ``MAX(4000, current manual provisioned RU/s, maximum RU/s ever provisioned / 10, storage in GB * 100)``, округлив результат до ближайшей тысячи ЕЗ/с. Фактический начальный максимум ЕЗ/с для автомасштабирования будет зависеть от конфигурации вашей учетной записи.

Пример 1. Предположим, что у вас есть контейнер с настроенной вручную пропускной способностью в 10 000 ЕЗ/с и 25 ГБ хранилища. При включении автомасштабирования начальный максимум ЕЗ/с для автомасштабирования составит 10 000 ЕЗ/с с масштабированием от 1000 до 10 000 ЕЗ/с. 

Пример 2. Предположим, что у вас есть контейнер с настроенной вручную пропускной способностью в 50 000 ЕЗ/с и 2500 ГБ хранилища. При включении автомасштабирования начальный максимум ЕЗ/с для автомасштабирования составит 250 000 ЕЗ/с с масштабированием от 25 000 до 250 000 ЕЗ/с. 

**Переход с автомасштабирования на стандартную пропускную способность, подготовленную вручную**

Начальная пропускная способность, подготовленная вручную, будет равна текущему значению максимума ЕЗ/с для автомасштабирования. 

Пример Предположим, что у вас есть база данных или контейнер с автомасштабированием и максимальной пропускной способностью 20 000 ЕЗ/с (с масштабированием от 2000 до 20 000 ЕЗ/с). При переходе на пропускную способность, подготовленную вручную, начальная пропускная способность составит 20 000 ЕЗ/с. 

### <a name="is-there-azure-cli-or-powershell-support-to-manage-databases-or-containers-with-autoscale"></a>Доступна ли поддержка Azure CLI или PowerShell для управления базами данных или контейнерами с автомасштабированием?
Пока создавать ресурсы с автомасштабированием и управлять ими можно только через портал Azure, а также .NET V3 SDK, Java V4 SDK и Azure Resource Manager. В Azure CLI, PowerShell и других пакетах SDK поддержка пока недоступна.

### <a name="is-autoscale-supported-for-shared-throughput-databases"></a>Поддерживается ли автомасштабирование в базах данных с общей пропускной способностью?
Да, в базах данных с общей пропускной способностью автомасштабирование поддерживается. Чтобы включить эту функцию, при создании базы данных выберите автомасштабирование и параметр **Подготовленная пропускная способность**. 

### <a name="what-is-the-number-of-allowed-containers-per-shared-throughput-database-when-autoscale-is-enabled"></a>Сколько контейнеров на базу данных с общей пропускной способностью допускается при включенном автомасштабировании?
Azure Cosmos DB допускает не больше 25 контейнеров в базе данных с общей пропускной способностью, включая базы данных с автомасштабированием и стандартной пропускной способностью, подготовленной вручную. 

### <a name="what-is-the-storage-limit-associated-with-each-max-rus-option"></a>Какой максимальный размер хранилища соответствует каждому максимальному значению ЕЗ/с?  
Максимальный размер хранилища в ГБ для каждого максимального значения ЕЗ/с определяется по формуле: максимум ЕЗ/с для базы данных или контейнера / 100. Например, если максимальная пропускная способность составляет 20 000 ЕЗ/с, ресурс может поддерживать хранилище объемом до 200 ГБ. Доступные максимальные значения ЕЗ/с и хранилища см. в статье [Ограничения для автомасштабирования](provision-throughput-autoscale.md#autoscale-limits). 

### <a name="what-happens-if-i-exceed-the-storage-limit-associated-with-my-max-throughput"></a>Что будет, если превысить ограничение на объем хранилища для своей максимальной пропускной способности?
Если ограничение на объем хранилища, соответствующее максимальной пропускной способности базы данных или контейнера, будет превышено, Azure Cosmos DB автоматически увеличит максимальную пропускную способность до следующего максимального значения ЕЗ/с в секунду, соответствующего этому уровню хранилища.

Например, если начать с максимальной пропускной способности в 50 000 ЕЗ/с (с масштабированием от 5000 до 50 000 ЕЗ/с), можно хранить до 500 ГБ данных. Если объем ваших данных превысит этот лимит и достигнет, например, 600 ГБ, новая максимальная пропускная способность составит 60 000 ЕЗ/с (с масштабированием от 6000 до 60 000 ЕЗ/с).

### <a name="can-i-change-the-max-rus-on-the-database-or-container"></a>Можно ли изменить максимальное значение ЕЗ/с в базе данных или контейнере? 
Да. Инструкции по изменению максимального значения ЕЗ/с см. в [этой статье](how-to-provision-autoscale-throughput.md). В зависимости от того, какое значение ЕЗ/с вас интересует, изменение максимальной пропускной способности может выполняться как асинхронная операция и занять какое-то время (до 4–6 часов в зависимости от выбранного значения ЕЗ/с).

#### <a name="increasing-the-max-rus"></a>Увеличение максимального значения ЕЗ/с
При отправке запроса на увеличение максимального значения ЕЗ/с `Tmax` служба подготавливает дополнительные ресурсы для поддержки более высокого максимального значения ЕЗ/с в зависимости от указанного вами значения. Это происходит в фоновом режиме и не влияет на ваши существующие рабочие нагрузки и операции. Система будет продолжать изменять масштаб базы данных или контейнера с предыдущего значения `0.1*Tmax` на `Tmax` до тех пор, пока новый диапазон масштабирования от `0.1*Tmax_new` до `Tmax_new` не будет готов.

#### <a name="lowering-the-max-rus"></a>Уменьшение максимального значения ЕЗ/с
Минимальное возможное значение максимальной пропускной способности определяется по формуле `MAX(4000, highest max RU/s ever provisioned / 10, current storage in GB * 100)` с округлением до ближайшей 1000 ЕЗ/с. 

Пример 1. Предположим, что у вас есть контейнер с автомасштабированием и максимальной пропускной способностью 20 000 ЕЗ/с (с масштабированием от 2000 до 20 000 ЕЗ/с), а также 50 ГБ хранилища. Минимальное значение максимальной пропускной способности, которое вы можете установить: MAX (4000, 20,000 / 10, **50 * 100**) = 5000 ЕЗ/с (с масштабированием от 500 до 5000 ЕЗ/с).

Пример 2. Предположим, что у вас есть контейнер с автомасштабированием и максимальной пропускной способностью 100 000 ЕЗ/с, а также 100 ГБ хранилища. Вы решили изменить максимальную пропускную способность на 150 000 ЕЗ/с (с масштабированием от 15 000 до 150 000 ЕЗ/с). Минимальное значение максимальной пропускной способности, которое вы можете установить: MAX (4000, **150 000 / 10**, 100 * 100) = 15 000 ЕЗ/с (с масштабированием от 1500 до 15 000 ЕЗ/с). 

Для базы данных с общей пропускной способностью минимальное возможное значение максимальной пропускной способности определяется по формуле `MAX(4000, highest max RU/s ever provisioned / 10, current storage in GB * 100,  4000 + (MAX(Container count - 25, 0) * 1000))` с округлением до ближайшей тысячи ЕЗ/с.  

Приведенные выше формулы и примеры относятся к наименьшему максимальному значению автомасштабирования, которое вы можете установить, и отличаются от диапазона масштабирования от `0.1 * Tmax` до `Tmax`, который система использует автоматически. Какое бы максимальное значение ЕЗ/с вы ни указали, система всегда будет масштабироваться от `0.1 * Tmax` до `Tmax`. 

### <a name="how-does-ttl-work-with-autoscale"></a>Как работает с автомасштабированием TTL?
При использовании автомасштабирования операции TTL не влияют на масштабирование пропускной способности. Единицы запросов, использованные в связи с TTL, не включаются в оплату ЕЗ/с для контейнера автомасштабирования. 

Например, предположим, что у вас есть контейнер с автомасштабированием от 400 до 4000 ЕЗ/с.
- Час 1. T = 0: контейнер не используется (нет TTL или запросов рабочей нагрузки). Счет будет выставлен на 400 ЕЗ/с.
- Час 1. T = 1: TTL включен.
- Час 1. T = 2: контейнер начинает получать запросы, которые используют 1000 ЕЗ/с. Кроме того, есть 200 единиц запросов TTL, которые нужно выполнить. Счет все равно будет выставлен на 1000 ЕЗ/с. Операции TTL, когда бы они ни выполнялись, не влияют на логику автомасштабирования.

### <a name="what-is-the-mapping-between-the-max-rus-and-physical-partitions"></a>Что представляет собой сопоставление между максимальным значением ЕЗ/с и физическими разделами?
Когда вы впервые выбираете максимальное значение ЕЗ/с, Azure Cosmos DB подготавливает: макс. ЕЗ/с / 10 000 ЕЗ/с = количество физических разделов. Каждый [физический раздел](partition-data.md#physical-partitions) способен поддерживать до 10 000 ЕЗ/с и 50 ГБ хранилища. С увеличением размера хранилища Azure Cosmos DB автоматически разбивает разделы, чтобы добавить физические разделы для хранения новых данных, или увеличивает максимальное значение ЕЗ/с, если хранилище [превышает соответствующий лимит](#what-is-the-storage-limit-associated-with-each-max-rus-option). 

Максимальное значение ЕЗ/с для базы данных или контейнера распределяется равномерно между всеми физическими разделами. Таким образом, максимальная общая пропускная способность для одного физического раздела составляет: максимум ЕЗ/с для базы данных или контейнера / количество физических разделов. 

### <a name="what-happens-if-incoming-requests-exceed-the-max-rus-of-the-database-or-container"></a>Что произойдет, если входящие запросы превысят максимальное значение ЕЗ/с для базы данных или контейнера?
Если общий объем ЕЗ/с превышает максимальное значение ЕЗ/с для базы данных или контейнера, запросы сверх максимального значения ЕЗ/с регулируются и возвращают код состояния 429. Также регулируются запросы, которые приводят к превышению 100 % нормализованной загрузки. Нормализованное использование определяется как максимальное использование ЕЗ/с во всех физических разделах. Например, предположим, что ваша максимальная пропускная способность составляет 20 000 ЕЗ/с и у вас есть два физических раздела, P_1 и P_2, каждый из которых поддерживает масштабирование до 10 000 ЕЗ/с. Если за определенную секунду P_1 использовал 6000 ЕЗ/с, а P_2 — 8000 ЕЗ/с, то нормализованная нагрузка составляет MAX (6000 ЕЗ / 10 000 ЕЗ, 8000 ЕЗ / 10 000 ЕЗ) = 0,8.

> [!NOTE]
> Клиентские пакеты SDK и средства импорта данных Azure Cosmos DB (Фабрика данных Azure, библиотека исполнителей массовых операций) при возникновении ошибки 429 автоматически перезапускаются, поэтому разовые случаи таких ошибок проблем не вызывают. Постоянное большое количество ошибок 429 может означать, что необходимо увеличить максимальное значение ЕЗ/с или пересмотреть стратегию выделения [горячего раздела](#autoscale-rate-limiting).

### <a name="is-it-still-possible-to-see-429s-throttlingrate-limiting-when-autoscale-is-enabled"></a><a id="autoscale-rate-limiting"></a> Возникают ли ошибки 429 (регулирование/ограничение скорости) при включенном автомасштабировании? 
Да. Ошибки 429 возникают в двух случаях. Во-первых, когда общее число использованных ЕЗ/с превышает максимальную пропускную способность базы данных или контейнера, служба начинает регулировать запросы соответствующим образом. 

Во-вторых, если есть горячий раздел, т. е. значение ключа логического раздела получает непропорционально большое количество запросов по сравнению со значениями ключей других разделов, возможно, что соответствующий физический раздел превысил свой максимум ЕЗ/с. Чтобы избежать возникновения горячих разделов, нужно [выбрать хороший ключ раздела](partitioning-overview.md#choose-partitionkey), который обеспечит равномерное распределение хранилища и пропускной способности. 

Например, если максимальная пропускная способность составляет 20 000 ЕЗ/с и у вас есть 200 ГБ хранилища с четырьмя физическими разделами, каждый физический раздел будет автоматически масштабироваться до 5000 ЕЗ/с. Если в определенном ключе логического раздела возникнет горячий раздел, ошибка 429 отобразится, когда соответствующий физический раздел получит больше 5000 ЕЗ/с, т. е. превысит 100 % своего нормализованного использования.


## <a name="next-steps"></a>Дальнейшие действия

* Подробнее о [включении автомасштабирования для базы данных или контейнера Azure Cosmos DB](how-to-provision-autoscale-throughput.md).
* Подробнее о [преимуществах подготовленной пропускной способности с автомасштабированием](provision-throughput-autoscale.md#benefits-of-autoscale).
* Подробнее о [логических и физических разделах ](partition-data.md).
                        