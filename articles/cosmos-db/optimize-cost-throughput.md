---
title: Оптимизация затрат на пропускную способность в Azure Cosmos DB
description: В этой статье объясняется, как оптимизировать затраты на пропускную способность для данных, хранящихся в Azure Cosmos DB.
author: rimman
ms.service: cosmos-db
ms.topic: conceptual
ms.date: 12/07/2018
ms.author: rimman
ms.openlocfilehash: f0d0442a8640a75b21e95e3ae024fd7994602b51
ms.sourcegitcommit: 9f87a992c77bf8e3927486f8d7d1ca46aa13e849
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 12/28/2018
ms.locfileid: "53807947"
---
# <a name="optimizing-throughput-cost-in-azure-cosmos-db"></a>Оптимизация затрат на пропускную способность в Azure Cosmos DB

Предлагая модель подготовленной пропускной способности, Azure Cosmos DB обеспечивает прогнозируемую производительность в любом масштабе. Заблаговременное резервирование или подготовка пропускной способности позволяет избежать влияния "шумного соседа" на производительность. Вы указываете точный объем пропускной способности, который вам нужен, а Azure Cosmos DB гарантированно настраивает эту пропускную способность в соответствии с соглашением об уровне обслуживания.

Можно начать с минимальной пропускной способности в 400 ЕЗ/с и масштабировать ее до десятков миллионов запросов в секунду или даже больше. Каждый отправленный вами запрос к контейнеру или базе данных Azure Cosmos, например запрос на чтение, на запись, на выполнение запроса или хранимые процедуры, связан с соответствующими затратами, которые вычитаются из подготовленной пропускной способности. Если подготовить 400 ЕЗ/с и создать запрос, который "стоит" 40 ЕЗ, вы сможете подавать 10 таких запросов в секунду. Любой запрос сверх этого количества будет ограничен по частоте, и вам придется его повторить. Если вы используете клиентские драйверы, они поддерживают логику автоматического повтора.

Вы можете подготовить пропускную способность в базах данных или контейнерах, и каждая из стратегий может помочь вам сократить затраты в зависимости от сценария.

## <a name="optimize-by-provisioning-throughput-at-different-levels"></a>Оптимизация путем подготовки пропускной способности на разных уровнях

* Если вы подготовите пропускную способность для базы данных, все содержащиеся в ней контейнеры, например коллекции, таблицы или графики, могут совместно использовать эту пропускную способность в зависимости от нагрузки. Пропускная способность, зарезервированная на уровне базы данных, распределяется неравномерно, в зависимости от рабочей нагрузки в определенном наборе контейнеров.

* Если вы подготовите пропускную способность для контейнера, пропускная способность будет гарантирована для этого контейнера в соответствии с соглашением об уровне обслуживания. Выбор ключа логической секции крайне важен для равномерного распределения нагрузки по всем логическим секциям контейнера. Подробные сведения см. в статьях о [секционировании](partitioning-overview.md) и [горизонтальном масштабировании](partition-data.md).

Ниже приведены некоторые рекомендации по выбору стратегии подготавливаемой пропускной способности.

**Рекомендуем подготовить пропускную способность для базы данных Azure Cosmos DB (содержащей набор контейнеров) в следующих случаях**:

1. У вас есть несколько десятков контейнеров Azure Cosmos и нужно совместно использовать пропускную способность для всех или некоторых из них. 

2. Вы выполняете переход с однотенантной базы данных, предназначенной для использования на виртуальных машинах, размещенных в IaaS или в локальной среде (например, NoSQL или реляционные базы данных), на базу данных Azure Cosmos DB. Также если у вас есть множество коллекций, таблиц, графиков и не требуется вносить изменения в модель данных. Обратите внимание на то, что часть преимуществ Azure Cosmos DB может быть потеряна, если при переходе с локальной базы данных не обновить модель данных. Рекомендуется всегда выполнять повторную оценку модели данных для получения максимальной производительности, а также для оптимизации затрат. 

3. Требуется выровнять незапланированные пики в рабочих нагрузках за счет объединения пропускной способности в пул на уровне базы данных, в которой возникают непредвиденные скачки рабочей нагрузки. 

4. Вместо настройки определенной пропускной способности для отдельных контейнеров вам нужно настроить общую пропускную способность в наборе контейнеров внутри базы данных.

**Рекомендуем подготовить пропускную способность для отдельного контейнера в следующих случаях:**

1. У вас есть небольшое количество контейнеров Azure Cosmos. Так как в Azure Cosmos DB не учитывается схема, контейнер может содержать элементы, которые имеют разнородные схемы, и не требует создания нескольких типов контейнеров, по одному для каждой сущности. Всегда можно решить, целесообразно ли сгруппировать, скажем, 10–20 отдельных контейнеров в единый контейнер. При минимуме 400 ЕЗ для контейнеров объединение всех 10–20 контейнеров в один может обеспечить экономию. 

2. Вам нужно контролировать пропускную способность в определенном контейнере и получить гарантированную пропускную способность для заданного контейнера в соответствии с соглашением об уровне обслуживания.

**Рекомендуем использовать гибридное сочетание двух стратегий в следующих случаях:**

1. Как упоминалось ранее, Azure Cosmos DB позволяет комбинировать две описанные выше стратегии. Поэтому для некоторых контейнеров в базе данных Azure Cosmos можно совместно использовать пропускную способность, выделенную для базы данных, а для других контейнеров в той же базе данных можно выделить определенные объемы подготовленной пропускной способности. 

2. Обе упомянутые стратегии можно сочетать в гибридной конфигурации, где будет как подготовленная пропускная способность на уровне базы данных, так и выделенная пропускная способность для некоторых контейнеров.

Как показано в следующей таблице, в зависимости от выбранного API можно подготовить пропускную способность с различными уровнями детализации.

|API|Для **общей** пропускной способности настройте следующее |Для **выделенной** пропускной способности настройте следующее |
|----|----|----|
|API-интерфейс SQL|База данных|Контейнер|
|API Azure Cosmos DB для MongoDB|База данных|Коллекция|
|API Cassandra|Пространство ключей|Таблица|
|API Gremlin|Учетная запись базы данных|График|
|API таблицы|Учетная запись базы данных|Таблица|

Подготовив пропускную способность на разных уровнях, можно оптимизировать затраты в зависимости от характеристик рабочей нагрузки. Как упоминалось ранее, программными средствами можно в любое время увеличить или уменьшить подготовленную пропускную способность либо для отдельных контейнеров, либо совокупно для набора контейнеров. Эластичное масштабирование пропускной способности по мере изменения рабочей нагрузки позволяет платить только за пропускную способность, которую вы настроили. Если контейнер или набор контейнеров распределены по нескольким регионам, то настроенная для этого контейнера или набора контейнеров пропускная способность будет гарантированно доступна по всем регионам.

## <a name="optimize-with-rate-limiting-your-requests"></a>Оптимизация с ограничением частоты запросов

Для рабочих нагрузок, не чувствительных к задержке, можно подготовить меньше пропускной способности и обрабатывать ограничение частоты запросов в приложении, когда фактическая пропускная способность превысит подготовленную. Сервер заранее завершит запрос с ошибкой RequestRateTooLarge (код состояния HTTP 429) и вернет в заголовке `x-ms-retry-after-ms` время (в миллисекундах), спустя которое пользователь сможет повторно выполнить этот запрос. 

```html
HTTP Status 429, 
 Status Line: RequestRateTooLarge 
 x-ms-retry-after-ms :100
```

### <a name="retry-logic-in-sdks"></a>Логика повтора в пакетах SDK 

Собственные пакеты SDK (.NET/.NET Core, Java, Node.js и Python) неявно перехватывают этот ответ, учитывают указанный сервером заголовок retry-after и повторяют попытку запроса. Если к вашей учетной записи получает доступ только один клиент, следующая попытка будет успешной.

Если сразу несколько клиентов регулярно выполняют запросы с частотой выше заданной, количество повторных попыток по умолчанию, которое сейчас равно 9, может быть недостаточным. В этом случае клиент создает в приложении исключение `DocumentClientException` с кодом состояния 429. Число повторных попыток по умолчанию можно изменить, задав свойство `RetryOptions` в экземпляре ConnectionPolicy. По умолчанию в случае превышения заданного счетчика повторов исключение DocumentClientException с кодом состояния 429 возвращается через 30 секунд (совокупное время ожидания). Это происходит, даже если текущее значение количества повторных попыток (по умолчанию (9) или определенное пользователем) меньше максимального значения. 

Для [MaxRetryAttemptsOnThrottledRequests](https://docs.microsoft.com/dotnet/api/microsoft.azure.documents.client.retryoptions.maxretryattemptsonthrottledrequests?view=azure-dotnet#Microsoft_Azure_Documents_Client_RetryOptions_MaxRetryAtte)  задано значение 3. Таким образом, если операции запроса ограничены по частоте зарезервированной пропускной способностью для коллекции, будут выполнены три повторные попытки операции запроса, прежде чем в приложении будет создано исключение. Для  [MaxRetryWaitTimeInSeconds](https://docs.microsoft.com/dotnet/api/microsoft.azure.documents.client.retryoptions.maxretrywaittimeinseconds?view=azure-dotnet#Microsoft_Azure_Documents_Client_RetryOptions_MaxRetryWaitTimeInSeconds)  задано значение 60. В этом случае, если совокупное время ожидания повторных попыток с момента первого запроса превысит 60 секунд, будет выдано исключение.

```csharp
ConnectionPolicy connectionPolicy = new ConnectionPolicy(); 

connectionPolicy.RetryOptions.MaxRetryAttemptsOnThrottledRequests = 3; 

connectionPolicy.RetryOptions.MaxRetryWaitTimeInSeconds = 60;
```

## <a name="partitioning-strategy-and-provisioned-throughput-costs"></a>Стратегия секционирования и затраты на подготовленную пропускную способность

Для оптимизации затрат в Azure Cosmos DB важна правильная стратегия секционирования. Убедитесь в отсутствии отклонений в секциях, которые предоставляются с использованием метрик хранилища. Убедитесь в отсутствии отклонений в пропускной способности для секции, которая предоставляется с использованием метрик пропускной способности. Убедитесь в отсутствии отклонений в направлении отдельных ключей секций. Главные ключи в хранилище предоставляются с использованием метрик, но ключ будет зависеть от схемы доступа к приложению. Оптимальный путь — правильно выбрать ключ логической секции. Правильный ключ секции должен соответствовать следующим характеристикам:

* Выберите ключ секции, который равномерно распределяет рабочую нагрузку по всем секциям и по времени. Иными словами, не должно быть ключей, которым соответствует большая часть данных, и ключей без данных или с небольшим количеством данных. 

* Выберите ключ секции, который позволяет равномерно распределять схемы доступа по логическим секциям. Рабочая нагрузка равномерно распределяется по всем ключам. Иными словами, большая часть рабочей нагрузки не должна быть сконцентрирована на нескольких конкретных ключах. 

* Выберите ключ секции, который имеет широкий диапазон значений. 

Основная идея заключается в распределении данных и действий в контейнере по набору логических секций, чтобы обеспечить возможность распределения ресурсов для хранилища данных и пропускной способности по логическим секциям. Кандидаты для ключей секций могут включать свойства, которые часто встречаются в качестве фильтра в запросах. Запросы можно эффективно перенаправлять путем включения ключа секции в предикат фильтра. С такой стратегией секционирования оптимизировать подготовленную пропускную способности будет гораздо легче. 

### <a name="design-smaller-items-for-higher-throughput"></a>Проектирование элементов меньшего размера для повышения пропускной способности 

Стоимость запроса или плата за обработку запроса для каждой операции напрямую зависит от размера элемента. Операции с крупными элементами будут стоить больше, чем операции с элементами меньшего размера. 

## <a name="data-access-patterns"></a>Схемы доступа к данным 

Всегда рекомендуется разделять данные на логические категории в зависимости от частоты доступа к данным. Разделение на категории "горячих", средних и "холодных" данных позволяет точно настроить используемый объем хранилища и необходимую пропускную способность. В зависимости от частоты доступа можно поместить данные в отдельные контейнеры (например, таблицы, графики и коллекции) и точно настроить подготавливаемую для них пропускную способность в соответствии с потребностями того или иного сегмента данных. 

Кроме того, если вы используете Azure Cosmos DB и знаете, что не будете выполнять поиск по определенным значениям данных или будете редко к ним обращаться, значения таких атрибутов следует хранить в сжатом виде. С помощью этого метода вы сэкономите место в хранилище и в индексе, и подготовленная пропускная способность приведет к меньшим затратам.

## <a name="optimize-by-changing-indexing-policy"></a>Оптимизация путем изменения политики индексирования 

По умолчанию Azure Cosmos DB автоматически индексирует все свойства каждой записи. Это делается для упрощения разработки и обеспечения высокой производительности для множества различных типов ad-hoc-запросов. При наличии крупных записей с тысячами свойств платить за пропускную способность для индексирования каждого свойства может быть нерационально, особенно если запросы выполняются только к 10 или 20 из этих свойств. Когда вы научитесь лучше управлять конкретной рабочей нагрузкой, рекомендуем настроить политику индексирования. Подробные сведения о политике индексирования в Azure Cosmos DB см. в [этой статье](indexing-policies.md). 

## <a name="monitoring-provisioned-and-consumed-throughput"></a>Мониторинг подготовленной и использованной пропускной способности 

На портале Azure можно отслеживать общее количество подготовленных единиц запроса, количество ограниченных по частоте запросов, а также количество использованных ЕЗ. На следующем изображении показан пример метрики использования:

![Мониторинг единиц запроса на портале Azure](./media/optimize-cost-throughput/monitoring.png)

Можно также настроить оповещения, чтобы проверить, превышает ли количество запросов с ограничением по частоте определенное пороговое значение. Дополнительные сведения см. в статье [Мониторинг и отладка с помощью метрик в Azure Cosmos DB](use-metrics.md). Эти оповещения могут отправлять сообщение электронной почты администраторам учетных записей или вызывать настраиваемый веб-перехватчик HTTP либо функцию Azure для автоматического увеличения подготовленной пропускной способности. 

## <a name="scale-your-throughput-elastically-and-on-demand"></a>Эластичное масштабирование пропускной способности и масштабирование по запросу 

Так как плата взимается за подготовленную пропускную способность, сопоставление подготовленной пропускной способности с вашими потребностями поможет вам избежать расходов на неиспользуемую пропускную способность. Масштаб подготовленной пропускной способности можно при необходимости увеличивать или уменьшать в любое время.  

* Благодаря мониторингу потребления ЕЗ и доли запросов с ограниченной частотой может выясниться, что вам не обязательно поддерживать постоянную подготовленную пропускную способность в течение всего дня или недели. Ночью или в выходные дни вы можете получать меньше трафика. С помощью портала Azure или собственных пакетов SDK либо REST API для Azure Cosmos DB можно в любое время масштабировать подготовленную пропускную способность. REST API для Azure Cosmos DB предоставляет конечные точки для программного изменения уровня производительности контейнеров, что упрощает регулирование пропускной способности из кода в зависимости от времени дня или дня недели. Операция выполняется без простоев и обычно вступает в силу в менее чем за минуту. 

* Одной из областей, где следует масштабировать пропускную способность, является прием данных в Azure Cosmos DB, например во время миграции данных. После завершения миграции можно уменьшить подготовленную пропускную способность для работы решения в стабильном состоянии.  

* Помните, что счета выставляются с почасовой детализацией, поэтому вы ничего не сэкономите, если будете изменять подготовленную пропускную способность чаще, чем один раз в час.

## <a name="determine-the-throughput-needed-for-a-new-workload"></a>Определение пропускной способности, необходимой для новой рабочей нагрузки 

Чтобы определить подготовленную пропускную способность для новой рабочей нагрузки, можно сделать следующее: 

1. Выполните первоначальную грубую оценку с помощью планировщика ресурсов и откорректируйте результаты оценки с помощью Обозревателя Azure Cosmos на портале Azure. 

2. Рекомендуем создавать контейнеры с более высокой пропускной способностью, чем ожидаемая, и уменьшать масштаб при необходимости. 

3. Рекомендуем использовать один из собственных пакетов SDK для Azure Cosmos DB, чтобы использовать преимущество автоматических повторов при ограничении частоты запросов. Если вы работаете на платформе, которая не поддерживается, и используете REST API для Cosmos DB, реализуйте собственную политику повтора с помощью заголовка `x-ms-retry-after-ms`. 

4. Убедитесь, что код вашего приложения корректно поддерживает ситуацию, когда все повторы завершаются неудачно. 

5. Можно настроить оповещения на портале Azure, чтобы получать уведомления об ограничении частоты. Начать можно с умеренных ограничений, например с 10 запросов с ограниченной частотой за последние 15 минут, а после выяснения фактического потребления ресурсов — переключиться на более строгие правила. Редкие нерегулярные ограничения частоты — это нормально, они показывают, что вы оперируете как раз в заданных пределах и это именно то, что вам требуется. 

6. Определите структуру трафика с помощью мониторинга, чтобы оценить потребность в динамической корректировке подготовленной пропускной способности в течение дня или недели. 

7. Регулярно отслеживайте подготовленную и потребляемую пропускную способность, чтобы убедиться в отсутствии лишних подготовленных ресурсов сверх необходимого количества контейнеров и баз данных. Подготовка пропускной способности с небольшим избытком — хорошая мера предосторожности.  

### <a name="best-practices-to-optimize-provisioned-throughput"></a>Рекомендации по оптимизации подготовленной пропускной способности 

Следующие действия помогут повысить масштабируемость и экономичность ваших решений при использовании Azure Cosmos DB.  

1. Если вы подготовили чрезмерный объем пропускной способности для всех контейнеров и баз данных, следует проанализировать количество подготовленных ЕЗ в сравнении с потребленными ЕЗ и точнее настроить рабочие нагрузки.  

2. Один из методов оценки необходимой для приложения зарезервированной пропускной способности — записать стоимость единиц запроса на выполнение стандартных операций над репрезентативным контейнером или базой данных Azure Cosmos, которые используются в приложении, а затем оценить предполагаемое количество операций в секунду. Не забудьте измерить и включить в расчет стандартные запросы и их потребление. Чтобы узнать, как оценить стоимость ЕЗ на выполнение запросов программным способом или с помощью портала, см. статью об [оптимизации затрат на запросы](online-backup-and-restore.md). 

3. Другой способ проанализировать операции и их стоимость в ЕЗ — включить Log Analytics, что позволит получить разбивку по операциям и их длительности и плате за запросы. В Azure Cosmos DB плата за запросы начисляется для каждой операции, поэтому сведения о плате за каждую операцию можно сохранить из ответа и затем использовать для анализа. 

4. Можно гибко масштабировать подготовленную пропускную способность в обе стороны по мере изменения потребностей рабочей нагрузки. 

5. Можно добавлять и удалять регионы, связанные с учетной записью Azure Cosmos, по мере необходимости и контролировать затраты. 

6. Убедитесь, что данные и рабочие нагрузки равномерно распределяются между логическими секциями контейнеров. Если секции распределены неравномерно, это может привести к подготовке более высокого объема пропускной способности, чем необходимо. Если обнаружится, что распределение неравномерно, рекомендуем перераспределить рабочую нагрузку равномерно между секциями или повторно секционировать данные. 

7. При наличии множества контейнеров, для которых не требуется соглашение об уровне обслуживания, можно использовать предложение на основе базы данных для случаев, когда соглашения об уровне обслуживания для пропускной способности каждого контейнера не применяются. Следует определить, какие из контейнеров Azure Cosmos, которые нужно перенести в базу данных, выравнивают предложение пропускной способности, а затем перенести их с помощью решения на базе веб-канала изменений. 

8. Рассмотрите возможность использования таких предложений, как бесплатный уровень Cosmos DB (бесплатно в течение одного года), пробная версия Cosmos DB (до трех регионов) или загружаемый эмулятор Cosmos DB для сценариев разработки или тестирования. Используя эти возможности для тестирования и разработки, можно существенно снизить затраты.  

9. Далее можно оптимизировать затраты для конкретных рабочих нагрузок — например, увеличить размер пакетов, распределить нагрузку операций чтения по нескольким регионам и провести дедупликацию данных (если это применимо).

10. Благодаря зарезервированной емкости Azure Cosmos DB можно получить значительные скидки (до 65 %) на три года. Модель зарезервированной емкости Azure Cosmos DB предусматривает авансовую оплату за единицы запроса, которые потребуются со временем. Скидки распределяются по уровням таким образом, что чем больше единиц запроса используется за продолжительный период времени, тем больше скидка. Эти скидки вступают в силу немедленно. За любые потребленные ЕЗ сверх подготовленных значений плата взимается на основе тарифов на незарезервированную емкость. Подробные сведения см. в статье [Предоплата ресурсов Azure Cosmos DB с резервной мощностью](cosmos-db-reserved-capacity.md). Рекомендуем приобрести зарезервированную емкость для дополнительного уменьшения затрат на подготовленную пропускную способность.  

## <a name="next-steps"></a>Дополнительная информация

Теперь вы можете перейти к подробным сведениям об оптимизации затрат в Azure Cosmos DB, которые представлены в следующих статьях.

* Дополнительные сведения [об оптимизации для разработки и тестирования](optimize-dev-test.md).
* Дополнительные сведения о [расшифровке счета за использование Azure Cosmos DB](understand-your-bill.md).
* Дополнительные сведения об [оптимизации затрат на хранилище](optimize-cost-storage.md).
* Дополнительные сведения об [оптимизации затрат на операции чтения и записи](optimize-cost-reads-writes.md).
* Дополнительные сведения об [оптимизации затрат на запросы](optimize-cost-queries.md).
* Дополнительные сведения об [оптимизации затрат на учетные записи Azure Cosmos с поддержкой нескольких регионов](optimize-cost-regions.md).

